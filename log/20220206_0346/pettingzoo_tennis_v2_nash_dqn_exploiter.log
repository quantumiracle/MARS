pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
tennis_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 5, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'exploiter_update_itr': 3}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220206_0346/pettingzoo_tennis_v2_nash_dqn_exploiter. 
 Save logs to: /home/zihan/research/MARS/data/log/20220206_0346/pettingzoo_tennis_v2_nash_dqn_exploiter.
Episode: 1/10000 (0.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 98.1782s / 98.1782 s
env0_first_0:                 episode reward: 30.0000,                 loss: 0.0901
env0_second_0:                 episode reward: -30.0000,                 loss: 0.0902
env1_first_0:                 episode reward: 26.0000,                 loss: nan
env1_second_0:                 episode reward: -26.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 4829.5,                last time consumption/overall running time: 1301.5507s / 1399.7289 s
env0_first_0:                 episode reward: 7.5000,                 loss: 0.0718
env0_second_0:                 episode reward: -7.5000,                 loss: 0.0721
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 2129.4,                last time consumption/overall running time: 643.7821s / 2043.5110 s
env0_first_0:                 episode reward: -13.9500,                 loss: 0.0493
env0_second_0:                 episode reward: 13.9500,                 loss: 0.0577
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 1844.5,                last time consumption/overall running time: 559.7854s / 2603.2964 s
env0_first_0:                 episode reward: -15.8500,                 loss: 0.0609
env0_second_0:                 episode reward: 15.8500,                 loss: 0.0655
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 1796.3,                last time consumption/overall running time: 547.1117s / 3150.4081 s
env0_first_0:                 episode reward: -20.7500,                 loss: 0.0605
env0_second_0:                 episode reward: 20.7500,                 loss: 0.0546
env1_first_0:                 episode reward: -19.9000,                 loss: nan
env1_second_0:                 episode reward: 19.9000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 1619.05,                last time consumption/overall running time: 496.5141s / 3646.9222 s
env0_first_0:                 episode reward: -23.4500,                 loss: 0.0626
env0_second_0:                 episode reward: 23.4500,                 loss: 0.0529
env1_first_0:                 episode reward: -22.6500,                 loss: nan
env1_second_0:                 episode reward: 22.6500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 1633.45,                last time consumption/overall running time: 497.9251s / 4144.8473 s
env0_first_0:                 episode reward: -22.8000,                 loss: 0.0556
env0_second_0:                 episode reward: 22.8000,                 loss: 0.0522
env1_first_0:                 episode reward: -23.3500,                 loss: nan
env1_second_0:                 episode reward: 23.3500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 1619.2,                last time consumption/overall running time: 499.2109s / 4644.0582 s
env0_first_0:                 episode reward: -22.6500,                 loss: 0.0474
env0_second_0:                 episode reward: 22.6500,                 loss: 0.0470
env1_first_0:                 episode reward: -23.3000,                 loss: nan
env1_second_0:                 episode reward: 23.3000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 1558.1,                last time consumption/overall running time: 473.5689s / 5117.6271 s
env0_first_0:                 episode reward: -23.0000,                 loss: 0.0414
env0_second_0:                 episode reward: 23.0000,                 loss: 0.0405
env1_first_0:                 episode reward: -24.3000,                 loss: nan
env1_second_0:                 episode reward: 24.3000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 1531.0,                last time consumption/overall running time: 473.5944s / 5591.2215 s
env0_first_0:                 episode reward: -22.7000,                 loss: 0.0356
env0_second_0:                 episode reward: 22.7000,                 loss: 0.0369
env1_first_0:                 episode reward: -24.0500,                 loss: nan
env1_second_0:                 episode reward: 24.0500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 1553.8,                last time consumption/overall running time: 477.4330s / 6068.6545 s
env0_first_0:                 episode reward: -22.1500,                 loss: 0.0318
env0_second_0:                 episode reward: 22.1500,                 loss: 0.0350
env1_first_0:                 episode reward: -22.3500,                 loss: nan
env1_second_0:                 episode reward: 22.3500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 1599.75,                last time consumption/overall running time: 485.3059s / 6553.9604 s
env0_first_0:                 episode reward: -23.2000,                 loss: 0.0306
env0_second_0:                 episode reward: 23.2000,                 loss: 0.0294
env1_first_0:                 episode reward: -24.2000,                 loss: nan
env1_second_0:                 episode reward: 24.2000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 1618.0,                last time consumption/overall running time: 496.0702s / 7050.0306 s
env0_first_0:                 episode reward: -23.2500,                 loss: 0.0322
env0_second_0:                 episode reward: 23.2500,                 loss: 0.0304
env1_first_0:                 episode reward: -23.5500,                 loss: nan
env1_second_0:                 episode reward: 23.5500,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 1585.0,                last time consumption/overall running time: 480.7409s / 7530.7715 s
env0_first_0:                 episode reward: -24.6500,                 loss: 0.0344
env0_second_0:                 episode reward: 24.6500,                 loss: 0.0369
env1_first_0:                 episode reward: -21.5000,                 loss: nan
env1_second_0:                 episode reward: 21.5000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 1612.95,                last time consumption/overall running time: 495.2500s / 8026.0215 s
env0_first_0:                 episode reward: -25.7500,                 loss: 0.0373
env0_second_0:                 episode reward: 25.7500,                 loss: 0.0385
env1_first_0:                 episode reward: -22.6500,                 loss: nan
env1_second_0:                 episode reward: 22.6500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 1600.8,                last time consumption/overall running time: 491.0544s / 8517.0759 s
env0_first_0:                 episode reward: -25.8500,                 loss: 0.0354
env0_second_0:                 episode reward: 25.8500,                 loss: 0.0345
env1_first_0:                 episode reward: -25.5000,                 loss: nan
env1_second_0:                 episode reward: 25.5000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 1584.7,                last time consumption/overall running time: 489.8389s / 9006.9149 s
env0_first_0:                 episode reward: -26.1000,                 loss: 0.0331
env0_second_0:                 episode reward: 26.1000,                 loss: 0.0347
env1_first_0:                 episode reward: -25.5000,                 loss: nan
env1_second_0:                 episode reward: 25.5000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 1521.0,                last time consumption/overall running time: 469.0262s / 9475.9411 s
env0_first_0:                 episode reward: -25.9000,                 loss: 0.0290
env0_second_0:                 episode reward: 25.9000,                 loss: 0.0305
env1_first_0:                 episode reward: -25.1500,                 loss: nan
env1_second_0:                 episode reward: 25.1500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 1554.85,                last time consumption/overall running time: 478.5324s / 9954.4735 s
env0_first_0:                 episode reward: -25.6500,                 loss: 0.0280
env0_second_0:                 episode reward: 25.6500,                 loss: 0.0284
env1_first_0:                 episode reward: -27.4000,                 loss: nan
env1_second_0:                 episode reward: 27.4000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 1516.6,                last time consumption/overall running time: 467.5285s / 10422.0019 s
env0_first_0:                 episode reward: -25.8000,                 loss: 0.0276
env0_second_0:                 episode reward: 25.8000,                 loss: 0.0266
env1_first_0:                 episode reward: -26.0000,                 loss: nan
env1_second_0:                 episode reward: 26.0000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 1547.8,                last time consumption/overall running time: 475.7519s / 10897.7539 s
env0_first_0:                 episode reward: -25.7500,                 loss: 0.0280
env0_second_0:                 episode reward: 25.7500,                 loss: 0.0267
env1_first_0:                 episode reward: -26.6000,                 loss: nan
env1_second_0:                 episode reward: 26.6000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 1527.0,                last time consumption/overall running time: 469.0388s / 11366.7927 s
env0_first_0:                 episode reward: -26.8000,                 loss: 0.0265
env0_second_0:                 episode reward: 26.8000,                 loss: 0.0283
env1_first_0:                 episode reward: -26.6500,                 loss: nan
env1_second_0:                 episode reward: 26.6500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 1787.8,                last time consumption/overall running time: 547.0617s / 11913.8544 s
env0_first_0:                 episode reward: -19.6000,                 loss: 0.0289
env0_second_0:                 episode reward: 19.6000,                 loss: 0.0302
env1_first_0:                 episode reward: -19.9000,                 loss: nan
env1_second_0:                 episode reward: 19.9000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 1508.8,                last time consumption/overall running time: 467.3357s / 12381.1901 s
env0_first_0:                 episode reward: -27.7000,                 loss: 0.0297
env0_second_0:                 episode reward: 27.7000,                 loss: 0.0334
env1_first_0:                 episode reward: -26.1500,                 loss: nan
env1_second_0:                 episode reward: 26.1500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 1520.9,                last time consumption/overall running time: 468.3241s / 12849.5141 s
env0_first_0:                 episode reward: -27.4500,                 loss: 0.0287
env0_second_0:                 episode reward: 27.4500,                 loss: 0.0310
env1_first_0:                 episode reward: -28.4000,                 loss: nan
env1_second_0:                 episode reward: 28.4000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 1518.15,                last time consumption/overall running time: 463.0390s / 13312.5531 s
env0_first_0:                 episode reward: -27.9000,                 loss: 0.0266
env0_second_0:                 episode reward: 27.9000,                 loss: 0.0300
env1_first_0:                 episode reward: -27.9500,                 loss: nan
env1_second_0:                 episode reward: 27.9500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 1511.5,                last time consumption/overall running time: 454.1014s / 13766.6545 s
env0_first_0:                 episode reward: -28.6500,                 loss: 0.0260
env0_second_0:                 episode reward: 28.6500,                 loss: 0.0277
env1_first_0:                 episode reward: -28.5000,                 loss: nan
env1_second_0:                 episode reward: 28.5000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 1544.9,                last time consumption/overall running time: 475.8250s / 14242.4795 s
env0_first_0:                 episode reward: -29.3000,                 loss: 0.0274
env0_second_0:                 episode reward: 29.3000,                 loss: 0.0286
env1_first_0:                 episode reward: -28.2000,                 loss: nan
env1_second_0:                 episode reward: 28.2000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 1528.5,                last time consumption/overall running time: 467.9656s / 14710.4451 s
env0_first_0:                 episode reward: -28.8500,                 loss: 0.0252
env0_second_0:                 episode reward: 28.8500,                 loss: 0.0278
env1_first_0:                 episode reward: -29.8000,                 loss: nan
env1_second_0:                 episode reward: 29.8000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 1547.7,                last time consumption/overall running time: 478.5938s / 15189.0389 s
env0_first_0:                 episode reward: -28.9000,                 loss: 0.0265
env0_second_0:                 episode reward: 28.9000,                 loss: 0.0273
env1_first_0:                 episode reward: -27.4000,                 loss: nan
env1_second_0:                 episode reward: 27.4000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 1524.75,                last time consumption/overall running time: 471.9986s / 15661.0375 s
env0_first_0:                 episode reward: -27.2000,                 loss: 0.0280
env0_second_0:                 episode reward: 27.2000,                 loss: 0.0291
env1_first_0:                 episode reward: -27.4000,                 loss: nan
env1_second_0:                 episode reward: 27.4000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 1528.1,                last time consumption/overall running time: 465.7388s / 16126.7763 s
env0_first_0:                 episode reward: -28.0000,                 loss: 0.0278
env0_second_0:                 episode reward: 28.0000,                 loss: 0.0306
env1_first_0:                 episode reward: -29.2000,                 loss: nan
env1_second_0:                 episode reward: 29.2000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 1576.3,                last time consumption/overall running time: 484.0332s / 16610.8095 s
env0_first_0:                 episode reward: -28.2000,                 loss: 0.0282
env0_second_0:                 episode reward: 28.2000,                 loss: 0.0317
env1_first_0:                 episode reward: -27.7500,                 loss: nan
env1_second_0:                 episode reward: 27.7500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 1499.3,                last time consumption/overall running time: 465.2180s / 17076.0275 s
env0_first_0:                 episode reward: -30.1000,                 loss: 0.0276
env0_second_0:                 episode reward: 30.1000,                 loss: 0.0297
env1_first_0:                 episode reward: -28.5000,                 loss: nan
env1_second_0:                 episode reward: 28.5000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 1565.35,                last time consumption/overall running time: 482.5830s / 17558.6105 s
env0_first_0:                 episode reward: -27.6500,                 loss: 0.0258
env0_second_0:                 episode reward: 27.6500,                 loss: 0.0278
env1_first_0:                 episode reward: -28.7000,                 loss: nan
env1_second_0:                 episode reward: 28.7000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 1528.45,                last time consumption/overall running time: 470.2071s / 18028.8176 s
env0_first_0:                 episode reward: -28.8500,                 loss: 0.0254
env0_second_0:                 episode reward: 28.8500,                 loss: 0.0272
env1_first_0:                 episode reward: -27.8500,                 loss: nan
env1_second_0:                 episode reward: 27.8500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 1554.75,                last time consumption/overall running time: 473.4749s / 18502.2925 s
env0_first_0:                 episode reward: -27.9500,                 loss: 0.0277
env0_second_0:                 episode reward: 27.9500,                 loss: 0.0267
env1_first_0:                 episode reward: -28.5000,                 loss: nan
env1_second_0:                 episode reward: 28.5000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 1530.2,                last time consumption/overall running time: 471.3000s / 18973.5925 s
env0_first_0:                 episode reward: -27.2500,                 loss: 0.0264
env0_second_0:                 episode reward: 27.2500,                 loss: 0.0276
env1_first_0:                 episode reward: -28.2000,                 loss: nan
env1_second_0:                 episode reward: 28.2000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 1623.15,                last time consumption/overall running time: 492.7554s / 19466.3479 s
env0_first_0:                 episode reward: -27.0000,                 loss: 0.0277
env0_second_0:                 episode reward: 27.0000,                 loss: 0.0283
env1_first_0:                 episode reward: -28.2000,                 loss: nan
env1_second_0:                 episode reward: 28.2000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 1522.85,                last time consumption/overall running time: 467.6532s / 19934.0010 s
env0_first_0:                 episode reward: -27.3500,                 loss: 0.0309
env0_second_0:                 episode reward: 27.3500,                 loss: 0.0286
env1_first_0:                 episode reward: -27.0000,                 loss: nan
env1_second_0:                 episode reward: 27.0000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 1540.4,                last time consumption/overall running time: 470.5505s / 20404.5515 s
env0_first_0:                 episode reward: -28.7000,                 loss: 0.0290
env0_second_0:                 episode reward: 28.7000,                 loss: 0.0293
env1_first_0:                 episode reward: -29.2500,                 loss: nan
env1_second_0:                 episode reward: 29.2500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 1554.15,                last time consumption/overall running time: 474.7024s / 20879.2539 s
env0_first_0:                 episode reward: -27.2500,                 loss: 0.0280
env0_second_0:                 episode reward: 27.2500,                 loss: 0.0278
env1_first_0:                 episode reward: -28.7500,                 loss: nan
env1_second_0:                 episode reward: 28.7500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 1530.8,                last time consumption/overall running time: 466.1302s / 21345.3841 s
env0_first_0:                 episode reward: -29.1000,                 loss: 0.0282
env0_second_0:                 episode reward: 29.1000,                 loss: 0.0266
env1_first_0:                 episode reward: -27.7500,                 loss: nan
env1_second_0:                 episode reward: 27.7500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 1581.55,                last time consumption/overall running time: 481.6374s / 21827.0215 s
env0_first_0:                 episode reward: -28.3500,                 loss: 0.0279
env0_second_0:                 episode reward: 28.3500,                 loss: 0.0278
env1_first_0:                 episode reward: -29.4500,                 loss: nan
env1_second_0:                 episode reward: 29.4500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 1532.4,                last time consumption/overall running time: 466.1575s / 22293.1790 s
env0_first_0:                 episode reward: -27.7500,                 loss: 0.0277
env0_second_0:                 episode reward: 27.7500,                 loss: 0.0272
env1_first_0:                 episode reward: -27.1000,                 loss: nan
env1_second_0:                 episode reward: 27.1000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 1543.55,                last time consumption/overall running time: 478.2645s / 22771.4435 s
env0_first_0:                 episode reward: -26.3000,                 loss: 0.0265
env0_second_0:                 episode reward: 26.3000,                 loss: 0.0282
env1_first_0:                 episode reward: -27.4500,                 loss: nan
env1_second_0:                 episode reward: 27.4500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 1502.55,                last time consumption/overall running time: 464.6270s / 23236.0705 s
env0_first_0:                 episode reward: -26.4000,                 loss: 0.0247
env0_second_0:                 episode reward: 26.4000,                 loss: 0.0251
env1_first_0:                 episode reward: -28.4500,                 loss: nan
env1_second_0:                 episode reward: 28.4500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 1506.4,                last time consumption/overall running time: 465.8518s / 23701.9223 s
env0_first_0:                 episode reward: -28.2000,                 loss: 0.0249
env0_second_0:                 episode reward: 28.2000,                 loss: 0.0245
env1_first_0:                 episode reward: -28.7500,                 loss: nan
env1_second_0:                 episode reward: 28.7500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 1500.5,                last time consumption/overall running time: 459.3488s / 24161.2711 s
env0_first_0:                 episode reward: -28.2500,                 loss: 0.0250
env0_second_0:                 episode reward: 28.2500,                 loss: 0.0248
env1_first_0:                 episode reward: -28.8000,                 loss: nan
env1_second_0:                 episode reward: 28.8000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 1517.2,                last time consumption/overall running time: 465.4866s / 24626.7577 s
env0_first_0:                 episode reward: -27.9000,                 loss: 0.0247
env0_second_0:                 episode reward: 27.9000,                 loss: 0.0236
env1_first_0:                 episode reward: -28.3000,                 loss: nan
env1_second_0:                 episode reward: 28.3000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 1550.05,                last time consumption/overall running time: 477.6693s / 25104.4270 s
env0_first_0:                 episode reward: -28.1500,                 loss: 0.0256
env0_second_0:                 episode reward: 28.1500,                 loss: 0.0247
env1_first_0:                 episode reward: -28.9000,                 loss: nan
env1_second_0:                 episode reward: 28.9000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 1525.55,                last time consumption/overall running time: 466.7969s / 25571.2239 s
env0_first_0:                 episode reward: -28.4000,                 loss: 0.0245
env0_second_0:                 episode reward: 28.4000,                 loss: 0.0247
env1_first_0:                 episode reward: -28.2500,                 loss: nan
env1_second_0:                 episode reward: 28.2500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 1539.35,                last time consumption/overall running time: 468.7280s / 26039.9520 s
env0_first_0:                 episode reward: -28.4000,                 loss: 0.0248
env0_second_0:                 episode reward: 28.4000,                 loss: 0.0232
env1_first_0:                 episode reward: -29.2000,                 loss: nan
env1_second_0:                 episode reward: 29.2000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 1511.25,                last time consumption/overall running time: 461.4915s / 26501.4435 s
env0_first_0:                 episode reward: -28.0000,                 loss: 0.0239
env0_second_0:                 episode reward: 28.0000,                 loss: 0.0239
env1_first_0:                 episode reward: -27.3500,                 loss: nan
env1_second_0:                 episode reward: 27.3500,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 1528.85,                last time consumption/overall running time: 473.8872s / 26975.3307 s
env0_first_0:                 episode reward: -28.1000,                 loss: 0.0245
env0_second_0:                 episode reward: 28.1000,                 loss: 0.0257
env1_first_0:                 episode reward: -26.3500,                 loss: nan
env1_second_0:                 episode reward: 26.3500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 1540.7,                last time consumption/overall running time: 473.6996s / 27449.0303 s
env0_first_0:                 episode reward: -27.0000,                 loss: 0.0243
env0_second_0:                 episode reward: 27.0000,                 loss: 0.0254
env1_first_0:                 episode reward: -27.2000,                 loss: nan
env1_second_0:                 episode reward: 27.2000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 1528.05,                last time consumption/overall running time: 463.8289s / 27912.8593 s
env0_first_0:                 episode reward: -27.3000,                 loss: 0.0267
env0_second_0:                 episode reward: 27.3000,                 loss: 0.0269
env1_first_0:                 episode reward: -27.9000,                 loss: nan
env1_second_0:                 episode reward: 27.9000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 1525.3,                last time consumption/overall running time: 472.6299s / 28385.4892 s
env0_first_0:                 episode reward: -26.2500,                 loss: 0.0252
env0_second_0:                 episode reward: 26.2500,                 loss: 0.0250
env1_first_0:                 episode reward: -27.4000,                 loss: nan
env1_second_0:                 episode reward: 27.4000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 1586.4,                last time consumption/overall running time: 486.7960s / 28872.2851 s
env0_first_0:                 episode reward: -27.8000,                 loss: 0.0255
env0_second_0:                 episode reward: 27.8000,                 loss: 0.0251
env1_first_0:                 episode reward: -27.7000,                 loss: nan
env1_second_0:                 episode reward: 27.7000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 1547.1,                last time consumption/overall running time: 480.6156s / 29352.9007 s
env0_first_0:                 episode reward: -25.7500,                 loss: 0.0272
env0_second_0:                 episode reward: 25.7500,                 loss: 0.0260
env1_first_0:                 episode reward: -26.5000,                 loss: nan
env1_second_0:                 episode reward: 26.5000,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 1513.75,                last time consumption/overall running time: 473.1046s / 29826.0053 s
env0_first_0:                 episode reward: -26.7000,                 loss: 0.0253
env0_second_0:                 episode reward: 26.7000,                 loss: 0.0246
env1_first_0:                 episode reward: -26.6000,                 loss: nan
env1_second_0:                 episode reward: 26.6000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 1534.0,                last time consumption/overall running time: 479.8563s / 30305.8616 s
env0_first_0:                 episode reward: -26.0500,                 loss: 0.0237
env0_second_0:                 episode reward: 26.0500,                 loss: 0.0235
env1_first_0:                 episode reward: -25.6500,                 loss: nan
env1_second_0:                 episode reward: 25.6500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 1520.7,                last time consumption/overall running time: 460.3833s / 30766.2449 s
env0_first_0:                 episode reward: -26.6500,                 loss: 0.0232
env0_second_0:                 episode reward: 26.6500,                 loss: 0.0236
env1_first_0:                 episode reward: -25.2500,                 loss: nan
env1_second_0:                 episode reward: 25.2500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 1509.45,                last time consumption/overall running time: 465.4585s / 31231.7034 s
env0_first_0:                 episode reward: -25.7500,                 loss: 0.0247
env0_second_0:                 episode reward: 25.7500,                 loss: 0.0234
env1_first_0:                 episode reward: -26.5500,                 loss: nan
env1_second_0:                 episode reward: 26.5500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 1549.75,                last time consumption/overall running time: 475.2334s / 31706.9368 s
env0_first_0:                 episode reward: -27.5000,                 loss: 0.0244
env0_second_0:                 episode reward: 27.5000,                 loss: 0.0262
env1_first_0:                 episode reward: -26.9500,                 loss: nan
env1_second_0:                 episode reward: 26.9500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 1541.85,                last time consumption/overall running time: 476.3605s / 32183.2973 s
env0_first_0:                 episode reward: -26.8500,                 loss: 0.0234
env0_second_0:                 episode reward: 26.8500,                 loss: 0.0250
env1_first_0:                 episode reward: -26.9000,                 loss: nan
env1_second_0:                 episode reward: 26.9000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 1511.3,                last time consumption/overall running time: 456.3395s / 32639.6367 s
env0_first_0:                 episode reward: -27.7000,                 loss: 0.0242
env0_second_0:                 episode reward: 27.7000,                 loss: 0.0237
env1_first_0:                 episode reward: -26.6500,                 loss: nan
env1_second_0:                 episode reward: 26.6500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 1523.15,                last time consumption/overall running time: 468.4391s / 33108.0758 s
env0_first_0:                 episode reward: -26.0000,                 loss: 0.0236
env0_second_0:                 episode reward: 26.0000,                 loss: 0.0235
env1_first_0:                 episode reward: -27.0500,                 loss: nan
env1_second_0:                 episode reward: 27.0500,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 1543.15,                last time consumption/overall running time: 476.1410s / 33584.2169 s
env0_first_0:                 episode reward: -25.8500,                 loss: 0.0243
env0_second_0:                 episode reward: 25.8500,                 loss: 0.0250
env1_first_0:                 episode reward: -27.4000,                 loss: nan
env1_second_0:                 episode reward: 27.4000,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 1504.8,                last time consumption/overall running time: 455.8950s / 34040.1119 s
env0_first_0:                 episode reward: -26.4000,                 loss: 0.0236
env0_second_0:                 episode reward: 26.4000,                 loss: 0.0244
env1_first_0:                 episode reward: -27.1000,                 loss: nan
env1_second_0:                 episode reward: 27.1000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 1523.7,                last time consumption/overall running time: 462.9453s / 34503.0572 s
env0_first_0:                 episode reward: -26.7000,                 loss: 0.0226
env0_second_0:                 episode reward: 26.7000,                 loss: 0.0250
env1_first_0:                 episode reward: -26.9500,                 loss: nan
env1_second_0:                 episode reward: 26.9500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 1555.9,                last time consumption/overall running time: 479.1590s / 34982.2162 s
env0_first_0:                 episode reward: -26.0000,                 loss: 0.0238
env0_second_0:                 episode reward: 26.0000,                 loss: 0.0225
env1_first_0:                 episode reward: -25.0000,                 loss: nan
env1_second_0:                 episode reward: 25.0000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 1500.0,                last time consumption/overall running time: 464.2028s / 35446.4190 s
env0_first_0:                 episode reward: -25.9500,                 loss: 0.0226
env0_second_0:                 episode reward: 25.9500,                 loss: 0.0231
env1_first_0:                 episode reward: -25.5500,                 loss: nan
env1_second_0:                 episode reward: 25.5500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 1537.35,                last time consumption/overall running time: 468.5161s / 35914.9352 s
env0_first_0:                 episode reward: -25.4000,                 loss: 0.0238
env0_second_0:                 episode reward: 25.4000,                 loss: 0.0238
env1_first_0:                 episode reward: -25.9500,                 loss: nan
env1_second_0:                 episode reward: 25.9500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 1560.2,                last time consumption/overall running time: 478.7500s / 36393.6852 s
env0_first_0:                 episode reward: -25.9000,                 loss: 0.0254
env0_second_0:                 episode reward: 25.9000,                 loss: 0.0256
env1_first_0:                 episode reward: -25.7500,                 loss: nan
env1_second_0:                 episode reward: 25.7500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 1510.65,                last time consumption/overall running time: 458.8725s / 36852.5576 s
env0_first_0:                 episode reward: -25.5500,                 loss: 0.0253
env0_second_0:                 episode reward: 25.5500,                 loss: 0.0235
env1_first_0:                 episode reward: -25.9500,                 loss: nan
env1_second_0:                 episode reward: 25.9500,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 1520.45,                last time consumption/overall running time: 469.0494s / 37321.6070 s
env0_first_0:                 episode reward: -26.4500,                 loss: 0.0234
env0_second_0:                 episode reward: 26.4500,                 loss: 0.0240
env1_first_0:                 episode reward: -26.4000,                 loss: nan
env1_second_0:                 episode reward: 26.4000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 1542.65,                last time consumption/overall running time: 473.6961s / 37795.3031 s
env0_first_0:                 episode reward: -27.6500,                 loss: 0.0235
env0_second_0:                 episode reward: 27.6500,                 loss: 0.0246
env1_first_0:                 episode reward: -27.1000,                 loss: nan
env1_second_0:                 episode reward: 27.1000,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 1517.5,                last time consumption/overall running time: 467.7364s / 38263.0396 s
env0_first_0:                 episode reward: -26.2500,                 loss: 0.0236
env0_second_0:                 episode reward: 26.2500,                 loss: 0.0241
env1_first_0:                 episode reward: -26.7500,                 loss: nan
env1_second_0:                 episode reward: 26.7500,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 1533.45,                last time consumption/overall running time: 466.0083s / 38729.0479 s
env0_first_0:                 episode reward: -26.0500,                 loss: 0.0238
env0_second_0:                 episode reward: 26.0500,                 loss: 0.0261
env1_first_0:                 episode reward: -26.4500,                 loss: nan
env1_second_0:                 episode reward: 26.4500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 1638.8,                last time consumption/overall running time: 502.1685s / 39231.2164 s
env0_first_0:                 episode reward: -26.3500,                 loss: 0.0238
env0_second_0:                 episode reward: 26.3500,                 loss: 0.0239
env1_first_0:                 episode reward: -24.6000,                 loss: nan
env1_second_0:                 episode reward: 24.6000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 1568.55,                last time consumption/overall running time: 480.8122s / 39712.0286 s
env0_first_0:                 episode reward: -23.7500,                 loss: 0.0242
env0_second_0:                 episode reward: 23.7500,                 loss: 0.0246
env1_first_0:                 episode reward: -27.6500,                 loss: nan
env1_second_0:                 episode reward: 27.6500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 1515.4,                last time consumption/overall running time: 470.4974s / 40182.5259 s
env0_first_0:                 episode reward: -25.6500,                 loss: 0.0254
env0_second_0:                 episode reward: 25.6500,                 loss: 0.0256
env1_first_0:                 episode reward: -25.7000,                 loss: nan
env1_second_0:                 episode reward: 25.7000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 1511.15,                last time consumption/overall running time: 471.3605s / 40653.8864 s
env0_first_0:                 episode reward: -25.5500,                 loss: 0.0254
env0_second_0:                 episode reward: 25.5500,                 loss: 0.0263
env1_first_0:                 episode reward: -26.2500,                 loss: nan
env1_second_0:                 episode reward: 26.2500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 1502.8,                last time consumption/overall running time: 473.8888s / 41127.7752 s
env0_first_0:                 episode reward: -25.6500,                 loss: 0.0244
env0_second_0:                 episode reward: 25.6500,                 loss: 0.0251
env1_first_0:                 episode reward: -26.5500,                 loss: nan
env1_second_0:                 episode reward: 26.5500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 1597.9,                last time consumption/overall running time: 499.2819s / 41627.0571 s
env0_first_0:                 episode reward: -24.9000,                 loss: 0.0217
env0_second_0:                 episode reward: 24.9000,                 loss: 0.0249
env1_first_0:                 episode reward: -26.0000,                 loss: nan
env1_second_0:                 episode reward: 26.0000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 1622.6,                last time consumption/overall running time: 509.9467s / 42137.0038 s
env0_first_0:                 episode reward: -24.5500,                 loss: 0.0250
env0_second_0:                 episode reward: 24.5500,                 loss: 0.0265
env1_first_0:                 episode reward: -23.4000,                 loss: nan
env1_second_0:                 episode reward: 23.4000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 1533.25,                last time consumption/overall running time: 487.3156s / 42624.3194 s
env0_first_0:                 episode reward: -26.4500,                 loss: 0.0245
env0_second_0:                 episode reward: 26.4500,                 loss: 0.0262
env1_first_0:                 episode reward: -26.8500,                 loss: nan
env1_second_0:                 episode reward: 26.8500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 1508.6,                last time consumption/overall running time: 474.4969s / 43098.8163 s
env0_first_0:                 episode reward: -25.3500,                 loss: 0.0250
env0_second_0:                 episode reward: 25.3500,                 loss: 0.0257
env1_first_0:                 episode reward: -26.0500,                 loss: nan
env1_second_0:                 episode reward: 26.0500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 1524.5,                last time consumption/overall running time: 481.0099s / 43579.8263 s
env0_first_0:                 episode reward: -25.9500,                 loss: 0.0241
env0_second_0:                 episode reward: 25.9500,                 loss: 0.0243
env1_first_0:                 episode reward: -25.0000,                 loss: nan
env1_second_0:                 episode reward: 25.0000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 1559.75,                last time consumption/overall running time: 488.2661s / 44068.0924 s
env0_first_0:                 episode reward: -24.5000,                 loss: 0.0234
env0_second_0:                 episode reward: 24.5000,                 loss: 0.0234
env1_first_0:                 episode reward: -24.9000,                 loss: nan
env1_second_0:                 episode reward: 24.9000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 1542.3,                last time consumption/overall running time: 485.1479s / 44553.2403 s
env0_first_0:                 episode reward: -25.9500,                 loss: 0.0232
env0_second_0:                 episode reward: 25.9500,                 loss: 0.0232
env1_first_0:                 episode reward: -25.6000,                 loss: nan
env1_second_0:                 episode reward: 25.6000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 1485.8,                last time consumption/overall running time: 470.6686s / 45023.9089 s
env0_first_0:                 episode reward: -24.8500,                 loss: 0.0226
env0_second_0:                 episode reward: 24.8500,                 loss: 0.0223
env1_first_0:                 episode reward: -26.0500,                 loss: nan
env1_second_0:                 episode reward: 26.0500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 1510.4,                last time consumption/overall running time: 482.4103s / 45506.3192 s
env0_first_0:                 episode reward: -26.1500,                 loss: 0.0221
env0_second_0:                 episode reward: 26.1500,                 loss: 0.0231
env1_first_0:                 episode reward: -25.9500,                 loss: nan
env1_second_0:                 episode reward: 25.9500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 1522.45,                last time consumption/overall running time: 478.6682s / 45984.9874 s
env0_first_0:                 episode reward: -25.9000,                 loss: 0.0209
env0_second_0:                 episode reward: 25.9000,                 loss: 0.0229
env1_first_0:                 episode reward: -26.5500,                 loss: nan
env1_second_0:                 episode reward: 26.5500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 1585.2,                last time consumption/overall running time: 495.1389s / 46480.1264 s
env0_first_0:                 episode reward: -26.3500,                 loss: 0.0224
env0_second_0:                 episode reward: 26.3500,                 loss: 0.0232
env1_first_0:                 episode reward: -24.8500,                 loss: nan
env1_second_0:                 episode reward: 24.8500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 1601.95,                last time consumption/overall running time: 505.8950s / 46986.0214 s
env0_first_0:                 episode reward: -24.0500,                 loss: 0.0232
env0_second_0:                 episode reward: 24.0500,                 loss: 0.0232
env1_first_0:                 episode reward: -27.3500,                 loss: nan
env1_second_0:                 episode reward: 27.3500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 1581.65,                last time consumption/overall running time: 502.1212s / 47488.1426 s
env0_first_0:                 episode reward: -24.6500,                 loss: 0.0255
env0_second_0:                 episode reward: 24.6500,                 loss: 0.0244
env1_first_0:                 episode reward: -26.2000,                 loss: nan
env1_second_0:                 episode reward: 26.2000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 1558.15,                last time consumption/overall running time: 485.7623s / 47973.9049 s
env0_first_0:                 episode reward: -22.8500,                 loss: 0.0237
env0_second_0:                 episode reward: 22.8500,                 loss: 0.0240
env1_first_0:                 episode reward: -25.8000,                 loss: nan
env1_second_0:                 episode reward: 25.8000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 1570.75,                last time consumption/overall running time: 490.8756s / 48464.7805 s
env0_first_0:                 episode reward: -25.0500,                 loss: 0.0234
env0_second_0:                 episode reward: 25.0500,                 loss: 0.0240
env1_first_0:                 episode reward: -24.4000,                 loss: nan
env1_second_0:                 episode reward: 24.4000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 1594.05,                last time consumption/overall running time: 500.6518s / 48965.4323 s
env0_first_0:                 episode reward: -24.9500,                 loss: 0.0234
env0_second_0:                 episode reward: 24.9500,                 loss: 0.0227
env1_first_0:                 episode reward: -25.6000,                 loss: nan
env1_second_0:                 episode reward: 25.6000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 1578.25,                last time consumption/overall running time: 487.7254s / 49453.1577 s
env0_first_0:                 episode reward: -25.9500,                 loss: 0.0232
env0_second_0:                 episode reward: 25.9500,                 loss: 0.0228
env1_first_0:                 episode reward: -24.7000,                 loss: nan
env1_second_0:                 episode reward: 24.7000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 1648.3,                last time consumption/overall running time: 503.9130s / 49957.0707 s
env0_first_0:                 episode reward: -25.2000,                 loss: 0.0228
env0_second_0:                 episode reward: 25.2000,                 loss: 0.0232
env1_first_0:                 episode reward: -25.9000,                 loss: nan
env1_second_0:                 episode reward: 25.9000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 1574.05,                last time consumption/overall running time: 492.4889s / 50449.5596 s
env0_first_0:                 episode reward: -24.7000,                 loss: 0.0234
env0_second_0:                 episode reward: 24.7000,                 loss: 0.0225
env1_first_0:                 episode reward: -25.2500,                 loss: nan
env1_second_0:                 episode reward: 25.2500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 1544.4,                last time consumption/overall running time: 479.9753s / 50929.5349 s
env0_first_0:                 episode reward: -24.8000,                 loss: 0.0220
env0_second_0:                 episode reward: 24.8000,                 loss: 0.0229
env1_first_0:                 episode reward: -24.8500,                 loss: nan
env1_second_0:                 episode reward: 24.8500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 1544.6,                last time consumption/overall running time: 484.6087s / 51414.1437 s
env0_first_0:                 episode reward: -25.3500,                 loss: 0.0220
env0_second_0:                 episode reward: 25.3500,                 loss: 0.0215
env1_first_0:                 episode reward: -24.1500,                 loss: nan
env1_second_0:                 episode reward: 24.1500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 1587.35,                last time consumption/overall running time: 488.6608s / 51902.8045 s
env0_first_0:                 episode reward: -25.5000,                 loss: 0.0208
env0_second_0:                 episode reward: 25.5000,                 loss: 0.0217
env1_first_0:                 episode reward: -23.1500,                 loss: nan
env1_second_0:                 episode reward: 23.1500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 1595.15,                last time consumption/overall running time: 493.5969s / 52396.4014 s
env0_first_0:                 episode reward: -24.0000,                 loss: 0.0218
env0_second_0:                 episode reward: 24.0000,                 loss: 0.0212
env1_first_0:                 episode reward: -24.0000,                 loss: nan
env1_second_0:                 episode reward: 24.0000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 1648.2,                last time consumption/overall running time: 522.7727s / 52919.1741 s
env0_first_0:                 episode reward: -24.7000,                 loss: 0.0223
env0_second_0:                 episode reward: 24.7000,                 loss: 0.0231
env1_first_0:                 episode reward: -25.3500,                 loss: nan
env1_second_0:                 episode reward: 25.3500,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 1605.8,                last time consumption/overall running time: 502.1978s / 53421.3719 s
env0_first_0:                 episode reward: -25.0000,                 loss: 0.0229
env0_second_0:                 episode reward: 25.0000,                 loss: 0.0235
env1_first_0:                 episode reward: -23.4000,                 loss: nan
env1_second_0:                 episode reward: 23.4000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 1624.7,                last time consumption/overall running time: 507.3089s / 53928.6808 s
env0_first_0:                 episode reward: -26.2500,                 loss: 0.0240
env0_second_0:                 episode reward: 26.2500,                 loss: 0.0242
env1_first_0:                 episode reward: -24.5500,                 loss: nan
env1_second_0:                 episode reward: 24.5500,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 1606.75,                last time consumption/overall running time: 505.9302s / 54434.6110 s
env0_first_0:                 episode reward: -24.6000,                 loss: 0.0232
env0_second_0:                 episode reward: 24.6000,                 loss: 0.0229
env1_first_0:                 episode reward: -24.5000,                 loss: nan
env1_second_0:                 episode reward: 24.5000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 1588.85,                last time consumption/overall running time: 490.3646s / 54924.9755 s
env0_first_0:                 episode reward: -25.0000,                 loss: 0.0224
env0_second_0:                 episode reward: 25.0000,                 loss: 0.0233
env1_first_0:                 episode reward: -23.9500,                 loss: nan
env1_second_0:                 episode reward: 23.9500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 1597.45,                last time consumption/overall running time: 499.2055s / 55424.1811 s
env0_first_0:                 episode reward: -25.0500,                 loss: 0.0231
env0_second_0:                 episode reward: 25.0500,                 loss: 0.0240
env1_first_0:                 episode reward: -24.6500,                 loss: nan
env1_second_0:                 episode reward: 24.6500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 1631.6,                last time consumption/overall running time: 510.1978s / 55934.3789 s
env0_first_0:                 episode reward: -25.4000,                 loss: 0.0232
env0_second_0:                 episode reward: 25.4000,                 loss: 0.0249
env1_first_0:                 episode reward: -23.6500,                 loss: nan
env1_second_0:                 episode reward: 23.6500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 1626.9,                last time consumption/overall running time: 506.1618s / 56440.5407 s
env0_first_0:                 episode reward: -24.1000,                 loss: 0.0230
env0_second_0:                 episode reward: 24.1000,                 loss: 0.0248
env1_first_0:                 episode reward: -24.4500,                 loss: nan
env1_second_0:                 episode reward: 24.4500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 1677.25,                last time consumption/overall running time: 526.4565s / 56966.9973 s
env0_first_0:                 episode reward: -23.6500,                 loss: 0.0228
env0_second_0:                 episode reward: 23.6500,                 loss: 0.0237
env1_first_0:                 episode reward: -25.4000,                 loss: nan
env1_second_0:                 episode reward: 25.4000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 1569.95,                last time consumption/overall running time: 491.7526s / 57458.7498 s
env0_first_0:                 episode reward: -24.4500,                 loss: 0.0226
env0_second_0:                 episode reward: 24.4500,                 loss: 0.0242
env1_first_0:                 episode reward: -24.6500,                 loss: nan
env1_second_0:                 episode reward: 24.6500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 1635.8,                last time consumption/overall running time: 515.0366s / 57973.7864 s
env0_first_0:                 episode reward: -24.2000,                 loss: 0.0232
env0_second_0:                 episode reward: 24.2000,                 loss: 0.0232
env1_first_0:                 episode reward: -25.0000,                 loss: nan
env1_second_0:                 episode reward: 25.0000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 1609.75,                last time consumption/overall running time: 507.2658s / 58481.0521 s
env0_first_0:                 episode reward: -24.1000,                 loss: 0.0236
env0_second_0:                 episode reward: 24.1000,                 loss: 0.0248
env1_first_0:                 episode reward: -24.3000,                 loss: nan
env1_second_0:                 episode reward: 24.3000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 1656.7,                last time consumption/overall running time: 525.0672s / 59006.1193 s
env0_first_0:                 episode reward: -25.6000,                 loss: 0.0235
env0_second_0:                 episode reward: 25.6000,                 loss: 0.0255
env1_first_0:                 episode reward: -24.7000,                 loss: nan
env1_second_0:                 episode reward: 24.7000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 1576.5,                last time consumption/overall running time: 490.9066s / 59497.0258 s
env0_first_0:                 episode reward: -25.3500,                 loss: 0.0219
env0_second_0:                 episode reward: 25.3500,                 loss: 0.0255
env1_first_0:                 episode reward: -23.7000,                 loss: nan
env1_second_0:                 episode reward: 23.7000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 1673.85,                last time consumption/overall running time: 518.7061s / 60015.7319 s
env0_first_0:                 episode reward: -25.3000,                 loss: 0.0231
env0_second_0:                 episode reward: 25.3000,                 loss: 0.0242
env1_first_0:                 episode reward: -24.2500,                 loss: nan
env1_second_0:                 episode reward: 24.2500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 1651.45,                last time consumption/overall running time: 513.3644s / 60529.0963 s
env0_first_0:                 episode reward: -25.2500,                 loss: 0.0227
env0_second_0:                 episode reward: 25.2500,                 loss: 0.0234
env1_first_0:                 episode reward: -24.1000,                 loss: nan
env1_second_0:                 episode reward: 24.1000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 1664.7,                last time consumption/overall running time: 524.9901s / 61054.0864 s
env0_first_0:                 episode reward: -24.2000,                 loss: 0.0230
env0_second_0:                 episode reward: 24.2000,                 loss: 0.0251
env1_first_0:                 episode reward: -24.3500,                 loss: nan
env1_second_0:                 episode reward: 24.3500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 1700.7,                last time consumption/overall running time: 533.4530s / 61587.5394 s
env0_first_0:                 episode reward: -25.3500,                 loss: 0.0230
env0_second_0:                 episode reward: 25.3500,                 loss: 0.0226
env1_first_0:                 episode reward: -23.7500,                 loss: nan
env1_second_0:                 episode reward: 23.7500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 1643.95,                last time consumption/overall running time: 504.0240s / 62091.5633 s
env0_first_0:                 episode reward: -24.5000,                 loss: 0.0221
env0_second_0:                 episode reward: 24.5000,                 loss: 0.0229
env1_first_0:                 episode reward: -24.0000,                 loss: nan
env1_second_0:                 episode reward: 24.0000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 1616.2,                last time consumption/overall running time: 503.1697s / 62594.7330 s
env0_first_0:                 episode reward: -24.9500,                 loss: 0.0209
env0_second_0:                 episode reward: 24.9500,                 loss: 0.0210
env1_first_0:                 episode reward: -24.2000,                 loss: nan
env1_second_0:                 episode reward: 24.2000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 1644.0,                last time consumption/overall running time: 519.9401s / 63114.6731 s
env0_first_0:                 episode reward: -25.5500,                 loss: 0.0219
env0_second_0:                 episode reward: 25.5500,                 loss: 0.0230
env1_first_0:                 episode reward: -23.4500,                 loss: nan
env1_second_0:                 episode reward: 23.4500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 1627.8,                last time consumption/overall running time: 497.2316s / 63611.9047 s
env0_first_0:                 episode reward: -23.7000,                 loss: 0.0221
env0_second_0:                 episode reward: 23.7000,                 loss: 0.0235
env1_first_0:                 episode reward: -23.8500,                 loss: nan
env1_second_0:                 episode reward: 23.8500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 1608.55,                last time consumption/overall running time: 500.9004s / 64112.8050 s
env0_first_0:                 episode reward: -24.3500,                 loss: 0.0241
env0_second_0:                 episode reward: 24.3500,                 loss: 0.0237
env1_first_0:                 episode reward: -25.6000,                 loss: nan
env1_second_0:                 episode reward: 25.6000,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 1691.75,                last time consumption/overall running time: 521.2500s / 64634.0550 s
env0_first_0:                 episode reward: -22.7500,                 loss: 0.0228
env0_second_0:                 episode reward: 22.7500,                 loss: 0.0251
env1_first_0:                 episode reward: -25.2500,                 loss: nan
env1_second_0:                 episode reward: 25.2500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 1657.1,                last time consumption/overall running time: 510.3389s / 65144.3939 s
env0_first_0:                 episode reward: -25.9500,                 loss: 0.0234
env0_second_0:                 episode reward: 25.9500,                 loss: 0.0255
env1_first_0:                 episode reward: -25.5000,                 loss: nan
env1_second_0:                 episode reward: 25.5000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 1640.95,                last time consumption/overall running time: 502.8484s / 65647.2423 s
env0_first_0:                 episode reward: -25.6000,                 loss: 0.0251
env0_second_0:                 episode reward: 25.6000,                 loss: 0.0274
env1_first_0:                 episode reward: -24.7000,                 loss: nan
env1_second_0:                 episode reward: 24.7000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 1631.55,                last time consumption/overall running time: 506.1271s / 66153.3694 s
env0_first_0:                 episode reward: -25.3000,                 loss: 0.0245
env0_second_0:                 episode reward: 25.3000,                 loss: 0.0255
env1_first_0:                 episode reward: -25.4500,                 loss: nan
env1_second_0:                 episode reward: 25.4500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 1669.8,                last time consumption/overall running time: 525.2072s / 66678.5766 s
env0_first_0:                 episode reward: -25.0500,                 loss: 0.0262
env0_second_0:                 episode reward: 25.0500,                 loss: 0.0262
env1_first_0:                 episode reward: -25.2000,                 loss: nan
env1_second_0:                 episode reward: 25.2000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 1654.0,                last time consumption/overall running time: 513.2005s / 67191.7771 s
env0_first_0:                 episode reward: -25.4000,                 loss: 0.0253
env0_second_0:                 episode reward: 25.4000,                 loss: 0.0250
env1_first_0:                 episode reward: -25.3500,                 loss: nan
env1_second_0:                 episode reward: 25.3500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 1813.15,                last time consumption/overall running time: 561.5794s / 67753.3564 s
env0_first_0:                 episode reward: -25.7000,                 loss: 0.0254
env0_second_0:                 episode reward: 25.7000,                 loss: 0.0266
env1_first_0:                 episode reward: -22.7000,                 loss: nan
env1_second_0:                 episode reward: 22.7000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 1703.5,                last time consumption/overall running time: 526.1984s / 68279.5549 s
env0_first_0:                 episode reward: -25.0500,                 loss: 0.0271
env0_second_0:                 episode reward: 25.0500,                 loss: 0.0264
env1_first_0:                 episode reward: -25.7500,                 loss: nan
env1_second_0:                 episode reward: 25.7500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 1628.0,                last time consumption/overall running time: 518.0200s / 68797.5748 s
env0_first_0:                 episode reward: -25.0000,                 loss: 0.0260
env0_second_0:                 episode reward: 25.0000,                 loss: 0.0263
env1_first_0:                 episode reward: -25.2500,                 loss: nan
env1_second_0:                 episode reward: 25.2500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 1643.15,                last time consumption/overall running time: 529.0856s / 69326.6604 s
env0_first_0:                 episode reward: -24.6500,                 loss: 0.0243
env0_second_0:                 episode reward: 24.6500,                 loss: 0.0244
env1_first_0:                 episode reward: -23.6500,                 loss: nan
env1_second_0:                 episode reward: 23.6500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 1633.5,                last time consumption/overall running time: 507.0361s / 69833.6965 s
env0_first_0:                 episode reward: -25.1000,                 loss: 0.0221
env0_second_0:                 episode reward: 25.1000,                 loss: 0.0226
env1_first_0:                 episode reward: -25.0000,                 loss: nan
env1_second_0:                 episode reward: 25.0000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 1650.9,                last time consumption/overall running time: 515.9614s / 70349.6579 s
env0_first_0:                 episode reward: -25.0500,                 loss: 0.0225
env0_second_0:                 episode reward: 25.0500,                 loss: 0.0222
env1_first_0:                 episode reward: -25.7000,                 loss: nan
env1_second_0:                 episode reward: 25.7000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 1651.85,                last time consumption/overall running time: 521.2467s / 70870.9046 s
env0_first_0:                 episode reward: -25.0500,                 loss: 0.0230
env0_second_0:                 episode reward: 25.0500,                 loss: 0.0236
env1_first_0:                 episode reward: -24.1000,                 loss: nan
env1_second_0:                 episode reward: 24.1000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 1649.3,                last time consumption/overall running time: 516.8451s / 71387.7497 s
env0_first_0:                 episode reward: -25.1000,                 loss: 0.0242
env0_second_0:                 episode reward: 25.1000,                 loss: 0.0228
env1_first_0:                 episode reward: -25.9500,                 loss: nan
env1_second_0:                 episode reward: 25.9500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 1599.65,                last time consumption/overall running time: 502.4012s / 71890.1509 s
env0_first_0:                 episode reward: -24.3500,                 loss: 0.0224
env0_second_0:                 episode reward: 24.3500,                 loss: 0.0218
env1_first_0:                 episode reward: -24.9000,                 loss: nan
env1_second_0:                 episode reward: 24.9000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 1605.45,                last time consumption/overall running time: 507.2792s / 72397.4301 s
env0_first_0:                 episode reward: -24.3500,                 loss: 0.0212
env0_second_0:                 episode reward: 24.3500,                 loss: 0.0218
env1_first_0:                 episode reward: -23.2500,                 loss: nan
env1_second_0:                 episode reward: 23.2500,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 1615.6,                last time consumption/overall running time: 507.1406s / 72904.5707 s
env0_first_0:                 episode reward: -23.2000,                 loss: 0.0203
env0_second_0:                 episode reward: 23.2000,                 loss: 0.0215
env1_first_0:                 episode reward: -22.2000,                 loss: nan
env1_second_0:                 episode reward: 22.2000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 1599.7,                last time consumption/overall running time: 496.7121s / 73401.2827 s
env0_first_0:                 episode reward: -24.0500,                 loss: 0.0197
env0_second_0:                 episode reward: 24.0500,                 loss: 0.0211
env1_first_0:                 episode reward: -24.8500,                 loss: nan
env1_second_0:                 episode reward: 24.8500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 1664.55,                last time consumption/overall running time: 518.1939s / 73919.4767 s
env0_first_0:                 episode reward: -24.8500,                 loss: 0.0214
env0_second_0:                 episode reward: 24.8500,                 loss: 0.0223
env1_first_0:                 episode reward: -25.4000,                 loss: nan
env1_second_0:                 episode reward: 25.4000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 1698.35,                last time consumption/overall running time: 527.0960s / 74446.5727 s
env0_first_0:                 episode reward: -24.6500,                 loss: 0.0232
env0_second_0:                 episode reward: 24.6500,                 loss: 0.0228
env1_first_0:                 episode reward: -24.7000,                 loss: nan
env1_second_0:                 episode reward: 24.7000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 1671.25,                last time consumption/overall running time: 526.6689s / 74973.2415 s
env0_first_0:                 episode reward: -25.0000,                 loss: 0.0233
env0_second_0:                 episode reward: 25.0000,                 loss: 0.0232
env1_first_0:                 episode reward: -23.7000,                 loss: nan
env1_second_0:                 episode reward: 23.7000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 1662.0,                last time consumption/overall running time: 515.1870s / 75488.4286 s
env0_first_0:                 episode reward: -23.8500,                 loss: 0.0242
env0_second_0:                 episode reward: 23.8500,                 loss: 0.0221
env1_first_0:                 episode reward: -25.4500,                 loss: nan
env1_second_0:                 episode reward: 25.4500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 1629.8,                last time consumption/overall running time: 497.9655s / 75986.3941 s
env0_first_0:                 episode reward: -23.5000,                 loss: 0.0243
env0_second_0:                 episode reward: 23.5000,                 loss: 0.0233
env1_first_0:                 episode reward: -22.7000,                 loss: nan
env1_second_0:                 episode reward: 22.7000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 1656.9,                last time consumption/overall running time: 505.0178s / 76491.4118 s
env0_first_0:                 episode reward: -23.9000,                 loss: 0.0248
env0_second_0:                 episode reward: 23.9000,                 loss: 0.0248
env1_first_0:                 episode reward: -23.2500,                 loss: nan
env1_second_0:                 episode reward: 23.2500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 1595.15,                last time consumption/overall running time: 491.4746s / 76982.8864 s
env0_first_0:                 episode reward: -24.9500,                 loss: 0.0241
env0_second_0:                 episode reward: 24.9500,                 loss: 0.0248
env1_first_0:                 episode reward: -25.0500,                 loss: nan
env1_second_0:                 episode reward: 25.0500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 1502.75,                last time consumption/overall running time: 465.1349s / 77448.0213 s
env0_first_0:                 episode reward: -23.6500,                 loss: 0.0222
env0_second_0:                 episode reward: 23.6500,                 loss: 0.0243
env1_first_0:                 episode reward: -22.9500,                 loss: nan
env1_second_0:                 episode reward: 22.9500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 1672.65,                last time consumption/overall running time: 516.8020s / 77964.8233 s
env0_first_0:                 episode reward: -23.9000,                 loss: 0.0230
env0_second_0:                 episode reward: 23.9000,                 loss: 0.0220
env1_first_0:                 episode reward: -24.4500,                 loss: nan
env1_second_0:                 episode reward: 24.4500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 1679.3,                last time consumption/overall running time: 519.8300s / 78484.6533 s
env0_first_0:                 episode reward: -24.3000,                 loss: 0.0221
env0_second_0:                 episode reward: 24.3000,                 loss: 0.0223
env1_first_0:                 episode reward: -23.3500,                 loss: nan
env1_second_0:                 episode reward: 23.3500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 1687.25,                last time consumption/overall running time: 531.5014s / 79016.1547 s
env0_first_0:                 episode reward: -22.4000,                 loss: 0.0236
env0_second_0:                 episode reward: 22.4000,                 loss: 0.0226
env1_first_0:                 episode reward: -25.4000,                 loss: nan
env1_second_0:                 episode reward: 25.4000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 1687.2,                last time consumption/overall running time: 519.0006s / 79535.1553 s
env0_first_0:                 episode reward: -23.4500,                 loss: 0.0244
env0_second_0:                 episode reward: 23.4500,                 loss: 0.0252
env1_first_0:                 episode reward: -23.7500,                 loss: nan
env1_second_0:                 episode reward: 23.7500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 1645.65,                last time consumption/overall running time: 508.0446s / 80043.1999 s
env0_first_0:                 episode reward: -22.3000,                 loss: 0.0253
env0_second_0:                 episode reward: 22.3000,                 loss: 0.0259
env1_first_0:                 episode reward: -24.1500,                 loss: nan
env1_second_0:                 episode reward: 24.1500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 1659.65,                last time consumption/overall running time: 514.9758s / 80558.1756 s
env0_first_0:                 episode reward: -23.2000,                 loss: 0.0245
env0_second_0:                 episode reward: 23.2000,                 loss: 0.0232
env1_first_0:                 episode reward: -23.3500,                 loss: nan
env1_second_0:                 episode reward: 23.3500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 1607.15,                last time consumption/overall running time: 512.5180s / 81070.6937 s
env0_first_0:                 episode reward: -24.4000,                 loss: 0.0222
env0_second_0:                 episode reward: 24.4000,                 loss: 0.0225
env1_first_0:                 episode reward: -23.4000,                 loss: nan
env1_second_0:                 episode reward: 23.4000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 1630.2,                last time consumption/overall running time: 503.8944s / 81574.5881 s
env0_first_0:                 episode reward: -24.0500,                 loss: 0.0214
env0_second_0:                 episode reward: 24.0500,                 loss: 0.0220
env1_first_0:                 episode reward: -23.7500,                 loss: nan
env1_second_0:                 episode reward: 23.7500,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 1662.2,                last time consumption/overall running time: 513.6338s / 82088.2218 s
env0_first_0:                 episode reward: -23.6000,                 loss: 0.0237
env0_second_0:                 episode reward: 23.6000,                 loss: 0.0217
env1_first_0:                 episode reward: -23.9500,                 loss: nan
env1_second_0:                 episode reward: 23.9500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 1658.6,                last time consumption/overall running time: 507.1595s / 82595.3813 s
env0_first_0:                 episode reward: -25.4000,                 loss: 0.0226
env0_second_0:                 episode reward: 25.4000,                 loss: 0.0237
env1_first_0:                 episode reward: -23.7000,                 loss: nan
env1_second_0:                 episode reward: 23.7000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 1624.55,                last time consumption/overall running time: 501.4778s / 83096.8591 s
env0_first_0:                 episode reward: -24.1500,                 loss: 0.0220
env0_second_0:                 episode reward: 24.1500,                 loss: 0.0234
env1_first_0:                 episode reward: -24.1000,                 loss: nan
env1_second_0:                 episode reward: 24.1000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 1615.5,                last time consumption/overall running time: 498.3709s / 83595.2301 s
env0_first_0:                 episode reward: -24.9500,                 loss: 0.0225
env0_second_0:                 episode reward: 24.9500,                 loss: 0.0245
env1_first_0:                 episode reward: -22.6500,                 loss: nan
env1_second_0:                 episode reward: 22.6500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 1695.5,                last time consumption/overall running time: 533.7311s / 84128.9612 s
env0_first_0:                 episode reward: -25.3000,                 loss: 0.0234
env0_second_0:                 episode reward: 25.3000,                 loss: 0.0242
env1_first_0:                 episode reward: -25.1500,                 loss: nan
env1_second_0:                 episode reward: 25.1500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 1707.2,                last time consumption/overall running time: 529.5338s / 84658.4950 s
env0_first_0:                 episode reward: -24.6500,                 loss: 0.0246
env0_second_0:                 episode reward: 24.6500,                 loss: 0.0237
env1_first_0:                 episode reward: -24.3500,                 loss: nan
env1_second_0:                 episode reward: 24.3500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 1732.2,                last time consumption/overall running time: 537.3481s / 85195.8431 s
env0_first_0:                 episode reward: -25.4500,                 loss: 0.0254
env0_second_0:                 episode reward: 25.4500,                 loss: 0.0231
env1_first_0:                 episode reward: -24.8000,                 loss: nan
env1_second_0:                 episode reward: 24.8000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 1637.0,                last time consumption/overall running time: 510.2623s / 85706.1054 s
env0_first_0:                 episode reward: -25.1500,                 loss: 0.0239
env0_second_0:                 episode reward: 25.1500,                 loss: 0.0234
env1_first_0:                 episode reward: -24.5000,                 loss: nan
env1_second_0:                 episode reward: 24.5000,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 1630.4,                last time consumption/overall running time: 517.7070s / 86223.8124 s
env0_first_0:                 episode reward: -23.4500,                 loss: 0.0232
env0_second_0:                 episode reward: 23.4500,                 loss: 0.0229
env1_first_0:                 episode reward: -25.6000,                 loss: nan
env1_second_0:                 episode reward: 25.6000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 1669.3,                last time consumption/overall running time: 532.4890s / 86756.3013 s
env0_first_0:                 episode reward: -24.5500,                 loss: 0.0222
env0_second_0:                 episode reward: 24.5500,                 loss: 0.0220
env1_first_0:                 episode reward: -24.1500,                 loss: nan
env1_second_0:                 episode reward: 24.1500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 1673.0,                last time consumption/overall running time: 516.5387s / 87272.8400 s
env0_first_0:                 episode reward: -24.0500,                 loss: 0.0227
env0_second_0:                 episode reward: 24.0500,                 loss: 0.0241
env1_first_0:                 episode reward: -23.8000,                 loss: nan
env1_second_0:                 episode reward: 23.8000,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 1660.8,                last time consumption/overall running time: 516.3766s / 87789.2166 s
env0_first_0:                 episode reward: -24.7500,                 loss: 0.0240
env0_second_0:                 episode reward: 24.7500,                 loss: 0.0239
env1_first_0:                 episode reward: -25.6000,                 loss: nan
env1_second_0:                 episode reward: 25.6000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 1640.25,                last time consumption/overall running time: 510.4822s / 88299.6989 s
env0_first_0:                 episode reward: -24.2500,                 loss: 0.0242
env0_second_0:                 episode reward: 24.2500,                 loss: 0.0238
env1_first_0:                 episode reward: -24.4000,                 loss: nan
env1_second_0:                 episode reward: 24.4000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 1648.5,                last time consumption/overall running time: 507.8709s / 88807.5698 s
env0_first_0:                 episode reward: -23.8500,                 loss: 0.0240
env0_second_0:                 episode reward: 23.8500,                 loss: 0.0246
env1_first_0:                 episode reward: -23.9500,                 loss: nan
env1_second_0:                 episode reward: 23.9500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 1632.5,                last time consumption/overall running time: 502.9194s / 89310.4891 s
env0_first_0:                 episode reward: -23.7000,                 loss: 0.0243
env0_second_0:                 episode reward: 23.7000,                 loss: 0.0256
env1_first_0:                 episode reward: -24.3000,                 loss: nan
env1_second_0:                 episode reward: 24.3000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 1654.4,                last time consumption/overall running time: 528.6535s / 89839.1426 s
env0_first_0:                 episode reward: -24.4000,                 loss: 0.0237
env0_second_0:                 episode reward: 24.4000,                 loss: 0.0258
env1_first_0:                 episode reward: -23.5500,                 loss: nan
env1_second_0:                 episode reward: 23.5500,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 1679.7,                last time consumption/overall running time: 527.1014s / 90366.2440 s
env0_first_0:                 episode reward: -23.9500,                 loss: 0.0234
env0_second_0:                 episode reward: 23.9500,                 loss: 0.0256
env1_first_0:                 episode reward: -24.7000,                 loss: nan
env1_second_0:                 episode reward: 24.7000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 1662.2,                last time consumption/overall running time: 513.1266s / 90879.3706 s
env0_first_0:                 episode reward: -25.1000,                 loss: 0.0231
env0_second_0:                 episode reward: 25.1000,                 loss: 0.0250
env1_first_0:                 episode reward: -25.0000,                 loss: nan
env1_second_0:                 episode reward: 25.0000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 1644.8,                last time consumption/overall running time: 522.2579s / 91401.6284 s
env0_first_0:                 episode reward: -26.4000,                 loss: 0.0245
env0_second_0:                 episode reward: 26.4000,                 loss: 0.0246
env1_first_0:                 episode reward: -24.1000,                 loss: nan
env1_second_0:                 episode reward: 24.1000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 1762.15,                last time consumption/overall running time: 549.5652s / 91951.1936 s
env0_first_0:                 episode reward: -25.8000,                 loss: 0.0247
env0_second_0:                 episode reward: 25.8000,                 loss: 0.0241
env1_first_0:                 episode reward: -24.5500,                 loss: nan
env1_second_0:                 episode reward: 24.5500,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 1673.6,                last time consumption/overall running time: 516.1888s / 92467.3824 s
env0_first_0:                 episode reward: -24.3500,                 loss: 0.0239
env0_second_0:                 episode reward: 24.3500,                 loss: 0.0243
env1_first_0:                 episode reward: -23.9500,                 loss: nan
env1_second_0:                 episode reward: 23.9500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 1644.65,                last time consumption/overall running time: 515.3072s / 92982.6897 s
env0_first_0:                 episode reward: -23.8500,                 loss: 0.0259
env0_second_0:                 episode reward: 23.8500,                 loss: 0.0262
env1_first_0:                 episode reward: -25.3000,                 loss: nan
env1_second_0:                 episode reward: 25.3000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 1626.2,                last time consumption/overall running time: 520.8015s / 93503.4912 s
env0_first_0:                 episode reward: -23.8000,                 loss: 0.0239
env0_second_0:                 episode reward: 23.8000,                 loss: 0.0256
env1_first_0:                 episode reward: -24.5500,                 loss: nan
env1_second_0:                 episode reward: 24.5500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 1693.9,                last time consumption/overall running time: 525.2449s / 94028.7361 s
env0_first_0:                 episode reward: -25.6000,                 loss: 0.0233
env0_second_0:                 episode reward: 25.6000,                 loss: 0.0234
env1_first_0:                 episode reward: -25.3500,                 loss: nan
env1_second_0:                 episode reward: 25.3500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 1668.0,                last time consumption/overall running time: 516.6793s / 94545.4154 s
env0_first_0:                 episode reward: -23.2000,                 loss: 0.0232
env0_second_0:                 episode reward: 23.2000,                 loss: 0.0231
env1_first_0:                 episode reward: -24.6000,                 loss: nan
env1_second_0:                 episode reward: 24.6000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 1712.5,                last time consumption/overall running time: 534.5122s / 95079.9276 s
env0_first_0:                 episode reward: -24.4500,                 loss: 0.0236
env0_second_0:                 episode reward: 24.4500,                 loss: 0.0238
env1_first_0:                 episode reward: -23.8500,                 loss: nan
env1_second_0:                 episode reward: 23.8500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 1707.7,                last time consumption/overall running time: 526.7510s / 95606.6786 s
env0_first_0:                 episode reward: -24.6000,                 loss: 0.0247
env0_second_0:                 episode reward: 24.6000,                 loss: 0.0257
env1_first_0:                 episode reward: -25.6500,                 loss: nan
env1_second_0:                 episode reward: 25.6500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 1697.05,                last time consumption/overall running time: 532.7805s / 96139.4591 s
env0_first_0:                 episode reward: -24.8000,                 loss: 0.0257
env0_second_0:                 episode reward: 24.8000,                 loss: 0.0255
env1_first_0:                 episode reward: -23.6500,                 loss: nan
env1_second_0:                 episode reward: 23.6500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 1701.25,                last time consumption/overall running time: 530.8280s / 96670.2871 s
env0_first_0:                 episode reward: -24.1000,                 loss: 0.0256
env0_second_0:                 episode reward: 24.1000,                 loss: 0.0259
env1_first_0:                 episode reward: -24.6500,                 loss: nan
env1_second_0:                 episode reward: 24.6500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 1727.5,                last time consumption/overall running time: 536.8638s / 97207.1509 s
env0_first_0:                 episode reward: -24.7500,                 loss: 0.0237
env0_second_0:                 episode reward: 24.7500,                 loss: 0.0247
env1_first_0:                 episode reward: -23.2000,                 loss: nan
env1_second_0:                 episode reward: 23.2000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 1748.3,                last time consumption/overall running time: 548.5048s / 97755.6557 s
env0_first_0:                 episode reward: -24.8000,                 loss: 0.0231
env0_second_0:                 episode reward: 24.8000,                 loss: 0.0240
env1_first_0:                 episode reward: -24.8000,                 loss: nan
env1_second_0:                 episode reward: 24.8000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 1651.95,                last time consumption/overall running time: 518.2345s / 98273.8901 s
env0_first_0:                 episode reward: -22.7500,                 loss: 0.0229
env0_second_0:                 episode reward: 22.7500,                 loss: 0.0224
env1_first_0:                 episode reward: -25.1000,                 loss: nan
env1_second_0:                 episode reward: 25.1000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 1705.0,                last time consumption/overall running time: 532.2225s / 98806.1127 s
env0_first_0:                 episode reward: -23.9500,                 loss: 0.0220
env0_second_0:                 episode reward: 23.9500,                 loss: 0.0215
env1_first_0:                 episode reward: -23.9500,                 loss: nan
env1_second_0:                 episode reward: 23.9500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 1707.4,                last time consumption/overall running time: 530.0769s / 99336.1895 s
env0_first_0:                 episode reward: -24.5500,                 loss: 0.0210
env0_second_0:                 episode reward: 24.5500,                 loss: 0.0230
env1_first_0:                 episode reward: -25.7500,                 loss: nan
env1_second_0:                 episode reward: 25.7500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 1652.75,                last time consumption/overall running time: 523.9117s / 99860.1013 s
env0_first_0:                 episode reward: -25.2500,                 loss: 0.0227
env0_second_0:                 episode reward: 25.2500,                 loss: 0.0242
env1_first_0:                 episode reward: -25.6500,                 loss: nan
env1_second_0:                 episode reward: 25.6500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 1695.5,                last time consumption/overall running time: 539.2945s / 100399.3958 s
env0_first_0:                 episode reward: -25.4000,                 loss: 0.0225
env0_second_0:                 episode reward: 25.4000,                 loss: 0.0234
env1_first_0:                 episode reward: -25.4000,                 loss: nan
env1_second_0:                 episode reward: 25.4000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 1700.25,                last time consumption/overall running time: 528.0302s / 100927.4259 s
env0_first_0:                 episode reward: -25.3500,                 loss: 0.0222
env0_second_0:                 episode reward: 25.3500,                 loss: 0.0237
env1_first_0:                 episode reward: -25.3000,                 loss: nan
env1_second_0:                 episode reward: 25.3000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 1663.35,                last time consumption/overall running time: 525.0560s / 101452.4820 s
env0_first_0:                 episode reward: -25.7000,                 loss: 0.0225
env0_second_0:                 episode reward: 25.7000,                 loss: 0.0243
env1_first_0:                 episode reward: -23.7500,                 loss: nan
env1_second_0:                 episode reward: 23.7500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 1677.45,                last time consumption/overall running time: 520.7933s / 101973.2753 s
env0_first_0:                 episode reward: -24.8000,                 loss: 0.0229
env0_second_0:                 episode reward: 24.8000,                 loss: 0.0238
env1_first_0:                 episode reward: -24.8500,                 loss: nan
env1_second_0:                 episode reward: 24.8500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 1651.85,                last time consumption/overall running time: 518.1285s / 102491.4038 s
env0_first_0:                 episode reward: -25.1500,                 loss: 0.0224
env0_second_0:                 episode reward: 25.1500,                 loss: 0.0226
env1_first_0:                 episode reward: -24.7500,                 loss: nan
env1_second_0:                 episode reward: 24.7500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 1694.35,                last time consumption/overall running time: 526.5228s / 103017.9266 s
env0_first_0:                 episode reward: -26.2500,                 loss: 0.0231
env0_second_0:                 episode reward: 26.2500,                 loss: 0.0227
env1_first_0:                 episode reward: -25.0000,                 loss: nan
env1_second_0:                 episode reward: 25.0000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 1626.45,                last time consumption/overall running time: 500.3700s / 103518.2967 s
env0_first_0:                 episode reward: -25.0500,                 loss: 0.0226
env0_second_0:                 episode reward: 25.0500,                 loss: 0.0233
env1_first_0:                 episode reward: -24.3500,                 loss: nan
env1_second_0:                 episode reward: 24.3500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 1642.55,                last time consumption/overall running time: 509.5986s / 104027.8952 s
env0_first_0:                 episode reward: -24.4000,                 loss: 0.0235
env0_second_0:                 episode reward: 24.4000,                 loss: 0.0233
env1_first_0:                 episode reward: -23.2500,                 loss: nan
env1_second_0:                 episode reward: 23.2500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 1671.65,                last time consumption/overall running time: 519.3835s / 104547.2788 s
env0_first_0:                 episode reward: -25.1500,                 loss: 0.0229
env0_second_0:                 episode reward: 25.1500,                 loss: 0.0229
env1_first_0:                 episode reward: -24.3000,                 loss: nan
env1_second_0:                 episode reward: 24.3000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 1613.8,                last time consumption/overall running time: 507.8359s / 105055.1147 s
env0_first_0:                 episode reward: -25.1000,                 loss: 0.0213
env0_second_0:                 episode reward: 25.1000,                 loss: 0.0216
env1_first_0:                 episode reward: -24.7000,                 loss: nan
env1_second_0:                 episode reward: 24.7000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 1669.1,                last time consumption/overall running time: 522.8099s / 105577.9245 s
env0_first_0:                 episode reward: -25.3500,                 loss: 0.0220
env0_second_0:                 episode reward: 25.3500,                 loss: 0.0228
env1_first_0:                 episode reward: -23.8000,                 loss: nan
env1_second_0:                 episode reward: 23.8000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 1598.45,                last time consumption/overall running time: 495.1181s / 106073.0426 s
env0_first_0:                 episode reward: -25.3500,                 loss: 0.0226
env0_second_0:                 episode reward: 25.3500,                 loss: 0.0247
env1_first_0:                 episode reward: -23.5500,                 loss: nan
env1_second_0:                 episode reward: 23.5500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 1612.05,                last time consumption/overall running time: 494.0329s / 106567.0755 s
env0_first_0:                 episode reward: -24.2500,                 loss: 0.0223
env0_second_0:                 episode reward: 24.2500,                 loss: 0.0235
env1_first_0:                 episode reward: -24.3000,                 loss: nan
env1_second_0:                 episode reward: 24.3000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 1717.75,                last time consumption/overall running time: 534.1178s / 107101.1933 s
env0_first_0:                 episode reward: -24.4500,                 loss: 0.0222
env0_second_0:                 episode reward: 24.4500,                 loss: 0.0227
env1_first_0:                 episode reward: -24.8500,                 loss: nan
env1_second_0:                 episode reward: 24.8500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 1645.3,                last time consumption/overall running time: 515.8199s / 107617.0132 s
env0_first_0:                 episode reward: -25.4000,                 loss: 0.0207
env0_second_0:                 episode reward: 25.4000,                 loss: 0.0213
env1_first_0:                 episode reward: -25.4000,                 loss: nan
env1_second_0:                 episode reward: 25.4000,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 1701.45,                last time consumption/overall running time: 531.0393s / 108148.0524 s
env0_first_0:                 episode reward: -22.1000,                 loss: 0.0226
env0_second_0:                 episode reward: 22.1000,                 loss: 0.0225
env1_first_0:                 episode reward: -24.5000,                 loss: nan
env1_second_0:                 episode reward: 24.5000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 1604.2,                last time consumption/overall running time: 502.1604s / 108650.2128 s
env0_first_0:                 episode reward: -24.6500,                 loss: 0.0227
env0_second_0:                 episode reward: 24.6500,                 loss: 0.0242
env1_first_0:                 episode reward: -24.0500,                 loss: nan
env1_second_0:                 episode reward: 24.0500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 1644.6,                last time consumption/overall running time: 515.0311s / 109165.2440 s
env0_first_0:                 episode reward: -23.9000,                 loss: 0.0223
env0_second_0:                 episode reward: 23.9000,                 loss: 0.0246
env1_first_0:                 episode reward: -23.9500,                 loss: nan
env1_second_0:                 episode reward: 23.9500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 1656.7,                last time consumption/overall running time: 513.9061s / 109679.1500 s
env0_first_0:                 episode reward: -24.1000,                 loss: 0.0234
env0_second_0:                 episode reward: 24.1000,                 loss: 0.0240
env1_first_0:                 episode reward: -24.9000,                 loss: nan
env1_second_0:                 episode reward: 24.9000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 1792.15,                last time consumption/overall running time: 565.6379s / 110244.7879 s
env0_first_0:                 episode reward: -25.1000,                 loss: 0.0245
env0_second_0:                 episode reward: 25.1000,                 loss: 0.0232
env1_first_0:                 episode reward: -24.4000,                 loss: nan
env1_second_0:                 episode reward: 24.4000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 1700.4,                last time consumption/overall running time: 529.5610s / 110774.3489 s
env0_first_0:                 episode reward: -23.9500,                 loss: 0.0255
env0_second_0:                 episode reward: 23.9500,                 loss: 0.0246
env1_first_0:                 episode reward: -23.2500,                 loss: nan
env1_second_0:                 episode reward: 23.2500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 1677.9,                last time consumption/overall running time: 523.0283s / 111297.3772 s
env0_first_0:                 episode reward: -23.7500,                 loss: 0.0263
env0_second_0:                 episode reward: 23.7500,                 loss: 0.0247
env1_first_0:                 episode reward: -24.9500,                 loss: nan
env1_second_0:                 episode reward: 24.9500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 1585.55,                last time consumption/overall running time: 485.2717s / 111782.6490 s
env0_first_0:                 episode reward: -24.0000,                 loss: 0.0251
env0_second_0:                 episode reward: 24.0000,                 loss: 0.0255
env1_first_0:                 episode reward: -24.6500,                 loss: nan
env1_second_0:                 episode reward: 24.6500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 1587.05,                last time consumption/overall running time: 490.1675s / 112272.8165 s
env0_first_0:                 episode reward: -24.4000,                 loss: 0.0231
env0_second_0:                 episode reward: 24.4000,                 loss: 0.0243
env1_first_0:                 episode reward: -24.5500,                 loss: nan
env1_second_0:                 episode reward: 24.5500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 1606.45,                last time consumption/overall running time: 499.2618s / 112772.0783 s
env0_first_0:                 episode reward: -24.9500,                 loss: 0.0232
env0_second_0:                 episode reward: 24.9500,                 loss: 0.0236
env1_first_0:                 episode reward: -24.0500,                 loss: nan
env1_second_0:                 episode reward: 24.0500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 1623.5,                last time consumption/overall running time: 518.1832s / 113290.2615 s
env0_first_0:                 episode reward: -25.7000,                 loss: 0.0218
env0_second_0:                 episode reward: 25.7000,                 loss: 0.0226
env1_first_0:                 episode reward: -24.0500,                 loss: nan
env1_second_0:                 episode reward: 24.0500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 1645.8,                last time consumption/overall running time: 519.6224s / 113809.8838 s
env0_first_0:                 episode reward: -25.4500,                 loss: 0.0222
env0_second_0:                 episode reward: 25.4500,                 loss: 0.0219
env1_first_0:                 episode reward: -24.4000,                 loss: nan
env1_second_0:                 episode reward: 24.4000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 1699.7,                last time consumption/overall running time: 535.7879s / 114345.6718 s
env0_first_0:                 episode reward: -24.4500,                 loss: 0.0222
env0_second_0:                 episode reward: 24.4500,                 loss: 0.0223
env1_first_0:                 episode reward: -24.0000,                 loss: nan
env1_second_0:                 episode reward: 24.0000,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 1659.4,                last time consumption/overall running time: 514.5479s / 114860.2197 s
env0_first_0:                 episode reward: -24.4500,                 loss: 0.0223
env0_second_0:                 episode reward: 24.4500,                 loss: 0.0229
env1_first_0:                 episode reward: -24.1000,                 loss: nan
env1_second_0:                 episode reward: 24.1000,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 1715.95,                last time consumption/overall running time: 537.0464s / 115397.2661 s
env0_first_0:                 episode reward: -24.6500,                 loss: 0.0232
env0_second_0:                 episode reward: 24.6500,                 loss: 0.0235
env1_first_0:                 episode reward: -22.7500,                 loss: nan
env1_second_0:                 episode reward: 22.7500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 1697.5,                last time consumption/overall running time: 525.7439s / 115923.0100 s
env0_first_0:                 episode reward: -25.2500,                 loss: 0.0230
env0_second_0:                 episode reward: 25.2500,                 loss: 0.0234
env1_first_0:                 episode reward: -24.8500,                 loss: nan
env1_second_0:                 episode reward: 24.8500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 1656.5,                last time consumption/overall running time: 506.0488s / 116429.0588 s
env0_first_0:                 episode reward: -24.6000,                 loss: 0.0227
env0_second_0:                 episode reward: 24.6000,                 loss: 0.0210
env1_first_0:                 episode reward: -24.8000,                 loss: nan
env1_second_0:                 episode reward: 24.8000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 1627.05,                last time consumption/overall running time: 518.7349s / 116947.7937 s
env0_first_0:                 episode reward: -23.8500,                 loss: 0.0209
env0_second_0:                 episode reward: 23.8500,                 loss: 0.0198
env1_first_0:                 episode reward: -23.7500,                 loss: nan
env1_second_0:                 episode reward: 23.7500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 1655.2,                last time consumption/overall running time: 512.6511s / 117460.4448 s
env0_first_0:                 episode reward: -24.4500,                 loss: 0.0217
env0_second_0:                 episode reward: 24.4500,                 loss: 0.0216
env1_first_0:                 episode reward: -23.5500,                 loss: nan
env1_second_0:                 episode reward: 23.5500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 1604.1,                last time consumption/overall running time: 499.8906s / 117960.3354 s
env0_first_0:                 episode reward: -25.0000,                 loss: 0.0220
env0_second_0:                 episode reward: 25.0000,                 loss: 0.0222
env1_first_0:                 episode reward: -23.7500,                 loss: nan
env1_second_0:                 episode reward: 23.7500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 1594.15,                last time consumption/overall running time: 496.4094s / 118456.7448 s
env0_first_0:                 episode reward: -24.2500,                 loss: 0.0217
env0_second_0:                 episode reward: 24.2500,                 loss: 0.0226
env1_first_0:                 episode reward: -24.9500,                 loss: nan
env1_second_0:                 episode reward: 24.9500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 1642.45,                last time consumption/overall running time: 510.8524s / 118967.5972 s
env0_first_0:                 episode reward: -24.2500,                 loss: 0.0208
env0_second_0:                 episode reward: 24.2500,                 loss: 0.0221
env1_first_0:                 episode reward: -24.2500,                 loss: nan
env1_second_0:                 episode reward: 24.2500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 1618.95,                last time consumption/overall running time: 505.8159s / 119473.4131 s
env0_first_0:                 episode reward: -23.7500,                 loss: 0.0206
env0_second_0:                 episode reward: 23.7500,                 loss: 0.0218
env1_first_0:                 episode reward: -24.0000,                 loss: nan
env1_second_0:                 episode reward: 24.0000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 1605.0,                last time consumption/overall running time: 505.7253s / 119979.1384 s
env0_first_0:                 episode reward: -24.6500,                 loss: 0.0213
env0_second_0:                 episode reward: 24.6500,                 loss: 0.0216
env1_first_0:                 episode reward: -24.4000,                 loss: nan
env1_second_0:                 episode reward: 24.4000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 1633.65,                last time consumption/overall running time: 510.2293s / 120489.3677 s
env0_first_0:                 episode reward: -25.6500,                 loss: 0.0223
env0_second_0:                 episode reward: 25.6500,                 loss: 0.0224
env1_first_0:                 episode reward: -24.4500,                 loss: nan
env1_second_0:                 episode reward: 24.4500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 1678.45,                last time consumption/overall running time: 520.7801s / 121010.1478 s
env0_first_0:                 episode reward: -24.9000,                 loss: 0.0224
env0_second_0:                 episode reward: 24.9000,                 loss: 0.0222
env1_first_0:                 episode reward: -24.7000,                 loss: nan
env1_second_0:                 episode reward: 24.7000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 1617.0,                last time consumption/overall running time: 515.4232s / 121525.5711 s
env0_first_0:                 episode reward: -24.8500,                 loss: 0.0228
env0_second_0:                 episode reward: 24.8500,                 loss: 0.0221
env1_first_0:                 episode reward: -23.1500,                 loss: nan
env1_second_0:                 episode reward: 23.1500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 1645.55,                last time consumption/overall running time: 518.8121s / 122044.3832 s
env0_first_0:                 episode reward: -23.4500,                 loss: 0.0212
env0_second_0:                 episode reward: 23.4500,                 loss: 0.0212
env1_first_0:                 episode reward: -23.6500,                 loss: nan
env1_second_0:                 episode reward: 23.6500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 1645.1,                last time consumption/overall running time: 512.9355s / 122557.3187 s
env0_first_0:                 episode reward: -24.1000,                 loss: 0.0219
env0_second_0:                 episode reward: 24.1000,                 loss: 0.0212
env1_first_0:                 episode reward: -23.6000,                 loss: nan
env1_second_0:                 episode reward: 23.6000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 1681.25,                last time consumption/overall running time: 522.0303s / 123079.3489 s
env0_first_0:                 episode reward: -23.8500,                 loss: 0.0221
env0_second_0:                 episode reward: 23.8500,                 loss: 0.0224
env1_first_0:                 episode reward: -24.4500,                 loss: nan
env1_second_0:                 episode reward: 24.4500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 1591.2,                last time consumption/overall running time: 493.7368s / 123573.0858 s
env0_first_0:                 episode reward: -23.0500,                 loss: 0.0217
env0_second_0:                 episode reward: 23.0500,                 loss: 0.0209
env1_first_0:                 episode reward: -23.3500,                 loss: nan
env1_second_0:                 episode reward: 23.3500,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 1655.2,                last time consumption/overall running time: 518.9684s / 124092.0542 s
env0_first_0:                 episode reward: -23.6500,                 loss: 0.0220
env0_second_0:                 episode reward: 23.6500,                 loss: 0.0217
env1_first_0:                 episode reward: -23.9500,                 loss: nan
env1_second_0:                 episode reward: 23.9500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 1642.25,                last time consumption/overall running time: 513.4577s / 124605.5118 s
env0_first_0:                 episode reward: -22.6000,                 loss: 0.0216
env0_second_0:                 episode reward: 22.6000,                 loss: 0.0213
env1_first_0:                 episode reward: -23.4000,                 loss: nan
env1_second_0:                 episode reward: 23.4000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 1680.2,                last time consumption/overall running time: 533.0623s / 125138.5741 s
env0_first_0:                 episode reward: -24.4500,                 loss: 0.0218
env0_second_0:                 episode reward: 24.4500,                 loss: 0.0217
env1_first_0:                 episode reward: -23.3000,                 loss: nan
env1_second_0:                 episode reward: 23.3000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 1632.4,                last time consumption/overall running time: 501.9698s / 125640.5439 s
env0_first_0:                 episode reward: -23.3500,                 loss: 0.0231
env0_second_0:                 episode reward: 23.3500,                 loss: 0.0209
env1_first_0:                 episode reward: -23.3000,                 loss: nan
env1_second_0:                 episode reward: 23.3000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 1619.0,                last time consumption/overall running time: 517.8188s / 126158.3627 s
env0_first_0:                 episode reward: -23.7500,                 loss: 0.0220
env0_second_0:                 episode reward: 23.7500,                 loss: 0.0205
env1_first_0:                 episode reward: -22.9000,                 loss: nan
env1_second_0:                 episode reward: 22.9000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 1609.8,                last time consumption/overall running time: 503.5457s / 126661.9084 s
env0_first_0:                 episode reward: -23.5500,                 loss: 0.0210
env0_second_0:                 episode reward: 23.5500,                 loss: 0.0186
env1_first_0:                 episode reward: -23.7000,                 loss: nan
env1_second_0:                 episode reward: 23.7000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 1653.9,                last time consumption/overall running time: 519.3558s / 127181.2642 s
env0_first_0:                 episode reward: -24.1500,                 loss: 0.0217
env0_second_0:                 episode reward: 24.1500,                 loss: 0.0204
env1_first_0:                 episode reward: -23.0500,                 loss: nan
env1_second_0:                 episode reward: 23.0500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 1673.65,                last time consumption/overall running time: 520.0717s / 127701.3358 s
env0_first_0:                 episode reward: -23.6500,                 loss: 0.0214
env0_second_0:                 episode reward: 23.6500,                 loss: 0.0199
env1_first_0:                 episode reward: -23.9500,                 loss: nan
env1_second_0:                 episode reward: 23.9500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 1600.65,                last time consumption/overall running time: 500.9235s / 128202.2593 s
env0_first_0:                 episode reward: -24.2500,                 loss: 0.0209
env0_second_0:                 episode reward: 24.2500,                 loss: 0.0208
env1_first_0:                 episode reward: -24.8500,                 loss: nan
env1_second_0:                 episode reward: 24.8500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 1672.45,                last time consumption/overall running time: 519.1894s / 128721.4487 s
env0_first_0:                 episode reward: -22.5500,                 loss: 0.0205
env0_second_0:                 episode reward: 22.5500,                 loss: 0.0214
env1_first_0:                 episode reward: -22.9500,                 loss: nan
env1_second_0:                 episode reward: 22.9500,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 1624.35,                last time consumption/overall running time: 502.2643s / 129223.7130 s
env0_first_0:                 episode reward: -23.3000,                 loss: 0.0212
env0_second_0:                 episode reward: 23.3000,                 loss: 0.0206
env1_first_0:                 episode reward: -24.1500,                 loss: nan
env1_second_0:                 episode reward: 24.1500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 1609.25,                last time consumption/overall running time: 497.9960s / 129721.7090 s
env0_first_0:                 episode reward: -23.3000,                 loss: 0.0203
env0_second_0:                 episode reward: 23.3000,                 loss: 0.0213
env1_first_0:                 episode reward: -23.2000,                 loss: nan
env1_second_0:                 episode reward: 23.2000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 1613.45,                last time consumption/overall running time: 518.5055s / 130240.2146 s
env0_first_0:                 episode reward: -24.0500,                 loss: 0.0204
env0_second_0:                 episode reward: 24.0500,                 loss: 0.0210
env1_first_0:                 episode reward: -23.8000,                 loss: nan
env1_second_0:                 episode reward: 23.8000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 1642.55,                last time consumption/overall running time: 508.1238s / 130748.3384 s
env0_first_0:                 episode reward: -24.0000,                 loss: 0.0202
env0_second_0:                 episode reward: 24.0000,                 loss: 0.0210
env1_first_0:                 episode reward: -24.0500,                 loss: nan
env1_second_0:                 episode reward: 24.0500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 1673.75,                last time consumption/overall running time: 522.3390s / 131270.6774 s
env0_first_0:                 episode reward: -25.6500,                 loss: 0.0215
env0_second_0:                 episode reward: 25.6500,                 loss: 0.0213
env1_first_0:                 episode reward: -24.0000,                 loss: nan
env1_second_0:                 episode reward: 24.0000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 1708.4,                last time consumption/overall running time: 533.6204s / 131804.2978 s
env0_first_0:                 episode reward: -24.2500,                 loss: 0.0226
env0_second_0:                 episode reward: 24.2500,                 loss: 0.0215
env1_first_0:                 episode reward: -23.8000,                 loss: nan
env1_second_0:                 episode reward: 23.8000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 1637.8,                last time consumption/overall running time: 505.9428s / 132310.2406 s
env0_first_0:                 episode reward: -23.9000,                 loss: 0.0231
env0_second_0:                 episode reward: 23.9000,                 loss: 0.0213
env1_first_0:                 episode reward: -24.3000,                 loss: nan
env1_second_0:                 episode reward: 24.3000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 1668.1,                last time consumption/overall running time: 516.1210s / 132826.3616 s
env0_first_0:                 episode reward: -24.5000,                 loss: 0.0223
env0_second_0:                 episode reward: 24.5000,                 loss: 0.0207
env1_first_0:                 episode reward: -23.2500,                 loss: nan
env1_second_0:                 episode reward: 23.2500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 1637.1,                last time consumption/overall running time: 522.4127s / 133348.7743 s
env0_first_0:                 episode reward: -24.1000,                 loss: 0.0215
env0_second_0:                 episode reward: 24.1000,                 loss: 0.0207
env1_first_0:                 episode reward: -23.9000,                 loss: nan
env1_second_0:                 episode reward: 23.9000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 1646.7,                last time consumption/overall running time: 515.1910s / 133863.9653 s
env0_first_0:                 episode reward: -24.3000,                 loss: 0.0216
env0_second_0:                 episode reward: 24.3000,                 loss: 0.0195
env1_first_0:                 episode reward: -24.0000,                 loss: nan
env1_second_0:                 episode reward: 24.0000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 1669.65,                last time consumption/overall running time: 521.0405s / 134385.0058 s
env0_first_0:                 episode reward: -24.9500,                 loss: 0.0209
env0_second_0:                 episode reward: 24.9500,                 loss: 0.0199
env1_first_0:                 episode reward: -24.0500,                 loss: nan
env1_second_0:                 episode reward: 24.0500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 1574.65,                last time consumption/overall running time: 485.3195s / 134870.3253 s
env0_first_0:                 episode reward: -23.2000,                 loss: 0.0210
env0_second_0:                 episode reward: 23.2000,                 loss: 0.0206
env1_first_0:                 episode reward: -24.3000,                 loss: nan
env1_second_0:                 episode reward: 24.3000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 1708.7,                last time consumption/overall running time: 528.3643s / 135398.6896 s
env0_first_0:                 episode reward: -23.0000,                 loss: 0.0217
env0_second_0:                 episode reward: 23.0000,                 loss: 0.0211
env1_first_0:                 episode reward: -24.3500,                 loss: nan
env1_second_0:                 episode reward: 24.3500,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 1643.35,                last time consumption/overall running time: 503.5384s / 135902.2280 s
env0_first_0:                 episode reward: -23.7500,                 loss: 0.0224
env0_second_0:                 episode reward: 23.7500,                 loss: 0.0224
env1_first_0:                 episode reward: -24.4000,                 loss: nan
env1_second_0:                 episode reward: 24.4000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 1695.95,                last time consumption/overall running time: 523.9243s / 136426.1522 s
env0_first_0:                 episode reward: -24.4500,                 loss: 0.0223
env0_second_0:                 episode reward: 24.4500,                 loss: 0.0226
env1_first_0:                 episode reward: -25.5000,                 loss: nan
env1_second_0:                 episode reward: 25.5000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 1693.15,                last time consumption/overall running time: 520.6014s / 136946.7536 s
env0_first_0:                 episode reward: -25.1500,                 loss: 0.0228
env0_second_0:                 episode reward: 25.1500,                 loss: 0.0239
env1_first_0:                 episode reward: -24.2500,                 loss: nan
env1_second_0:                 episode reward: 24.2500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 1638.2,                last time consumption/overall running time: 519.3195s / 137466.0731 s
env0_first_0:                 episode reward: -23.1500,                 loss: 0.0221
env0_second_0:                 episode reward: 23.1500,                 loss: 0.0235
env1_first_0:                 episode reward: -24.6000,                 loss: nan
env1_second_0:                 episode reward: 24.6000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 1635.9,                last time consumption/overall running time: 520.0010s / 137986.0740 s
env0_first_0:                 episode reward: -25.4000,                 loss: 0.0221
env0_second_0:                 episode reward: 25.4000,                 loss: 0.0226
env1_first_0:                 episode reward: -23.9000,                 loss: nan
env1_second_0:                 episode reward: 23.9000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 1581.0,                last time consumption/overall running time: 497.2100s / 138483.2840 s
env0_first_0:                 episode reward: -24.8000,                 loss: 0.0218
env0_second_0:                 episode reward: 24.8000,                 loss: 0.0220
env1_first_0:                 episode reward: -24.3000,                 loss: nan
env1_second_0:                 episode reward: 24.3000,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 1615.4,                last time consumption/overall running time: 506.6437s / 138989.9277 s
env0_first_0:                 episode reward: -24.9500,                 loss: 0.0210
env0_second_0:                 episode reward: 24.9500,                 loss: 0.0204
env1_first_0:                 episode reward: -24.5000,                 loss: nan
env1_second_0:                 episode reward: 24.5000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 1585.9,                last time consumption/overall running time: 491.0690s / 139480.9967 s
env0_first_0:                 episode reward: -24.8000,                 loss: 0.0201
env0_second_0:                 episode reward: 24.8000,                 loss: 0.0197
env1_first_0:                 episode reward: -25.3000,                 loss: nan
env1_second_0:                 episode reward: 25.3000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 1528.3,                last time consumption/overall running time: 473.6460s / 139954.6427 s
env0_first_0:                 episode reward: -25.3500,                 loss: 0.0181
env0_second_0:                 episode reward: 25.3500,                 loss: 0.0186
env1_first_0:                 episode reward: -24.7500,                 loss: nan
env1_second_0:                 episode reward: 24.7500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 1562.1,                last time consumption/overall running time: 488.0206s / 140442.6633 s
env0_first_0:                 episode reward: -24.7500,                 loss: 0.0178
env0_second_0:                 episode reward: 24.7500,                 loss: 0.0185
env1_first_0:                 episode reward: -23.3500,                 loss: nan
env1_second_0:                 episode reward: 23.3500,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 1622.15,                last time consumption/overall running time: 503.7924s / 140946.4557 s
env0_first_0:                 episode reward: -25.0500,                 loss: 0.0190
env0_second_0:                 episode reward: 25.0500,                 loss: 0.0182
env1_first_0:                 episode reward: -24.4000,                 loss: nan
env1_second_0:                 episode reward: 24.4000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 1613.7,                last time consumption/overall running time: 508.5993s / 141455.0549 s
env0_first_0:                 episode reward: -24.4500,                 loss: 0.0202
env0_second_0:                 episode reward: 24.4500,                 loss: 0.0197
env1_first_0:                 episode reward: -24.0000,                 loss: nan
env1_second_0:                 episode reward: 24.0000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 1681.1,                last time consumption/overall running time: 522.0397s / 141977.0946 s
env0_first_0:                 episode reward: -24.8000,                 loss: 0.0220
env0_second_0:                 episode reward: 24.8000,                 loss: 0.0210
env1_first_0:                 episode reward: -24.6500,                 loss: nan
env1_second_0:                 episode reward: 24.6500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 1642.15,                last time consumption/overall running time: 525.6026s / 142502.6972 s
env0_first_0:                 episode reward: -24.5000,                 loss: 0.0220
env0_second_0:                 episode reward: 24.5000,                 loss: 0.0228
env1_first_0:                 episode reward: -24.3500,                 loss: nan
env1_second_0:                 episode reward: 24.3500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 1683.75,                last time consumption/overall running time: 528.1663s / 143030.8635 s
env0_first_0:                 episode reward: -25.0500,                 loss: 0.0231
env0_second_0:                 episode reward: 25.0500,                 loss: 0.0224
env1_first_0:                 episode reward: -24.6500,                 loss: nan
env1_second_0:                 episode reward: 24.6500,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 1691.55,                last time consumption/overall running time: 532.1703s / 143563.0338 s
env0_first_0:                 episode reward: -23.6000,                 loss: 0.0239
env0_second_0:                 episode reward: 23.6000,                 loss: 0.0226
env1_first_0:                 episode reward: -24.3000,                 loss: nan
env1_second_0:                 episode reward: 24.3000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 1642.15,                last time consumption/overall running time: 509.4481s / 144072.4818 s
env0_first_0:                 episode reward: -25.0500,                 loss: 0.0234
env0_second_0:                 episode reward: 25.0500,                 loss: 0.0224
env1_first_0:                 episode reward: -24.2000,                 loss: nan
env1_second_0:                 episode reward: 24.2000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 1623.75,                last time consumption/overall running time: 503.5714s / 144576.0532 s
env0_first_0:                 episode reward: -24.9000,                 loss: 0.0215
env0_second_0:                 episode reward: 24.9000,                 loss: 0.0223
env1_first_0:                 episode reward: -24.7000,                 loss: nan
env1_second_0:                 episode reward: 24.7000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 1593.1,                last time consumption/overall running time: 501.5732s / 145077.6264 s
env0_first_0:                 episode reward: -24.6500,                 loss: 0.0192
env0_second_0:                 episode reward: 24.6500,                 loss: 0.0202
env1_first_0:                 episode reward: -24.5000,                 loss: nan
env1_second_0:                 episode reward: 24.5000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 1669.7,                last time consumption/overall running time: 511.3065s / 145588.9329 s
env0_first_0:                 episode reward: -25.4000,                 loss: 0.0188
env0_second_0:                 episode reward: 25.4000,                 loss: 0.0195
env1_first_0:                 episode reward: -25.7500,                 loss: nan
env1_second_0:                 episode reward: 25.7500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 1698.9,                last time consumption/overall running time: 529.4063s / 146118.3392 s
env0_first_0:                 episode reward: -23.8000,                 loss: 0.0203
env0_second_0:                 episode reward: 23.8000,                 loss: 0.0206
env1_first_0:                 episode reward: -24.7500,                 loss: nan
env1_second_0:                 episode reward: 24.7500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 1678.8,                last time consumption/overall running time: 512.1288s / 146630.4680 s
env0_first_0:                 episode reward: -23.9500,                 loss: 0.0212
env0_second_0:                 episode reward: 23.9500,                 loss: 0.0226
env1_first_0:                 episode reward: -24.0000,                 loss: nan
env1_second_0:                 episode reward: 24.0000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 1614.15,                last time consumption/overall running time: 490.7180s / 147121.1860 s
env0_first_0:                 episode reward: -24.5500,                 loss: 0.0219
env0_second_0:                 episode reward: 24.5500,                 loss: 0.0233
env1_first_0:                 episode reward: -22.8000,                 loss: nan
env1_second_0:                 episode reward: 22.8000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 1715.3,                last time consumption/overall running time: 524.0241s / 147645.2101 s
env0_first_0:                 episode reward: -23.1000,                 loss: 0.0223
env0_second_0:                 episode reward: 23.1000,                 loss: 0.0233
env1_first_0:                 episode reward: -23.6000,                 loss: nan
env1_second_0:                 episode reward: 23.6000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 1694.4,                last time consumption/overall running time: 516.4568s / 148161.6669 s
env0_first_0:                 episode reward: -21.8000,                 loss: 0.0246
env0_second_0:                 episode reward: 21.8000,                 loss: 0.0236
env1_first_0:                 episode reward: -24.9500,                 loss: nan
env1_second_0:                 episode reward: 24.9500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 1702.1,                last time consumption/overall running time: 540.3694s / 148702.0363 s
env0_first_0:                 episode reward: -23.9500,                 loss: 0.0239
env0_second_0:                 episode reward: 23.9500,                 loss: 0.0240
env1_first_0:                 episode reward: -25.0500,                 loss: nan
env1_second_0:                 episode reward: 25.0500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 1727.15,                last time consumption/overall running time: 536.1002s / 149238.1364 s
env0_first_0:                 episode reward: -24.6000,                 loss: 0.0239
env0_second_0:                 episode reward: 24.6000,                 loss: 0.0256
env1_first_0:                 episode reward: -25.4000,                 loss: nan
env1_second_0:                 episode reward: 25.4000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 1703.15,                last time consumption/overall running time: 531.3049s / 149769.4414 s
env0_first_0:                 episode reward: -24.1000,                 loss: 0.0245
env0_second_0:                 episode reward: 24.1000,                 loss: 0.0231
env1_first_0:                 episode reward: -24.7500,                 loss: nan
env1_second_0:                 episode reward: 24.7500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 1734.7,                last time consumption/overall running time: 561.0104s / 150330.4517 s
env0_first_0:                 episode reward: -24.1000,                 loss: 0.0224
env0_second_0:                 episode reward: 24.1000,                 loss: 0.0230
env1_first_0:                 episode reward: -25.0500,                 loss: nan
env1_second_0:                 episode reward: 25.0500,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 1658.75,                last time consumption/overall running time: 530.0113s / 150860.4631 s
env0_first_0:                 episode reward: -25.1000,                 loss: 0.0221
env0_second_0:                 episode reward: 25.1000,                 loss: 0.0238
env1_first_0:                 episode reward: -24.0000,                 loss: nan
env1_second_0:                 episode reward: 24.0000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 1734.85,                last time consumption/overall running time: 544.0559s / 151404.5190 s
env0_first_0:                 episode reward: -23.8500,                 loss: 0.0224
env0_second_0:                 episode reward: 23.8500,                 loss: 0.0234
env1_first_0:                 episode reward: -23.9000,                 loss: nan
env1_second_0:                 episode reward: 23.9000,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 1736.45,                last time consumption/overall running time: 535.2545s / 151939.7734 s
env0_first_0:                 episode reward: -24.9500,                 loss: 0.0233
env0_second_0:                 episode reward: 24.9500,                 loss: 0.0236
env1_first_0:                 episode reward: -25.2500,                 loss: nan
env1_second_0:                 episode reward: 25.2500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 1638.0,                last time consumption/overall running time: 515.7477s / 152455.5212 s
env0_first_0:                 episode reward: -24.7000,                 loss: 0.0219
env0_second_0:                 episode reward: 24.7000,                 loss: 0.0223
env1_first_0:                 episode reward: -24.3500,                 loss: nan
env1_second_0:                 episode reward: 24.3500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 1716.75,                last time consumption/overall running time: 522.0779s / 152977.5991 s
env0_first_0:                 episode reward: -25.9500,                 loss: 0.0222
env0_second_0:                 episode reward: 25.9500,                 loss: 0.0229
env1_first_0:                 episode reward: -25.1500,                 loss: nan
env1_second_0:                 episode reward: 25.1500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 1698.4,                last time consumption/overall running time: 517.3214s / 153494.9205 s
env0_first_0:                 episode reward: -25.9500,                 loss: 0.0219
env0_second_0:                 episode reward: 25.9500,                 loss: 0.0218
env1_first_0:                 episode reward: -26.3000,                 loss: nan
env1_second_0:                 episode reward: 26.3000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 1695.05,                last time consumption/overall running time: 524.8378s / 154019.7582 s
env0_first_0:                 episode reward: -24.8500,                 loss: 0.0217
env0_second_0:                 episode reward: 24.8500,                 loss: 0.0224
env1_first_0:                 episode reward: -25.0500,                 loss: nan
env1_second_0:                 episode reward: 25.0500,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 1647.3,                last time consumption/overall running time: 509.5906s / 154529.3488 s
env0_first_0:                 episode reward: -23.2500,                 loss: 0.0220
env0_second_0:                 episode reward: 23.2500,                 loss: 0.0217
env1_first_0:                 episode reward: -24.5000,                 loss: nan
env1_second_0:                 episode reward: 24.5000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 1677.25,                last time consumption/overall running time: 511.4970s / 155040.8458 s
env0_first_0:                 episode reward: -25.8500,                 loss: 0.0223
env0_second_0:                 episode reward: 25.8500,                 loss: 0.0215
env1_first_0:                 episode reward: -24.9000,                 loss: nan
env1_second_0:                 episode reward: 24.9000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 1726.35,                last time consumption/overall running time: 527.5849s / 155568.4308 s
env0_first_0:                 episode reward: -25.5000,                 loss: 0.0225
env0_second_0:                 episode reward: 25.5000,                 loss: 0.0218
env1_first_0:                 episode reward: -25.9000,                 loss: nan
env1_second_0:                 episode reward: 25.9000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 1626.55,                last time consumption/overall running time: 504.6482s / 156073.0789 s
env0_first_0:                 episode reward: -24.3000,                 loss: 0.0217
env0_second_0:                 episode reward: 24.3000,                 loss: 0.0207
env1_first_0:                 episode reward: -26.0500,                 loss: nan
env1_second_0:                 episode reward: 26.0500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 1615.25,                last time consumption/overall running time: 498.9378s / 156572.0167 s
env0_first_0:                 episode reward: -23.2000,                 loss: 0.0217
env0_second_0:                 episode reward: 23.2000,                 loss: 0.0205
env1_first_0:                 episode reward: -24.8500,                 loss: nan
env1_second_0:                 episode reward: 24.8500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 1560.1,                last time consumption/overall running time: 474.8628s / 157046.8796 s
env0_first_0:                 episode reward: -24.6500,                 loss: 0.0205
env0_second_0:                 episode reward: 24.6500,                 loss: 0.0195
env1_first_0:                 episode reward: -24.5500,                 loss: nan
env1_second_0:                 episode reward: 24.5500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 1629.95,                last time consumption/overall running time: 500.7824s / 157547.6620 s
env0_first_0:                 episode reward: -25.1500,                 loss: 0.0195
env0_second_0:                 episode reward: 25.1500,                 loss: 0.0194
env1_first_0:                 episode reward: -25.1000,                 loss: nan
env1_second_0:                 episode reward: 25.1000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 1639.65,                last time consumption/overall running time: 524.2290s / 158071.8910 s
env0_first_0:                 episode reward: -26.0500,                 loss: 0.0194
env0_second_0:                 episode reward: 26.0500,                 loss: 0.0191
env1_first_0:                 episode reward: -24.6000,                 loss: nan
env1_second_0:                 episode reward: 24.6000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 1558.7,                last time consumption/overall running time: 474.5096s / 158546.4006 s
env0_first_0:                 episode reward: -24.3500,                 loss: 0.0193
env0_second_0:                 episode reward: 24.3500,                 loss: 0.0205
env1_first_0:                 episode reward: -25.4500,                 loss: nan
env1_second_0:                 episode reward: 25.4500,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 1636.8,                last time consumption/overall running time: 494.2432s / 159040.6438 s
env0_first_0:                 episode reward: -25.1500,                 loss: 0.0214
env0_second_0:                 episode reward: 25.1500,                 loss: 0.0207
env1_first_0:                 episode reward: -23.8500,                 loss: nan
env1_second_0:                 episode reward: 23.8500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 1678.25,                last time consumption/overall running time: 515.7607s / 159556.4045 s
env0_first_0:                 episode reward: -25.3500,                 loss: 0.0215
env0_second_0:                 episode reward: 25.3500,                 loss: 0.0208
env1_first_0:                 episode reward: -24.8500,                 loss: nan
env1_second_0:                 episode reward: 24.8500,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 1667.9,                last time consumption/overall running time: 509.0684s / 160065.4729 s
env0_first_0:                 episode reward: -25.0000,                 loss: 0.0228
env0_second_0:                 episode reward: 25.0000,                 loss: 0.0221
env1_first_0:                 episode reward: -24.2500,                 loss: nan
env1_second_0:                 episode reward: 24.2500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 1643.85,                last time consumption/overall running time: 513.3547s / 160578.8275 s
env0_first_0:                 episode reward: -24.0000,                 loss: 0.0229
env0_second_0:                 episode reward: 24.0000,                 loss: 0.0220
env1_first_0:                 episode reward: -23.4500,                 loss: nan
env1_second_0:                 episode reward: 23.4500,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 1633.3,                last time consumption/overall running time: 503.7905s / 161082.6180 s
env0_first_0:                 episode reward: -24.5500,                 loss: 0.0219
env0_second_0:                 episode reward: 24.5500,                 loss: 0.0205
env1_first_0:                 episode reward: -23.9500,                 loss: nan
env1_second_0:                 episode reward: 23.9500,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 1631.1,                last time consumption/overall running time: 506.0859s / 161588.7039 s
env0_first_0:                 episode reward: -25.5000,                 loss: 0.0206
env0_second_0:                 episode reward: 25.5000,                 loss: 0.0197
env1_first_0:                 episode reward: -23.5500,                 loss: nan
env1_second_0:                 episode reward: 23.5500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 1637.05,                last time consumption/overall running time: 503.1353s / 162091.8392 s
env0_first_0:                 episode reward: -23.6500,                 loss: 0.0206
env0_second_0:                 episode reward: 23.6500,                 loss: 0.0208
env1_first_0:                 episode reward: -24.0000,                 loss: nan
env1_second_0:                 episode reward: 24.0000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 1661.65,                last time consumption/overall running time: 516.6295s / 162608.4687 s
env0_first_0:                 episode reward: -24.8500,                 loss: 0.0214
env0_second_0:                 episode reward: 24.8500,                 loss: 0.0217
env1_first_0:                 episode reward: -25.6000,                 loss: nan
env1_second_0:                 episode reward: 25.6000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 1705.35,                last time consumption/overall running time: 517.5552s / 163126.0239 s
env0_first_0:                 episode reward: -24.6500,                 loss: 0.0221
env0_second_0:                 episode reward: 24.6500,                 loss: 0.0220
env1_first_0:                 episode reward: -25.4000,                 loss: nan
env1_second_0:                 episode reward: 25.4000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 1750.5,                last time consumption/overall running time: 540.1557s / 163666.1796 s
env0_first_0:                 episode reward: -24.6000,                 loss: 0.0223
env0_second_0:                 episode reward: 24.6000,                 loss: 0.0234
env1_first_0:                 episode reward: -25.8500,                 loss: nan
env1_second_0:                 episode reward: 25.8500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 1619.15,                last time consumption/overall running time: 511.8052s / 164177.9848 s
env0_first_0:                 episode reward: -24.1000,                 loss: 0.0221
env0_second_0:                 episode reward: 24.1000,                 loss: 0.0232
env1_first_0:                 episode reward: -24.5000,                 loss: nan
env1_second_0:                 episode reward: 24.5000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 1664.35,                last time consumption/overall running time: 508.9115s / 164686.8963 s
env0_first_0:                 episode reward: -24.1000,                 loss: 0.0224
env0_second_0:                 episode reward: 24.1000,                 loss: 0.0236
env1_first_0:                 episode reward: -25.9500,                 loss: nan
env1_second_0:                 episode reward: 25.9500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 1684.15,                last time consumption/overall running time: 512.4306s / 165199.3269 s
env0_first_0:                 episode reward: -25.1000,                 loss: 0.0234
env0_second_0:                 episode reward: 25.1000,                 loss: 0.0232
env1_first_0:                 episode reward: -24.9500,                 loss: nan
env1_second_0:                 episode reward: 24.9500,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 1801.2,                last time consumption/overall running time: 553.6441s / 165752.9710 s
env0_first_0:                 episode reward: -24.8000,                 loss: 0.0237
env0_second_0:                 episode reward: 24.8000,                 loss: 0.0229
env1_first_0:                 episode reward: -22.2500,                 loss: nan
env1_second_0:                 episode reward: 22.2500,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 1750.0,                last time consumption/overall running time: 536.3375s / 166289.3085 s
env0_first_0:                 episode reward: -24.7000,                 loss: 0.0246
env0_second_0:                 episode reward: 24.7000,                 loss: 0.0233
env1_first_0:                 episode reward: -25.1500,                 loss: nan
env1_second_0:                 episode reward: 25.1500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 1730.65,                last time consumption/overall running time: 534.9830s / 166824.2914 s
env0_first_0:                 episode reward: -24.3500,                 loss: 0.0239
env0_second_0:                 episode reward: 24.3500,                 loss: 0.0245
env1_first_0:                 episode reward: -24.9000,                 loss: nan
env1_second_0:                 episode reward: 24.9000,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 1665.5,                last time consumption/overall running time: 507.5367s / 167331.8282 s
env0_first_0:                 episode reward: -23.4000,                 loss: 0.0222
env0_second_0:                 episode reward: 23.4000,                 loss: 0.0233
env1_first_0:                 episode reward: -23.3500,                 loss: nan
env1_second_0:                 episode reward: 23.3500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 1622.5,                last time consumption/overall running time: 497.5702s / 167829.3984 s
env0_first_0:                 episode reward: -23.8000,                 loss: 0.0231
env0_second_0:                 episode reward: 23.8000,                 loss: 0.0227
env1_first_0:                 episode reward: -24.3000,                 loss: nan
env1_second_0:                 episode reward: 24.3000,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 1583.55,                last time consumption/overall running time: 479.5500s / 168308.9484 s
env0_first_0:                 episode reward: -24.5500,                 loss: 0.0213
env0_second_0:                 episode reward: 24.5500,                 loss: 0.0216
env1_first_0:                 episode reward: -23.4500,                 loss: nan
env1_second_0:                 episode reward: 23.4500,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 1591.3,                last time consumption/overall running time: 481.9475s / 168790.8959 s
env0_first_0:                 episode reward: -23.9500,                 loss: 0.0188
env0_second_0:                 episode reward: 23.9500,                 loss: 0.0191
env1_first_0:                 episode reward: -24.8000,                 loss: nan
env1_second_0:                 episode reward: 24.8000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 1579.1,                last time consumption/overall running time: 478.1214s / 169269.0173 s
env0_first_0:                 episode reward: -23.9500,                 loss: 0.0178
env0_second_0:                 episode reward: 23.9500,                 loss: 0.0171
env1_first_0:                 episode reward: -23.6500,                 loss: nan
env1_second_0:                 episode reward: 23.6500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 1581.25,                last time consumption/overall running time: 474.5906s / 169743.6079 s
env0_first_0:                 episode reward: -24.0500,                 loss: 0.0185
env0_second_0:                 episode reward: 24.0500,                 loss: 0.0174
env1_first_0:                 episode reward: -25.1500,                 loss: nan
env1_second_0:                 episode reward: 25.1500,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 1626.1,                last time consumption/overall running time: 488.4987s / 170232.1066 s
env0_first_0:                 episode reward: -24.6500,                 loss: 0.0187
env0_second_0:                 episode reward: 24.6500,                 loss: 0.0180
env1_first_0:                 episode reward: -23.3500,                 loss: nan
env1_second_0:                 episode reward: 23.3500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 1613.0,                last time consumption/overall running time: 491.3143s / 170723.4209 s
env0_first_0:                 episode reward: -26.0000,                 loss: 0.0208
env0_second_0:                 episode reward: 26.0000,                 loss: 0.0190
env1_first_0:                 episode reward: -24.2500,                 loss: nan
env1_second_0:                 episode reward: 24.2500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 1655.1,                last time consumption/overall running time: 507.6088s / 171231.0297 s
env0_first_0:                 episode reward: -24.0000,                 loss: 0.0201
env0_second_0:                 episode reward: 24.0000,                 loss: 0.0208
env1_first_0:                 episode reward: -24.4500,                 loss: nan
env1_second_0:                 episode reward: 24.4500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 1652.95,                last time consumption/overall running time: 508.9112s / 171739.9409 s
env0_first_0:                 episode reward: -24.0000,                 loss: 0.0198
env0_second_0:                 episode reward: 24.0000,                 loss: 0.0200
env1_first_0:                 episode reward: -25.3000,                 loss: nan
env1_second_0:                 episode reward: 25.3000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 1611.85,                last time consumption/overall running time: 494.3297s / 172234.2706 s
env0_first_0:                 episode reward: -24.6500,                 loss: 0.0199
env0_second_0:                 episode reward: 24.6500,                 loss: 0.0200
env1_first_0:                 episode reward: -24.3000,                 loss: nan
env1_second_0:                 episode reward: 24.3000,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 1617.45,                last time consumption/overall running time: 496.5237s / 172730.7943 s
env0_first_0:                 episode reward: -24.7500,                 loss: 0.0191
env0_second_0:                 episode reward: 24.7500,                 loss: 0.0201
env1_first_0:                 episode reward: -23.4000,                 loss: nan
env1_second_0:                 episode reward: 23.4000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 1583.85,                last time consumption/overall running time: 490.8661s / 173221.6604 s
env0_first_0:                 episode reward: -24.8000,                 loss: 0.0196
env0_second_0:                 episode reward: 24.8000,                 loss: 0.0203
env1_first_0:                 episode reward: -23.9000,                 loss: nan
env1_second_0:                 episode reward: 23.9000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 1638.55,                last time consumption/overall running time: 502.6374s / 173724.2978 s
env0_first_0:                 episode reward: -23.1500,                 loss: 0.0212
env0_second_0:                 episode reward: 23.1500,                 loss: 0.0199
env1_first_0:                 episode reward: -24.7500,                 loss: nan
env1_second_0:                 episode reward: 24.7500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 1691.85,                last time consumption/overall running time: 518.2410s / 174242.5389 s
env0_first_0:                 episode reward: -23.7500,                 loss: 0.0214
env0_second_0:                 episode reward: 23.7500,                 loss: 0.0195
env1_first_0:                 episode reward: -23.9500,                 loss: nan
env1_second_0:                 episode reward: 23.9500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 1672.45,                last time consumption/overall running time: 521.1307s / 174763.6695 s
env0_first_0:                 episode reward: -23.3500,                 loss: 0.0221
env0_second_0:                 episode reward: 23.3500,                 loss: 0.0207
env1_first_0:                 episode reward: -25.4000,                 loss: nan
env1_second_0:                 episode reward: 25.4000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 1712.15,                last time consumption/overall running time: 524.0920s / 175287.7616 s
env0_first_0:                 episode reward: -24.3500,                 loss: 0.0228
env0_second_0:                 episode reward: 24.3500,                 loss: 0.0219
env1_first_0:                 episode reward: -25.0000,                 loss: nan
env1_second_0:                 episode reward: 25.0000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 1712.55,                last time consumption/overall running time: 515.4586s / 175803.2202 s
env0_first_0:                 episode reward: -24.3000,                 loss: 0.0236
env0_second_0:                 episode reward: 24.3000,                 loss: 0.0218
env1_first_0:                 episode reward: -24.7500,                 loss: nan
env1_second_0:                 episode reward: 24.7500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 1628.8,                last time consumption/overall running time: 501.2311s / 176304.4513 s
env0_first_0:                 episode reward: -25.2500,                 loss: 0.0221
env0_second_0:                 episode reward: 25.2500,                 loss: 0.0230
env1_first_0:                 episode reward: -25.1000,                 loss: nan
env1_second_0:                 episode reward: 25.1000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 1616.65,                last time consumption/overall running time: 488.0481s / 176792.4994 s
env0_first_0:                 episode reward: -25.2000,                 loss: 0.0215
env0_second_0:                 episode reward: 25.2000,                 loss: 0.0213
env1_first_0:                 episode reward: -23.5000,                 loss: nan
env1_second_0:                 episode reward: 23.5000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 1591.75,                last time consumption/overall running time: 481.5207s / 177274.0201 s
env0_first_0:                 episode reward: -24.3000,                 loss: 0.0203
env0_second_0:                 episode reward: 24.3000,                 loss: 0.0200
env1_first_0:                 episode reward: -25.1000,                 loss: nan
env1_second_0:                 episode reward: 25.1000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 1632.5,                last time consumption/overall running time: 492.7573s / 177766.7774 s
env0_first_0:                 episode reward: -24.5000,                 loss: 0.0195
env0_second_0:                 episode reward: 24.5000,                 loss: 0.0194
env1_first_0:                 episode reward: -23.4500,                 loss: nan
env1_second_0:                 episode reward: 23.4500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 1687.95,                last time consumption/overall running time: 514.5787s / 178281.3560 s
env0_first_0:                 episode reward: -24.3500,                 loss: 0.0208
env0_second_0:                 episode reward: 24.3500,                 loss: 0.0206
env1_first_0:                 episode reward: -25.6000,                 loss: nan
env1_second_0:                 episode reward: 25.6000,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 1733.95,                last time consumption/overall running time: 522.2446s / 178803.6006 s
env0_first_0:                 episode reward: -24.4000,                 loss: 0.0223
env0_second_0:                 episode reward: 24.4000,                 loss: 0.0229
env1_first_0:                 episode reward: -25.0000,                 loss: nan
env1_second_0:                 episode reward: 25.0000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 1673.95,                last time consumption/overall running time: 512.3924s / 179315.9930 s
env0_first_0:                 episode reward: -25.1000,                 loss: 0.0225
env0_second_0:                 episode reward: 25.1000,                 loss: 0.0234
env1_first_0:                 episode reward: -25.3000,                 loss: nan
env1_second_0:                 episode reward: 25.3000,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 1688.8,                last time consumption/overall running time: 522.8072s / 179838.8002 s
env0_first_0:                 episode reward: -24.7000,                 loss: 0.0235
env0_second_0:                 episode reward: 24.7000,                 loss: 0.0249
env1_first_0:                 episode reward: -24.6500,                 loss: nan
env1_second_0:                 episode reward: 24.6500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 1711.4,                last time consumption/overall running time: 535.3926s / 180374.1927 s
env0_first_0:                 episode reward: -23.7000,                 loss: 0.0233
env0_second_0:                 episode reward: 23.7000,                 loss: 0.0235
env1_first_0:                 episode reward: -24.9500,                 loss: nan
env1_second_0:                 episode reward: 24.9500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 1713.7,                last time consumption/overall running time: 563.7551s / 180937.9478 s
env0_first_0:                 episode reward: -25.5000,                 loss: 0.0229
env0_second_0:                 episode reward: 25.5000,                 loss: 0.0231
env1_first_0:                 episode reward: -25.7000,                 loss: nan
env1_second_0:                 episode reward: 25.7000,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 1694.15,                last time consumption/overall running time: 523.0373s / 181460.9851 s
env0_first_0:                 episode reward: -24.8500,                 loss: 0.0220
env0_second_0:                 episode reward: 24.8500,                 loss: 0.0220
env1_first_0:                 episode reward: -24.9000,                 loss: nan
env1_second_0:                 episode reward: 24.9000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 1690.3,                last time consumption/overall running time: 513.4672s / 181974.4522 s
env0_first_0:                 episode reward: -24.2500,                 loss: 0.0220
env0_second_0:                 episode reward: 24.2500,                 loss: 0.0224
env1_first_0:                 episode reward: -23.3500,                 loss: nan
env1_second_0:                 episode reward: 23.3500,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 1683.5,                last time consumption/overall running time: 505.6432s / 182480.0955 s
env0_first_0:                 episode reward: -24.5000,                 loss: 0.0227
env0_second_0:                 episode reward: 24.5000,                 loss: 0.0225
env1_first_0:                 episode reward: -24.3500,                 loss: nan
env1_second_0:                 episode reward: 24.3500,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 1709.7,                last time consumption/overall running time: 513.3532s / 182993.4486 s
env0_first_0:                 episode reward: -22.6500,                 loss: 0.0229
env0_second_0:                 episode reward: 22.6500,                 loss: 0.0226
env1_first_0:                 episode reward: -25.2000,                 loss: nan
env1_second_0:                 episode reward: 25.2000,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 1641.35,                last time consumption/overall running time: 494.1688s / 183487.6174 s
env0_first_0:                 episode reward: -24.5500,                 loss: 0.0227
env0_second_0:                 episode reward: 24.5500,                 loss: 0.0223
env1_first_0:                 episode reward: -24.2500,                 loss: nan
env1_second_0:                 episode reward: 24.2500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 1679.95,                last time consumption/overall running time: 545.6350s / 184033.2524 s
env0_first_0:                 episode reward: -23.9500,                 loss: 0.0225
env0_second_0:                 episode reward: 23.9500,                 loss: 0.0221
env1_first_0:                 episode reward: -24.6000,                 loss: nan
env1_second_0:                 episode reward: 24.6000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 1706.85,                last time consumption/overall running time: 541.0418s / 184574.2942 s
env0_first_0:                 episode reward: -24.6000,                 loss: 0.0218
env0_second_0:                 episode reward: 24.6000,                 loss: 0.0224
env1_first_0:                 episode reward: -25.4500,                 loss: nan
env1_second_0:                 episode reward: 25.4500,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 1696.9,                last time consumption/overall running time: 514.7511s / 185089.0453 s
env0_first_0:                 episode reward: -24.7000,                 loss: 0.0218
env0_second_0:                 episode reward: 24.7000,                 loss: 0.0211
env1_first_0:                 episode reward: -25.4500,                 loss: nan
env1_second_0:                 episode reward: 25.4500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 1683.6,                last time consumption/overall running time: 509.0812s / 185598.1265 s
env0_first_0:                 episode reward: -23.8000,                 loss: 0.0221
env0_second_0:                 episode reward: 23.8000,                 loss: 0.0198
env1_first_0:                 episode reward: -23.7000,                 loss: nan
env1_second_0:                 episode reward: 23.7000,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 1700.75,                last time consumption/overall running time: 521.6874s / 186119.8139 s
env0_first_0:                 episode reward: -24.4000,                 loss: 0.0221
env0_second_0:                 episode reward: 24.4000,                 loss: 0.0203
env1_first_0:                 episode reward: -25.3000,                 loss: nan
env1_second_0:                 episode reward: 25.3000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 1688.45,                last time consumption/overall running time: 515.3592s / 186635.1731 s
env0_first_0:                 episode reward: -23.9000,                 loss: 0.0218
env0_second_0:                 episode reward: 23.9000,                 loss: 0.0206
env1_first_0:                 episode reward: -25.2000,                 loss: nan
env1_second_0:                 episode reward: 25.2000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 1728.4,                last time consumption/overall running time: 532.6269s / 187167.8000 s
env0_first_0:                 episode reward: -25.5500,                 loss: 0.0234
env0_second_0:                 episode reward: 25.5500,                 loss: 0.0238
env1_first_0:                 episode reward: -25.3500,                 loss: nan
env1_second_0:                 episode reward: 25.3500,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 1730.8,                last time consumption/overall running time: 534.4645s / 187702.2645 s
env0_first_0:                 episode reward: -24.8000,                 loss: 0.0226
env0_second_0:                 episode reward: 24.8000,                 loss: 0.0228
env1_first_0:                 episode reward: -25.8500,                 loss: nan
env1_second_0:                 episode reward: 25.8500,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 1739.25,                last time consumption/overall running time: 530.6439s / 188232.9084 s
env0_first_0:                 episode reward: -25.1000,                 loss: 0.0242
env0_second_0:                 episode reward: 25.1000,                 loss: 0.0235
env1_first_0:                 episode reward: -25.7500,                 loss: nan
env1_second_0:                 episode reward: 25.7500,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 1629.3,                last time consumption/overall running time: 501.1903s / 188734.0987 s
env0_first_0:                 episode reward: -24.4000,                 loss: 0.0231
env0_second_0:                 episode reward: 24.4000,                 loss: 0.0234
env1_first_0:                 episode reward: -25.3000,                 loss: nan
env1_second_0:                 episode reward: 25.3000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 1646.35,                last time consumption/overall running time: 502.8312s / 189236.9299 s
env0_first_0:                 episode reward: -24.5000,                 loss: 0.0224
env0_second_0:                 episode reward: 24.5000,                 loss: 0.0232
env1_first_0:                 episode reward: -24.7000,                 loss: nan
env1_second_0:                 episode reward: 24.7000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 1694.55,                last time consumption/overall running time: 511.4601s / 189748.3900 s
env0_first_0:                 episode reward: -24.8500,                 loss: 0.0216
env0_second_0:                 episode reward: 24.8500,                 loss: 0.0216
env1_first_0:                 episode reward: -24.4500,                 loss: nan
env1_second_0:                 episode reward: 24.4500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 1692.05,                last time consumption/overall running time: 511.7207s / 190260.1107 s
env0_first_0:                 episode reward: -23.2000,                 loss: 0.0221
env0_second_0:                 episode reward: 23.2000,                 loss: 0.0210
env1_first_0:                 episode reward: -24.7500,                 loss: nan
env1_second_0:                 episode reward: 24.7500,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 1691.5,                last time consumption/overall running time: 515.4727s / 190775.5834 s
env0_first_0:                 episode reward: -24.7500,                 loss: 0.0213
env0_second_0:                 episode reward: 24.7500,                 loss: 0.0217
env1_first_0:                 episode reward: -25.7000,                 loss: nan
env1_second_0:                 episode reward: 25.7000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 1692.1,                last time consumption/overall running time: 521.9623s / 191297.5458 s
env0_first_0:                 episode reward: -25.0500,                 loss: 0.0220
env0_second_0:                 episode reward: 25.0500,                 loss: 0.0206
env1_first_0:                 episode reward: -24.7500,                 loss: nan
env1_second_0:                 episode reward: 24.7500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 1683.1,                last time consumption/overall running time: 521.1536s / 191818.6994 s
env0_first_0:                 episode reward: -25.5500,                 loss: 0.0210
env0_second_0:                 episode reward: 25.5500,                 loss: 0.0213
env1_first_0:                 episode reward: -25.2500,                 loss: nan
env1_second_0:                 episode reward: 25.2500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 1674.7,                last time consumption/overall running time: 505.5782s / 192324.2776 s
env0_first_0:                 episode reward: -24.4500,                 loss: 0.0208
env0_second_0:                 episode reward: 24.4500,                 loss: 0.0207
env1_first_0:                 episode reward: -24.9500,                 loss: nan
env1_second_0:                 episode reward: 24.9500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 1642.15,                last time consumption/overall running time: 494.7207s / 192818.9983 s
env0_first_0:                 episode reward: -25.4500,                 loss: 0.0203
env0_second_0:                 episode reward: 25.4500,                 loss: 0.0197
env1_first_0:                 episode reward: -25.3000,                 loss: nan
env1_second_0:                 episode reward: 25.3000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 1596.85,                last time consumption/overall running time: 495.0001s / 193313.9984 s
env0_first_0:                 episode reward: -24.4500,                 loss: 0.0199
env0_second_0:                 episode reward: 24.4500,                 loss: 0.0194
env1_first_0:                 episode reward: -24.8000,                 loss: nan
env1_second_0:                 episode reward: 24.8000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 1661.3,                last time consumption/overall running time: 515.4090s / 193829.4074 s
env0_first_0:                 episode reward: -25.3500,                 loss: 0.0197
env0_second_0:                 episode reward: 25.3500,                 loss: 0.0196
env1_first_0:                 episode reward: -26.1000,                 loss: nan
env1_second_0:                 episode reward: 26.1000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 1708.5,                last time consumption/overall running time: 534.2763s / 194363.6836 s
env0_first_0:                 episode reward: -24.7500,                 loss: 0.0207
env0_second_0:                 episode reward: 24.7500,                 loss: 0.0194
env1_first_0:                 episode reward: -26.6000,                 loss: nan
env1_second_0:                 episode reward: 26.6000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 1689.95,                last time consumption/overall running time: 513.2892s / 194876.9728 s
env0_first_0:                 episode reward: -24.9500,                 loss: 0.0206
env0_second_0:                 episode reward: 24.9500,                 loss: 0.0200
env1_first_0:                 episode reward: -26.6000,                 loss: nan
env1_second_0:                 episode reward: 26.6000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 1625.15,                last time consumption/overall running time: 493.5909s / 195370.5637 s
env0_first_0:                 episode reward: -26.3500,                 loss: 0.0205
env0_second_0:                 episode reward: 26.3500,                 loss: 0.0205
env1_first_0:                 episode reward: -24.4000,                 loss: nan
env1_second_0:                 episode reward: 24.4000,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 1648.25,                last time consumption/overall running time: 510.4197s / 195880.9833 s
env0_first_0:                 episode reward: -24.9000,                 loss: 0.0202
env0_second_0:                 episode reward: 24.9000,                 loss: 0.0210
env1_first_0:                 episode reward: -25.4000,                 loss: nan
env1_second_0:                 episode reward: 25.4000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 1684.6,                last time consumption/overall running time: 509.1704s / 196390.1538 s
env0_first_0:                 episode reward: -26.4500,                 loss: 0.0203
env0_second_0:                 episode reward: 26.4500,                 loss: 0.0199
env1_first_0:                 episode reward: -25.8000,                 loss: nan
env1_second_0:                 episode reward: 25.8000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 1641.75,                last time consumption/overall running time: 499.2768s / 196889.4305 s
env0_first_0:                 episode reward: -26.8000,                 loss: 0.0205
env0_second_0:                 episode reward: 26.8000,                 loss: 0.0209
env1_first_0:                 episode reward: -25.6500,                 loss: nan
env1_second_0:                 episode reward: 25.6500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 1663.0,                last time consumption/overall running time: 512.8139s / 197402.2444 s
env0_first_0:                 episode reward: -26.4500,                 loss: 0.0203
env0_second_0:                 episode reward: 26.4500,                 loss: 0.0206
env1_first_0:                 episode reward: -25.6500,                 loss: nan
env1_second_0:                 episode reward: 25.6500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 1763.55,                last time consumption/overall running time: 550.2346s / 197952.4790 s
env0_first_0:                 episode reward: -25.3500,                 loss: 0.0204
env0_second_0:                 episode reward: 25.3500,                 loss: 0.0207
env1_first_0:                 episode reward: -25.1000,                 loss: nan
env1_second_0:                 episode reward: 25.1000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 1786.4,                last time consumption/overall running time: 560.3771s / 198512.8561 s
env0_first_0:                 episode reward: -24.4000,                 loss: 0.0226
env0_second_0:                 episode reward: 24.4000,                 loss: 0.0214
env1_first_0:                 episode reward: -24.8500,                 loss: nan
env1_second_0:                 episode reward: 24.8500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 1697.2,                last time consumption/overall running time: 520.8678s / 199033.7239 s
env0_first_0:                 episode reward: -23.9000,                 loss: 0.0234
env0_second_0:                 episode reward: 23.9000,                 loss: 0.0224
env1_first_0:                 episode reward: -24.6500,                 loss: nan
env1_second_0:                 episode reward: 24.6500,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 1750.85,                last time consumption/overall running time: 531.5510s / 199565.2748 s
env0_first_0:                 episode reward: -25.2000,                 loss: 0.0232
env0_second_0:                 episode reward: 25.2000,                 loss: 0.0239
env1_first_0:                 episode reward: -23.4000,                 loss: nan
env1_second_0:                 episode reward: 23.4000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 1719.25,                last time consumption/overall running time: 550.8550s / 200116.1298 s
env0_first_0:                 episode reward: -25.1000,                 loss: 0.0228
env0_second_0:                 episode reward: 25.1000,                 loss: 0.0229
env1_first_0:                 episode reward: -24.1500,                 loss: nan
env1_second_0:                 episode reward: 24.1500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 1682.55,                last time consumption/overall running time: 516.9442s / 200633.0741 s
env0_first_0:                 episode reward: -24.3500,                 loss: 0.0242
env0_second_0:                 episode reward: 24.3500,                 loss: 0.0229
env1_first_0:                 episode reward: -23.6500,                 loss: nan
env1_second_0:                 episode reward: 23.6500,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 1707.6,                last time consumption/overall running time: 527.9710s / 201161.0450 s
env0_first_0:                 episode reward: -24.6000,                 loss: 0.0232
env0_second_0:                 episode reward: 24.6000,                 loss: 0.0233
env1_first_0:                 episode reward: -25.4000,                 loss: nan
env1_second_0:                 episode reward: 25.4000,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 1726.65,                last time consumption/overall running time: 532.3415s / 201693.3865 s
env0_first_0:                 episode reward: -24.3500,                 loss: 0.0226
env0_second_0:                 episode reward: 24.3500,                 loss: 0.0229
env1_first_0:                 episode reward: -24.7500,                 loss: nan
env1_second_0:                 episode reward: 24.7500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 1682.25,                last time consumption/overall running time: 510.3992s / 202203.7857 s
env0_first_0:                 episode reward: -24.2500,                 loss: 0.0216
env0_second_0:                 episode reward: 24.2500,                 loss: 0.0211
env1_first_0:                 episode reward: -24.3500,                 loss: nan
env1_second_0:                 episode reward: 24.3500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 1700.55,                last time consumption/overall running time: 528.8057s / 202732.5914 s
env0_first_0:                 episode reward: -25.4500,                 loss: 0.0221
env0_second_0:                 episode reward: 25.4500,                 loss: 0.0213
env1_first_0:                 episode reward: -23.9500,                 loss: nan
env1_second_0:                 episode reward: 23.9500,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 1587.8,                last time consumption/overall running time: 486.3252s / 203218.9166 s
env0_first_0:                 episode reward: -24.1500,                 loss: 0.0216
env0_second_0:                 episode reward: 24.1500,                 loss: 0.0215
env1_first_0:                 episode reward: -24.2000,                 loss: nan
env1_second_0:                 episode reward: 24.2000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 1671.15,                last time consumption/overall running time: 514.4115s / 203733.3281 s
env0_first_0:                 episode reward: -24.5500,                 loss: 0.0205
env0_second_0:                 episode reward: 24.5500,                 loss: 0.0215
env1_first_0:                 episode reward: -23.8000,                 loss: nan
env1_second_0:                 episode reward: 23.8000,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 1616.25,                last time consumption/overall running time: 492.4814s / 204225.8095 s
env0_first_0:                 episode reward: -24.6500,                 loss: 0.0204
env0_second_0:                 episode reward: 24.6500,                 loss: 0.0209
env1_first_0:                 episode reward: -25.3000,                 loss: nan
env1_second_0:                 episode reward: 25.3000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 1606.95,                last time consumption/overall running time: 489.9506s / 204715.7602 s
env0_first_0:                 episode reward: -24.7500,                 loss: 0.0198
env0_second_0:                 episode reward: 24.7500,                 loss: 0.0198
env1_first_0:                 episode reward: -24.1500,                 loss: nan
env1_second_0:                 episode reward: 24.1500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 1612.15,                last time consumption/overall running time: 490.9693s / 205206.7295 s
env0_first_0:                 episode reward: -25.0000,                 loss: 0.0199
env0_second_0:                 episode reward: 25.0000,                 loss: 0.0193
env1_first_0:                 episode reward: -24.1500,                 loss: nan
env1_second_0:                 episode reward: 24.1500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 1640.45,                last time consumption/overall running time: 505.9194s / 205712.6488 s
env0_first_0:                 episode reward: -23.7500,                 loss: 0.0202
env0_second_0:                 episode reward: 23.7500,                 loss: 0.0192
env1_first_0:                 episode reward: -24.7500,                 loss: nan
env1_second_0:                 episode reward: 24.7500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 1707.15,                last time consumption/overall running time: 516.8688s / 206229.5176 s
env0_first_0:                 episode reward: -23.6000,                 loss: 0.0205
env0_second_0:                 episode reward: 23.6000,                 loss: 0.0198
env1_first_0:                 episode reward: -24.6500,                 loss: nan
env1_second_0:                 episode reward: 24.6500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 1645.4,                last time consumption/overall running time: 499.5943s / 206729.1120 s
env0_first_0:                 episode reward: -24.1000,                 loss: 0.0204
env0_second_0:                 episode reward: 24.1000,                 loss: 0.0206
env1_first_0:                 episode reward: -24.4500,                 loss: nan
env1_second_0:                 episode reward: 24.4500,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 1692.7,                last time consumption/overall running time: 510.8360s / 207239.9480 s
env0_first_0:                 episode reward: -24.4000,                 loss: 0.0225
env0_second_0:                 episode reward: 24.4000,                 loss: 0.0213
env1_first_0:                 episode reward: -25.5000,                 loss: nan
env1_second_0:                 episode reward: 25.5000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 1630.65,                last time consumption/overall running time: 496.3474s / 207736.2954 s
env0_first_0:                 episode reward: -24.0500,                 loss: 0.0226
env0_second_0:                 episode reward: 24.0500,                 loss: 0.0214
env1_first_0:                 episode reward: -24.5500,                 loss: nan
env1_second_0:                 episode reward: 24.5500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 1601.85,                last time consumption/overall running time: 490.3310s / 208226.6264 s
env0_first_0:                 episode reward: -24.7000,                 loss: 0.0215
env0_second_0:                 episode reward: 24.7000,                 loss: 0.0203
env1_first_0:                 episode reward: -23.7000,                 loss: nan
env1_second_0:                 episode reward: 23.7000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 1670.6,                last time consumption/overall running time: 512.9997s / 208739.6261 s
env0_first_0:                 episode reward: -25.8500,                 loss: 0.0212
env0_second_0:                 episode reward: 25.8500,                 loss: 0.0211
env1_first_0:                 episode reward: -24.5000,                 loss: nan
env1_second_0:                 episode reward: 24.5000,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 1691.7,                last time consumption/overall running time: 518.8901s / 209258.5162 s
env0_first_0:                 episode reward: -23.7000,                 loss: 0.0218
env0_second_0:                 episode reward: 23.7000,                 loss: 0.0218
env1_first_0:                 episode reward: -25.4500,                 loss: nan
env1_second_0:                 episode reward: 25.4500,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 1640.6,                last time consumption/overall running time: 507.0374s / 209765.5536 s
env0_first_0:                 episode reward: -26.6000,                 loss: 0.0224
env0_second_0:                 episode reward: 26.6000,                 loss: 0.0216
env1_first_0:                 episode reward: -24.5000,                 loss: nan
env1_second_0:                 episode reward: 24.5000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 1691.55,                last time consumption/overall running time: 521.1688s / 210286.7224 s
env0_first_0:                 episode reward: -25.4500,                 loss: 0.0226
env0_second_0:                 episode reward: 25.4500,                 loss: 0.0223
env1_first_0:                 episode reward: -26.5000,                 loss: nan
env1_second_0:                 episode reward: 26.5000,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 1641.2,                last time consumption/overall running time: 501.8864s / 210788.6088 s
env0_first_0:                 episode reward: -25.4500,                 loss: 0.0224
env0_second_0:                 episode reward: 25.4500,                 loss: 0.0223
env1_first_0:                 episode reward: -25.8500,                 loss: nan
env1_second_0:                 episode reward: 25.8500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 1720.2,                last time consumption/overall running time: 517.2811s / 211305.8900 s
env0_first_0:                 episode reward: -24.2000,                 loss: 0.0229
env0_second_0:                 episode reward: 24.2000,                 loss: 0.0229
env1_first_0:                 episode reward: -25.6500,                 loss: nan
env1_second_0:                 episode reward: 25.6500,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 1750.65,                last time consumption/overall running time: 528.8087s / 211834.6987 s
env0_first_0:                 episode reward: -24.5000,                 loss: 0.0231
env0_second_0:                 episode reward: 24.5000,                 loss: 0.0225
env1_first_0:                 episode reward: -25.1500,                 loss: nan
env1_second_0:                 episode reward: 25.1500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 1633.8,                last time consumption/overall running time: 502.2017s / 212336.9004 s
env0_first_0:                 episode reward: -24.0000,                 loss: 0.0229
env0_second_0:                 episode reward: 24.0000,                 loss: 0.0225
env1_first_0:                 episode reward: -23.8500,                 loss: nan
env1_second_0:                 episode reward: 23.8500,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 1710.7,                last time consumption/overall running time: 518.6032s / 212855.5036 s
env0_first_0:                 episode reward: -23.8000,                 loss: 0.0232
env0_second_0:                 episode reward: 23.8000,                 loss: 0.0238
env1_first_0:                 episode reward: -25.3500,                 loss: nan
env1_second_0:                 episode reward: 25.3500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 1609.95,                last time consumption/overall running time: 483.7474s / 213339.2511 s
env0_first_0:                 episode reward: -24.6500,                 loss: 0.0218
env0_second_0:                 episode reward: 24.6500,                 loss: 0.0227
env1_first_0:                 episode reward: -25.1000,                 loss: nan
env1_second_0:                 episode reward: 25.1000,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 1670.95,                last time consumption/overall running time: 508.9415s / 213848.1926 s
env0_first_0:                 episode reward: -24.9500,                 loss: 0.0211
env0_second_0:                 episode reward: 24.9500,                 loss: 0.0217
env1_first_0:                 episode reward: -25.1500,                 loss: nan
env1_second_0:                 episode reward: 25.1500,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 1632.05,                last time consumption/overall running time: 499.2126s / 214347.4051 s
env0_first_0:                 episode reward: -24.5500,                 loss: 0.0214
env0_second_0:                 episode reward: 24.5500,                 loss: 0.0211
env1_first_0:                 episode reward: -25.4000,                 loss: nan
env1_second_0:                 episode reward: 25.4000,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 1635.2,                last time consumption/overall running time: 507.7320s / 214855.1371 s
env0_first_0:                 episode reward: -25.1500,                 loss: 0.0211
env0_second_0:                 episode reward: 25.1500,                 loss: 0.0206
env1_first_0:                 episode reward: -25.9500,                 loss: nan
env1_second_0:                 episode reward: 25.9500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 1645.05,                last time consumption/overall running time: 503.7285s / 215358.8656 s
env0_first_0:                 episode reward: -26.4500,                 loss: 0.0213
env0_second_0:                 episode reward: 26.4500,                 loss: 0.0210
env1_first_0:                 episode reward: -26.2000,                 loss: nan
env1_second_0:                 episode reward: 26.2000,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 1674.6,                last time consumption/overall running time: 518.3883s / 215877.2540 s
env0_first_0:                 episode reward: -25.2500,                 loss: 0.0214
env0_second_0:                 episode reward: 25.2500,                 loss: 0.0218
env1_first_0:                 episode reward: -26.0500,                 loss: nan
env1_second_0:                 episode reward: 26.0500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 1658.75,                last time consumption/overall running time: 508.6513s / 216385.9052 s
env0_first_0:                 episode reward: -25.5000,                 loss: 0.0216
env0_second_0:                 episode reward: 25.5000,                 loss: 0.0217
env1_first_0:                 episode reward: -24.8000,                 loss: nan
env1_second_0:                 episode reward: 24.8000,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 1656.6,                last time consumption/overall running time: 509.0772s / 216894.9824 s
env0_first_0:                 episode reward: -25.6000,                 loss: 0.0214
env0_second_0:                 episode reward: 25.6000,                 loss: 0.0210
env1_first_0:                 episode reward: -23.8500,                 loss: nan
env1_second_0:                 episode reward: 23.8500,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 1612.45,                last time consumption/overall running time: 495.5216s / 217390.5040 s
env0_first_0:                 episode reward: -25.4500,                 loss: 0.0203
env0_second_0:                 episode reward: 25.4500,                 loss: 0.0207
env1_first_0:                 episode reward: -24.6000,                 loss: nan
env1_second_0:                 episode reward: 24.6000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 1620.25,                last time consumption/overall running time: 501.9446s / 217892.4486 s
env0_first_0:                 episode reward: -24.9500,                 loss: 0.0213
env0_second_0:                 episode reward: 24.9500,                 loss: 0.0206
env1_first_0:                 episode reward: -25.1000,                 loss: nan
env1_second_0:                 episode reward: 25.1000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 1658.5,                last time consumption/overall running time: 511.9746s / 218404.4232 s
env0_first_0:                 episode reward: -24.9500,                 loss: 0.0206
env0_second_0:                 episode reward: 24.9500,                 loss: 0.0197
env1_first_0:                 episode reward: -24.8000,                 loss: nan
env1_second_0:                 episode reward: 24.8000,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 1662.95,                last time consumption/overall running time: 517.2414s / 218921.6646 s
env0_first_0:                 episode reward: -26.5500,                 loss: 0.0203
env0_second_0:                 episode reward: 26.5500,                 loss: 0.0201
env1_first_0:                 episode reward: -25.1500,                 loss: nan
env1_second_0:                 episode reward: 25.1500,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 1639.25,                last time consumption/overall running time: 503.3281s / 219424.9926 s
env0_first_0:                 episode reward: -24.7500,                 loss: 0.0201
env0_second_0:                 episode reward: 24.7500,                 loss: 0.0202
env1_first_0:                 episode reward: -24.4000,                 loss: nan
env1_second_0:                 episode reward: 24.4000,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 1725.6,                last time consumption/overall running time: 530.8178s / 219955.8104 s
env0_first_0:                 episode reward: -24.7000,                 loss: 0.0213
env0_second_0:                 episode reward: 24.7000,                 loss: 0.0208
env1_first_0:                 episode reward: -25.2000,                 loss: nan
env1_second_0:                 episode reward: 25.2000,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 1644.55,                last time consumption/overall running time: 502.5810s / 220458.3914 s
env0_first_0:                 episode reward: -25.4000,                 loss: 0.0214
env0_second_0:                 episode reward: 25.4000,                 loss: 0.0217
env1_first_0:                 episode reward: -26.3000,                 loss: nan
env1_second_0:                 episode reward: 26.3000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 1697.9,                last time consumption/overall running time: 526.7320s / 220985.1234 s
env0_first_0:                 episode reward: -25.6000,                 loss: 0.0225
env0_second_0:                 episode reward: 25.6000,                 loss: 0.0223
env1_first_0:                 episode reward: -26.3500,                 loss: nan
env1_second_0:                 episode reward: 26.3500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 1675.1,                last time consumption/overall running time: 508.4422s / 221493.5655 s
env0_first_0:                 episode reward: -27.1000,                 loss: 0.0223
env0_second_0:                 episode reward: 27.1000,                 loss: 0.0220
env1_first_0:                 episode reward: -24.7500,                 loss: nan
env1_second_0:                 episode reward: 24.7500,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 1708.8,                last time consumption/overall running time: 521.1184s / 222014.6839 s
env0_first_0:                 episode reward: -24.5000,                 loss: 0.0221
env0_second_0:                 episode reward: 24.5000,                 loss: 0.0217
env1_first_0:                 episode reward: -25.0500,                 loss: nan
env1_second_0:                 episode reward: 25.0500,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 1685.45,                last time consumption/overall running time: 522.8786s / 222537.5626 s
env0_first_0:                 episode reward: -24.1000,                 loss: 0.0214
env0_second_0:                 episode reward: 24.1000,                 loss: 0.0212
env1_first_0:                 episode reward: -26.3500,                 loss: nan
env1_second_0:                 episode reward: 26.3500,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 1717.25,                last time consumption/overall running time: 528.8975s / 223066.4601 s
env0_first_0:                 episode reward: -25.7500,                 loss: 0.0215
env0_second_0:                 episode reward: 25.7500,                 loss: 0.0222
env1_first_0:                 episode reward: -25.4500,                 loss: nan
env1_second_0:                 episode reward: 25.4500,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 1702.55,                last time consumption/overall running time: 512.7294s / 223579.1895 s
env0_first_0:                 episode reward: -26.7500,                 loss: 0.0207
env0_second_0:                 episode reward: 26.7500,                 loss: 0.0222
env1_first_0:                 episode reward: -25.6500,                 loss: nan
env1_second_0:                 episode reward: 25.6500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 1690.4,                last time consumption/overall running time: 513.8609s / 224093.0503 s
env0_first_0:                 episode reward: -25.1500,                 loss: 0.0221
env0_second_0:                 episode reward: 25.1500,                 loss: 0.0223
env1_first_0:                 episode reward: -25.1500,                 loss: nan
env1_second_0:                 episode reward: 25.1500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 1653.3,                last time consumption/overall running time: 508.3996s / 224601.4500 s
env0_first_0:                 episode reward: -25.4500,                 loss: 0.0213
env0_second_0:                 episode reward: 25.4500,                 loss: 0.0228
env1_first_0:                 episode reward: -23.7000,                 loss: nan
env1_second_0:                 episode reward: 23.7000,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 1600.25,                last time consumption/overall running time: 479.7214s / 225081.1714 s
env0_first_0:                 episode reward: -25.2000,                 loss: 0.0218
env0_second_0:                 episode reward: 25.2000,                 loss: 0.0210
env1_first_0:                 episode reward: -25.5000,                 loss: nan
env1_second_0:                 episode reward: 25.5000,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 1623.4,                last time consumption/overall running time: 493.3054s / 225574.4768 s
env0_first_0:                 episode reward: -25.1000,                 loss: 0.0211
env0_second_0:                 episode reward: 25.1000,                 loss: 0.0200
env1_first_0:                 episode reward: -22.9000,                 loss: nan
env1_second_0:                 episode reward: 22.9000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 1615.75,                last time consumption/overall running time: 494.1385s / 226068.6153 s
env0_first_0:                 episode reward: -25.2000,                 loss: 0.0207
env0_second_0:                 episode reward: 25.2000,                 loss: 0.0207
env1_first_0:                 episode reward: -25.9000,                 loss: nan
env1_second_0:                 episode reward: 25.9000,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 1663.6,                last time consumption/overall running time: 512.9889s / 226581.6042 s
env0_first_0:                 episode reward: -26.8000,                 loss: 0.0208
env0_second_0:                 episode reward: 26.8000,                 loss: 0.0214
env1_first_0:                 episode reward: -25.5500,                 loss: nan
env1_second_0:                 episode reward: 25.5500,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 1707.5,                last time consumption/overall running time: 519.7177s / 227101.3218 s
env0_first_0:                 episode reward: -24.8000,                 loss: 0.0212
env0_second_0:                 episode reward: 24.8000,                 loss: 0.0205
env1_first_0:                 episode reward: -25.1000,                 loss: nan
env1_second_0:                 episode reward: 25.1000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 1707.45,                last time consumption/overall running time: 515.9633s / 227617.2851 s
env0_first_0:                 episode reward: -26.7500,                 loss: 0.0214
env0_second_0:                 episode reward: 26.7500,                 loss: 0.0205
env1_first_0:                 episode reward: -26.4500,                 loss: nan
env1_second_0:                 episode reward: 26.4500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 1650.95,                last time consumption/overall running time: 499.5603s / 228116.8455 s
env0_first_0:                 episode reward: -24.5500,                 loss: 0.0226
env0_second_0:                 episode reward: 24.5500,                 loss: 0.0216
env1_first_0:                 episode reward: -25.4500,                 loss: nan
env1_second_0:                 episode reward: 25.4500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 1731.6,                last time consumption/overall running time: 527.0214s / 228643.8669 s
env0_first_0:                 episode reward: -24.6500,                 loss: 0.0236
env0_second_0:                 episode reward: 24.6500,                 loss: 0.0223
env1_first_0:                 episode reward: -24.8500,                 loss: nan
env1_second_0:                 episode reward: 24.8500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 1652.35,                last time consumption/overall running time: 501.7148s / 229145.5817 s
env0_first_0:                 episode reward: -24.0000,                 loss: 0.0233
env0_second_0:                 episode reward: 24.0000,                 loss: 0.0220
env1_first_0:                 episode reward: -25.2500,                 loss: nan
env1_second_0:                 episode reward: 25.2500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 1678.35,                last time consumption/overall running time: 509.0337s / 229654.6154 s
env0_first_0:                 episode reward: -25.3000,                 loss: 0.0229
env0_second_0:                 episode reward: 25.3000,                 loss: 0.0216
env1_first_0:                 episode reward: -25.3000,                 loss: nan
env1_second_0:                 episode reward: 25.3000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 1643.5,                last time consumption/overall running time: 507.4568s / 230162.0722 s
env0_first_0:                 episode reward: -24.3000,                 loss: 0.0222
env0_second_0:                 episode reward: 24.3000,                 loss: 0.0209
env1_first_0:                 episode reward: -25.3000,                 loss: nan
env1_second_0:                 episode reward: 25.3000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 1599.2,                last time consumption/overall running time: 479.9639s / 230642.0361 s
env0_first_0:                 episode reward: -24.8000,                 loss: 0.0217
env0_second_0:                 episode reward: 24.8000,                 loss: 0.0208
env1_first_0:                 episode reward: -24.6000,                 loss: nan
env1_second_0:                 episode reward: 24.6000,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 1636.5,                last time consumption/overall running time: 499.1695s / 231141.2056 s
env0_first_0:                 episode reward: -24.3000,                 loss: 0.0217
env0_second_0:                 episode reward: 24.3000,                 loss: 0.0201
env1_first_0:                 episode reward: -24.3000,                 loss: nan
env1_second_0:                 episode reward: 24.3000,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 1651.6,                last time consumption/overall running time: 495.4486s / 231636.6543 s
env0_first_0:                 episode reward: -25.3000,                 loss: 0.0217
env0_second_0:                 episode reward: 25.3000,                 loss: 0.0206
env1_first_0:                 episode reward: -24.9500,                 loss: nan
env1_second_0:                 episode reward: 24.9500,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 1604.15,                last time consumption/overall running time: 476.9411s / 232113.5954 s
env0_first_0:                 episode reward: -24.3000,                 loss: 0.0211
env0_second_0:                 episode reward: 24.3000,                 loss: 0.0202
env1_first_0:                 episode reward: -24.4000,                 loss: nan
env1_second_0:                 episode reward: 24.4000,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 1539.9,                last time consumption/overall running time: 479.1901s / 232592.7855 s
env0_first_0:                 episode reward: -24.6000,                 loss: 0.0211
env0_second_0:                 episode reward: 24.6000,                 loss: 0.0205
env1_first_0:                 episode reward: -24.9000,                 loss: nan
env1_second_0:                 episode reward: 24.9000,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 1646.7,                last time consumption/overall running time: 503.0106s / 233095.7961 s
env0_first_0:                 episode reward: -25.1500,                 loss: 0.0204
env0_second_0:                 episode reward: 25.1500,                 loss: 0.0199
env1_first_0:                 episode reward: -25.2000,                 loss: nan
env1_second_0:                 episode reward: 25.2000,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 1661.4,                last time consumption/overall running time: 503.4078s / 233599.2039 s
env0_first_0:                 episode reward: -24.1000,                 loss: 0.0208
env0_second_0:                 episode reward: 24.1000,                 loss: 0.0200
env1_first_0:                 episode reward: -24.3500,                 loss: nan
env1_second_0:                 episode reward: 24.3500,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 1636.8,                last time consumption/overall running time: 505.6903s / 234104.8942 s
env0_first_0:                 episode reward: -26.7000,                 loss: 0.0205
env0_second_0:                 episode reward: 26.7000,                 loss: 0.0207
env1_first_0:                 episode reward: -25.4500,                 loss: nan
env1_second_0:                 episode reward: 25.4500,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 1632.75,                last time consumption/overall running time: 501.2925s / 234606.1867 s
env0_first_0:                 episode reward: -26.2000,                 loss: 0.0218
env0_second_0:                 episode reward: 26.2000,                 loss: 0.0220
env1_first_0:                 episode reward: -24.4500,                 loss: nan
env1_second_0:                 episode reward: 24.4500,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 1584.75,                last time consumption/overall running time: 476.3341s / 235082.5208 s
env0_first_0:                 episode reward: -25.6000,                 loss: 0.0212
env0_second_0:                 episode reward: 25.6000,                 loss: 0.0203
env1_first_0:                 episode reward: -24.4000,                 loss: nan
env1_second_0:                 episode reward: 24.4000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 1652.8,                last time consumption/overall running time: 495.8943s / 235578.4152 s
env0_first_0:                 episode reward: -25.8500,                 loss: 0.0212
env0_second_0:                 episode reward: 25.8500,                 loss: 0.0209
env1_first_0:                 episode reward: -26.5000,                 loss: nan
env1_second_0:                 episode reward: 26.5000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 1604.9,                last time consumption/overall running time: 486.5993s / 236065.0145 s
env0_first_0:                 episode reward: -25.0500,                 loss: 0.0204
env0_second_0:                 episode reward: 25.0500,                 loss: 0.0198
env1_first_0:                 episode reward: -23.5000,                 loss: nan
env1_second_0:                 episode reward: 23.5000,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 1605.35,                last time consumption/overall running time: 481.8777s / 236546.8922 s
env0_first_0:                 episode reward: -23.4000,                 loss: 0.0208
env0_second_0:                 episode reward: 23.4000,                 loss: 0.0195
env1_first_0:                 episode reward: -25.4500,                 loss: nan
env1_second_0:                 episode reward: 25.4500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 1654.0,                last time consumption/overall running time: 505.0383s / 237051.9305 s
env0_first_0:                 episode reward: -24.7500,                 loss: 0.0200
env0_second_0:                 episode reward: 24.7500,                 loss: 0.0184
env1_first_0:                 episode reward: -25.2000,                 loss: nan
env1_second_0:                 episode reward: 25.2000,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 1676.1,                last time consumption/overall running time: 512.4276s / 237564.3581 s
env0_first_0:                 episode reward: -24.9000,                 loss: 0.0198
env0_second_0:                 episode reward: 24.9000,                 loss: 0.0191
env1_first_0:                 episode reward: -25.4000,                 loss: nan
env1_second_0:                 episode reward: 25.4000,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 1609.2,                last time consumption/overall running time: 484.8615s / 238049.2196 s
env0_first_0:                 episode reward: -25.5500,                 loss: 0.0202
env0_second_0:                 episode reward: 25.5500,                 loss: 0.0196
env1_first_0:                 episode reward: -25.2000,                 loss: nan
env1_second_0:                 episode reward: 25.2000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 1611.65,                last time consumption/overall running time: 488.4479s / 238537.6675 s
env0_first_0:                 episode reward: -25.5000,                 loss: 0.0201
env0_second_0:                 episode reward: 25.5000,                 loss: 0.0201
env1_first_0:                 episode reward: -24.8500,                 loss: nan
env1_second_0:                 episode reward: 24.8500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 1651.05,                last time consumption/overall running time: 513.0923s / 239050.7598 s
env0_first_0:                 episode reward: -25.0500,                 loss: 0.0206
env0_second_0:                 episode reward: 25.0500,                 loss: 0.0203
env1_first_0:                 episode reward: -25.5000,                 loss: nan
env1_second_0:                 episode reward: 25.5000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 1688.8,                last time consumption/overall running time: 503.6382s / 239554.3981 s
env0_first_0:                 episode reward: -25.3000,                 loss: 0.0234
env0_second_0:                 episode reward: 25.3000,                 loss: 0.0214
env1_first_0:                 episode reward: -25.7500,                 loss: nan
env1_second_0:                 episode reward: 25.7500,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 1625.0,                last time consumption/overall running time: 497.7606s / 240052.1587 s
env0_first_0:                 episode reward: -25.4500,                 loss: 0.0242
env0_second_0:                 episode reward: 25.4500,                 loss: 0.0221
env1_first_0:                 episode reward: -25.5000,                 loss: nan
env1_second_0:                 episode reward: 25.5000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 1710.2,                last time consumption/overall running time: 520.2090s / 240572.3677 s
env0_first_0:                 episode reward: -25.8000,                 loss: 0.0249
env0_second_0:                 episode reward: 25.8000,                 loss: 0.0220
env1_first_0:                 episode reward: -24.2000,                 loss: nan
env1_second_0:                 episode reward: 24.2000,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 1708.95,                last time consumption/overall running time: 510.9686s / 241083.3363 s
env0_first_0:                 episode reward: -26.0000,                 loss: 0.0227
env0_second_0:                 episode reward: 26.0000,                 loss: 0.0210
env1_first_0:                 episode reward: -25.4500,                 loss: nan
env1_second_0:                 episode reward: 25.4500,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 1633.75,                last time consumption/overall running time: 511.9137s / 241595.2501 s
env0_first_0:                 episode reward: -25.7500,                 loss: 0.0223
env0_second_0:                 episode reward: 25.7500,                 loss: 0.0205
env1_first_0:                 episode reward: -24.7000,                 loss: nan
env1_second_0:                 episode reward: 24.7000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 1655.65,                last time consumption/overall running time: 504.3475s / 242099.5976 s
env0_first_0:                 episode reward: -24.4500,                 loss: 0.0230
env0_second_0:                 episode reward: 24.4500,                 loss: 0.0218
env1_first_0:                 episode reward: -24.2500,                 loss: nan
env1_second_0:                 episode reward: 24.2500,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 1609.25,                last time consumption/overall running time: 497.3186s / 242596.9162 s
env0_first_0:                 episode reward: -24.9500,                 loss: 0.0224
env0_second_0:                 episode reward: 24.9500,                 loss: 0.0209
env1_first_0:                 episode reward: -23.4500,                 loss: nan
env1_second_0:                 episode reward: 23.4500,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 1636.15,                last time consumption/overall running time: 512.3571s / 243109.2733 s
env0_first_0:                 episode reward: -24.3000,                 loss: 0.0223
env0_second_0:                 episode reward: 24.3000,                 loss: 0.0211
env1_first_0:                 episode reward: -25.2500,                 loss: nan
env1_second_0:                 episode reward: 25.2500,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 1620.7,                last time consumption/overall running time: 499.1740s / 243608.4473 s
env0_first_0:                 episode reward: -24.7500,                 loss: 0.0215
env0_second_0:                 episode reward: 24.7500,                 loss: 0.0209
env1_first_0:                 episode reward: -24.1500,                 loss: nan
env1_second_0:                 episode reward: 24.1500,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 1664.25,                last time consumption/overall running time: 514.4559s / 244122.9032 s
env0_first_0:                 episode reward: -25.0500,                 loss: 0.0239
env0_second_0:                 episode reward: 25.0500,                 loss: 0.0230
env1_first_0:                 episode reward: -24.1000,                 loss: nan
env1_second_0:                 episode reward: 24.1000,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 1672.85,                last time consumption/overall running time: 510.7171s / 244633.6203 s
env0_first_0:                 episode reward: -24.6000,                 loss: 0.0266
env0_second_0:                 episode reward: 24.6000,                 loss: 0.0245
env1_first_0:                 episode reward: -25.1000,                 loss: nan
env1_second_0:                 episode reward: 25.1000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 1842.2,                last time consumption/overall running time: 555.0201s / 245188.6404 s
env0_first_0:                 episode reward: -20.9500,                 loss: 0.0270
env0_second_0:                 episode reward: 20.9500,                 loss: 0.0242
env1_first_0:                 episode reward: -21.0000,                 loss: nan
env1_second_0:                 episode reward: 21.0000,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 1699.4,                last time consumption/overall running time: 508.4738s / 245697.1142 s
env0_first_0:                 episode reward: -22.4500,                 loss: 0.0273
env0_second_0:                 episode reward: 22.4500,                 loss: 0.0273
env1_first_0:                 episode reward: -23.2500,                 loss: nan
env1_second_0:                 episode reward: 23.2500,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 1708.25,                last time consumption/overall running time: 524.3159s / 246221.4302 s
env0_first_0:                 episode reward: -23.5500,                 loss: 0.0275
env0_second_0:                 episode reward: 23.5500,                 loss: 0.0273
env1_first_0:                 episode reward: -23.2000,                 loss: nan
env1_second_0:                 episode reward: 23.2000,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 1683.85,                last time consumption/overall running time: 520.0279s / 246741.4580 s
env0_first_0:                 episode reward: -22.7500,                 loss: 0.0282
env0_second_0:                 episode reward: 22.7500,                 loss: 0.0275
env1_first_0:                 episode reward: -20.7500,                 loss: nan
env1_second_0:                 episode reward: 20.7500,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 1688.8,                last time consumption/overall running time: 502.0699s / 247243.5280 s
env0_first_0:                 episode reward: -24.8500,                 loss: 0.0252
env0_second_0:                 episode reward: 24.8500,                 loss: 0.0242
env1_first_0:                 episode reward: -25.3500,                 loss: nan
env1_second_0:                 episode reward: 25.3500,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 1720.25,                last time consumption/overall running time: 533.8000s / 247777.3279 sLoad tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: -24.7000,                 loss: 0.0250
env0_second_0:                 episode reward: 24.7000,                 loss: 0.0240
env1_first_0:                 episode reward: -24.4500,                 loss: nan
env1_second_0:                 episode reward: 24.4500,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 1668.6,                last time consumption/overall running time: 516.4224s / 248293.7503 s
env0_first_0:                 episode reward: -25.5000,                 loss: 0.0237
env0_second_0:                 episode reward: 25.5000,                 loss: 0.0236
env1_first_0:                 episode reward: -24.1500,                 loss: nan
env1_second_0:                 episode reward: 24.1500,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 1604.35,                last time consumption/overall running time: 480.2885s / 248774.0388 s
env0_first_0:                 episode reward: -23.1500,                 loss: 0.0228
env0_second_0:                 episode reward: 23.1500,                 loss: 0.0227
env1_first_0:                 episode reward: -23.3000,                 loss: nan
env1_second_0:                 episode reward: 23.3000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 1736.0,                last time consumption/overall running time: 516.2079s / 249290.2467 s
env0_first_0:                 episode reward: -25.6500,                 loss: 0.0225
env0_second_0:                 episode reward: 25.6500,                 loss: 0.0212
env1_first_0:                 episode reward: -25.2500,                 loss: nan
env1_second_0:                 episode reward: 25.2500,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 1712.35,                last time consumption/overall running time: 504.7432s / 249794.9899 s
env0_first_0:                 episode reward: -25.7500,                 loss: 0.0224
env0_second_0:                 episode reward: 25.7500,                 loss: 0.0206
env1_first_0:                 episode reward: -26.2500,                 loss: nan
env1_second_0:                 episode reward: 26.2500,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 1675.75,                last time consumption/overall running time: 504.8379s / 250299.8278 s
env0_first_0:                 episode reward: -26.2500,                 loss: 0.0217
env0_second_0:                 episode reward: 26.2500,                 loss: 0.0210
env1_first_0:                 episode reward: -25.7000,                 loss: nan
env1_second_0:                 episode reward: 25.7000,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 1668.8,                last time consumption/overall running time: 521.9386s / 250821.7664 s
env0_first_0:                 episode reward: -25.7500,                 loss: 0.0217
env0_second_0:                 episode reward: 25.7500,                 loss: 0.0217
env1_first_0:                 episode reward: -25.7000,                 loss: nan
env1_second_0:                 episode reward: 25.7000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 1643.05,                last time consumption/overall running time: 510.7891s / 251332.5555 s
env0_first_0:                 episode reward: -25.3500,                 loss: 0.0221
env0_second_0:                 episode reward: 25.3500,                 loss: 0.0222
env1_first_0:                 episode reward: -26.3000,                 loss: nan
env1_second_0:                 episode reward: 26.3000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 1988.45,                last time consumption/overall running time: 611.1767s / 251943.7322 s
env0_first_0:                 episode reward: -19.5000,                 loss: 0.0247
env0_second_0:                 episode reward: 19.5000,                 loss: 0.0249
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 1635.2,                last time consumption/overall running time: 509.7693s / 252453.5015 s
env0_first_0:                 episode reward: -25.0500,                 loss: 0.0281
env0_second_0:                 episode reward: 25.0500,                 loss: 0.0278
env1_first_0:                 episode reward: -25.6500,                 loss: nan
env1_second_0:                 episode reward: 25.6500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 1723.65,                last time consumption/overall running time: 523.9483s / 252977.4498 s
env0_first_0:                 episode reward: -24.7000,                 loss: 0.0288
env0_second_0:                 episode reward: 24.7000,                 loss: 0.0284
env1_first_0:                 episode reward: -26.8000,                 loss: nan
env1_second_0:                 episode reward: 26.8000,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 1638.3,                last time consumption/overall running time: 493.1577s / 253470.6075 s
env0_first_0:                 episode reward: -24.4000,                 loss: 0.0265
env0_second_0:                 episode reward: 24.4000,                 loss: 0.0261
env1_first_0:                 episode reward: -25.3000,                 loss: nan
env1_second_0:                 episode reward: 25.3000,                 loss: nan
