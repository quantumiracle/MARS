2022-05-11 12:53:26.967213: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 12:53:26.967278: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia:/home/quantumiracle/.mujoco/mujoco200/bin:/home/quantumiracle/.mujoco/mujoco210/bin:/usr/lib/nvidia
2022-05-11 12:53:26.967282: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7eff8a34a550>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): ReLU()
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ReLU()
      (4): Linear(in_features=32, out_features=32, bias=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220511124050/mdp_arbitrary_mdp_selfplay2/10000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 1.0, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 8000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220511124050/mdp_arbitrary_mdp_selfplay2/10000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 1000, 'net_architecture': {'hidden_dim_list': [32, 32, 32], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220511124050_exploit_10000/mdp_arbitrary_mdp_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220511124050_exploit_10000/mdp_arbitrary_mdp_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7590s / 0.7590 s
agent0:                 episode reward: 0.9093,                 loss: nan
agent1:                 episode reward: -0.9093,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0232s / 0.7821 s
agent0:                 episode reward: 0.3178,                 loss: nan
agent1:                 episode reward: -0.3178,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0214s / 0.8035 s
agent0:                 episode reward: 0.2911,                 loss: nan
agent1:                 episode reward: -0.2911,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0216s / 0.8252 s
agent0:                 episode reward: 0.4082,                 loss: nan
agent1:                 episode reward: -0.4082,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0211s / 0.8462 s
agent0:                 episode reward: 0.1244,                 loss: nan
agent1:                 episode reward: -0.1244,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0288s / 0.8751 s
agent0:                 episode reward: 0.1121,                 loss: nan
agent1:                 episode reward: -0.1121,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0219s / 0.8969 s
agent0:                 episode reward: 0.3010,                 loss: nan
agent1:                 episode reward: -0.3010,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0217s / 0.9186 s
agent0:                 episode reward: 0.4340,                 loss: nan
agent1:                 episode reward: -0.4340,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0235s / 0.9421 s
agent0:                 episode reward: 0.0010,                 loss: nan
agent1:                 episode reward: -0.0010,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0224s / 0.9645 s
agent0:                 episode reward: 0.4198,                 loss: nan
agent1:                 episode reward: -0.4198,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0227s / 0.9872 s
agent0:                 episode reward: 0.3513,                 loss: nan
agent1:                 episode reward: -0.3513,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0924s / 1.0795 s
agent0:                 episode reward: 0.0896,                 loss: nan
agent1:                 episode reward: -0.0896,                 loss: 0.4679
Episode: 241/10000 (2.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1946s / 1.2741 s
agent0:                 episode reward: 0.0288,                 loss: nan
agent1:                 episode reward: -0.0288,                 loss: 0.4580
Episode: 261/10000 (2.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 1.4711 s
agent0:                 episode reward: 0.6694,                 loss: nan
agent1:                 episode reward: -0.6694,                 loss: 0.4515
Episode: 281/10000 (2.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 1.6691 s
agent0:                 episode reward: 0.5560,                 loss: nan
agent1:                 episode reward: -0.5560,                 loss: 0.4470
Episode: 301/10000 (3.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1936s / 1.8627 s
agent0:                 episode reward: -0.0201,                 loss: nan
agent1:                 episode reward: 0.0201,                 loss: 0.4421
Episode: 321/10000 (3.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2165s / 2.0792 s
agent0:                 episode reward: 0.0658,                 loss: nan
agent1:                 episode reward: -0.0658,                 loss: 0.4410
Episode: 341/10000 (3.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2098s / 2.2890 s
agent0:                 episode reward: 0.1883,                 loss: nan
agent1:                 episode reward: -0.1883,                 loss: 0.4387
Episode: 361/10000 (3.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 2.4870 s
agent0:                 episode reward: 0.3044,                 loss: nan
agent1:                 episode reward: -0.3044,                 loss: 0.4362
Episode: 381/10000 (3.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 2.6871 s
agent0:                 episode reward: -0.1428,                 loss: nan
agent1:                 episode reward: 0.1428,                 loss: 0.4345
Episode: 401/10000 (4.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 2.8856 s
agent0:                 episode reward: 0.0083,                 loss: nan
agent1:                 episode reward: -0.0083,                 loss: 0.4319
Episode: 421/10000 (4.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1951s / 3.0806 s
agent0:                 episode reward: -0.1444,                 loss: nan
agent1:                 episode reward: 0.1444,                 loss: 0.4332
Episode: 441/10000 (4.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 3.2797 s
agent0:                 episode reward: 0.2200,                 loss: nan
agent1:                 episode reward: -0.2200,                 loss: 0.4302
Episode: 461/10000 (4.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 3.4799 s
agent0:                 episode reward: 0.1260,                 loss: nan
agent1:                 episode reward: -0.1260,                 loss: 0.4266
Episode: 481/10000 (4.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2017s / 3.6816 s
agent0:                 episode reward: 0.3111,                 loss: nan
agent1:                 episode reward: -0.3111,                 loss: 0.4233
Episode: 501/10000 (5.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 3.8825 s
agent0:                 episode reward: 0.4035,                 loss: nan
agent1:                 episode reward: -0.4035,                 loss: 0.4202
Episode: 521/10000 (5.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 4.0845 s
agent0:                 episode reward: -0.0464,                 loss: nan
agent1:                 episode reward: 0.0464,                 loss: 0.4160
Episode: 541/10000 (5.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2029s / 4.2875 s
agent0:                 episode reward: -0.2696,                 loss: nan
agent1:                 episode reward: 0.2696,                 loss: 0.4148
Episode: 561/10000 (5.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 4.4892 s
agent0:                 episode reward: 0.1165,                 loss: nan
agent1:                 episode reward: -0.1165,                 loss: 0.4119
Episode: 581/10000 (5.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2061s / 4.6954 s
agent0:                 episode reward: 0.2497,                 loss: nan
agent1:                 episode reward: -0.2497,                 loss: 0.4058
Episode: 601/10000 (6.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 4.8964 s
agent0:                 episode reward: 0.1305,                 loss: nan
agent1:                 episode reward: -0.1305,                 loss: 0.4004
Episode: 621/10000 (6.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 5.0975 s
agent0:                 episode reward: -0.3993,                 loss: nan
agent1:                 episode reward: 0.3993,                 loss: 0.3950
Episode: 641/10000 (6.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2110s / 5.3085 s
agent0:                 episode reward: 0.2255,                 loss: nan
agent1:                 episode reward: -0.2255,                 loss: 0.3898
Episode: 661/10000 (6.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2048s / 5.5132 s
agent0:                 episode reward: 0.2348,                 loss: nan
agent1:                 episode reward: -0.2348,                 loss: 0.3846
Episode: 681/10000 (6.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2035s / 5.7168 s
agent0:                 episode reward: 0.0435,                 loss: nan
agent1:                 episode reward: -0.0435,                 loss: 0.3770
Episode: 701/10000 (7.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 5.9195 s
agent0:                 episode reward: 0.0304,                 loss: nan
agent1:                 episode reward: -0.0304,                 loss: 0.3743
Episode: 721/10000 (7.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2065s / 6.1260 s
agent0:                 episode reward: -0.2821,                 loss: nan
agent1:                 episode reward: 0.2821,                 loss: 0.3719
Episode: 741/10000 (7.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 6.3249 s
agent0:                 episode reward: 0.2733,                 loss: nan
agent1:                 episode reward: -0.2733,                 loss: 0.3665
Episode: 761/10000 (7.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2071s / 6.5320 s
agent0:                 episode reward: -0.1406,                 loss: nan
agent1:                 episode reward: 0.1406,                 loss: 0.3608
Episode: 781/10000 (7.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2039s / 6.7359 s
agent0:                 episode reward: -0.4078,                 loss: nan
agent1:                 episode reward: 0.4078,                 loss: 0.3573
Episode: 801/10000 (8.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2058s / 6.9417 s
agent0:                 episode reward: 0.4111,                 loss: nan
agent1:                 episode reward: -0.4111,                 loss: 0.3532
Episode: 821/10000 (8.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2095s / 7.1512 s
agent0:                 episode reward: -0.6003,                 loss: nan
agent1:                 episode reward: 0.6003,                 loss: 0.3494
Episode: 841/10000 (8.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2079s / 7.3591 s
agent0:                 episode reward: -0.1381,                 loss: nan
agent1:                 episode reward: 0.1381,                 loss: 0.3488
Episode: 861/10000 (8.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2720s / 7.6311 s
agent0:                 episode reward: -0.3453,                 loss: nan
agent1:                 episode reward: 0.3453,                 loss: 0.3452
Episode: 881/10000 (8.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2092s / 7.8403 s
agent0:                 episode reward: -0.1588,                 loss: nan
agent1:                 episode reward: 0.1588,                 loss: 0.3437
Episode: 901/10000 (9.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2092s / 8.0495 s
agent0:                 episode reward: -0.6490,                 loss: nan
agent1:                 episode reward: 0.6490,                 loss: 0.3414
Episode: 921/10000 (9.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2126s / 8.2621 s
agent0:                 episode reward: -0.4605,                 loss: nan
agent1:                 episode reward: 0.4605,                 loss: 0.3380
Episode: 941/10000 (9.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2082s / 8.4703 s
agent0:                 episode reward: 0.0425,                 loss: nan
agent1:                 episode reward: -0.0425,                 loss: 0.3345
Episode: 961/10000 (9.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2082s / 8.6786 s
agent0:                 episode reward: -0.1400,                 loss: nan
agent1:                 episode reward: 0.1400,                 loss: 0.3325
Episode: 981/10000 (9.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2052s / 8.8838 s
agent0:                 episode reward: -0.6451,                 loss: nan
agent1:                 episode reward: 0.6451,                 loss: 0.3321
Episode: 1001/10000 (10.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2099s / 9.0937 s
agent0:                 episode reward: -0.5819,                 loss: nan
agent1:                 episode reward: 0.5819,                 loss: 0.3314
Episode: 1021/10000 (10.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2120s / 9.3057 s
agent0:                 episode reward: 0.0050,                 loss: nan
agent1:                 episode reward: -0.0050,                 loss: 0.3308
Episode: 1041/10000 (10.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2104s / 9.5161 s
agent0:                 episode reward: -0.0767,                 loss: nan
agent1:                 episode reward: 0.0767,                 loss: 0.3292
Episode: 1061/10000 (10.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2098s / 9.7259 s
agent0:                 episode reward: -0.0798,                 loss: nan
agent1:                 episode reward: 0.0798,                 loss: 0.3326
Episode: 1081/10000 (10.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2112s / 9.9372 s
agent0:                 episode reward: -0.7087,                 loss: nan
agent1:                 episode reward: 0.7087,                 loss: 0.3297
Episode: 1101/10000 (11.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2114s / 10.1486 s
agent0:                 episode reward: 0.0333,                 loss: nan
agent1:                 episode reward: -0.0333,                 loss: 0.3274
Episode: 1121/10000 (11.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2256s / 10.3742 s
agent0:                 episode reward: -0.3245,                 loss: nan
agent1:                 episode reward: 0.3245,                 loss: 0.3237
Episode: 1141/10000 (11.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2134s / 10.5875 s
agent0:                 episode reward: -0.2795,                 loss: nan
agent1:                 episode reward: 0.2795,                 loss: 0.3211
Episode: 1161/10000 (11.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2113s / 10.7988 s
agent0:                 episode reward: 0.2537,                 loss: nan
agent1:                 episode reward: -0.2537,                 loss: 0.3243
Episode: 1181/10000 (11.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2150s / 11.0137 s
agent0:                 episode reward: -0.4671,                 loss: nan
agent1:                 episode reward: 0.4671,                 loss: 0.3246
Episode: 1201/10000 (12.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2246s / 11.2383 s
agent0:                 episode reward: -0.1969,                 loss: nan
agent1:                 episode reward: 0.1969,                 loss: 0.3232
Episode: 1221/10000 (12.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2181s / 11.4565 s
agent0:                 episode reward: -0.2460,                 loss: nan
agent1:                 episode reward: 0.2460,                 loss: 0.3145
Episode: 1241/10000 (12.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2146s / 11.6710 s
agent0:                 episode reward: -0.3096,                 loss: nan
agent1:                 episode reward: 0.3096,                 loss: 0.2983
Episode: 1261/10000 (12.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2119s / 11.8830 s
agent0:                 episode reward: -0.4508,                 loss: nan
agent1:                 episode reward: 0.4508,                 loss: 0.2974
Episode: 1281/10000 (12.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2156s / 12.0985 s
agent0:                 episode reward: -0.1979,                 loss: nan
agent1:                 episode reward: 0.1979,                 loss: 0.2914
Episode: 1301/10000 (13.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2113s / 12.3098 s
agent0:                 episode reward: -0.0712,                 loss: nan
agent1:                 episode reward: 0.0712,                 loss: 0.2912
Episode: 1321/10000 (13.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2165s / 12.5263 s
agent0:                 episode reward: -0.1414,                 loss: nan
agent1:                 episode reward: 0.1414,                 loss: 0.2921
Episode: 1341/10000 (13.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2119s / 12.7382 s
agent0:                 episode reward: -0.1355,                 loss: nan
agent1:                 episode reward: 0.1355,                 loss: 0.2893
Episode: 1361/10000 (13.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2148s / 12.9529 s
agent0:                 episode reward: -0.4806,                 loss: nan
agent1:                 episode reward: 0.4806,                 loss: 0.2858
Episode: 1381/10000 (13.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2172s / 13.1701 s
agent0:                 episode reward: -0.0998,                 loss: nan
agent1:                 episode reward: 0.0998,                 loss: 0.2893
Episode: 1401/10000 (14.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2128s / 13.3829 s
agent0:                 episode reward: -0.6956,                 loss: nan
agent1:                 episode reward: 0.6956,                 loss: 0.2896
Episode: 1421/10000 (14.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2180s / 13.6009 s
agent0:                 episode reward: -0.3057,                 loss: nan
agent1:                 episode reward: 0.3057,                 loss: 0.2864
Episode: 1441/10000 (14.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2179s / 13.8188 s
agent0:                 episode reward: 0.1612,                 loss: nan
agent1:                 episode reward: -0.1612,                 loss: 0.2864
Episode: 1461/10000 (14.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2147s / 14.0335 s
agent0:                 episode reward: -0.3090,                 loss: nan
agent1:                 episode reward: 0.3090,                 loss: 0.2888
Episode: 1481/10000 (14.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2210s / 14.2545 s
agent0:                 episode reward: -0.2654,                 loss: nan
agent1:                 episode reward: 0.2654,                 loss: 0.2859
Episode: 1501/10000 (15.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2194s / 14.4739 s
agent0:                 episode reward: -0.4406,                 loss: nan
agent1:                 episode reward: 0.4406,                 loss: 0.2833
Episode: 1521/10000 (15.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2177s / 14.6916 s
agent0:                 episode reward: -0.9712,                 loss: nan
agent1:                 episode reward: 0.9712,                 loss: 0.2804
Episode: 1541/10000 (15.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2202s / 14.9118 s
agent0:                 episode reward: -0.2246,                 loss: nan
agent1:                 episode reward: 0.2246,                 loss: 0.2800
Episode: 1561/10000 (15.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2149s / 15.1267 s
agent0:                 episode reward: -0.8612,                 loss: nan
agent1:                 episode reward: 0.8612,                 loss: 0.2757
Episode: 1581/10000 (15.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2169s / 15.3436 s
agent0:                 episode reward: -0.0742,                 loss: nan
agent1:                 episode reward: 0.0742,                 loss: 0.2729
Episode: 1601/10000 (16.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2216s / 15.5652 s
agent0:                 episode reward: -0.8036,                 loss: nan
agent1:                 episode reward: 0.8036,                 loss: 0.2719
Episode: 1621/10000 (16.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2177s / 15.7829 s
agent0:                 episode reward: 0.2805,                 loss: nan
agent1:                 episode reward: -0.2805,                 loss: 0.2704
Episode: 1641/10000 (16.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2190s / 16.0019 s
agent0:                 episode reward: -0.4718,                 loss: nan
agent1:                 episode reward: 0.4718,                 loss: 0.2675
Episode: 1661/10000 (16.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2202s / 16.2221 s
agent0:                 episode reward: -0.4714,                 loss: nan
agent1:                 episode reward: 0.4714,                 loss: 0.2682
Episode: 1681/10000 (16.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2181s / 16.4402 s
agent0:                 episode reward: -0.5338,                 loss: nan
agent1:                 episode reward: 0.5338,                 loss: 0.2658
Episode: 1701/10000 (17.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2199s / 16.6601 s
agent0:                 episode reward: -0.3351,                 loss: nan
agent1:                 episode reward: 0.3351,                 loss: 0.2643
Episode: 1721/10000 (17.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2148s / 16.8749 s
agent0:                 episode reward: -0.6749,                 loss: nan
agent1:                 episode reward: 0.6749,                 loss: 0.2630
Episode: 1741/10000 (17.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2188s / 17.0937 s
agent0:                 episode reward: -0.5179,                 loss: nan
agent1:                 episode reward: 0.5179,                 loss: 0.2620
Episode: 1761/10000 (17.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2314s / 17.3251 s
agent0:                 episode reward: -0.2235,                 loss: nan
agent1:                 episode reward: 0.2235,                 loss: 0.2574
Episode: 1781/10000 (17.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2240s / 17.5491 s
agent0:                 episode reward: -0.2159,                 loss: nan
agent1:                 episode reward: 0.2159,                 loss: 0.2586
Episode: 1801/10000 (18.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2586s / 17.8077 s
agent0:                 episode reward: -0.6886,                 loss: nan
agent1:                 episode reward: 0.6886,                 loss: 0.2566
Episode: 1821/10000 (18.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2286s / 18.0363 s
agent0:                 episode reward: -0.1540,                 loss: nan
agent1:                 episode reward: 0.1540,                 loss: 0.2572
Episode: 1841/10000 (18.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2209s / 18.2573 s
agent0:                 episode reward: -0.4932,                 loss: nan
agent1:                 episode reward: 0.4932,                 loss: 0.2557
Episode: 1861/10000 (18.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2209s / 18.4782 s
agent0:                 episode reward: -0.1805,                 loss: nan
agent1:                 episode reward: 0.1805,                 loss: 0.2564
Episode: 1881/10000 (18.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2445s / 18.7227 s
agent0:                 episode reward: -0.0371,                 loss: nan
agent1:                 episode reward: 0.0371,                 loss: 0.2544
Episode: 1901/10000 (19.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2236s / 18.9462 s
agent0:                 episode reward: -0.2976,                 loss: nan
agent1:                 episode reward: 0.2976,                 loss: 0.2668
Episode: 1921/10000 (19.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2212s / 19.1675 s
agent0:                 episode reward: -0.5607,                 loss: nan
agent1:                 episode reward: 0.5607,                 loss: 0.2650
Episode: 1941/10000 (19.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2274s / 19.3949 s
agent0:                 episode reward: -0.6522,                 loss: nan
agent1:                 episode reward: 0.6522,                 loss: 0.2627
Episode: 1961/10000 (19.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2256s / 19.6205 s
agent0:                 episode reward: -0.3515,                 loss: nan
agent1:                 episode reward: 0.3515,                 loss: 0.2586
Episode: 1981/10000 (19.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2238s / 19.8444 s
agent0:                 episode reward: -0.3598,                 loss: nan
agent1:                 episode reward: 0.3598,                 loss: 0.2632
Episode: 2001/10000 (20.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2261s / 20.0705 s
agent0:                 episode reward: -0.8723,                 loss: nan
agent1:                 episode reward: 0.8723,                 loss: 0.2642
Episode: 2021/10000 (20.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2437s / 20.3142 s
agent0:                 episode reward: -0.5407,                 loss: nan
agent1:                 episode reward: 0.5407,                 loss: 0.2623
Episode: 2041/10000 (20.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2404s / 20.5546 s
agent0:                 episode reward: -0.8696,                 loss: nan
agent1:                 episode reward: 0.8696,                 loss: 0.2621
Episode: 2061/10000 (20.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2256s / 20.7802 s
agent0:                 episode reward: -0.5698,                 loss: nan
agent1:                 episode reward: 0.5698,                 loss: 0.2619
Episode: 2081/10000 (20.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2287s / 21.0089 s
agent0:                 episode reward: -0.2523,                 loss: nan
agent1:                 episode reward: 0.2523,                 loss: 0.2606
Episode: 2101/10000 (21.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2320s / 21.2409 s
agent0:                 episode reward: -0.1427,                 loss: nan
agent1:                 episode reward: 0.1427,                 loss: 0.2589
Episode: 2121/10000 (21.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2292s / 21.4700 s
agent0:                 episode reward: -0.9360,                 loss: nan
agent1:                 episode reward: 0.9360,                 loss: 0.2606
Episode: 2141/10000 (21.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2278s / 21.6979 s
agent0:                 episode reward: -0.3439,                 loss: nan
agent1:                 episode reward: 0.3439,                 loss: 0.2585
Episode: 2161/10000 (21.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2238s / 21.9216 s
agent0:                 episode reward: 0.0713,                 loss: nan
agent1:                 episode reward: -0.0713,                 loss: 0.2575
Episode: 2181/10000 (21.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2273s / 22.1489 s
agent0:                 episode reward: -0.5510,                 loss: nan
agent1:                 episode reward: 0.5510,                 loss: 0.2565
Episode: 2201/10000 (22.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2268s / 22.3757 s
agent0:                 episode reward: -0.3481,                 loss: nan
agent1:                 episode reward: 0.3481,                 loss: 0.2570
Episode: 2221/10000 (22.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2276s / 22.6033 s
agent0:                 episode reward: -0.3036,                 loss: nan
agent1:                 episode reward: 0.3036,                 loss: 0.2610
Episode: 2241/10000 (22.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2269s / 22.8302 s
agent0:                 episode reward: -0.2740,                 loss: nan
agent1:                 episode reward: 0.2740,                 loss: 0.2712
Episode: 2261/10000 (22.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2295s / 23.0597 s
agent0:                 episode reward: -0.5790,                 loss: nan
agent1:                 episode reward: 0.5790,                 loss: 0.2690
Episode: 2281/10000 (22.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2305s / 23.2902 s
agent0:                 episode reward: -0.2946,                 loss: nan
agent1:                 episode reward: 0.2946,                 loss: 0.2702
Episode: 2301/10000 (23.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2343s / 23.5245 s
agent0:                 episode reward: -1.0019,                 loss: nan
agent1:                 episode reward: 1.0019,                 loss: 0.2661
Episode: 2321/10000 (23.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2287s / 23.7531 s
agent0:                 episode reward: -0.5528,                 loss: nan
agent1:                 episode reward: 0.5528,                 loss: 0.2672
Episode: 2341/10000 (23.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2285s / 23.9817 s
agent0:                 episode reward: -0.7256,                 loss: nan
agent1:                 episode reward: 0.7256,                 loss: 0.2665
Episode: 2361/10000 (23.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2311s / 24.2127 s
agent0:                 episode reward: -0.3653,                 loss: nan
agent1:                 episode reward: 0.3653,                 loss: 0.2669
Episode: 2381/10000 (23.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2292s / 24.4419 s
agent0:                 episode reward: -0.6878,                 loss: nan
agent1:                 episode reward: 0.6878,                 loss: 0.2642
Episode: 2401/10000 (24.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2289s / 24.6708 s
agent0:                 episode reward: -0.5694,                 loss: nan
agent1:                 episode reward: 0.5694,                 loss: 0.2683
Episode: 2421/10000 (24.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2268s / 24.8976 s
agent0:                 episode reward: -0.4337,                 loss: nan
agent1:                 episode reward: 0.4337,                 loss: 0.2652
Episode: 2441/10000 (24.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2340s / 25.1316 s
agent0:                 episode reward: -0.6713,                 loss: nan
agent1:                 episode reward: 0.6713,                 loss: 0.2631
Episode: 2461/10000 (24.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2295s / 25.3611 s
agent0:                 episode reward: -0.4567,                 loss: nan
agent1:                 episode reward: 0.4567,                 loss: 0.2661
Episode: 2481/10000 (24.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2311s / 25.5922 s
agent0:                 episode reward: -0.6358,                 loss: nan
agent1:                 episode reward: 0.6358,                 loss: 0.2623
Episode: 2501/10000 (25.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2320s / 25.8242 s
agent0:                 episode reward: 0.1822,                 loss: nan
agent1:                 episode reward: -0.1822,                 loss: 0.2653
Episode: 2521/10000 (25.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2338s / 26.0581 s
agent0:                 episode reward: -0.7091,                 loss: nan
agent1:                 episode reward: 0.7091,                 loss: 0.2599
Episode: 2541/10000 (25.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2384s / 26.2964 s
agent0:                 episode reward: -0.8434,                 loss: nan
agent1:                 episode reward: 0.8434,                 loss: 0.2600
Episode: 2561/10000 (25.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2394s / 26.5358 s
agent0:                 episode reward: -0.9373,                 loss: nan
agent1:                 episode reward: 0.9373,                 loss: 0.2671
Episode: 2581/10000 (25.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2342s / 26.7700 s
agent0:                 episode reward: -0.3104,                 loss: nan
agent1:                 episode reward: 0.3104,                 loss: 0.2663
Episode: 2601/10000 (26.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2516s / 27.0216 s
agent0:                 episode reward: -0.7974,                 loss: nan
agent1:                 episode reward: 0.7974,                 loss: 0.2620
Episode: 2621/10000 (26.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2348s / 27.2565 s
agent0:                 episode reward: -0.5866,                 loss: nan
agent1:                 episode reward: 0.5866,                 loss: 0.2643
Episode: 2641/10000 (26.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2340s / 27.4904 s
agent0:                 episode reward: -0.6273,                 loss: nan
agent1:                 episode reward: 0.6273,                 loss: 0.2628
Episode: 2661/10000 (26.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2348s / 27.7253 s
agent0:                 episode reward: -0.8306,                 loss: nan
agent1:                 episode reward: 0.8306,                 loss: 0.2631
Episode: 2681/10000 (26.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2745s / 27.9997 s
agent0:                 episode reward: -0.5894,                 loss: nan
agent1:                 episode reward: 0.5894,                 loss: 0.2656
Episode: 2701/10000 (27.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2481s / 28.2478 s
agent0:                 episode reward: -0.5898,                 loss: nan
agent1:                 episode reward: 0.5898,                 loss: 0.2610
Episode: 2721/10000 (27.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2363s / 28.4841 s
agent0:                 episode reward: -0.9018,                 loss: nan
agent1:                 episode reward: 0.9018,                 loss: 0.2610
Episode: 2741/10000 (27.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2326s / 28.7167 s
agent0:                 episode reward: -0.9007,                 loss: nan
agent1:                 episode reward: 0.9007,                 loss: 0.2615
Episode: 2761/10000 (27.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2328s / 28.9495 s
agent0:                 episode reward: -0.8318,                 loss: nan
agent1:                 episode reward: 0.8318,                 loss: 0.2614
Episode: 2781/10000 (27.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2346s / 29.1841 s
agent0:                 episode reward: -0.4047,                 loss: nan
agent1:                 episode reward: 0.4047,                 loss: 0.2626
Episode: 2801/10000 (28.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2490s / 29.4331 s
agent0:                 episode reward: -0.7107,                 loss: nan
agent1:                 episode reward: 0.7107,                 loss: 0.2643
Episode: 2821/10000 (28.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2396s / 29.6726 s
agent0:                 episode reward: -0.4897,                 loss: nan
agent1:                 episode reward: 0.4897,                 loss: 0.2613
Episode: 2841/10000 (28.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2364s / 29.9090 s
agent0:                 episode reward: -0.4034,                 loss: nan
agent1:                 episode reward: 0.4034,                 loss: 0.2594
Episode: 2861/10000 (28.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2397s / 30.1487 s
agent0:                 episode reward: -0.9688,                 loss: nan
agent1:                 episode reward: 0.9688,                 loss: 0.2612
Episode: 2881/10000 (28.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2396s / 30.3883 s
agent0:                 episode reward: -0.6327,                 loss: nan
agent1:                 episode reward: 0.6327,                 loss: 0.2562
Episode: 2901/10000 (29.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2397s / 30.6280 s
agent0:                 episode reward: -0.9044,                 loss: nan
agent1:                 episode reward: 0.9044,                 loss: 0.2656
Episode: 2921/10000 (29.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2377s / 30.8657 s
agent0:                 episode reward: -0.9394,                 loss: nan
agent1:                 episode reward: 0.9394,                 loss: 0.2677
Episode: 2941/10000 (29.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2394s / 31.1051 s
agent0:                 episode reward: -0.9833,                 loss: nan
agent1:                 episode reward: 0.9833,                 loss: 0.2645
Episode: 2961/10000 (29.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2403s / 31.3453 s
agent0:                 episode reward: -0.1360,                 loss: nan
agent1:                 episode reward: 0.1360,                 loss: 0.2646
Episode: 2981/10000 (29.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2468s / 31.5922 s
agent0:                 episode reward: -0.1388,                 loss: nan
agent1:                 episode reward: 0.1388,                 loss: 0.2651
Episode: 3001/10000 (30.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2399s / 31.8321 s
agent0:                 episode reward: -0.5492,                 loss: nan
agent1:                 episode reward: 0.5492,                 loss: 0.2627
Episode: 3021/10000 (30.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2460s / 32.0780 s
agent0:                 episode reward: -0.6524,                 loss: nan
agent1:                 episode reward: 0.6524,                 loss: 0.2676
Episode: 3041/10000 (30.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2449s / 32.3230 s
agent0:                 episode reward: -0.4417,                 loss: nan
agent1:                 episode reward: 0.4417,                 loss: 0.2642
Episode: 3061/10000 (30.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2484s / 32.5713 s
agent0:                 episode reward: -0.2467,                 loss: nan
agent1:                 episode reward: 0.2467,                 loss: 0.2651
Episode: 3081/10000 (30.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2394s / 32.8108 s
agent0:                 episode reward: -0.7616,                 loss: nan
agent1:                 episode reward: 0.7616,                 loss: 0.2649
Episode: 3101/10000 (31.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2408s / 33.0516 s
agent0:                 episode reward: -0.6223,                 loss: nan
agent1:                 episode reward: 0.6223,                 loss: 0.2673
Episode: 3121/10000 (31.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2381s / 33.2897 s
agent0:                 episode reward: -0.4844,                 loss: nan
agent1:                 episode reward: 0.4844,                 loss: 0.2650
Episode: 3141/10000 (31.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2441s / 33.5338 s
agent0:                 episode reward: -0.5436,                 loss: nan
agent1:                 episode reward: 0.5436,                 loss: 0.2655
Episode: 3161/10000 (31.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2415s / 33.7753 s
agent0:                 episode reward: -0.6728,                 loss: nan
agent1:                 episode reward: 0.6728,                 loss: 0.2669
Episode: 3181/10000 (31.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2435s / 34.0189 s
agent0:                 episode reward: -0.9891,                 loss: nan
agent1:                 episode reward: 0.9891,                 loss: 0.2667
Episode: 3201/10000 (32.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2443s / 34.2632 s
agent0:                 episode reward: -0.4918,                 loss: nan
agent1:                 episode reward: 0.4918,                 loss: 0.2666
Episode: 3221/10000 (32.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2432s / 34.5064 s
agent0:                 episode reward: -0.6690,                 loss: nan
agent1:                 episode reward: 0.6690,                 loss: 0.2666
Episode: 3241/10000 (32.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2436s / 34.7500 s
agent0:                 episode reward: -1.0830,                 loss: nan
agent1:                 episode reward: 1.0830,                 loss: 0.2668
Episode: 3261/10000 (32.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2432s / 34.9932 s
agent0:                 episode reward: -0.4174,                 loss: nan
agent1:                 episode reward: 0.4174,                 loss: 0.2688
Episode: 3281/10000 (32.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2668s / 35.2600 s
agent0:                 episode reward: -0.4255,                 loss: nan
agent1:                 episode reward: 0.4255,                 loss: 0.2654
Episode: 3301/10000 (33.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2435s / 35.5036 s
agent0:                 episode reward: -0.5644,                 loss: nan
agent1:                 episode reward: 0.5644,                 loss: 0.2646
Episode: 3321/10000 (33.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2431s / 35.7467 s
agent0:                 episode reward: -0.6712,                 loss: nan
agent1:                 episode reward: 0.6712,                 loss: 0.2663
Episode: 3341/10000 (33.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2490s / 35.9957 s
agent0:                 episode reward: -1.0017,                 loss: nan
agent1:                 episode reward: 1.0017,                 loss: 0.2667
Episode: 3361/10000 (33.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2465s / 36.2421 s
agent0:                 episode reward: -0.5829,                 loss: nan
agent1:                 episode reward: 0.5829,                 loss: 0.2658
Episode: 3381/10000 (33.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2461s / 36.4883 s
agent0:                 episode reward: -0.9306,                 loss: nan
agent1:                 episode reward: 0.9306,                 loss: 0.2656
Episode: 3401/10000 (34.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2466s / 36.7348 s
agent0:                 episode reward: -1.0115,                 loss: nan
agent1:                 episode reward: 1.0115,                 loss: 0.2628
Episode: 3421/10000 (34.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2451s / 36.9800 s
agent0:                 episode reward: -0.4875,                 loss: nan
agent1:                 episode reward: 0.4875,                 loss: 0.2635
Episode: 3441/10000 (34.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2436s / 37.2236 s
agent0:                 episode reward: -0.2990,                 loss: nan
agent1:                 episode reward: 0.2990,                 loss: 0.2664
Episode: 3461/10000 (34.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2447s / 37.4683 s
agent0:                 episode reward: -0.6995,                 loss: nan
agent1:                 episode reward: 0.6995,                 loss: 0.2650
Episode: 3481/10000 (34.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2470s / 37.7153 s
agent0:                 episode reward: -0.7202,                 loss: nan
agent1:                 episode reward: 0.7202,                 loss: 0.2634
Episode: 3501/10000 (35.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2472s / 37.9624 s
agent0:                 episode reward: -0.6608,                 loss: nan
agent1:                 episode reward: 0.6608,                 loss: 0.2655
Episode: 3521/10000 (35.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2974s / 38.2598 s
agent0:                 episode reward: -0.3896,                 loss: nan
agent1:                 episode reward: 0.3896,                 loss: 0.2664
Episode: 3541/10000 (35.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2782s / 38.5380 s
agent0:                 episode reward: -0.8294,                 loss: nan
agent1:                 episode reward: 0.8294,                 loss: 0.2649
Episode: 3561/10000 (35.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2455s / 38.7835 s
agent0:                 episode reward: -0.7073,                 loss: nan
agent1:                 episode reward: 0.7073,                 loss: 0.2658
Episode: 3581/10000 (35.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2481s / 39.0316 s
agent0:                 episode reward: -1.0181,                 loss: nan
agent1:                 episode reward: 1.0181,                 loss: 0.2634
Episode: 3601/10000 (36.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2473s / 39.2789 s
agent0:                 episode reward: -0.8516,                 loss: nan
agent1:                 episode reward: 0.8516,                 loss: 0.2640
Episode: 3621/10000 (36.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2494s / 39.5283 s
agent0:                 episode reward: -0.4006,                 loss: nan
agent1:                 episode reward: 0.4006,                 loss: 0.2629
Episode: 3641/10000 (36.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2485s / 39.7768 s
agent0:                 episode reward: -0.2116,                 loss: nan
agent1:                 episode reward: 0.2116,                 loss: 0.2622
Episode: 3661/10000 (36.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2508s / 40.0276 s
agent0:                 episode reward: -0.5771,                 loss: nan
agent1:                 episode reward: 0.5771,                 loss: 0.2636
Episode: 3681/10000 (36.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2502s / 40.2779 s
agent0:                 episode reward: -0.7597,                 loss: nan
agent1:                 episode reward: 0.7597,                 loss: 0.2619
Episode: 3701/10000 (37.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2503s / 40.5282 s
agent0:                 episode reward: -0.5760,                 loss: nan
agent1:                 episode reward: 0.5760,                 loss: 0.2619
Episode: 3721/10000 (37.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2468s / 40.7750 s
agent0:                 episode reward: -0.8580,                 loss: nan
agent1:                 episode reward: 0.8580,                 loss: 0.2649
Episode: 3741/10000 (37.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2518s / 41.0268 s
agent0:                 episode reward: -0.7738,                 loss: nan
agent1:                 episode reward: 0.7738,                 loss: 0.2616
Episode: 3761/10000 (37.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2508s / 41.2776 s
agent0:                 episode reward: -0.8834,                 loss: nan
agent1:                 episode reward: 0.8834,                 loss: 0.2597
Episode: 3781/10000 (37.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2741s / 41.5517 s
agent0:                 episode reward: -0.3709,                 loss: nan
agent1:                 episode reward: 0.3709,                 loss: 0.2592
Episode: 3801/10000 (38.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2528s / 41.8045 s
agent0:                 episode reward: -1.0102,                 loss: nan
agent1:                 episode reward: 1.0102,                 loss: 0.2606
Episode: 3821/10000 (38.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2503s / 42.0548 s
agent0:                 episode reward: -0.8247,                 loss: nan
agent1:                 episode reward: 0.8247,                 loss: 0.2609
Episode: 3841/10000 (38.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2518s / 42.3066 s
agent0:                 episode reward: -0.9843,                 loss: nan
agent1:                 episode reward: 0.9843,                 loss: 0.2608
Episode: 3861/10000 (38.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2555s / 42.5621 s
agent0:                 episode reward: -0.4141,                 loss: nan
agent1:                 episode reward: 0.4141,                 loss: 0.2589
Episode: 3881/10000 (38.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2504s / 42.8126 s
agent0:                 episode reward: -0.6596,                 loss: nan
agent1:                 episode reward: 0.6596,                 loss: 0.2595
Episode: 3901/10000 (39.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2523s / 43.0649 s
agent0:                 episode reward: -0.9597,                 loss: nan
agent1:                 episode reward: 0.9597,                 loss: 0.2652
Episode: 3921/10000 (39.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2501s / 43.3150 s
agent0:                 episode reward: -1.0833,                 loss: nan
agent1:                 episode reward: 1.0833,                 loss: 0.2646
Episode: 3941/10000 (39.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2729s / 43.5879 s
agent0:                 episode reward: -0.8699,                 loss: nan
agent1:                 episode reward: 0.8699,                 loss: 0.2617
Episode: 3961/10000 (39.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2559s / 43.8438 s
agent0:                 episode reward: -0.3372,                 loss: nan
agent1:                 episode reward: 0.3372,                 loss: 0.2656
Episode: 3981/10000 (39.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2579s / 44.1017 s
agent0:                 episode reward: -0.8997,                 loss: nan
agent1:                 episode reward: 0.8997,                 loss: 0.2616
Episode: 4001/10000 (40.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2620s / 44.3636 s
agent0:                 episode reward: -0.6077,                 loss: nan
agent1:                 episode reward: 0.6077,                 loss: 0.2654
Episode: 4021/10000 (40.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2613s / 44.6249 s
agent0:                 episode reward: -0.9919,                 loss: nan
agent1:                 episode reward: 0.9919,                 loss: 0.2632
Episode: 4041/10000 (40.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2536s / 44.8785 s
agent0:                 episode reward: -0.6383,                 loss: nan
agent1:                 episode reward: 0.6383,                 loss: 0.2647
Episode: 4061/10000 (40.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2568s / 45.1353 s
agent0:                 episode reward: -0.7872,                 loss: nan
agent1:                 episode reward: 0.7872,                 loss: 0.2649
Episode: 4081/10000 (40.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2542s / 45.3895 s
agent0:                 episode reward: -0.4210,                 loss: nan
agent1:                 episode reward: 0.4210,                 loss: 0.2598
Episode: 4101/10000 (41.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2543s / 45.6438 s
agent0:                 episode reward: -0.7803,                 loss: nan
agent1:                 episode reward: 0.7803,                 loss: 0.2632
Episode: 4121/10000 (41.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2572s / 45.9010 s
agent0:                 episode reward: -0.6540,                 loss: nan
agent1:                 episode reward: 0.6540,                 loss: 0.2629
Episode: 4141/10000 (41.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2574s / 46.1583 s
agent0:                 episode reward: -0.7818,                 loss: nan
agent1:                 episode reward: 0.7818,                 loss: 0.2625
Episode: 4161/10000 (41.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2584s / 46.4167 s
agent0:                 episode reward: -0.8074,                 loss: nan
agent1:                 episode reward: 0.8074,                 loss: 0.2647
Episode: 4181/10000 (41.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2601s / 46.6768 s
agent0:                 episode reward: -0.8024,                 loss: nan
agent1:                 episode reward: 0.8024,                 loss: 0.2632
Episode: 4201/10000 (42.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2579s / 46.9347 s
agent0:                 episode reward: -0.8935,                 loss: nan
agent1:                 episode reward: 0.8935,                 loss: 0.2636
Episode: 4221/10000 (42.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2599s / 47.1946 s
agent0:                 episode reward: -0.8323,                 loss: nan
agent1:                 episode reward: 0.8323,                 loss: 0.2635
Episode: 4241/10000 (42.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2719s / 47.4665 s
agent0:                 episode reward: -0.6303,                 loss: nan
agent1:                 episode reward: 0.6303,                 loss: 0.2656
Episode: 4261/10000 (42.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2622s / 47.7287 s
agent0:                 episode reward: -0.4736,                 loss: nan
agent1:                 episode reward: 0.4736,                 loss: 0.2644
Episode: 4281/10000 (42.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2632s / 47.9919 s
agent0:                 episode reward: -0.1037,                 loss: nan
agent1:                 episode reward: 0.1037,                 loss: 0.2694
Episode: 4301/10000 (43.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2583s / 48.2502 s
agent0:                 episode reward: -0.9797,                 loss: nan
agent1:                 episode reward: 0.9797,                 loss: 0.2644
Episode: 4321/10000 (43.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3118s / 48.5619 s
agent0:                 episode reward: -0.9707,                 loss: nan
agent1:                 episode reward: 0.9707,                 loss: 0.2662
Episode: 4341/10000 (43.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2653s / 48.8272 s
agent0:                 episode reward: -0.9355,                 loss: nan
agent1:                 episode reward: 0.9355,                 loss: 0.2684
Episode: 4361/10000 (43.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2677s / 49.0949 s
agent0:                 episode reward: -0.7256,                 loss: nan
agent1:                 episode reward: 0.7256,                 loss: 0.2680
Episode: 4381/10000 (43.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2666s / 49.3615 s
agent0:                 episode reward: -0.6805,                 loss: nan
agent1:                 episode reward: 0.6805,                 loss: 0.2637
Episode: 4401/10000 (44.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2628s / 49.6243 s
agent0:                 episode reward: -0.9283,                 loss: nan
agent1:                 episode reward: 0.9283,                 loss: 0.2687
Episode: 4421/10000 (44.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2633s / 49.8876 s
agent0:                 episode reward: -0.8821,                 loss: nan
agent1:                 episode reward: 0.8821,                 loss: 0.2644
Episode: 4441/10000 (44.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2650s / 50.1526 s
agent0:                 episode reward: -0.5453,                 loss: nan
agent1:                 episode reward: 0.5453,                 loss: 0.2653
Episode: 4461/10000 (44.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2720s / 50.4246 s
agent0:                 episode reward: -0.8258,                 loss: nan
agent1:                 episode reward: 0.8258,                 loss: 0.2622
Episode: 4481/10000 (44.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2683s / 50.6929 s
agent0:                 episode reward: -0.5147,                 loss: nan
agent1:                 episode reward: 0.5147,                 loss: 0.2619
Episode: 4501/10000 (45.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2592s / 50.9521 s
agent0:                 episode reward: -0.6875,                 loss: nan
agent1:                 episode reward: 0.6875,                 loss: 0.2620
Episode: 4521/10000 (45.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2631s / 51.2152 s
agent0:                 episode reward: -1.0768,                 loss: nan
agent1:                 episode reward: 1.0768,                 loss: 0.2645
Episode: 4541/10000 (45.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2648s / 51.4800 s
agent0:                 episode reward: -0.8306,                 loss: nan
agent1:                 episode reward: 0.8306,                 loss: 0.2649
Episode: 4561/10000 (45.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2754s / 51.7554 s
agent0:                 episode reward: -0.7435,                 loss: nan
agent1:                 episode reward: 0.7435,                 loss: 0.2676
Episode: 4581/10000 (45.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2797s / 52.0351 s
agent0:                 episode reward: -0.8972,                 loss: nan
agent1:                 episode reward: 0.8972,                 loss: 0.2696
Episode: 4601/10000 (46.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2687s / 52.3038 s
agent0:                 episode reward: -0.6320,                 loss: nan
agent1:                 episode reward: 0.6320,                 loss: 0.2679
Episode: 4621/10000 (46.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2667s / 52.5705 s
agent0:                 episode reward: -1.1688,                 loss: nan
agent1:                 episode reward: 1.1688,                 loss: 0.2691
Episode: 4641/10000 (46.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2678s / 52.8383 s
agent0:                 episode reward: -0.8170,                 loss: nan
agent1:                 episode reward: 0.8170,                 loss: 0.2689
Episode: 4661/10000 (46.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2660s / 53.1043 s
agent0:                 episode reward: -0.6179,                 loss: nan
agent1:                 episode reward: 0.6179,                 loss: 0.2712
Episode: 4681/10000 (46.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2668s / 53.3710 s
agent0:                 episode reward: -1.1457,                 loss: nan
agent1:                 episode reward: 1.1457,                 loss: 0.2678
Episode: 4701/10000 (47.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2771s / 53.6481 s
agent0:                 episode reward: -0.9297,                 loss: nan
agent1:                 episode reward: 0.9297,                 loss: 0.2690
Episode: 4721/10000 (47.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2684s / 53.9165 s
agent0:                 episode reward: -0.7361,                 loss: nan
agent1:                 episode reward: 0.7361,                 loss: 0.2689
Episode: 4741/10000 (47.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2717s / 54.1882 s
agent0:                 episode reward: -0.7862,                 loss: nan
agent1:                 episode reward: 0.7862,                 loss: 0.2726
Episode: 4761/10000 (47.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2656s / 54.4538 s
agent0:                 episode reward: -1.1540,                 loss: nan
agent1:                 episode reward: 1.1540,                 loss: 0.2696
Episode: 4781/10000 (47.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2670s / 54.7207 s
agent0:                 episode reward: -0.4689,                 loss: nan
agent1:                 episode reward: 0.4689,                 loss: 0.2695
Episode: 4801/10000 (48.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2675s / 54.9883 s
agent0:                 episode reward: -0.3691,                 loss: nan
agent1:                 episode reward: 0.3691,                 loss: 0.2702
Episode: 4821/10000 (48.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2690s / 55.2572 s
agent0:                 episode reward: -0.7050,                 loss: nan
agent1:                 episode reward: 0.7050,                 loss: 0.2696
Episode: 4841/10000 (48.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2670s / 55.5242 s
agent0:                 episode reward: -0.5614,                 loss: nan
agent1:                 episode reward: 0.5614,                 loss: 0.2669
Episode: 4861/10000 (48.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2698s / 55.7940 s
agent0:                 episode reward: -0.7236,                 loss: nan
agent1:                 episode reward: 0.7236,                 loss: 0.2702
Episode: 4881/10000 (48.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2706s / 56.0646 s
agent0:                 episode reward: -1.1843,                 loss: nan
agent1:                 episode reward: 1.1843,                 loss: 0.2655
Episode: 4901/10000 (49.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2688s / 56.3334 s
agent0:                 episode reward: -0.6922,                 loss: nan
agent1:                 episode reward: 0.6922,                 loss: 0.2733
Episode: 4921/10000 (49.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2729s / 56.6063 s
agent0:                 episode reward: -0.7902,                 loss: nan
agent1:                 episode reward: 0.7902,                 loss: 0.2727
Episode: 4941/10000 (49.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2671s / 56.8734 s
agent0:                 episode reward: -0.7372,                 loss: nan
agent1:                 episode reward: 0.7372,                 loss: 0.2736
Episode: 4961/10000 (49.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2670s / 57.1405 s
agent0:                 episode reward: -0.8302,                 loss: nan
agent1:                 episode reward: 0.8302,                 loss: 0.2705
Episode: 4981/10000 (49.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2629s / 57.4034 s
agent0:                 episode reward: -0.6031,                 loss: nan
agent1:                 episode reward: 0.6031,                 loss: 0.2714
Episode: 5001/10000 (50.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2634s / 57.6668 s
agent0:                 episode reward: -1.1522,                 loss: nan
agent1:                 episode reward: 1.1522,                 loss: 0.2705
Episode: 5021/10000 (50.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2618s / 57.9286 s
agent0:                 episode reward: -0.6935,                 loss: nan
agent1:                 episode reward: 0.6935,                 loss: 0.2686
Episode: 5041/10000 (50.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2665s / 58.1951 s
agent0:                 episode reward: -1.1201,                 loss: nan
agent1:                 episode reward: 1.1201,                 loss: 0.2709
Episode: 5061/10000 (50.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2658s / 58.4608 s
agent0:                 episode reward: -0.6188,                 loss: nan
agent1:                 episode reward: 0.6188,                 loss: 0.2734
Episode: 5081/10000 (50.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3141s / 58.7749 s
agent0:                 episode reward: -0.9718,                 loss: nan
agent1:                 episode reward: 0.9718,                 loss: 0.2739
Episode: 5101/10000 (51.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2779s / 59.0528 s
agent0:                 episode reward: -0.6591,                 loss: nan
agent1:                 episode reward: 0.6591,                 loss: 0.2735
Episode: 5121/10000 (51.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2698s / 59.3226 s
agent0:                 episode reward: -0.7224,                 loss: nan
agent1:                 episode reward: 0.7224,                 loss: 0.2678
Episode: 5141/10000 (51.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2971s / 59.6198 s
agent0:                 episode reward: -0.9736,                 loss: nan
agent1:                 episode reward: 0.9736,                 loss: 0.2704
Episode: 5161/10000 (51.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2653s / 59.8851 s
agent0:                 episode reward: -0.6623,                 loss: nan
agent1:                 episode reward: 0.6623,                 loss: 0.2701
Episode: 5181/10000 (51.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2889s / 60.1740 s
agent0:                 episode reward: -0.6930,                 loss: nan
agent1:                 episode reward: 0.6930,                 loss: 0.2773
Episode: 5201/10000 (52.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2674s / 60.4414 s
agent0:                 episode reward: -1.1766,                 loss: nan
agent1:                 episode reward: 1.1766,                 loss: 0.2720
Episode: 5221/10000 (52.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2758s / 60.7172 s
agent0:                 episode reward: -0.6587,                 loss: nan
agent1:                 episode reward: 0.6587,                 loss: 0.2705
Episode: 5241/10000 (52.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2670s / 60.9842 s
agent0:                 episode reward: -0.9752,                 loss: nan
agent1:                 episode reward: 0.9752,                 loss: 0.2736
Episode: 5261/10000 (52.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2679s / 61.2521 s
agent0:                 episode reward: -0.8055,                 loss: nan
agent1:                 episode reward: 0.8055,                 loss: 0.2751
Episode: 5281/10000 (52.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2680s / 61.5201 s
agent0:                 episode reward: -0.7541,                 loss: nan
agent1:                 episode reward: 0.7541,                 loss: 0.2736
Episode: 5301/10000 (53.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2797s / 61.7998 s
agent0:                 episode reward: -0.9873,                 loss: nan
agent1:                 episode reward: 0.9873,                 loss: 0.2753
Episode: 5321/10000 (53.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2722s / 62.0720 s
agent0:                 episode reward: -1.0020,                 loss: nan
agent1:                 episode reward: 1.0020,                 loss: 0.2723
Episode: 5341/10000 (53.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2686s / 62.3406 s
agent0:                 episode reward: -0.6236,                 loss: nan
agent1:                 episode reward: 0.6236,                 loss: 0.2743
Episode: 5361/10000 (53.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2877s / 62.6282 s
agent0:                 episode reward: -0.9249,                 loss: nan
agent1:                 episode reward: 0.9249,                 loss: 0.2718
Episode: 5381/10000 (53.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2727s / 62.9009 s
agent0:                 episode reward: -0.9586,                 loss: nan
agent1:                 episode reward: 0.9586,                 loss: 0.2747
Episode: 5401/10000 (54.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2835s / 63.1845 s
agent0:                 episode reward: -1.1003,                 loss: nan
agent1:                 episode reward: 1.1003,                 loss: 0.2731
Episode: 5421/10000 (54.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2690s / 63.4535 s
agent0:                 episode reward: -0.6748,                 loss: nan
agent1:                 episode reward: 0.6748,                 loss: 0.2745
Episode: 5441/10000 (54.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2716s / 63.7251 s
agent0:                 episode reward: -1.1086,                 loss: nan
agent1:                 episode reward: 1.1086,                 loss: 0.2768
Episode: 5461/10000 (54.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2727s / 63.9978 s
agent0:                 episode reward: -0.9743,                 loss: nan
agent1:                 episode reward: 0.9743,                 loss: 0.2743
Episode: 5481/10000 (54.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2711s / 64.2689 s
agent0:                 episode reward: -1.0345,                 loss: nan
agent1:                 episode reward: 1.0345,                 loss: 0.2738
Episode: 5501/10000 (55.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2757s / 64.5446 s
agent0:                 episode reward: -0.8245,                 loss: nan
agent1:                 episode reward: 0.8245,                 loss: 0.2748
Episode: 5521/10000 (55.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2750s / 64.8196 s
agent0:                 episode reward: -0.9543,                 loss: nan
agent1:                 episode reward: 0.9543,                 loss: 0.2739
Episode: 5541/10000 (55.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2817s / 65.1013 s
agent0:                 episode reward: -1.0109,                 loss: nan
agent1:                 episode reward: 1.0109,                 loss: 0.2737
Episode: 5561/10000 (55.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2684s / 65.3696 s
agent0:                 episode reward: -0.5963,                 loss: nan
agent1:                 episode reward: 0.5963,                 loss: 0.2799
Episode: 5581/10000 (55.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2754s / 65.6450 s
agent0:                 episode reward: -0.7769,                 loss: nan
agent1:                 episode reward: 0.7769,                 loss: 0.2749
Episode: 5601/10000 (56.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2725s / 65.9175 s
agent0:                 episode reward: -0.8646,                 loss: nan
agent1:                 episode reward: 0.8646,                 loss: 0.2778
Episode: 5621/10000 (56.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2764s / 66.1939 s
agent0:                 episode reward: -0.7857,                 loss: nan
agent1:                 episode reward: 0.7857,                 loss: 0.2794
Episode: 5641/10000 (56.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2708s / 66.4647 s
agent0:                 episode reward: -1.0338,                 loss: nan
agent1:                 episode reward: 1.0338,                 loss: 0.2743
Episode: 5661/10000 (56.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2725s / 66.7372 s
agent0:                 episode reward: -0.8568,                 loss: nan
agent1:                 episode reward: 0.8568,                 loss: 0.2750
Episode: 5681/10000 (56.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2754s / 67.0125 s
agent0:                 episode reward: -0.7219,                 loss: nan
agent1:                 episode reward: 0.7219,                 loss: 0.2754
Episode: 5701/10000 (57.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2749s / 67.2875 s
agent0:                 episode reward: -1.1328,                 loss: nan
agent1:                 episode reward: 1.1328,                 loss: 0.2775
Episode: 5721/10000 (57.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2757s / 67.5632 s
agent0:                 episode reward: -1.1088,                 loss: nan
agent1:                 episode reward: 1.1088,                 loss: 0.2774
Episode: 5741/10000 (57.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2731s / 67.8363 s
agent0:                 episode reward: -0.6758,                 loss: nan
agent1:                 episode reward: 0.6758,                 loss: 0.2744
Episode: 5761/10000 (57.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2782s / 68.1145 s
agent0:                 episode reward: -0.7345,                 loss: nan
agent1:                 episode reward: 0.7345,                 loss: 0.2753
Episode: 5781/10000 (57.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2902s / 68.4048 s
agent0:                 episode reward: -1.0268,                 loss: nan
agent1:                 episode reward: 1.0268,                 loss: 0.2742
Episode: 5801/10000 (58.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2916s / 68.6963 s
agent0:                 episode reward: -0.7592,                 loss: nan
agent1:                 episode reward: 0.7592,                 loss: 0.2733
Episode: 5821/10000 (58.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3247s / 69.0210 s
agent0:                 episode reward: -0.6694,                 loss: nan
agent1:                 episode reward: 0.6694,                 loss: 0.2773
Episode: 5841/10000 (58.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2834s / 69.3044 s
agent0:                 episode reward: -0.4584,                 loss: nan
agent1:                 episode reward: 0.4584,                 loss: 0.2756
Episode: 5861/10000 (58.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2788s / 69.5832 s
agent0:                 episode reward: -1.2451,                 loss: nan
agent1:                 episode reward: 1.2451,                 loss: 0.2760
Episode: 5881/10000 (58.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2788s / 69.8620 s
agent0:                 episode reward: -0.7597,                 loss: nan
agent1:                 episode reward: 0.7597,                 loss: 0.2737
Episode: 5901/10000 (59.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2784s / 70.1404 s
agent0:                 episode reward: -1.1290,                 loss: nan
agent1:                 episode reward: 1.1290,                 loss: 0.2854
Episode: 5921/10000 (59.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2771s / 70.4175 s
agent0:                 episode reward: -1.0579,                 loss: nan
agent1:                 episode reward: 1.0579,                 loss: 0.2800
Episode: 5941/10000 (59.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2795s / 70.6970 s
agent0:                 episode reward: -0.7432,                 loss: nan
agent1:                 episode reward: 0.7432,                 loss: 0.2802
Episode: 5961/10000 (59.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2772s / 70.9742 s
agent0:                 episode reward: -0.8753,                 loss: nan
agent1:                 episode reward: 0.8753,                 loss: 0.2790
Episode: 5981/10000 (59.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2780s / 71.2522 s
agent0:                 episode reward: -0.9310,                 loss: nan
agent1:                 episode reward: 0.9310,                 loss: 0.2796
Episode: 6001/10000 (60.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2950s / 71.5472 s
agent0:                 episode reward: -0.6931,                 loss: nan
agent1:                 episode reward: 0.6931,                 loss: 0.2819
Episode: 6021/10000 (60.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2772s / 71.8244 s
agent0:                 episode reward: -0.4868,                 loss: nan
agent1:                 episode reward: 0.4868,                 loss: 0.2764
Episode: 6041/10000 (60.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2898s / 72.1141 s
agent0:                 episode reward: -1.0026,                 loss: nan
agent1:                 episode reward: 1.0026,                 loss: 0.2779
Episode: 6061/10000 (60.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2769s / 72.3910 s
agent0:                 episode reward: -0.8566,                 loss: nan
agent1:                 episode reward: 0.8566,                 loss: 0.2789
Episode: 6081/10000 (60.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2827s / 72.6737 s
agent0:                 episode reward: -0.4620,                 loss: nan
agent1:                 episode reward: 0.4620,                 loss: 0.2794
Episode: 6101/10000 (61.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2780s / 72.9516 s
agent0:                 episode reward: -0.8223,                 loss: nan
agent1:                 episode reward: 0.8223,                 loss: 0.2791
Episode: 6121/10000 (61.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2809s / 73.2325 s
agent0:                 episode reward: -1.1054,                 loss: nan
agent1:                 episode reward: 1.1054,                 loss: 0.2783
Episode: 6141/10000 (61.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2840s / 73.5165 s
agent0:                 episode reward: -0.5864,                 loss: nan
agent1:                 episode reward: 0.5864,                 loss: 0.2787
Episode: 6161/10000 (61.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2820s / 73.7985 s
agent0:                 episode reward: -0.9957,                 loss: nan
agent1:                 episode reward: 0.9957,                 loss: 0.2812
Episode: 6181/10000 (61.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2858s / 74.0843 s
agent0:                 episode reward: -0.9343,                 loss: nan
agent1:                 episode reward: 0.9343,                 loss: 0.2815
Episode: 6201/10000 (62.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2843s / 74.3686 s
agent0:                 episode reward: -1.1343,                 loss: nan
agent1:                 episode reward: 1.1343,                 loss: 0.2810
Episode: 6221/10000 (62.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2861s / 74.6548 s
agent0:                 episode reward: -0.7435,                 loss: nan
agent1:                 episode reward: 0.7435,                 loss: 0.2783
Episode: 6241/10000 (62.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2815s / 74.9363 s
agent0:                 episode reward: -0.9778,                 loss: nan
agent1:                 episode reward: 0.9778,                 loss: 0.2755
Episode: 6261/10000 (62.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2829s / 75.2192 s
agent0:                 episode reward: -1.3030,                 loss: nan
agent1:                 episode reward: 1.3030,                 loss: 0.2743
Episode: 6281/10000 (62.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2822s / 75.5015 s
agent0:                 episode reward: -0.9780,                 loss: nan
agent1:                 episode reward: 0.9780,                 loss: 0.2811
Episode: 6301/10000 (63.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2839s / 75.7854 s
agent0:                 episode reward: -0.8202,                 loss: nan
agent1:                 episode reward: 0.8202,                 loss: 0.2741
Episode: 6321/10000 (63.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2860s / 76.0714 s
agent0:                 episode reward: -0.7870,                 loss: nan
agent1:                 episode reward: 0.7870,                 loss: 0.2769
Episode: 6341/10000 (63.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2861s / 76.3575 s
agent0:                 episode reward: -1.2755,                 loss: nan
agent1:                 episode reward: 1.2755,                 loss: 0.2801
Episode: 6361/10000 (63.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2877s / 76.6452 s
agent0:                 episode reward: -0.8929,                 loss: nan
agent1:                 episode reward: 0.8929,                 loss: 0.2788
Episode: 6381/10000 (63.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3022s / 76.9475 s
agent0:                 episode reward: -0.9671,                 loss: nan
agent1:                 episode reward: 0.9671,                 loss: 0.2787
Episode: 6401/10000 (64.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2850s / 77.2325 s
agent0:                 episode reward: -0.5698,                 loss: nan
agent1:                 episode reward: 0.5698,                 loss: 0.2755
Episode: 6421/10000 (64.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3477s / 77.5802 s
agent0:                 episode reward: -0.7227,                 loss: nan
agent1:                 episode reward: 0.7227,                 loss: 0.2732
Episode: 6441/10000 (64.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2857s / 77.8659 s
agent0:                 episode reward: -1.0263,                 loss: nan
agent1:                 episode reward: 1.0263,                 loss: 0.2782
Episode: 6461/10000 (64.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2883s / 78.1542 s
agent0:                 episode reward: -0.8509,                 loss: nan
agent1:                 episode reward: 0.8509,                 loss: 0.2790
Episode: 6481/10000 (64.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2827s / 78.4369 s
agent0:                 episode reward: -0.8687,                 loss: nan
agent1:                 episode reward: 0.8687,                 loss: 0.2744
Episode: 6501/10000 (65.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2864s / 78.7233 s
agent0:                 episode reward: -0.9691,                 loss: nan
agent1:                 episode reward: 0.9691,                 loss: 0.2740
Episode: 6521/10000 (65.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2894s / 79.0127 s
agent0:                 episode reward: -1.0201,                 loss: nan
agent1:                 episode reward: 1.0201,                 loss: 0.2763
Episode: 6541/10000 (65.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3378s / 79.3505 s
agent0:                 episode reward: -1.0234,                 loss: nan
agent1:                 episode reward: 1.0234,                 loss: 0.2802
Episode: 6561/10000 (65.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2908s / 79.6413 s
agent0:                 episode reward: -1.0009,                 loss: nan
agent1:                 episode reward: 1.0009,                 loss: 0.2785
Episode: 6581/10000 (65.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2876s / 79.9288 s
agent0:                 episode reward: -0.4429,                 loss: nan
agent1:                 episode reward: 0.4429,                 loss: 0.2827
Episode: 6601/10000 (66.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2915s / 80.2204 s
agent0:                 episode reward: -0.8436,                 loss: nan
agent1:                 episode reward: 0.8436,                 loss: 0.2838
Episode: 6621/10000 (66.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3154s / 80.5357 s
agent0:                 episode reward: -0.7788,                 loss: nan
agent1:                 episode reward: 0.7788,                 loss: 0.2831
Episode: 6641/10000 (66.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2921s / 80.8278 s
agent0:                 episode reward: -1.0230,                 loss: nan
agent1:                 episode reward: 1.0230,                 loss: 0.2818
Episode: 6661/10000 (66.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2895s / 81.1172 s
agent0:                 episode reward: -0.8386,                 loss: nan
agent1:                 episode reward: 0.8386,                 loss: 0.2851
Episode: 6681/10000 (66.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2892s / 81.4065 s
agent0:                 episode reward: -0.8250,                 loss: nan
agent1:                 episode reward: 0.8250,                 loss: 0.2830
Episode: 6701/10000 (67.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2901s / 81.6966 s
agent0:                 episode reward: -0.9822,                 loss: nan
agent1:                 episode reward: 0.9822,                 loss: 0.2843
Episode: 6721/10000 (67.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2930s / 81.9896 s
agent0:                 episode reward: -1.0347,                 loss: nan
agent1:                 episode reward: 1.0347,                 loss: 0.2852
Episode: 6741/10000 (67.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2936s / 82.2831 s
agent0:                 episode reward: -1.1868,                 loss: nan
agent1:                 episode reward: 1.1868,                 loss: 0.2817
Episode: 6761/10000 (67.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2912s / 82.5743 s
agent0:                 episode reward: -0.8661,                 loss: nan
agent1:                 episode reward: 0.8661,                 loss: 0.2822
Episode: 6781/10000 (67.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2891s / 82.8633 s
agent0:                 episode reward: -1.0130,                 loss: nan
agent1:                 episode reward: 1.0130,                 loss: 0.2844
Episode: 6801/10000 (68.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2934s / 83.1568 s
agent0:                 episode reward: -0.8417,                 loss: nan
agent1:                 episode reward: 0.8417,                 loss: 0.2817
Episode: 6821/10000 (68.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2871s / 83.4439 s
agent0:                 episode reward: -1.1959,                 loss: nan
agent1:                 episode reward: 1.1959,                 loss: 0.2860
Episode: 6841/10000 (68.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2984s / 83.7422 s
agent0:                 episode reward: -0.9425,                 loss: nan
agent1:                 episode reward: 0.9425,                 loss: 0.2839
Episode: 6861/10000 (68.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2917s / 84.0339 s
agent0:                 episode reward: -0.8743,                 loss: nan
agent1:                 episode reward: 0.8743,                 loss: 0.2824
Episode: 6881/10000 (68.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2919s / 84.3259 s
agent0:                 episode reward: -1.0232,                 loss: nan
agent1:                 episode reward: 1.0232,                 loss: 0.2815
Episode: 6901/10000 (69.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2924s / 84.6182 s
agent0:                 episode reward: -1.0705,                 loss: nan
agent1:                 episode reward: 1.0705,                 loss: 0.2845
Episode: 6921/10000 (69.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2932s / 84.9115 s
agent0:                 episode reward: -0.8643,                 loss: nan
agent1:                 episode reward: 0.8643,                 loss: 0.2816
Episode: 6941/10000 (69.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3114s / 85.2229 s
agent0:                 episode reward: -0.8349,                 loss: nan
agent1:                 episode reward: 0.8349,                 loss: 0.2811
Episode: 6961/10000 (69.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2940s / 85.5169 s
agent0:                 episode reward: -1.1502,                 loss: nan
agent1:                 episode reward: 1.1502,                 loss: 0.2799
Episode: 6981/10000 (69.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2913s / 85.8082 s
agent0:                 episode reward: -0.5657,                 loss: nan
agent1:                 episode reward: 0.5657,                 loss: 0.2789
Episode: 7001/10000 (70.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2963s / 86.1045 s
agent0:                 episode reward: -1.0218,                 loss: nan
agent1:                 episode reward: 1.0218,                 loss: 0.2818
Episode: 7021/10000 (70.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2940s / 86.3985 s
agent0:                 episode reward: -1.2724,                 loss: nan
agent1:                 episode reward: 1.2724,                 loss: 0.2805
Episode: 7041/10000 (70.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2947s / 86.6932 s
agent0:                 episode reward: -1.1928,                 loss: nan
agent1:                 episode reward: 1.1928,                 loss: 0.2816
Episode: 7061/10000 (70.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2970s / 86.9902 s
agent0:                 episode reward: -0.5689,                 loss: nan
agent1:                 episode reward: 0.5689,                 loss: 0.2837
Episode: 7081/10000 (70.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2971s / 87.2873 s
agent0:                 episode reward: -0.8493,                 loss: nan
agent1:                 episode reward: 0.8493,                 loss: 0.2831
Episode: 7101/10000 (71.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2984s / 87.5858 s
agent0:                 episode reward: -0.7629,                 loss: nan
agent1:                 episode reward: 0.7629,                 loss: 0.2755
Episode: 7121/10000 (71.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2981s / 87.8838 s
agent0:                 episode reward: -0.6248,                 loss: nan
agent1:                 episode reward: 0.6248,                 loss: 0.2795
Episode: 7141/10000 (71.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2962s / 88.1801 s
agent0:                 episode reward: -0.7536,                 loss: nan
agent1:                 episode reward: 0.7536,                 loss: 0.2809
Episode: 7161/10000 (71.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2924s / 88.4725 s
agent0:                 episode reward: -0.8363,                 loss: nan
agent1:                 episode reward: 0.8363,                 loss: 0.2815
Episode: 7181/10000 (71.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2934s / 88.7658 s
agent0:                 episode reward: -0.9375,                 loss: nan
agent1:                 episode reward: 0.9375,                 loss: 0.2789
Episode: 7201/10000 (72.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2950s / 89.0609 s
agent0:                 episode reward: -1.0146,                 loss: nan
agent1:                 episode reward: 1.0146,                 loss: 0.2858
Episode: 7221/10000 (72.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3221s / 89.3829 s
agent0:                 episode reward: -1.0811,                 loss: nan
agent1:                 episode reward: 1.0811,                 loss: 0.2822
Episode: 7241/10000 (72.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3219s / 89.7048 s
agent0:                 episode reward: -1.2171,                 loss: nan
agent1:                 episode reward: 1.2171,                 loss: 0.2812
Episode: 7261/10000 (72.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2963s / 90.0012 s
agent0:                 episode reward: -1.2265,                 loss: nan
agent1:                 episode reward: 1.2265,                 loss: 0.2850
Episode: 7281/10000 (72.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2940s / 90.2951 s
agent0:                 episode reward: -1.0999,                 loss: nan
agent1:                 episode reward: 1.0999,                 loss: 0.2829
Episode: 7301/10000 (73.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2972s / 90.5923 s
agent0:                 episode reward: -0.8688,                 loss: nan
agent1:                 episode reward: 0.8688,                 loss: 0.2853
Episode: 7321/10000 (73.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3003s / 90.8926 s
agent0:                 episode reward: -0.9835,                 loss: nan
agent1:                 episode reward: 0.9835,                 loss: 0.2841
Episode: 7341/10000 (73.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2967s / 91.1893 s
agent0:                 episode reward: -0.9548,                 loss: nan
agent1:                 episode reward: 0.9548,                 loss: 0.2839
Episode: 7361/10000 (73.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2961s / 91.4854 s
agent0:                 episode reward: -0.9882,                 loss: nan
agent1:                 episode reward: 0.9882,                 loss: 0.2852
Episode: 7381/10000 (73.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2988s / 91.7842 s
agent0:                 episode reward: -0.9086,                 loss: nan
agent1:                 episode reward: 0.9086,                 loss: 0.2847
Episode: 7401/10000 (74.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3005s / 92.0847 s
agent0:                 episode reward: -1.0195,                 loss: nan
agent1:                 episode reward: 1.0195,                 loss: 0.2810
Episode: 7421/10000 (74.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3088s / 92.3934 s
agent0:                 episode reward: -0.8079,                 loss: nan
agent1:                 episode reward: 0.8079,                 loss: 0.2773
Episode: 7441/10000 (74.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3140s / 92.7075 s
agent0:                 episode reward: -0.8236,                 loss: nan
agent1:                 episode reward: 0.8236,                 loss: 0.2847
Episode: 7461/10000 (74.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3023s / 93.0098 s
agent0:                 episode reward: -0.7432,                 loss: nan
agent1:                 episode reward: 0.7432,                 loss: 0.2834
Episode: 7481/10000 (74.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3115s / 93.3213 s
agent0:                 episode reward: -0.6949,                 loss: nan
agent1:                 episode reward: 0.6949,                 loss: 0.2795
Episode: 7501/10000 (75.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3060s / 93.6273 s
agent0:                 episode reward: -0.7653,                 loss: nan
agent1:                 episode reward: 0.7653,                 loss: 0.2832
Episode: 7521/10000 (75.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3013s / 93.9286 s
agent0:                 episode reward: -0.9743,                 loss: nan
agent1:                 episode reward: 0.9743,                 loss: 0.2865
Episode: 7541/10000 (75.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3021s / 94.2307 s
agent0:                 episode reward: -0.6812,                 loss: nan
agent1:                 episode reward: 0.6812,                 loss: 0.2825
Episode: 7561/10000 (75.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3044s / 94.5351 s
agent0:                 episode reward: -0.9800,                 loss: nan
agent1:                 episode reward: 0.9800,                 loss: 0.2823
Episode: 7581/10000 (75.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3002s / 94.8354 s
agent0:                 episode reward: -1.3168,                 loss: nan
agent1:                 episode reward: 1.3168,                 loss: 0.2830
Episode: 7601/10000 (76.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2997s / 95.1351 s
agent0:                 episode reward: -0.9170,                 loss: nan
agent1:                 episode reward: 0.9170,                 loss: 0.2840
Episode: 7621/10000 (76.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3024s / 95.4375 s
agent0:                 episode reward: -1.0319,                 loss: nan
agent1:                 episode reward: 1.0319,                 loss: 0.2821
Episode: 7641/10000 (76.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2993s / 95.7368 s
agent0:                 episode reward: -0.9163,                 loss: nan
agent1:                 episode reward: 0.9163,                 loss: 0.2841
Episode: 7661/10000 (76.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3215s / 96.0584 s
agent0:                 episode reward: -0.9712,                 loss: nan
agent1:                 episode reward: 0.9712,                 loss: 0.2831
Episode: 7681/10000 (76.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3017s / 96.3600 s
agent0:                 episode reward: -1.0235,                 loss: nan
agent1:                 episode reward: 1.0235,                 loss: 0.2815
Episode: 7701/10000 (77.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3073s / 96.6673 s
agent0:                 episode reward: -0.8884,                 loss: nan
agent1:                 episode reward: 0.8884,                 loss: 0.2834
Episode: 7721/10000 (77.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2977s / 96.9650 s
agent0:                 episode reward: -0.8895,                 loss: nan
agent1:                 episode reward: 0.8895,                 loss: 0.2839
Episode: 7741/10000 (77.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3013s / 97.2663 s
agent0:                 episode reward: -0.7665,                 loss: nan
agent1:                 episode reward: 0.7665,                 loss: 0.2850
Episode: 7761/10000 (77.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3038s / 97.5701 s
agent0:                 episode reward: -0.8615,                 loss: nan
agent1:                 episode reward: 0.8615,                 loss: 0.2823
Episode: 7781/10000 (77.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2979s / 97.8681 s
agent0:                 episode reward: -1.1416,                 loss: nan
agent1:                 episode reward: 1.1416,                 loss: 0.2823
Episode: 7801/10000 (78.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3027s / 98.1708 s
agent0:                 episode reward: -0.9670,                 loss: nan
agent1:                 episode reward: 0.9670,                 loss: 0.2815
Episode: 7821/10000 (78.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3185s / 98.4894 s
agent0:                 episode reward: -1.0826,                 loss: nan
agent1:                 episode reward: 1.0826,                 loss: 0.2820
Episode: 7841/10000 (78.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3051s / 98.7945 s
agent0:                 episode reward: -0.8698,                 loss: nan
agent1:                 episode reward: 0.8698,                 loss: 0.2781
Episode: 7861/10000 (78.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3073s / 99.1018 s
agent0:                 episode reward: -0.8316,                 loss: nan
agent1:                 episode reward: 0.8316,                 loss: 0.2801
Episode: 7881/10000 (78.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3046s / 99.4064 s
agent0:                 episode reward: -1.0281,                 loss: nan
agent1:                 episode reward: 1.0281,                 loss: 0.2803
Episode: 7901/10000 (79.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3531s / 99.7595 s
agent0:                 episode reward: -1.2106,                 loss: nan
agent1:                 episode reward: 1.2106,                 loss: 0.2850
Episode: 7921/10000 (79.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3049s / 100.0644 s
agent0:                 episode reward: -1.0459,                 loss: nan
agent1:                 episode reward: 1.0459,                 loss: 0.2823
Episode: 7941/10000 (79.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3051s / 100.3695 s
agent0:                 episode reward: -0.8763,                 loss: nan
agent1:                 episode reward: 0.8763,                 loss: 0.2833
Episode: 7961/10000 (79.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3113s / 100.6808 s
agent0:                 episode reward: -0.9013,                 loss: nan
agent1:                 episode reward: 0.9013,                 loss: 0.2852
Episode: 7981/10000 (79.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3043s / 100.9852 s
agent0:                 episode reward: -1.2020,                 loss: nan
agent1:                 episode reward: 1.2020,                 loss: 0.2836
Episode: 8001/10000 (80.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3050s / 101.2902 s
agent0:                 episode reward: -0.8196,                 loss: nan
agent1:                 episode reward: 0.8196,                 loss: 0.2839
Episode: 8021/10000 (80.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3484s / 101.6385 s
agent0:                 episode reward: -0.9533,                 loss: nan
agent1:                 episode reward: 0.9533,                 loss: 0.2882
Episode: 8041/10000 (80.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3274s / 101.9659 s
agent0:                 episode reward: -0.9371,                 loss: nan
agent1:                 episode reward: 0.9371,                 loss: 0.2871
Episode: 8061/10000 (80.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3111s / 102.2770 s
agent0:                 episode reward: -0.6072,                 loss: nan
agent1:                 episode reward: 0.6072,                 loss: 0.2793
Episode: 8081/10000 (80.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3075s / 102.5845 s
agent0:                 episode reward: -0.8069,                 loss: nan
agent1:                 episode reward: 0.8069,                 loss: 0.2843
Episode: 8101/10000 (81.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3018s / 102.8863 s
agent0:                 episode reward: -0.9540,                 loss: nan
agent1:                 episode reward: 0.9540,                 loss: 0.2870
Episode: 8121/10000 (81.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3069s / 103.1932 s
agent0:                 episode reward: -0.9889,                 loss: nan
agent1:                 episode reward: 0.9889,                 loss: 0.2852
Episode: 8141/10000 (81.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3040s / 103.4972 s
agent0:                 episode reward: -0.4363,                 loss: nan
agent1:                 episode reward: 0.4363,                 loss: 0.2844
Episode: 8161/10000 (81.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3099s / 103.8071 s
agent0:                 episode reward: -1.1749,                 loss: nan
agent1:                 episode reward: 1.1749,                 loss: 0.2826
Episode: 8181/10000 (81.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3108s / 104.1179 s
agent0:                 episode reward: -0.9658,                 loss: nan
agent1:                 episode reward: 0.9658,                 loss: 0.2832
Episode: 8201/10000 (82.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3175s / 104.4353 s
agent0:                 episode reward: -0.9227,                 loss: nan
agent1:                 episode reward: 0.9227,                 loss: 0.2818
Episode: 8221/10000 (82.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3242s / 104.7596 s
agent0:                 episode reward: -0.8578,                 loss: nan
agent1:                 episode reward: 0.8578,                 loss: 0.2876
Episode: 8241/10000 (82.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3074s / 105.0670 s
agent0:                 episode reward: -0.9157,                 loss: nan
agent1:                 episode reward: 0.9157,                 loss: 0.2896
Episode: 8261/10000 (82.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3068s / 105.3738 s
agent0:                 episode reward: -1.2302,                 loss: nan
agent1:                 episode reward: 1.2302,                 loss: 0.2911
Episode: 8281/10000 (82.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3135s / 105.6872 s
agent0:                 episode reward: -1.0694,                 loss: nan
agent1:                 episode reward: 1.0694,                 loss: 0.2911
Episode: 8301/10000 (83.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3120s / 105.9992 s
agent0:                 episode reward: -0.9663,                 loss: nan
agent1:                 episode reward: 0.9663,                 loss: 0.2899
Episode: 8321/10000 (83.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3074s / 106.3067 s
agent0:                 episode reward: -0.9686,                 loss: nan
agent1:                 episode reward: 0.9686,                 loss: 0.2888
Episode: 8341/10000 (83.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3130s / 106.6197 s
agent0:                 episode reward: -0.9048,                 loss: nan
agent1:                 episode reward: 0.9048,                 loss: 0.2872
Episode: 8361/10000 (83.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3108s / 106.9305 s
agent0:                 episode reward: -0.8315,                 loss: nan
agent1:                 episode reward: 0.8315,                 loss: 0.2877
Episode: 8381/10000 (83.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3078s / 107.2383 s
agent0:                 episode reward: -1.2243,                 loss: nan
agent1:                 episode reward: 1.2243,                 loss: 0.2886
Episode: 8401/10000 (84.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3208s / 107.5591 s
agent0:                 episode reward: -1.3920,                 loss: nan
agent1:                 episode reward: 1.3920,                 loss: 0.2861
Episode: 8421/10000 (84.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3105s / 107.8697 s
agent0:                 episode reward: -1.3009,                 loss: nan
agent1:                 episode reward: 1.3009,                 loss: 0.2832
Episode: 8441/10000 (84.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3158s / 108.1855 s
agent0:                 episode reward: -0.6845,                 loss: nan
agent1:                 episode reward: 0.6845,                 loss: 0.2858
Episode: 8461/10000 (84.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3096s / 108.4951 s
agent0:                 episode reward: -0.8843,                 loss: nan
agent1:                 episode reward: 0.8843,                 loss: 0.2865
Episode: 8481/10000 (84.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3107s / 108.8057 s
agent0:                 episode reward: -0.6181,                 loss: nan
agent1:                 episode reward: 0.6181,                 loss: 0.2884
Episode: 8501/10000 (85.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3120s / 109.1178 s
agent0:                 episode reward: -0.9495,                 loss: nan
agent1:                 episode reward: 0.9495,                 loss: 0.2899
Episode: 8521/10000 (85.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3126s / 109.4303 s
agent0:                 episode reward: -1.0566,                 loss: nan
agent1:                 episode reward: 1.0566,                 loss: 0.2864
Episode: 8541/10000 (85.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3115s / 109.7418 s
agent0:                 episode reward: -1.0127,                 loss: nan
agent1:                 episode reward: 1.0127,                 loss: 0.2863
Episode: 8561/10000 (85.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3808s / 110.1226 s
agent0:                 episode reward: -1.0855,                 loss: nan
agent1:                 episode reward: 1.0855,                 loss: 0.2877
Episode: 8581/10000 (85.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3107s / 110.4333 s
agent0:                 episode reward: -1.1805,                 loss: nan
agent1:                 episode reward: 1.1805,                 loss: 0.2874
Episode: 8601/10000 (86.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3215s / 110.7548 s
agent0:                 episode reward: -0.7701,                 loss: nan
agent1:                 episode reward: 0.7701,                 loss: 0.2830
Episode: 8621/10000 (86.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3133s / 111.0681 s
agent0:                 episode reward: -1.0630,                 loss: nan
agent1:                 episode reward: 1.0630,                 loss: 0.2839
Episode: 8641/10000 (86.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3090s / 111.3770 s
agent0:                 episode reward: -0.8679,                 loss: nan
agent1:                 episode reward: 0.8679,                 loss: 0.2890
Episode: 8661/10000 (86.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3119s / 111.6890 s
agent0:                 episode reward: -0.8589,                 loss: nan
agent1:                 episode reward: 0.8589,                 loss: 0.2899
Episode: 8681/10000 (86.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3133s / 112.0023 s
agent0:                 episode reward: -0.6433,                 loss: nan
agent1:                 episode reward: 0.6433,                 loss: 0.2870
Episode: 8701/10000 (87.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3307s / 112.3330 s
agent0:                 episode reward: -1.0392,                 loss: nan
agent1:                 episode reward: 1.0392,                 loss: 0.2851
Episode: 8721/10000 (87.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3209s / 112.6539 s
agent0:                 episode reward: -0.8292,                 loss: nan
agent1:                 episode reward: 0.8292,                 loss: 0.2838
Episode: 8741/10000 (87.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3155s / 112.9694 s
agent0:                 episode reward: -0.9519,                 loss: nan
agent1:                 episode reward: 0.9519,                 loss: 0.2833
Episode: 8761/10000 (87.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3132s / 113.2826 s
agent0:                 episode reward: -0.9317,                 loss: nan
agent1:                 episode reward: 0.9317,                 loss: 0.2890
Episode: 8781/10000 (87.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3224s / 113.6050 s
agent0:                 episode reward: -1.0641,                 loss: nan
agent1:                 episode reward: 1.0641,                 loss: 0.2887
Episode: 8801/10000 (88.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3164s / 113.9214 s
agent0:                 episode reward: -0.8304,                 loss: nan
agent1:                 episode reward: 0.8304,                 loss: 0.2868
Episode: 8821/10000 (88.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3185s / 114.2399 s
agent0:                 episode reward: -1.1971,                 loss: nan
agent1:                 episode reward: 1.1971,                 loss: 0.2829
Episode: 8841/10000 (88.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3159s / 114.5558 s
agent0:                 episode reward: -1.0516,                 loss: nan
agent1:                 episode reward: 1.0516,                 loss: 0.2885
Episode: 8861/10000 (88.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3131s / 114.8689 s
agent0:                 episode reward: -0.5711,                 loss: nan
agent1:                 episode reward: 0.5711,                 loss: 0.2871
Episode: 8881/10000 (88.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3163s / 115.1852 s
agent0:                 episode reward: -0.4172,                 loss: nan
agent1:                 episode reward: 0.4172,                 loss: 0.2839
Episode: 8901/10000 (89.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3154s / 115.5005 s
agent0:                 episode reward: -0.8030,                 loss: nan
agent1:                 episode reward: 0.8030,                 loss: 0.2854
Episode: 8921/10000 (89.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3179s / 115.8185 s
agent0:                 episode reward: -1.1135,                 loss: nan
agent1:                 episode reward: 1.1135,                 loss: 0.2823
Episode: 8941/10000 (89.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3173s / 116.1358 s
agent0:                 episode reward: -0.7579,                 loss: nan
agent1:                 episode reward: 0.7579,                 loss: 0.2818
Episode: 8961/10000 (89.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3177s / 116.4535 s
agent0:                 episode reward: -1.4060,                 loss: nan
agent1:                 episode reward: 1.4060,                 loss: 0.2818
Episode: 8981/10000 (89.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3265s / 116.7800 s
agent0:                 episode reward: -0.7586,                 loss: nan
agent1:                 episode reward: 0.7586,                 loss: 0.2831
Episode: 9001/10000 (90.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3211s / 117.1011 s
agent0:                 episode reward: -1.0313,                 loss: nan
agent1:                 episode reward: 1.0313,                 loss: 0.2866
Episode: 9021/10000 (90.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3207s / 117.4218 s
agent0:                 episode reward: -0.8655,                 loss: nan
agent1:                 episode reward: 0.8655,                 loss: 0.2843
Episode: 9041/10000 (90.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3189s / 117.7407 s
agent0:                 episode reward: -0.9701,                 loss: nan
agent1:                 episode reward: 0.9701,                 loss: 0.2835
Episode: 9061/10000 (90.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3201s / 118.0608 s
agent0:                 episode reward: -1.0201,                 loss: nan
agent1:                 episode reward: 1.0201,                 loss: 0.2859
Episode: 9081/10000 (90.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3342s / 118.3950 s
agent0:                 episode reward: -1.1217,                 loss: nan
agent1:                 episode reward: 1.1217,                 loss: 0.2841
Episode: 9101/10000 (91.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3198s / 118.7148 s
agent0:                 episode reward: -0.9954,                 loss: nan
agent1:                 episode reward: 0.9954,                 loss: 0.2808
Episode: 9121/10000 (91.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3201s / 119.0348 s
agent0:                 episode reward: -0.9928,                 loss: nan
agent1:                 episode reward: 0.9928,                 loss: 0.2822
Episode: 9141/10000 (91.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3163s / 119.3512 s
agent0:                 episode reward: -1.0601,                 loss: nan
agent1:                 episode reward: 1.0601,                 loss: 0.2866
Episode: 9161/10000 (91.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3323s / 119.6835 s
agent0:                 episode reward: -1.0336,                 loss: nan
agent1:                 episode reward: 1.0336,                 loss: 0.2833
Episode: 9181/10000 (91.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3205s / 120.0040 s
agent0:                 episode reward: -0.9297,                 loss: nan
agent1:                 episode reward: 0.9297,                 loss: 0.2822
Episode: 9201/10000 (92.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3912s / 120.3952 s
agent0:                 episode reward: -0.4487,                 loss: nan
agent1:                 episode reward: 0.4487,                 loss: 0.2850
Episode: 9221/10000 (92.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3222s / 120.7174 s
agent0:                 episode reward: -1.1487,                 loss: nan
agent1:                 episode reward: 1.1487,                 loss: 0.2851
Episode: 9241/10000 (92.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3234s / 121.0408 s
agent0:                 episode reward: -0.8538,                 loss: nan
agent1:                 episode reward: 0.8538,                 loss: 0.2838
Episode: 9261/10000 (92.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3154s / 121.3563 s
agent0:                 episode reward: -1.1452,                 loss: nan
agent1:                 episode reward: 1.1452,                 loss: 0.2891
Episode: 9281/10000 (92.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3236s / 121.6799 s
agent0:                 episode reward: -1.0032,                 loss: nan
agent1:                 episode reward: 1.0032,                 loss: 0.2871
Episode: 9301/10000 (93.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3213s / 122.0012 s
agent0:                 episode reward: -0.9010,                 loss: nan
agent1:                 episode reward: 0.9010,                 loss: 0.2896
Episode: 9321/10000 (93.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3155s / 122.3167 s
agent0:                 episode reward: -0.9348,                 loss: nan
agent1:                 episode reward: 0.9348,                 loss: 0.2885
Episode: 9341/10000 (93.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3434s / 122.6601 s
agent0:                 episode reward: -0.8005,                 loss: nan
agent1:                 episode reward: 0.8005,                 loss: 0.2911
Episode: 9361/10000 (93.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3306s / 122.9907 s
agent0:                 episode reward: -0.4335,                 loss: nan
agent1:                 episode reward: 0.4335,                 loss: 0.2864
Episode: 9381/10000 (93.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3185s / 123.3092 s
agent0:                 episode reward: -0.7185,                 loss: nan
agent1:                 episode reward: 0.7185,                 loss: 0.2874
Episode: 9401/10000 (94.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3205s / 123.6298 s
agent0:                 episode reward: -1.0744,                 loss: nan
agent1:                 episode reward: 1.0744,                 loss: 0.2870
Episode: 9421/10000 (94.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3259s / 123.9557 s
agent0:                 episode reward: -1.1738,                 loss: nan
agent1:                 episode reward: 1.1738,                 loss: 0.2899
Episode: 9441/10000 (94.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3232s / 124.2789 s
agent0:                 episode reward: -0.8886,                 loss: nan
agent1:                 episode reward: 0.8886,                 loss: 0.2860
Episode: 9461/10000 (94.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3229s / 124.6019 s
agent0:                 episode reward: -0.7828,                 loss: nan
agent1:                 episode reward: 0.7828,                 loss: 0.2836
Episode: 9481/10000 (94.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3197s / 124.9216 s
agent0:                 episode reward: -1.4060,                 loss: nan
agent1:                 episode reward: 1.4060,                 loss: 0.2865
Episode: 9501/10000 (95.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3238s / 125.2454 s
agent0:                 episode reward: -0.8000,                 loss: nan
agent1:                 episode reward: 0.8000,                 loss: 0.2845
Episode: 9521/10000 (95.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3245s / 125.5699 s
agent0:                 episode reward: -1.2094,                 loss: nan
agent1:                 episode reward: 1.2094,                 loss: 0.2903
Episode: 9541/10000 (95.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3323s / 125.9022 s
agent0:                 episode reward: -1.0641,                 loss: nan
agent1:                 episode reward: 1.0641,                 loss: 0.2868
Episode: 9561/10000 (95.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3222s / 126.2243 s
agent0:                 episode reward: -0.7607,                 loss: nan
agent1:                 episode reward: 0.7607,                 loss: 0.2939
Episode: 9581/10000 (95.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3240s / 126.5483 s
agent0:                 episode reward: -1.2168,                 loss: nan
agent1:                 episode reward: 1.2168,                 loss: 0.2882
Episode: 9601/10000 (96.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3391s / 126.8875 s
agent0:                 episode reward: -1.0663,                 loss: nan
agent1:                 episode reward: 1.0663,                 loss: 0.2927
Episode: 9621/10000 (96.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3257s / 127.2132 s
agent0:                 episode reward: -0.6247,                 loss: nan
agent1:                 episode reward: 0.6247,                 loss: 0.2912
Episode: 9641/10000 (96.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3271s / 127.5402 s
agent0:                 episode reward: -1.1053,                 loss: nan
agent1:                 episode reward: 1.1053,                 loss: 0.2914
Episode: 9661/10000 (96.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3233s / 127.8635 s
agent0:                 episode reward: -1.1873,                 loss: nan
agent1:                 episode reward: 1.1873,                 loss: 0.2912
Episode: 9681/10000 (96.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3306s / 128.1941 s
agent0:                 episode reward: -0.7518,                 loss: nan
agent1:                 episode reward: 0.7518,                 loss: 0.2880
Episode: 9701/10000 (97.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3252s / 128.5193 s
agent0:                 episode reward: -1.0527,                 loss: nan
agent1:                 episode reward: 1.0527,                 loss: 0.2867
Episode: 9721/10000 (97.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3420s / 128.8613 s
agent0:                 episode reward: -1.0500,                 loss: nan
agent1:                 episode reward: 1.0500,                 loss: 0.2918
Episode: 9741/10000 (97.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3331s / 129.1944 s
agent0:                 episode reward: -0.9891,                 loss: nan
agent1:                 episode reward: 0.9891,                 loss: 0.2893
Episode: 9761/10000 (97.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3224s / 129.5168 s
agent0:                 episode reward: -0.8917,                 loss: nan
agent1:                 episode reward: 0.8917,                 loss: 0.2865
Episode: 9781/10000 (97.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3272s / 129.8440 s
agent0:                 episode reward: -0.9548,                 loss: nan
agent1:                 episode reward: 0.9548,                 loss: 0.2885
Episode: 9801/10000 (98.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3303s / 130.1744 s
agent0:                 episode reward: -1.1913,                 loss: nan
agent1:                 episode reward: 1.1913,                 loss: 0.2895
Episode: 9821/10000 (98.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3780s / 130.5524 s
agent0:                 episode reward: -0.9204,                 loss: nan
agent1:                 episode reward: 0.9204,                 loss: 0.2879
Episode: 9841/10000 (98.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3279s / 130.8803 s
agent0:                 episode reward: -0.7448,                 loss: nan
agent1:                 episode reward: 0.7448,                 loss: 0.2911
Episode: 9861/10000 (98.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3296s / 131.2099 s
agent0:                 episode reward: -0.6515,                 loss: nan
agent1:                 episode reward: 0.6515,                 loss: 0.2864/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 9881/10000 (98.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3298s / 131.5397 s
agent0:                 episode reward: -0.9303,                 loss: nan
agent1:                 episode reward: 0.9303,                 loss: 0.2907
Episode: 9901/10000 (99.0100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3387s / 131.8784 s
agent0:                 episode reward: -0.8519,                 loss: nan
agent1:                 episode reward: 0.8519,                 loss: 0.2888
Episode: 9921/10000 (99.2100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3341s / 132.2125 s
agent0:                 episode reward: -0.8745,                 loss: nan
agent1:                 episode reward: 0.8745,                 loss: 0.2914
Episode: 9941/10000 (99.4100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3299s / 132.5424 s
agent0:                 episode reward: -1.0260,                 loss: nan
agent1:                 episode reward: 1.0260,                 loss: 0.2877
Episode: 9961/10000 (99.6100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3376s / 132.8800 s
agent0:                 episode reward: -1.3136,                 loss: nan
agent1:                 episode reward: 1.3136,                 loss: 0.2886
Episode: 9981/10000 (99.8100%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3350s / 133.2151 s
agent0:                 episode reward: -0.8277,                 loss: nan
agent1:                 episode reward: 0.8277,                 loss: 0.2869
