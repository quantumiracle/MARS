pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'eta': 0.1}}
Save models to : /home/zihan/research/MARS/data/model/20220119_0521/pettingzoo_boxing_v1_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0521/pettingzoo_boxing_v1_nfsp.
Episode: 1/10000 (0.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 5.4170s / 5.4170 s
env0_first_0:                 episode reward: -3.0000,                 loss: nan
env0_second_0:                 episode reward: 3.0000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 737.3050s / 742.7220 s
env0_first_0:                 episode reward: 3.3500,                 loss: 0.0060
env0_second_0:                 episode reward: -3.3500,                 loss: 0.0057
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 1335.1900s / 2077.9119 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0216
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0190
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 1728.75,                last time consumption/overall running time: 1314.1484s / 3392.0604 s
env0_first_0:                 episode reward: 17.1000,                 loss: 0.0436
env0_second_0:                 episode reward: -17.1000,                 loss: 0.0385
env1_first_0:                 episode reward: 16.8500,                 loss: nan
env1_second_0:                 episode reward: -16.8500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 1402.45,                last time consumption/overall running time: 1070.8269s / 4462.8873 s
env0_first_0:                 episode reward: 49.5000,                 loss: 0.0820
env0_second_0:                 episode reward: -49.5000,                 loss: 0.0569
env1_first_0:                 episode reward: 40.6500,                 loss: nan
env1_second_0:                 episode reward: -40.6500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 1021.9,                last time consumption/overall running time: 782.8621s / 5245.7493 s
env0_first_0:                 episode reward: 57.6000,                 loss: 0.1221
env0_second_0:                 episode reward: -57.6000,                 loss: 0.0874
env1_first_0:                 episode reward: 46.4500,                 loss: nan
env1_second_0:                 episode reward: -46.4500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 471.5,                last time consumption/overall running time: 363.5152s / 5609.2645 s
env0_first_0:                 episode reward: 67.9000,                 loss: 0.1566
env0_second_0:                 episode reward: -67.9000,                 loss: 0.1107
env1_first_0:                 episode reward: 55.1000,                 loss: nan
env1_second_0:                 episode reward: -55.1000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 519.25,                last time consumption/overall running time: 397.3788s / 6006.6433 s
env0_first_0:                 episode reward: 59.5000,                 loss: 0.1702
env0_second_0:                 episode reward: -59.5000,                 loss: 0.1169
env1_first_0:                 episode reward: 57.8500,                 loss: nan
env1_second_0:                 episode reward: -57.8500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 768.95,                last time consumption/overall running time: 588.4550s / 6595.0983 s
env0_first_0:                 episode reward: 37.0500,                 loss: 0.1848
env0_second_0:                 episode reward: -37.0500,                 loss: 0.1226
env1_first_0:                 episode reward: 56.0500,                 loss: nan
env1_second_0:                 episode reward: -56.0500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 842.4,                last time consumption/overall running time: 646.9489s / 7242.0472 s
env0_first_0:                 episode reward: 35.1500,                 loss: 0.2061
env0_second_0:                 episode reward: -35.1500,                 loss: 0.1402
env1_first_0:                 episode reward: 53.8000,                 loss: nan
env1_second_0:                 episode reward: -53.8000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 756.5,                last time consumption/overall running time: 579.8840s / 7821.9312 s
env0_first_0:                 episode reward: 37.1500,                 loss: 0.2538
env0_second_0:                 episode reward: -37.1500,                 loss: 0.1458
env1_first_0:                 episode reward: 38.5000,                 loss: nan
env1_second_0:                 episode reward: -38.5000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 1056.45,                last time consumption/overall running time: 812.8707s / 8634.8019 s
env0_first_0:                 episode reward: 13.8000,                 loss: 0.2989
env0_second_0:                 episode reward: -13.8000,                 loss: 0.1805
env1_first_0:                 episode reward: 53.0500,                 loss: nan
env1_second_0:                 episode reward: -53.0500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 497.65,                last time consumption/overall running time: 382.7268s / 9017.5287 s
env0_first_0:                 episode reward: 26.5000,                 loss: 0.3351
env0_second_0:                 episode reward: -26.5000,                 loss: 0.2456
env1_first_0:                 episode reward: 31.3000,                 loss: nan
env1_second_0:                 episode reward: -31.3000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 345.75,                last time consumption/overall running time: 264.5535s / 9282.0822 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.4346
env0_second_0:                 episode reward: 6.7500,                 loss: 0.2849
env1_first_0:                 episode reward: -17.5500,                 loss: nan
env1_second_0:                 episode reward: 17.5500,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 318.2,                last time consumption/overall running time: 244.4305s / 9526.5127 s
env0_first_0:                 episode reward: -7.1500,                 loss: 0.5203
env0_second_0:                 episode reward: 7.1500,                 loss: 0.3345
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 429.25,                last time consumption/overall running time: 330.4131s / 9856.9259 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.4879
env0_second_0:                 episode reward: -1.7000,                 loss: 0.3260
env1_first_0:                 episode reward: 13.9500,                 loss: nan
env1_second_0:                 episode reward: -13.9500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 505.9,                last time consumption/overall running time: 389.9458s / 10246.8717 s
env0_first_0:                 episode reward: 31.5500,                 loss: 0.5287
env0_second_0:                 episode reward: -31.5500,                 loss: 0.3413
env1_first_0:                 episode reward: 18.9000,                 loss: nan
env1_second_0:                 episode reward: -18.9000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 306.0,                last time consumption/overall running time: 235.6537s / 10482.5254 s
env0_first_0:                 episode reward: 23.0500,                 loss: 0.5970
env0_second_0:                 episode reward: -23.0500,                 loss: 0.4213
env1_first_0:                 episode reward: 13.7000,                 loss: nan
env1_second_0:                 episode reward: -13.7000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 283.8,                last time consumption/overall running time: 217.6434s / 10700.1688 s
env0_first_0:                 episode reward: 40.8500,                 loss: 0.6349
env0_second_0:                 episode reward: -40.8500,                 loss: 0.4953
env1_first_0:                 episode reward: 41.5000,                 loss: nan
env1_second_0:                 episode reward: -41.5000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 337.15,                last time consumption/overall running time: 259.5467s / 10959.7155 s
env0_first_0:                 episode reward: 19.7000,                 loss: 0.6535
env0_second_0:                 episode reward: -19.7000,                 loss: 0.5210
env1_first_0:                 episode reward: 38.0500,                 loss: nan
env1_second_0:                 episode reward: -38.0500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 395.9,                last time consumption/overall running time: 305.2935s / 11265.0090 s
env0_first_0:                 episode reward: 13.2000,                 loss: 0.6590
env0_second_0:                 episode reward: -13.2000,                 loss: 0.5395
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 304.8,                last time consumption/overall running time: 235.8303s / 11500.8394 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.6756
env0_second_0:                 episode reward: 3.6500,                 loss: 0.5233
env1_first_0:                 episode reward: 4.4000,                 loss: nan
env1_second_0:                 episode reward: -4.4000,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 293.05,                last time consumption/overall running time: 226.9033s / 11727.7427 s
env0_first_0:                 episode reward: 23.0000,                 loss: 0.7194
env0_second_0:                 episode reward: -23.0000,                 loss: 0.5652
env1_first_0:                 episode reward: 4.7000,                 loss: nan
env1_second_0:                 episode reward: -4.7000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 348.3,                last time consumption/overall running time: 266.8314s / 11994.5741 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.7713
env0_second_0:                 episode reward: -2.9500,                 loss: 0.6024
env1_first_0:                 episode reward: 8.5000,                 loss: nan
env1_second_0:                 episode reward: -8.5000,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 310.35,                last time consumption/overall running time: 238.9966s / 12233.5707 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.8136
env0_second_0:                 episode reward: 7.3000,                 loss: 0.5800
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 500.3,                last time consumption/overall running time: 384.1206s / 12617.6913 s
env0_first_0:                 episode reward: -27.5500,                 loss: 0.7790
env0_second_0:                 episode reward: 27.5500,                 loss: 0.5548
env1_first_0:                 episode reward: -23.6000,                 loss: nan
env1_second_0:                 episode reward: 23.6000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 268.5,                last time consumption/overall running time: 206.2758s / 12823.9671 s
env0_first_0:                 episode reward: -18.6000,                 loss: 0.7617
env0_second_0:                 episode reward: 18.6000,                 loss: 0.5659
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 335.1,                last time consumption/overall running time: 257.1657s / 13081.1328 s
env0_first_0:                 episode reward: -35.1000,                 loss: 0.8006
env0_second_0:                 episode reward: 35.1000,                 loss: 0.6160
env1_first_0:                 episode reward: -25.4000,                 loss: nan
env1_second_0:                 episode reward: 25.4000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 325.65,                last time consumption/overall running time: 250.5250s / 13331.6578 s
env0_first_0:                 episode reward: -42.2000,                 loss: 0.8466
env0_second_0:                 episode reward: 42.2000,                 loss: 0.6675
env1_first_0:                 episode reward: -45.3500,                 loss: nan
env1_second_0:                 episode reward: 45.3500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 449.85,                last time consumption/overall running time: 346.5642s / 13678.2220 s
env0_first_0:                 episode reward: -21.3500,                 loss: 0.8888
env0_second_0:                 episode reward: 21.3500,                 loss: 0.7484
env1_first_0:                 episode reward: 21.1000,                 loss: nan
env1_second_0:                 episode reward: -21.1000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 377.6,                last time consumption/overall running time: 291.2132s / 13969.4352 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.9110
env0_second_0:                 episode reward: -20.9500,                 loss: 0.7457
env1_first_0:                 episode reward: 39.7000,                 loss: nan
env1_second_0:                 episode reward: -39.7000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 318.5,                last time consumption/overall running time: 246.4069s / 14215.8421 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.9388
env0_second_0:                 episode reward: -3.3000,                 loss: 0.7474
env1_first_0:                 episode reward: 10.7500,                 loss: nan
env1_second_0:                 episode reward: -10.7500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 280.4,                last time consumption/overall running time: 215.9951s / 14431.8372 s
env0_first_0:                 episode reward: 25.9500,                 loss: 0.9706
env0_second_0:                 episode reward: -25.9500,                 loss: 0.7562
env1_first_0:                 episode reward: 19.9500,                 loss: nan
env1_second_0:                 episode reward: -19.9500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 321.05,                last time consumption/overall running time: 246.3506s / 14678.1879 s
env0_first_0:                 episode reward: 15.8000,                 loss: 0.9677
env0_second_0:                 episode reward: -15.8000,                 loss: 0.8285
env1_first_0:                 episode reward: 24.2500,                 loss: nan
env1_second_0:                 episode reward: -24.2500,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 280.95,                last time consumption/overall running time: 214.9328s / 14893.1207 s
env0_first_0:                 episode reward: 12.3000,                 loss: 0.9245
env0_second_0:                 episode reward: -12.3000,                 loss: 0.8023
env1_first_0:                 episode reward: 21.2000,                 loss: nan
env1_second_0:                 episode reward: -21.2000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 291.7,                last time consumption/overall running time: 225.0821s / 15118.2028 s
env0_first_0:                 episode reward: -5.3500,                 loss: 0.9149
env0_second_0:                 episode reward: 5.3500,                 loss: 0.7865
env1_first_0:                 episode reward: 17.8500,                 loss: nan
env1_second_0:                 episode reward: -17.8500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 288.65,                last time consumption/overall running time: 221.8230s / 15340.0257 s
env0_first_0:                 episode reward: 14.6500,                 loss: 0.9413
env0_second_0:                 episode reward: -14.6500,                 loss: 0.7572
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 256.8,                last time consumption/overall running time: 197.0312s / 15537.0569 s
env0_first_0:                 episode reward: 13.0500,                 loss: 0.9632
env0_second_0:                 episode reward: -13.0500,                 loss: 0.7630
env1_first_0:                 episode reward: 17.9500,                 loss: nan
env1_second_0:                 episode reward: -17.9500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 303.65,                last time consumption/overall running time: 233.6084s / 15770.6653 s
env0_first_0:                 episode reward: 30.2000,                 loss: 0.9398
env0_second_0:                 episode reward: -30.2000,                 loss: 0.7346
env1_first_0:                 episode reward: 16.9000,                 loss: nan
env1_second_0:                 episode reward: -16.9000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 351.2,                last time consumption/overall running time: 270.8253s / 16041.4906 s
env0_first_0:                 episode reward: -18.4000,                 loss: 0.9753
env0_second_0:                 episode reward: 18.4000,                 loss: 0.7622
env1_first_0:                 episode reward: 8.4000,                 loss: nan
env1_second_0:                 episode reward: -8.4000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 345.95,                last time consumption/overall running time: 266.8846s / 16308.3753 s
env0_first_0:                 episode reward: -7.1500,                 loss: 0.9893
env0_second_0:                 episode reward: 7.1500,                 loss: 0.8041
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 299.5,                last time consumption/overall running time: 231.2819s / 16539.6571 s
env0_first_0:                 episode reward: -22.7000,                 loss: 1.0711
env0_second_0:                 episode reward: 22.7000,                 loss: 0.8901
env1_first_0:                 episode reward: -31.2000,                 loss: nan
env1_second_0:                 episode reward: 31.2000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 341.05,                last time consumption/overall running time: 260.8735s / 16800.5306 s
env0_first_0:                 episode reward: -29.1500,                 loss: 1.1711
env0_second_0:                 episode reward: 29.1500,                 loss: 0.9523
env1_first_0:                 episode reward: -45.1000,                 loss: nan
env1_second_0:                 episode reward: 45.1000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 283.3,                last time consumption/overall running time: 216.7315s / 17017.2621 s
env0_first_0:                 episode reward: 17.3000,                 loss: 1.2412
env0_second_0:                 episode reward: -17.3000,                 loss: 0.9865
env1_first_0:                 episode reward: 11.7500,                 loss: nan
env1_second_0:                 episode reward: -11.7500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 313.55,                last time consumption/overall running time: 240.6742s / 17257.9362 s
env0_first_0:                 episode reward: -25.8000,                 loss: 1.2375
env0_second_0:                 episode reward: 25.8000,                 loss: 0.9920
env1_first_0:                 episode reward: -32.6500,                 loss: nan
env1_second_0:                 episode reward: 32.6500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 309.85,                last time consumption/overall running time: 238.5723s / 17496.5086 s
env0_first_0:                 episode reward: -32.1000,                 loss: 1.2011
env0_second_0:                 episode reward: 32.1000,                 loss: 1.0282
env1_first_0:                 episode reward: -21.2000,                 loss: nan
env1_second_0:                 episode reward: 21.2000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 320.45,                last time consumption/overall running time: 246.6487s / 17743.1573 s
env0_first_0:                 episode reward: -40.7000,                 loss: 1.2003
env0_second_0:                 episode reward: 40.7000,                 loss: 1.0243
env1_first_0:                 episode reward: -24.5000,                 loss: nan
env1_second_0:                 episode reward: 24.5000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 391.95,                last time consumption/overall running time: 303.0951s / 18046.2524 s
env0_first_0:                 episode reward: -54.4500,                 loss: 1.2138
env0_second_0:                 episode reward: 54.4500,                 loss: 1.0026
env1_first_0:                 episode reward: -26.1500,                 loss: nan
env1_second_0:                 episode reward: 26.1500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 433.55,                last time consumption/overall running time: 334.4231s / 18380.6754 s
env0_first_0:                 episode reward: -53.0000,                 loss: 1.1053
env0_second_0:                 episode reward: 53.0000,                 loss: 0.9075
env1_first_0:                 episode reward: -52.9500,                 loss: nan
env1_second_0:                 episode reward: 52.9500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 459.45,                last time consumption/overall running time: 353.4355s / 18734.1110 s
env0_first_0:                 episode reward: -27.9500,                 loss: 0.9906
env0_second_0:                 episode reward: 27.9500,                 loss: 0.7963
env1_first_0:                 episode reward: -66.1500,                 loss: nan
env1_second_0:                 episode reward: 66.1500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 362.6,                last time consumption/overall running time: 279.7127s / 19013.8237 s
env0_first_0:                 episode reward: -31.2500,                 loss: 0.9467
env0_second_0:                 episode reward: 31.2500,                 loss: 0.6903
env1_first_0:                 episode reward: -42.3500,                 loss: nan
env1_second_0:                 episode reward: 42.3500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 303.1,                last time consumption/overall running time: 232.6627s / 19246.4864 s
env0_first_0:                 episode reward: -24.8000,                 loss: 1.0026
env0_second_0:                 episode reward: 24.8000,                 loss: 0.6760
env1_first_0:                 episode reward: -46.5500,                 loss: nan
env1_second_0:                 episode reward: 46.5500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 278.3,                last time consumption/overall running time: 215.4393s / 19461.9257 s
env0_first_0:                 episode reward: -51.6500,                 loss: 1.0291
env0_second_0:                 episode reward: 51.6500,                 loss: 0.7202
env1_first_0:                 episode reward: -45.7000,                 loss: nan
env1_second_0:                 episode reward: 45.7000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 271.4,                last time consumption/overall running time: 210.3701s / 19672.2958 s
env0_first_0:                 episode reward: -56.8500,                 loss: 1.0744
env0_second_0:                 episode reward: 56.8500,                 loss: 0.7754
env1_first_0:                 episode reward: -51.3500,                 loss: nan
env1_second_0:                 episode reward: 51.3500,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 315.8,                last time consumption/overall running time: 243.5398s / 19915.8356 s
env0_first_0:                 episode reward: -38.3500,                 loss: 1.1035
env0_second_0:                 episode reward: 38.3500,                 loss: 0.8223
env1_first_0:                 episode reward: -31.0500,                 loss: nan
env1_second_0:                 episode reward: 31.0500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 411.55,                last time consumption/overall running time: 316.2698s / 20232.1054 s
env0_first_0:                 episode reward: -87.2500,                 loss: 1.0787
env0_second_0:                 episode reward: 87.2500,                 loss: 0.8442
env1_first_0:                 episode reward: -47.4000,                 loss: nan
env1_second_0:                 episode reward: 47.4000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 359.2,                last time consumption/overall running time: 275.4399s / 20507.5453 s
env0_first_0:                 episode reward: -59.5000,                 loss: 1.1119
env0_second_0:                 episode reward: 59.5000,                 loss: 0.8015
env1_first_0:                 episode reward: -75.0000,                 loss: nan
env1_second_0:                 episode reward: 75.0000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 327.25,                last time consumption/overall running time: 252.7767s / 20760.3220 s
env0_first_0:                 episode reward: -63.1000,                 loss: 1.1700
env0_second_0:                 episode reward: 63.1000,                 loss: 0.8279
env1_first_0:                 episode reward: -44.0000,                 loss: nan
env1_second_0:                 episode reward: 44.0000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 299.1,                last time consumption/overall running time: 230.8484s / 20991.1704 s
env0_first_0:                 episode reward: -65.5500,                 loss: 1.2324
env0_second_0:                 episode reward: 65.5500,                 loss: 0.8443
env1_first_0:                 episode reward: -72.2500,                 loss: nan
env1_second_0:                 episode reward: 72.2500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 621.45,                last time consumption/overall running time: 477.3372s / 21468.5076 s
env0_first_0:                 episode reward: -53.6000,                 loss: 1.0943
env0_second_0:                 episode reward: 53.6000,                 loss: 0.7933
env1_first_0:                 episode reward: -33.0500,                 loss: nan
env1_second_0:                 episode reward: 33.0500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 339.7,                last time consumption/overall running time: 262.2983s / 21730.8059 s
env0_first_0:                 episode reward: -38.2500,                 loss: 1.0246
env0_second_0:                 episode reward: 38.2500,                 loss: 0.6915
env1_first_0:                 episode reward: -22.1500,                 loss: nan
env1_second_0:                 episode reward: 22.1500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 290.4,                last time consumption/overall running time: 223.4978s / 21954.3037 s
env0_first_0:                 episode reward: -31.9500,                 loss: 0.9968
env0_second_0:                 episode reward: 31.9500,                 loss: 0.6666
env1_first_0:                 episode reward: -37.6000,                 loss: nan
env1_second_0:                 episode reward: 37.6000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 255.8,                last time consumption/overall running time: 196.7963s / 22151.1000 s
env0_first_0:                 episode reward: 8.7500,                 loss: 1.1227
env0_second_0:                 episode reward: -8.7500,                 loss: 0.6897
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 297.0,                last time consumption/overall running time: 228.4705s / 22379.5705 s
env0_first_0:                 episode reward: 0.7500,                 loss: 1.1735
env0_second_0:                 episode reward: -0.7500,                 loss: 0.7078
env1_first_0:                 episode reward: -14.1500,                 loss: nan
env1_second_0:                 episode reward: 14.1500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 348.95,                last time consumption/overall running time: 267.1862s / 22646.7567 s
env0_first_0:                 episode reward: -37.1000,                 loss: 1.2783
env0_second_0:                 episode reward: 37.1000,                 loss: 0.7600
env1_first_0:                 episode reward: -51.4000,                 loss: nan
env1_second_0:                 episode reward: 51.4000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 321.85,                last time consumption/overall running time: 247.3327s / 22894.0893 s
env0_first_0:                 episode reward: -37.8000,                 loss: 1.1925
env0_second_0:                 episode reward: 37.8000,                 loss: 0.7663
env1_first_0:                 episode reward: -49.6000,                 loss: nan
env1_second_0:                 episode reward: 49.6000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 1193.15,                last time consumption/overall running time: 913.9161s / 23808.0054 s
env0_first_0:                 episode reward: -14.8500,                 loss: 1.0238
env0_second_0:                 episode reward: 14.8500,                 loss: 0.6729
env1_first_0:                 episode reward: -29.8500,                 loss: nan
env1_second_0:                 episode reward: 29.8500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 469.05,                last time consumption/overall running time: 360.5028s / 24168.5081 s
env0_first_0:                 episode reward: -80.0500,                 loss: 0.6730
env0_second_0:                 episode reward: 80.0500,                 loss: 0.4475
env1_first_0:                 episode reward: -55.8000,                 loss: nan
env1_second_0:                 episode reward: 55.8000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 334.75,                last time consumption/overall running time: 258.0052s / 24426.5133 s
env0_first_0:                 episode reward: -50.1500,                 loss: 0.6662
env0_second_0:                 episode reward: 50.1500,                 loss: 0.4450
env1_first_0:                 episode reward: -62.9000,                 loss: nan
env1_second_0:                 episode reward: 62.9000,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 367.75,                last time consumption/overall running time: 283.0993s / 24709.6126 s
env0_first_0:                 episode reward: -23.6500,                 loss: 0.6616
env0_second_0:                 episode reward: 23.6500,                 loss: 0.4446
env1_first_0:                 episode reward: -45.8000,                 loss: nan
env1_second_0:                 episode reward: 45.8000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 303.4,                last time consumption/overall running time: 233.2087s / 24942.8213 s
env0_first_0:                 episode reward: -27.8500,                 loss: 0.7221
env0_second_0:                 episode reward: 27.8500,                 loss: 0.4643
env1_first_0:                 episode reward: -33.7500,                 loss: nan
env1_second_0:                 episode reward: 33.7500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 432.65,                last time consumption/overall running time: 333.3549s / 25276.1762 s
env0_first_0:                 episode reward: -34.5000,                 loss: 0.7943
env0_second_0:                 episode reward: 34.5000,                 loss: 0.5091
env1_first_0:                 episode reward: -76.3000,                 loss: nan
env1_second_0:                 episode reward: 76.3000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 366.65,                last time consumption/overall running time: 281.2621s / 25557.4383 s
env0_first_0:                 episode reward: -39.0500,                 loss: 0.8837
env0_second_0:                 episode reward: 39.0500,                 loss: 0.6012
env1_first_0:                 episode reward: -33.8000,                 loss: nan
env1_second_0:                 episode reward: 33.8000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 256.35,                last time consumption/overall running time: 198.1382s / 25755.5765 s
env0_first_0:                 episode reward: -59.8000,                 loss: 0.9634
env0_second_0:                 episode reward: 59.8000,                 loss: 0.6839
env1_first_0:                 episode reward: -60.6500,                 loss: nan
env1_second_0:                 episode reward: 60.6500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 266.15,                last time consumption/overall running time: 205.2670s / 25960.8435 s
env0_first_0:                 episode reward: -51.4500,                 loss: 1.0652
env0_second_0:                 episode reward: 51.4500,                 loss: 0.7554
env1_first_0:                 episode reward: -40.5000,                 loss: nan
env1_second_0:                 episode reward: 40.5000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 271.6,                last time consumption/overall running time: 208.9813s / 26169.8248 s
env0_first_0:                 episode reward: -57.6500,                 loss: 1.0688
env0_second_0:                 episode reward: 57.6500,                 loss: 0.8210
env1_first_0:                 episode reward: -25.0000,                 loss: nan
env1_second_0:                 episode reward: 25.0000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 267.8,                last time consumption/overall running time: 206.0563s / 26375.8811 s
env0_first_0:                 episode reward: -4.1500,                 loss: 1.0935
env0_second_0:                 episode reward: 4.1500,                 loss: 0.8694
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 273.15,                last time consumption/overall running time: 210.0974s / 26585.9786 s
env0_first_0:                 episode reward: -30.7000,                 loss: 1.0648
env0_second_0:                 episode reward: 30.7000,                 loss: 0.8430
env1_first_0:                 episode reward: -26.2500,                 loss: nan
env1_second_0:                 episode reward: 26.2500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 258.4,                last time consumption/overall running time: 198.4494s / 26784.4280 s
env0_first_0:                 episode reward: -25.3000,                 loss: 1.0124
env0_second_0:                 episode reward: 25.3000,                 loss: 0.8318
env1_first_0:                 episode reward: -64.8000,                 loss: nan
env1_second_0:                 episode reward: 64.8000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 515.85,                last time consumption/overall running time: 396.3079s / 27180.7359 s
env0_first_0:                 episode reward: -24.2500,                 loss: 1.0775
env0_second_0:                 episode reward: 24.2500,                 loss: 0.8145
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 314.2,                last time consumption/overall running time: 241.0491s / 27421.7850 s
env0_first_0:                 episode reward: -75.4500,                 loss: 1.1880
env0_second_0:                 episode reward: 75.4500,                 loss: 0.8633
env1_first_0:                 episode reward: -46.3500,                 loss: nan
env1_second_0:                 episode reward: 46.3500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 501.6,                last time consumption/overall running time: 384.7106s / 27806.4956 s
env0_first_0:                 episode reward: -50.5500,                 loss: 1.1097
env0_second_0:                 episode reward: 50.5500,                 loss: 0.8170
env1_first_0:                 episode reward: -63.1500,                 loss: nan
env1_second_0:                 episode reward: 63.1500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 287.0,                last time consumption/overall running time: 221.4808s / 28027.9764 s
env0_first_0:                 episode reward: -63.6000,                 loss: 1.0566
env0_second_0:                 episode reward: 63.6000,                 loss: 0.7654
env1_first_0:                 episode reward: -55.8000,                 loss: nan
env1_second_0:                 episode reward: 55.8000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 246.8,                last time consumption/overall running time: 190.6237s / 28218.6001 s
env0_first_0:                 episode reward: -79.8500,                 loss: 1.0702
env0_second_0:                 episode reward: 79.8500,                 loss: 0.7449
env1_first_0:                 episode reward: -95.2500,                 loss: nan
env1_second_0:                 episode reward: 95.2500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 246.95,                last time consumption/overall running time: 191.2866s / 28409.8868 s
env0_first_0:                 episode reward: -90.0000,                 loss: 1.0251
env0_second_0:                 episode reward: 90.0000,                 loss: 0.6778
env1_first_0:                 episode reward: -79.8000,                 loss: nan
env1_second_0:                 episode reward: 79.8000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 230.25,                last time consumption/overall running time: 177.6678s / 28587.5546 s
env0_first_0:                 episode reward: -84.8500,                 loss: 1.0498
env0_second_0:                 episode reward: 84.8500,                 loss: 0.6680
env1_first_0:                 episode reward: -76.2500,                 loss: nan
env1_second_0:                 episode reward: 76.2500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 285.75,                last time consumption/overall running time: 220.1848s / 28807.7394 s
env0_first_0:                 episode reward: -76.9500,                 loss: 1.0561
env0_second_0:                 episode reward: 76.9500,                 loss: 0.6477
env1_first_0:                 episode reward: -83.8000,                 loss: nan
env1_second_0:                 episode reward: 83.8000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 259.95,                last time consumption/overall running time: 201.3956s / 29009.1350 s
env0_first_0:                 episode reward: -80.8000,                 loss: 1.1202
env0_second_0:                 episode reward: 80.8000,                 loss: 0.6489
env1_first_0:                 episode reward: -75.3500,                 loss: nan
env1_second_0:                 episode reward: 75.3500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 363.35,                last time consumption/overall running time: 281.1162s / 29290.2512 s
env0_first_0:                 episode reward: -60.4000,                 loss: 1.1409
env0_second_0:                 episode reward: 60.4000,                 loss: 0.6218
env1_first_0:                 episode reward: -67.4500,                 loss: nan
env1_second_0:                 episode reward: 67.4500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 488.25,                last time consumption/overall running time: 378.0116s / 29668.2628 s
env0_first_0:                 episode reward: -82.5500,                 loss: 1.1770
env0_second_0:                 episode reward: 82.5500,                 loss: 0.6262
env1_first_0:                 episode reward: -61.0000,                 loss: nan
env1_second_0:                 episode reward: 61.0000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 334.0,                last time consumption/overall running time: 256.9479s / 29925.2107 s
env0_first_0:                 episode reward: -66.5000,                 loss: 1.1468
env0_second_0:                 episode reward: 66.5000,                 loss: 0.6606
env1_first_0:                 episode reward: -50.5000,                 loss: nan
env1_second_0:                 episode reward: 50.5000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 263.05,                last time consumption/overall running time: 203.2545s / 30128.4652 s
env0_first_0:                 episode reward: -78.7000,                 loss: 1.1501
env0_second_0:                 episode reward: 78.7000,                 loss: 0.6646
env1_first_0:                 episode reward: -88.5000,                 loss: nan
env1_second_0:                 episode reward: 88.5000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 281.55,                last time consumption/overall running time: 217.0414s / 30345.5065 s
env0_first_0:                 episode reward: -56.7000,                 loss: 1.1408
env0_second_0:                 episode reward: 56.7000,                 loss: 0.7503
env1_first_0:                 episode reward: -63.0500,                 loss: nan
env1_second_0:                 episode reward: 63.0500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 258.55,                last time consumption/overall running time: 199.4067s / 30544.9133 s
env0_first_0:                 episode reward: -68.6500,                 loss: 1.2113
env0_second_0:                 episode reward: 68.6500,                 loss: 0.8224
env1_first_0:                 episode reward: -66.9500,                 loss: nan
env1_second_0:                 episode reward: 66.9500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 319.45,                last time consumption/overall running time: 245.5100s / 30790.4233 s
env0_first_0:                 episode reward: -62.3000,                 loss: 1.2528
env0_second_0:                 episode reward: 62.3000,                 loss: 0.8428
env1_first_0:                 episode reward: -68.6000,                 loss: nan
env1_second_0:                 episode reward: 68.6000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 289.65,                last time consumption/overall running time: 222.7841s / 31013.2074 s
env0_first_0:                 episode reward: -28.3000,                 loss: 1.3225
env0_second_0:                 episode reward: 28.3000,                 loss: 0.9096
env1_first_0:                 episode reward: -42.7500,                 loss: nan
env1_second_0:                 episode reward: 42.7500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 310.0,                last time consumption/overall running time: 239.7339s / 31252.9413 s
env0_first_0:                 episode reward: -37.2500,                 loss: 1.4548
env0_second_0:                 episode reward: 37.2500,                 loss: 0.9813
env1_first_0:                 episode reward: -47.6500,                 loss: nan
env1_second_0:                 episode reward: 47.6500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 321.25,                last time consumption/overall running time: 247.6440s / 31500.5854 s
env0_first_0:                 episode reward: -47.3000,                 loss: 1.6251
env0_second_0:                 episode reward: 47.3000,                 loss: 1.1358
env1_first_0:                 episode reward: -57.3500,                 loss: nan
env1_second_0:                 episode reward: 57.3500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 288.6,                last time consumption/overall running time: 221.8036s / 31722.3890 s
env0_first_0:                 episode reward: -66.7000,                 loss: 1.7772
env0_second_0:                 episode reward: 66.7000,                 loss: 1.1670
env1_first_0:                 episode reward: -24.9000,                 loss: nan
env1_second_0:                 episode reward: 24.9000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 320.65,                last time consumption/overall running time: 245.5747s / 31967.9636 s
env0_first_0:                 episode reward: -56.8000,                 loss: 1.7946
env0_second_0:                 episode reward: 56.8000,                 loss: 1.1751
env1_first_0:                 episode reward: -61.4500,                 loss: nan
env1_second_0:                 episode reward: 61.4500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 246.75,                last time consumption/overall running time: 189.6729s / 32157.6365 s
env0_first_0:                 episode reward: -85.4500,                 loss: 1.7685
env0_second_0:                 episode reward: 85.4500,                 loss: 1.1650
env1_first_0:                 episode reward: -61.8500,                 loss: nan
env1_second_0:                 episode reward: 61.8500,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 264.75,                last time consumption/overall running time: 204.2550s / 32361.8915 s
env0_first_0:                 episode reward: -66.5500,                 loss: 1.6991
env0_second_0:                 episode reward: 66.5500,                 loss: 1.0806
env1_first_0:                 episode reward: -88.5500,                 loss: nan
env1_second_0:                 episode reward: 88.5500,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 252.65,                last time consumption/overall running time: 194.7511s / 32556.6426 s
env0_first_0:                 episode reward: -64.1000,                 loss: 1.5981
env0_second_0:                 episode reward: 64.1000,                 loss: 1.0199
env1_first_0:                 episode reward: -84.3500,                 loss: nan
env1_second_0:                 episode reward: 84.3500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 271.35,                last time consumption/overall running time: 209.1743s / 32765.8169 s
env0_first_0:                 episode reward: -77.5000,                 loss: 1.5778
env0_second_0:                 episode reward: 77.5000,                 loss: 1.0283
env1_first_0:                 episode reward: -80.5000,                 loss: nan
env1_second_0:                 episode reward: 80.5000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 345.05,                last time consumption/overall running time: 266.3404s / 33032.1573 s
env0_first_0:                 episode reward: -58.9500,                 loss: 1.5510
env0_second_0:                 episode reward: 58.9500,                 loss: 0.9999
env1_first_0:                 episode reward: -50.8500,                 loss: nan
env1_second_0:                 episode reward: 50.8500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 283.3,                last time consumption/overall running time: 218.5769s / 33250.7343 s
env0_first_0:                 episode reward: -74.2500,                 loss: 1.5455
env0_second_0:                 episode reward: 74.2500,                 loss: 0.9698
env1_first_0:                 episode reward: -36.6500,                 loss: nan
env1_second_0:                 episode reward: 36.6500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 367.2,                last time consumption/overall running time: 283.0049s / 33533.7392 s
env0_first_0:                 episode reward: -25.6000,                 loss: 1.4840
env0_second_0:                 episode reward: 25.6000,                 loss: 0.9267
env1_first_0:                 episode reward: -47.9000,                 loss: nan
env1_second_0:                 episode reward: 47.9000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 343.3,                last time consumption/overall running time: 264.1832s / 33797.9224 s
env0_first_0:                 episode reward: -29.1000,                 loss: 1.4762
env0_second_0:                 episode reward: 29.1000,                 loss: 0.8802
env1_first_0:                 episode reward: -47.8000,                 loss: nan
env1_second_0:                 episode reward: 47.8000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 274.35,                last time consumption/overall running time: 211.7977s / 34009.7200 s
env0_first_0:                 episode reward: -52.3000,                 loss: 1.4641
env0_second_0:                 episode reward: 52.3000,                 loss: 0.9819
env1_first_0:                 episode reward: -41.6000,                 loss: nan
env1_second_0:                 episode reward: 41.6000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 268.15,                last time consumption/overall running time: 206.7592s / 34216.4792 s
env0_first_0:                 episode reward: -44.1500,                 loss: 1.4868
env0_second_0:                 episode reward: 44.1500,                 loss: 1.0023
env1_first_0:                 episode reward: -77.6500,                 loss: nan
env1_second_0:                 episode reward: 77.6500,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 235.3,                last time consumption/overall running time: 181.8706s / 34398.3498 s
env0_first_0:                 episode reward: -87.7500,                 loss: 1.5731
env0_second_0:                 episode reward: 87.7500,                 loss: 1.0268
env1_first_0:                 episode reward: -62.7000,                 loss: nan
env1_second_0:                 episode reward: 62.7000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 265.25,                last time consumption/overall running time: 204.7344s / 34603.0843 s
env0_first_0:                 episode reward: -54.2500,                 loss: 1.6004
env0_second_0:                 episode reward: 54.2500,                 loss: 0.9997
env1_first_0:                 episode reward: -79.2000,                 loss: nan
env1_second_0:                 episode reward: 79.2000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 574.35,                last time consumption/overall running time: 441.9296s / 35045.0138 s
env0_first_0:                 episode reward: -60.7000,                 loss: 1.3790
env0_second_0:                 episode reward: 60.7000,                 loss: 0.8823
env1_first_0:                 episode reward: -57.7500,                 loss: nan
env1_second_0:                 episode reward: 57.7500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 467.4,                last time consumption/overall running time: 358.3967s / 35403.4105 s
env0_first_0:                 episode reward: -38.3500,                 loss: 1.1723
env0_second_0:                 episode reward: 38.3500,                 loss: 0.7556
env1_first_0:                 episode reward: -49.1500,                 loss: nan
env1_second_0:                 episode reward: 49.1500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 280.0,                last time consumption/overall running time: 215.9207s / 35619.3312 s
env0_first_0:                 episode reward: -54.7000,                 loss: 1.1876
env0_second_0:                 episode reward: 54.7000,                 loss: 0.7378
env1_first_0:                 episode reward: -76.1500,                 loss: nan
env1_second_0:                 episode reward: 76.1500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 269.2,                last time consumption/overall running time: 207.7416s / 35827.0728 s
env0_first_0:                 episode reward: -72.6500,                 loss: 1.1581
env0_second_0:                 episode reward: 72.6500,                 loss: 0.7326
env1_first_0:                 episode reward: -58.7000,                 loss: nan
env1_second_0:                 episode reward: 58.7000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 435.05,                last time consumption/overall running time: 334.1491s / 36161.2219 s
env0_first_0:                 episode reward: -38.7500,                 loss: 1.1537
env0_second_0:                 episode reward: 38.7500,                 loss: 0.7323
env1_first_0:                 episode reward: -62.8000,                 loss: nan
env1_second_0:                 episode reward: 62.8000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 367.75,                last time consumption/overall running time: 282.0403s / 36443.2621 s
env0_first_0:                 episode reward: -33.7000,                 loss: 1.1528
env0_second_0:                 episode reward: 33.7000,                 loss: 0.7285
env1_first_0:                 episode reward: -56.0500,                 loss: nan
env1_second_0:                 episode reward: 56.0500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 254.95,                last time consumption/overall running time: 197.3886s / 36640.6507 s
env0_first_0:                 episode reward: -56.2000,                 loss: 1.0973
env0_second_0:                 episode reward: 56.2000,                 loss: 0.7407
env1_first_0:                 episode reward: -84.5000,                 loss: nan
env1_second_0:                 episode reward: 84.5000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 267.85,                last time consumption/overall running time: 207.7942s / 36848.4448 s
env0_first_0:                 episode reward: -45.6000,                 loss: 1.1558
env0_second_0:                 episode reward: 45.6000,                 loss: 0.8031
env1_first_0:                 episode reward: -52.1500,                 loss: nan
env1_second_0:                 episode reward: 52.1500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 251.2,                last time consumption/overall running time: 193.7566s / 37042.2015 s
env0_first_0:                 episode reward: -75.1500,                 loss: 1.2114
env0_second_0:                 episode reward: 75.1500,                 loss: 0.8115
env1_first_0:                 episode reward: -67.5500,                 loss: nan
env1_second_0:                 episode reward: 67.5500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 416.7,                last time consumption/overall running time: 321.9989s / 37364.2004 s
env0_first_0:                 episode reward: -21.6000,                 loss: 1.2532
env0_second_0:                 episode reward: 21.6000,                 loss: 0.8360
env1_first_0:                 episode reward: -29.1500,                 loss: nan
env1_second_0:                 episode reward: 29.1500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 287.35,                last time consumption/overall running time: 245.5309s / 37609.7312 s
env0_first_0:                 episode reward: -29.8000,                 loss: 1.2217
env0_second_0:                 episode reward: 29.8000,                 loss: 0.7790
env1_first_0:                 episode reward: -35.0500,                 loss: nan
env1_second_0:                 episode reward: 35.0500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 266.7,                last time consumption/overall running time: 236.5013s / 37846.2325 s
env0_first_0:                 episode reward: -66.0500,                 loss: 1.1312
env0_second_0:                 episode reward: 66.0500,                 loss: 0.8003
env1_first_0:                 episode reward: -52.4000,                 loss: nan
env1_second_0:                 episode reward: 52.4000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 269.1,                last time consumption/overall running time: 249.6019s / 38095.8344 s
env0_first_0:                 episode reward: -82.6000,                 loss: 1.0890
env0_second_0:                 episode reward: 82.6000,                 loss: 0.7828
env1_first_0:                 episode reward: -46.9500,                 loss: nan
env1_second_0:                 episode reward: 46.9500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 307.3,                last time consumption/overall running time: 286.1831s / 38382.0175 s
env0_first_0:                 episode reward: -48.9000,                 loss: 1.1271
env0_second_0:                 episode reward: 48.9000,                 loss: 0.8674
env1_first_0:                 episode reward: -63.7000,                 loss: nan
env1_second_0:                 episode reward: 63.7000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 318.4,                last time consumption/overall running time: 294.1764s / 38676.1938 s
env0_first_0:                 episode reward: -58.9000,                 loss: 1.2164
env0_second_0:                 episode reward: 58.9000,                 loss: 0.9428
env1_first_0:                 episode reward: -58.5000,                 loss: nan
env1_second_0:                 episode reward: 58.5000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 412.2,                last time consumption/overall running time: 379.3090s / 39055.5029 s
env0_first_0:                 episode reward: -33.2500,                 loss: 1.3097
env0_second_0:                 episode reward: 33.2500,                 loss: 1.0345
env1_first_0:                 episode reward: -33.5500,                 loss: nan
env1_second_0:                 episode reward: 33.5500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 405.5,                last time consumption/overall running time: 371.0195s / 39426.5223 s
env0_first_0:                 episode reward: -24.1500,                 loss: 1.3241
env0_second_0:                 episode reward: 24.1500,                 loss: 1.0571
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 305.45,                last time consumption/overall running time: 280.1637s / 39706.6861 s
env0_first_0:                 episode reward: -77.4000,                 loss: 1.4388
env0_second_0:                 episode reward: 77.4000,                 loss: 1.0653
env1_first_0:                 episode reward: -64.1500,                 loss: nan
env1_second_0:                 episode reward: 64.1500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 264.1,                last time consumption/overall running time: 241.7115s / 39948.3976 s
env0_first_0:                 episode reward: -56.3000,                 loss: 1.5673
env0_second_0:                 episode reward: 56.3000,                 loss: 1.0791
env1_first_0:                 episode reward: -79.5000,                 loss: nan
env1_second_0:                 episode reward: 79.5000,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 280.9,                last time consumption/overall running time: 257.5962s / 40205.9938 s
env0_first_0:                 episode reward: -66.1500,                 loss: 1.4502
env0_second_0:                 episode reward: 66.1500,                 loss: 1.1154
env1_first_0:                 episode reward: -54.9500,                 loss: nan
env1_second_0:                 episode reward: 54.9500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 288.15,                last time consumption/overall running time: 263.5059s / 40469.4996 s
env0_first_0:                 episode reward: -53.8500,                 loss: 1.3659
env0_second_0:                 episode reward: 53.8500,                 loss: 1.1431
env1_first_0:                 episode reward: -48.7500,                 loss: nan
env1_second_0:                 episode reward: 48.7500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 323.4,                last time consumption/overall running time: 295.8081s / 40765.3077 s
env0_first_0:                 episode reward: -59.1000,                 loss: 1.4123
env0_second_0:                 episode reward: 59.1000,                 loss: 1.1451
env1_first_0:                 episode reward: -40.1500,                 loss: nan
env1_second_0:                 episode reward: 40.1500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 733.3,                last time consumption/overall running time: 670.8150s / 41436.1227 s
env0_first_0:                 episode reward: -17.7500,                 loss: 1.3321
env0_second_0:                 episode reward: 17.7500,                 loss: 1.0736
env1_first_0:                 episode reward: -31.8500,                 loss: nan
env1_second_0:                 episode reward: 31.8500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 414.6,                last time consumption/overall running time: 379.2577s / 41815.3805 s
env0_first_0:                 episode reward: -30.2000,                 loss: 1.2557
env0_second_0:                 episode reward: 30.2000,                 loss: 1.0162
env1_first_0:                 episode reward: -19.0500,                 loss: nan
env1_second_0:                 episode reward: 19.0500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 374.3,                last time consumption/overall running time: 342.2180s / 42157.5984 s
env0_first_0:                 episode reward: -36.1000,                 loss: 1.3764
env0_second_0:                 episode reward: 36.1000,                 loss: 1.0673
env1_first_0:                 episode reward: -40.2500,                 loss: nan
env1_second_0:                 episode reward: 40.2500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 341.95,                last time consumption/overall running time: 312.5994s / 42470.1979 s
env0_first_0:                 episode reward: -13.7000,                 loss: 1.5293
env0_second_0:                 episode reward: 13.7000,                 loss: 1.1605
env1_first_0:                 episode reward: -28.7500,                 loss: nan
env1_second_0:                 episode reward: 28.7500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 334.2,                last time consumption/overall running time: 305.3209s / 42775.5187 s
env0_first_0:                 episode reward: 0.7500,                 loss: 1.6053
env0_second_0:                 episode reward: -0.7500,                 loss: 1.2408
env1_first_0:                 episode reward: -39.6500,                 loss: nan
env1_second_0:                 episode reward: 39.6500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 276.05,                last time consumption/overall running time: 253.0069s / 43028.5256 s
env0_first_0:                 episode reward: -34.2500,                 loss: 1.5898
env0_second_0:                 episode reward: 34.2500,                 loss: 1.2000
env1_first_0:                 episode reward: -53.0500,                 loss: nan
env1_second_0:                 episode reward: 53.0500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 287.25,                last time consumption/overall running time: 263.2520s / 43291.7776 s
env0_first_0:                 episode reward: -43.4000,                 loss: 1.5984
env0_second_0:                 episode reward: 43.4000,                 loss: 1.2472
env1_first_0:                 episode reward: -39.8000,                 loss: nan
env1_second_0:                 episode reward: 39.8000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 300.7,                last time consumption/overall running time: 275.3498s / 43567.1273 s
env0_first_0:                 episode reward: -55.5000,                 loss: 1.7869
env0_second_0:                 episode reward: 55.5000,                 loss: 1.4292
env1_first_0:                 episode reward: -58.1500,                 loss: nan
env1_second_0:                 episode reward: 58.1500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 281.4,                last time consumption/overall running time: 258.1404s / 43825.2677 s
env0_first_0:                 episode reward: -49.6000,                 loss: 1.8868
env0_second_0:                 episode reward: 49.6000,                 loss: 1.4369
env1_first_0:                 episode reward: -51.0500,                 loss: nan
env1_second_0:                 episode reward: 51.0500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 278.25,                last time consumption/overall running time: 254.8332s / 44080.1009 s
env0_first_0:                 episode reward: -46.5000,                 loss: 1.7844
env0_second_0:                 episode reward: 46.5000,                 loss: 1.4111
env1_first_0:                 episode reward: -53.4500,                 loss: nan
env1_second_0:                 episode reward: 53.4500,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 281.1,                last time consumption/overall running time: 258.8327s / 44338.9336 s
env0_first_0:                 episode reward: -54.9000,                 loss: 1.6508
env0_second_0:                 episode reward: 54.9000,                 loss: 1.3797
env1_first_0:                 episode reward: -86.4500,                 loss: nan
env1_second_0:                 episode reward: 86.4500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 276.0,                last time consumption/overall running time: 253.6987s / 44592.6322 s
env0_first_0:                 episode reward: -78.5000,                 loss: 1.5556
env0_second_0:                 episode reward: 78.5000,                 loss: 1.2555
env1_first_0:                 episode reward: -62.7500,                 loss: nan
env1_second_0:                 episode reward: 62.7500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 251.65,                last time consumption/overall running time: 231.0969s / 44823.7291 s
env0_first_0:                 episode reward: -80.4000,                 loss: 1.7061
env0_second_0:                 episode reward: 80.4000,                 loss: 1.2517
env1_first_0:                 episode reward: -75.1000,                 loss: nan
env1_second_0:                 episode reward: 75.1000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 317.25,                last time consumption/overall running time: 289.7378s / 45113.4670 s
env0_first_0:                 episode reward: -28.7500,                 loss: 1.6499
env0_second_0:                 episode reward: 28.7500,                 loss: 1.1614
env1_first_0:                 episode reward: -45.0000,                 loss: nan
env1_second_0:                 episode reward: 45.0000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 279.75,                last time consumption/overall running time: 255.5949s / 45369.0618 s
env0_first_0:                 episode reward: -29.6000,                 loss: 1.6024
env0_second_0:                 episode reward: 29.6000,                 loss: 1.1315
env1_first_0:                 episode reward: -39.0500,                 loss: nan
env1_second_0:                 episode reward: 39.0500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 359.6,                last time consumption/overall running time: 328.4030s / 45697.4649 s
env0_first_0:                 episode reward: -46.9500,                 loss: 1.5977
env0_second_0:                 episode reward: 46.9500,                 loss: 1.0439
env1_first_0:                 episode reward: -29.1500,                 loss: nan
env1_second_0:                 episode reward: 29.1500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 323.95,                last time consumption/overall running time: 296.0631s / 45993.5279 s
env0_first_0:                 episode reward: -22.6500,                 loss: 1.6258
env0_second_0:                 episode reward: 22.6500,                 loss: 1.0896
env1_first_0:                 episode reward: -52.4000,                 loss: nan
env1_second_0:                 episode reward: 52.4000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 345.75,                last time consumption/overall running time: 316.0513s / 46309.5792 s
env0_first_0:                 episode reward: -21.4000,                 loss: 1.6422
env0_second_0:                 episode reward: 21.4000,                 loss: 1.1792
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 319.25,                last time consumption/overall running time: 291.9117s / 46601.4909 s
env0_first_0:                 episode reward: -33.0500,                 loss: 1.6805
env0_second_0:                 episode reward: 33.0500,                 loss: 1.1961
env1_first_0:                 episode reward: -46.4500,                 loss: nan
env1_second_0:                 episode reward: 46.4500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 334.15,                last time consumption/overall running time: 305.4554s / 46906.9463 s
env0_first_0:                 episode reward: -53.1500,                 loss: 1.6479
env0_second_0:                 episode reward: 53.1500,                 loss: 1.1952
env1_first_0:                 episode reward: -51.0500,                 loss: nan
env1_second_0:                 episode reward: 51.0500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 375.55,                last time consumption/overall running time: 343.1299s / 47250.0762 s
env0_first_0:                 episode reward: -44.0000,                 loss: 1.6150
env0_second_0:                 episode reward: 44.0000,                 loss: 1.2209
env1_first_0:                 episode reward: -28.2000,                 loss: nan
env1_second_0:                 episode reward: 28.2000,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 315.9,                last time consumption/overall running time: 288.9259s / 47539.0021 s
env0_first_0:                 episode reward: -31.4500,                 loss: 1.6363
env0_second_0:                 episode reward: 31.4500,                 loss: 1.2368
env1_first_0:                 episode reward: -46.8000,                 loss: nan
env1_second_0:                 episode reward: 46.8000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 360.5,                last time consumption/overall running time: 328.8654s / 47867.8675 s
env0_first_0:                 episode reward: -19.2000,                 loss: 1.6773
env0_second_0:                 episode reward: 19.2000,                 loss: 1.2645
env1_first_0:                 episode reward: -38.0000,                 loss: nan
env1_second_0:                 episode reward: 38.0000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 318.35,                last time consumption/overall running time: 291.5005s / 48159.3679 s
env0_first_0:                 episode reward: -38.5000,                 loss: 1.6328
env0_second_0:                 episode reward: 38.5000,                 loss: 1.2474
env1_first_0:                 episode reward: -63.3000,                 loss: nan
env1_second_0:                 episode reward: 63.3000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 279.8,                last time consumption/overall running time: 255.5154s / 48414.8833 s
env0_first_0:                 episode reward: -69.0500,                 loss: 1.6094
env0_second_0:                 episode reward: 69.0500,                 loss: 1.1950
env1_first_0:                 episode reward: -22.9500,                 loss: nan
env1_second_0:                 episode reward: 22.9500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 301.45,                last time consumption/overall running time: 275.7351s / 48690.6184 s
env0_first_0:                 episode reward: -32.3000,                 loss: 1.6162
env0_second_0:                 episode reward: 32.3000,                 loss: 1.2225
env1_first_0:                 episode reward: -55.9000,                 loss: nan
env1_second_0:                 episode reward: 55.9000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 291.7,                last time consumption/overall running time: 267.3288s / 48957.9472 s
env0_first_0:                 episode reward: -57.2500,                 loss: 1.7110
env0_second_0:                 episode reward: 57.2500,                 loss: 1.2203
env1_first_0:                 episode reward: -30.7500,                 loss: nan
env1_second_0:                 episode reward: 30.7500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 299.15,                last time consumption/overall running time: 273.4026s / 49231.3498 s
env0_first_0:                 episode reward: -8.2500,                 loss: 1.7345
env0_second_0:                 episode reward: 8.2500,                 loss: 1.2349
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 302.7,                last time consumption/overall running time: 276.9400s / 49508.2898 s
env0_first_0:                 episode reward: -21.4500,                 loss: 1.7719
env0_second_0:                 episode reward: 21.4500,                 loss: 1.2944
env1_first_0:                 episode reward: -19.2500,                 loss: nan
env1_second_0:                 episode reward: 19.2500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 310.7,                last time consumption/overall running time: 283.8866s / 49792.1764 s
env0_first_0:                 episode reward: -10.5500,                 loss: 1.8835
env0_second_0:                 episode reward: 10.5500,                 loss: 1.3846
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 293.25,                last time consumption/overall running time: 268.7114s / 50060.8878 s
env0_first_0:                 episode reward: -32.8000,                 loss: 1.8705
env0_second_0:                 episode reward: 32.8000,                 loss: 1.4530
env1_first_0:                 episode reward: -49.1000,                 loss: nan
env1_second_0:                 episode reward: 49.1000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 339.35,                last time consumption/overall running time: 309.7144s / 50370.6022 s
env0_first_0:                 episode reward: -23.4000,                 loss: 1.7788
env0_second_0:                 episode reward: 23.4000,                 loss: 1.3791
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 544.15,                last time consumption/overall running time: 498.5203s / 50869.1225 s
env0_first_0:                 episode reward: 7.6500,                 loss: 1.7324
env0_second_0:                 episode reward: -7.6500,                 loss: 1.3791
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 383.15,                last time consumption/overall running time: 349.3950s / 51218.5175 s
env0_first_0:                 episode reward: -36.1500,                 loss: 1.5359
env0_second_0:                 episode reward: 36.1500,                 loss: 1.3667
env1_first_0:                 episode reward: -24.4000,                 loss: nan
env1_second_0:                 episode reward: 24.4000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 367.5,                last time consumption/overall running time: 336.1221s / 51554.6396 s
env0_first_0:                 episode reward: -14.6000,                 loss: 1.5187
env0_second_0:                 episode reward: 14.6000,                 loss: 1.3250
env1_first_0:                 episode reward: -54.5000,                 loss: nan
env1_second_0:                 episode reward: 54.5000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 294.15,                last time consumption/overall running time: 269.2561s / 51823.8957 s
env0_first_0:                 episode reward: -33.0000,                 loss: 1.5427
env0_second_0:                 episode reward: 33.0000,                 loss: 1.1676
env1_first_0:                 episode reward: -35.4000,                 loss: nan
env1_second_0:                 episode reward: 35.4000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 321.7,                last time consumption/overall running time: 294.0204s / 52117.9160 s
env0_first_0:                 episode reward: -41.6000,                 loss: 1.6031
env0_second_0:                 episode reward: 41.6000,                 loss: 1.2108
env1_first_0:                 episode reward: -38.9500,                 loss: nan
env1_second_0:                 episode reward: 38.9500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 292.6,                last time consumption/overall running time: 267.4005s / 52385.3165 s
env0_first_0:                 episode reward: -58.2000,                 loss: 1.6122
env0_second_0:                 episode reward: 58.2000,                 loss: 1.2428
env1_first_0:                 episode reward: -41.4000,                 loss: nan
env1_second_0:                 episode reward: 41.4000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 335.45,                last time consumption/overall running time: 306.6753s / 52691.9918 s
env0_first_0:                 episode reward: -25.9000,                 loss: 1.7299
env0_second_0:                 episode reward: 25.9000,                 loss: 1.1825
env1_first_0:                 episode reward: -55.8500,                 loss: nan
env1_second_0:                 episode reward: 55.8500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 311.0,                last time consumption/overall running time: 283.6908s / 52975.6826 s
env0_first_0:                 episode reward: -43.5500,                 loss: 1.7356
env0_second_0:                 episode reward: 43.5500,                 loss: 1.2001
env1_first_0:                 episode reward: -57.5000,                 loss: nan
env1_second_0:                 episode reward: 57.5000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 315.05,                last time consumption/overall running time: 287.5344s / 53263.2170 s
env0_first_0:                 episode reward: -47.8500,                 loss: 1.7842
env0_second_0:                 episode reward: 47.8500,                 loss: 1.1889
env1_first_0:                 episode reward: -54.5000,                 loss: nan
env1_second_0:                 episode reward: 54.5000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 369.55,                last time consumption/overall running time: 337.3606s / 53600.5776 s
env0_first_0:                 episode reward: -16.9500,                 loss: 1.8178
env0_second_0:                 episode reward: 16.9500,                 loss: 1.2529
env1_first_0:                 episode reward: -40.7000,                 loss: nan
env1_second_0:                 episode reward: 40.7000,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 311.5,                last time consumption/overall running time: 284.8099s / 53885.3875 s
env0_first_0:                 episode reward: -38.1500,                 loss: 1.8328
env0_second_0:                 episode reward: 38.1500,                 loss: 1.3953
env1_first_0:                 episode reward: -34.6500,                 loss: nan
env1_second_0:                 episode reward: 34.6500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 439.9,                last time consumption/overall running time: 400.5580s / 54285.9454 s
env0_first_0:                 episode reward: -50.3000,                 loss: 1.7614
env0_second_0:                 episode reward: 50.3000,                 loss: 1.4020
env1_first_0:                 episode reward: -47.2500,                 loss: nan
env1_second_0:                 episode reward: 47.2500,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 584.85,                last time consumption/overall running time: 533.4594s / 54819.4049 s
env0_first_0:                 episode reward: -43.3000,                 loss: 1.5372
env0_second_0:                 episode reward: 43.3000,                 loss: 1.2879
env1_first_0:                 episode reward: -43.4000,                 loss: nan
env1_second_0:                 episode reward: 43.4000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 468.2,                last time consumption/overall running time: 428.6908s / 55248.0956 s
env0_first_0:                 episode reward: -5.4500,                 loss: 1.3661
env0_second_0:                 episode reward: 5.4500,                 loss: 1.0832
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 361.9,                last time consumption/overall running time: 331.0450s / 55579.1407 s
env0_first_0:                 episode reward: -56.8500,                 loss: 1.3288
env0_second_0:                 episode reward: 56.8500,                 loss: 1.0155
env1_first_0:                 episode reward: -28.5000,                 loss: nan
env1_second_0:                 episode reward: 28.5000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 738.4,                last time consumption/overall running time: 673.8961s / 56253.0368 s
env0_first_0:                 episode reward: -26.9000,                 loss: 1.1119
env0_second_0:                 episode reward: 26.9000,                 loss: 0.7643
env1_first_0:                 episode reward: -29.8000,                 loss: nan
env1_second_0:                 episode reward: 29.8000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 237.95,                last time consumption/overall running time: 217.4553s / 56470.4921 s
env0_first_0:                 episode reward: -66.5500,                 loss: 0.8673
env0_second_0:                 episode reward: 66.5500,                 loss: 0.6031
env1_first_0:                 episode reward: -91.2500,                 loss: nan
env1_second_0:                 episode reward: 91.2500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 270.7,                last time consumption/overall running time: 246.9915s / 56717.4836 s
env0_first_0:                 episode reward: -70.7000,                 loss: 0.9540
env0_second_0:                 episode reward: 70.7000,                 loss: 0.6529
env1_first_0:                 episode reward: -82.2000,                 loss: nan
env1_second_0:                 episode reward: 82.2000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 298.5,                last time consumption/overall running time: 272.1563s / 56989.6399 s
env0_first_0:                 episode reward: -65.3000,                 loss: 1.0789
env0_second_0:                 episode reward: 65.3000,                 loss: 0.7451
env1_first_0:                 episode reward: -63.1500,                 loss: nan
env1_second_0:                 episode reward: 63.1500,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 338.15,                last time consumption/overall running time: 308.0728s / 57297.7126 s
env0_first_0:                 episode reward: -53.8000,                 loss: 1.2006
env0_second_0:                 episode reward: 53.8000,                 loss: 0.8504
env1_first_0:                 episode reward: -67.7000,                 loss: nan
env1_second_0:                 episode reward: 67.7000,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 316.8,                last time consumption/overall running time: 289.2016s / 57586.9143 s
env0_first_0:                 episode reward: -41.1500,                 loss: 1.2643
env0_second_0:                 episode reward: 41.1500,                 loss: 0.9168
env1_first_0:                 episode reward: -36.3000,                 loss: nan
env1_second_0:                 episode reward: 36.3000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 384.3,                last time consumption/overall running time: 350.7314s / 57937.6457 s
env0_first_0:                 episode reward: -28.7000,                 loss: 1.3438
env0_second_0:                 episode reward: 28.7000,                 loss: 0.8350
env1_first_0:                 episode reward: 3.8000,                 loss: nan
env1_second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 301.6,                last time consumption/overall running time: 274.6577s / 58212.3034 s
env0_first_0:                 episode reward: -43.5500,                 loss: 1.4502
env0_second_0:                 episode reward: 43.5500,                 loss: 0.8773
env1_first_0:                 episode reward: -56.4000,                 loss: nan
env1_second_0:                 episode reward: 56.4000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 267.75,                last time consumption/overall running time: 244.6828s / 58456.9861 s
env0_first_0:                 episode reward: -78.4000,                 loss: 1.6412
env0_second_0:                 episode reward: 78.4000,                 loss: 0.9475
env1_first_0:                 episode reward: -82.9500,                 loss: nan
env1_second_0:                 episode reward: 82.9500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 243.6,                last time consumption/overall running time: 222.5538s / 58679.5399 s
env0_first_0:                 episode reward: -80.4000,                 loss: 1.6531
env0_second_0:                 episode reward: 80.4000,                 loss: 0.9614
env1_first_0:                 episode reward: -70.4500,                 loss: nan
env1_second_0:                 episode reward: 70.4500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 254.5,                last time consumption/overall running time: 232.0059s / 58911.5458 s
env0_first_0:                 episode reward: -77.3000,                 loss: 1.6859
env0_second_0:                 episode reward: 77.3000,                 loss: 0.9295
env1_first_0:                 episode reward: -83.1500,                 loss: nan
env1_second_0:                 episode reward: 83.1500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 259.45,                last time consumption/overall running time: 237.4403s / 59148.9861 s
env0_first_0:                 episode reward: -58.8500,                 loss: 1.6824
env0_second_0:                 episode reward: 58.8500,                 loss: 0.9285
env1_first_0:                 episode reward: -37.7500,                 loss: nan
env1_second_0:                 episode reward: 37.7500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 270.65,                last time consumption/overall running time: 247.0394s / 59396.0255 s
env0_first_0:                 episode reward: -71.1000,                 loss: 1.6888
env0_second_0:                 episode reward: 71.1000,                 loss: 0.9335
env1_first_0:                 episode reward: -68.2500,                 loss: nan
env1_second_0:                 episode reward: 68.2500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 273.2,                last time consumption/overall running time: 249.9341s / 59645.9596 s
env0_first_0:                 episode reward: -64.5500,                 loss: 1.6115
env0_second_0:                 episode reward: 64.5500,                 loss: 0.9288
env1_first_0:                 episode reward: -26.2000,                 loss: nan
env1_second_0:                 episode reward: 26.2000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 324.85,                last time consumption/overall running time: 296.2232s / 59942.1828 s
env0_first_0:                 episode reward: -15.6500,                 loss: 1.6117
env0_second_0:                 episode reward: 15.6500,                 loss: 0.9011
env1_first_0:                 episode reward: -31.9500,                 loss: nan
env1_second_0:                 episode reward: 31.9500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 317.35,                last time consumption/overall running time: 289.4879s / 60231.6708 s
env0_first_0:                 episode reward: -53.5000,                 loss: 1.5661
env0_second_0:                 episode reward: 53.5000,                 loss: 0.8848
env1_first_0:                 episode reward: -48.2000,                 loss: nan
env1_second_0:                 episode reward: 48.2000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 306.45,                last time consumption/overall running time: 279.7627s / 60511.4334 s
env0_first_0:                 episode reward: -40.7500,                 loss: 1.4882
env0_second_0:                 episode reward: 40.7500,                 loss: 0.8710
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 354.4,                last time consumption/overall running time: 323.0911s / 60834.5246 s
env0_first_0:                 episode reward: -35.6500,                 loss: 1.4920
env0_second_0:                 episode reward: 35.6500,                 loss: 0.8369
env1_first_0:                 episode reward: -60.8000,                 loss: nan
env1_second_0:                 episode reward: 60.8000,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 292.35,                last time consumption/overall running time: 266.5290s / 61101.0536 s
env0_first_0:                 episode reward: -50.0500,                 loss: 1.5036
env0_second_0:                 episode reward: 50.0500,                 loss: 0.8719
env1_first_0:                 episode reward: -57.2500,                 loss: nan
env1_second_0:                 episode reward: 57.2500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 291.35,                last time consumption/overall running time: 265.7134s / 61366.7669 s
env0_first_0:                 episode reward: -51.1500,                 loss: 1.5314
env0_second_0:                 episode reward: 51.1500,                 loss: 0.9713
env1_first_0:                 episode reward: -26.7000,                 loss: nan
env1_second_0:                 episode reward: 26.7000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 292.95,                last time consumption/overall running time: 268.0105s / 61634.7775 s
env0_first_0:                 episode reward: -50.5000,                 loss: 1.6347
env0_second_0:                 episode reward: 50.5000,                 loss: 1.0620
env1_first_0:                 episode reward: -43.6500,                 loss: nan
env1_second_0:                 episode reward: 43.6500,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 282.95,                last time consumption/overall running time: 257.9791s / 61892.7566 s
env0_first_0:                 episode reward: -67.8000,                 loss: 1.6892
env0_second_0:                 episode reward: 67.8000,                 loss: 1.0527
env1_first_0:                 episode reward: -70.9000,                 loss: nan
env1_second_0:                 episode reward: 70.9000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 278.7,                last time consumption/overall running time: 253.7481s / 62146.5047 s
env0_first_0:                 episode reward: -59.1000,                 loss: 1.7536
env0_second_0:                 episode reward: 59.1000,                 loss: 1.0767
env1_first_0:                 episode reward: -43.2000,                 loss: nan
env1_second_0:                 episode reward: 43.2000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 327.4,                last time consumption/overall running time: 298.4794s / 62444.9841 s
env0_first_0:                 episode reward: -19.7500,                 loss: 1.6921
env0_second_0:                 episode reward: 19.7500,                 loss: 1.1088
env1_first_0:                 episode reward: -44.6000,                 loss: nan
env1_second_0:                 episode reward: 44.6000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 317.55,                last time consumption/overall running time: 289.7446s / 62734.7286 s
env0_first_0:                 episode reward: -58.2000,                 loss: 1.6539
env0_second_0:                 episode reward: 58.2000,                 loss: 1.1502
env1_first_0:                 episode reward: -37.8000,                 loss: nan
env1_second_0:                 episode reward: 37.8000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 284.55,                last time consumption/overall running time: 259.9429s / 62994.6716 s
env0_first_0:                 episode reward: -32.4000,                 loss: 1.6701
env0_second_0:                 episode reward: 32.4000,                 loss: 1.1750
env1_first_0:                 episode reward: -38.8000,                 loss: nan
env1_second_0:                 episode reward: 38.8000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 267.75,                last time consumption/overall running time: 244.4885s / 63239.1601 s
env0_first_0:                 episode reward: -60.1500,                 loss: 1.8499
env0_second_0:                 episode reward: 60.1500,                 loss: 1.2086
env1_first_0:                 episode reward: -54.7500,                 loss: nan
env1_second_0:                 episode reward: 54.7500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 276.05,                last time consumption/overall running time: 252.4369s / 63491.5970 s
env0_first_0:                 episode reward: -48.7000,                 loss: 1.8532
env0_second_0:                 episode reward: 48.7000,                 loss: 1.1630
env1_first_0:                 episode reward: -70.4500,                 loss: nan
env1_second_0:                 episode reward: 70.4500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 252.0,                last time consumption/overall running time: 230.5396s / 63722.1366 s
env0_first_0:                 episode reward: -61.4500,                 loss: 1.7511
env0_second_0:                 episode reward: 61.4500,                 loss: 1.0906
env1_first_0:                 episode reward: -48.0500,                 loss: nan
env1_second_0:                 episode reward: 48.0500,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 266.35,                last time consumption/overall running time: 243.7177s / 63965.8543 s
env0_first_0:                 episode reward: -74.1500,                 loss: 1.6877
env0_second_0:                 episode reward: 74.1500,                 loss: 1.0356
env1_first_0:                 episode reward: -67.4000,                 loss: nan
env1_second_0:                 episode reward: 67.4000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 270.95,                last time consumption/overall running time: 247.3904s / 64213.2447 s
env0_first_0:                 episode reward: -59.8000,                 loss: 1.6165
env0_second_0:                 episode reward: 59.8000,                 loss: 0.9929
env1_first_0:                 episode reward: -57.2500,                 loss: nan
env1_second_0:                 episode reward: 57.2500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 276.3,                last time consumption/overall running time: 252.8950s / 64466.1397 s
env0_first_0:                 episode reward: -23.7500,                 loss: 1.5505
env0_second_0:                 episode reward: 23.7500,                 loss: 1.0068
env1_first_0:                 episode reward: -40.7000,                 loss: nan
env1_second_0:                 episode reward: 40.7000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 271.0,                last time consumption/overall running time: 248.2003s / 64714.3400 s
env0_first_0:                 episode reward: -69.1000,                 loss: 1.5910
env0_second_0:                 episode reward: 69.1000,                 loss: 1.0016
env1_first_0:                 episode reward: -76.9500,                 loss: nan
env1_second_0:                 episode reward: 76.9500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 307.8,                last time consumption/overall running time: 281.3320s / 64995.6720 s
env0_first_0:                 episode reward: -45.8000,                 loss: 1.6339
env0_second_0:                 episode reward: 45.8000,                 loss: 1.0434
env1_first_0:                 episode reward: -60.9000,                 loss: nan
env1_second_0:                 episode reward: 60.9000,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 286.45,                last time consumption/overall running time: 262.2204s / 65257.8924 s
env0_first_0:                 episode reward: -35.8000,                 loss: 1.7275
env0_second_0:                 episode reward: 35.8000,                 loss: 1.1008
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 312.1,                last time consumption/overall running time: 284.1477s / 65542.0400 s
env0_first_0:                 episode reward: -28.0500,                 loss: 1.7466
env0_second_0:                 episode reward: 28.0500,                 loss: 1.1106
env1_first_0:                 episode reward: -45.7000,                 loss: nan
env1_second_0:                 episode reward: 45.7000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 357.6,                last time consumption/overall running time: 326.8326s / 65868.8727 s
env0_first_0:                 episode reward: -8.7000,                 loss: 1.8016
env0_second_0:                 episode reward: 8.7000,                 loss: 1.2377
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 336.4,                last time consumption/overall running time: 306.8986s / 66175.7713 s
env0_first_0:                 episode reward: -40.6000,                 loss: 1.9196
env0_second_0:                 episode reward: 40.6000,                 loss: 1.3474
env1_first_0:                 episode reward: -18.8000,                 loss: nan
env1_second_0:                 episode reward: 18.8000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 294.8,                last time consumption/overall running time: 269.2606s / 66445.0318 s
env0_first_0:                 episode reward: -47.7500,                 loss: 1.9978
env0_second_0:                 episode reward: 47.7500,                 loss: 1.3465
env1_first_0:                 episode reward: -26.8500,                 loss: nan
env1_second_0:                 episode reward: 26.8500,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 294.85,                last time consumption/overall running time: 268.5098s / 66713.5416 s
env0_first_0:                 episode reward: -53.4000,                 loss: 2.0053
env0_second_0:                 episode reward: 53.4000,                 loss: 1.3310
env1_first_0:                 episode reward: -52.8500,                 loss: nan
env1_second_0:                 episode reward: 52.8500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 293.9,                last time consumption/overall running time: 267.9996s / 66981.5412 s
env0_first_0:                 episode reward: -49.8500,                 loss: 1.9934
env0_second_0:                 episode reward: 49.8500,                 loss: 1.4250
env1_first_0:                 episode reward: -32.8000,                 loss: nan
env1_second_0:                 episode reward: 32.8000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 450.35,                last time consumption/overall running time: 410.2656s / 67391.8068 s
env0_first_0:                 episode reward: -40.3000,                 loss: 1.8954
env0_second_0:                 episode reward: 40.3000,                 loss: 1.4033
env1_first_0:                 episode reward: -66.8000,                 loss: nan
env1_second_0:                 episode reward: 66.8000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 363.95,                last time consumption/overall running time: 332.1073s / 67723.9141 s
env0_first_0:                 episode reward: -57.0500,                 loss: 1.7946
env0_second_0:                 episode reward: 57.0500,                 loss: 1.3013
env1_first_0:                 episode reward: -53.1000,                 loss: nan
env1_second_0:                 episode reward: 53.1000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 331.45,                last time consumption/overall running time: 302.3152s / 68026.2293 s
env0_first_0:                 episode reward: -76.8500,                 loss: 1.7067
env0_second_0:                 episode reward: 76.8500,                 loss: 1.2228
env1_first_0:                 episode reward: -63.1000,                 loss: nan
env1_second_0:                 episode reward: 63.1000,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 259.6,                last time consumption/overall running time: 237.4118s / 68263.6411 s
env0_first_0:                 episode reward: -55.5000,                 loss: 1.5477
env0_second_0:                 episode reward: 55.5000,                 loss: 1.0810
env1_first_0:                 episode reward: -88.0000,                 loss: nan
env1_second_0:                 episode reward: 88.0000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 266.35,                last time consumption/overall running time: 243.6342s / 68507.2752 s
env0_first_0:                 episode reward: -45.0000,                 loss: 1.4673
env0_second_0:                 episode reward: 45.0000,                 loss: 1.0155
env1_first_0:                 episode reward: -39.0500,                 loss: nan
env1_second_0:                 episode reward: 39.0500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 266.7,                last time consumption/overall running time: 244.1139s / 68751.3892 s
env0_first_0:                 episode reward: -60.3000,                 loss: 1.3903
env0_second_0:                 episode reward: 60.3000,                 loss: 0.9823
env1_first_0:                 episode reward: -56.1000,                 loss: nan
env1_second_0:                 episode reward: 56.1000,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 243.85,                last time consumption/overall running time: 222.9079s / 68974.2971 s
env0_first_0:                 episode reward: -65.1500,                 loss: 1.3901
env0_second_0:                 episode reward: 65.1500,                 loss: 0.9944
env1_first_0:                 episode reward: -64.9500,                 loss: nan
env1_second_0:                 episode reward: 64.9500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 249.7,                last time consumption/overall running time: 227.8869s / 69202.1840 s
env0_first_0:                 episode reward: -53.8000,                 loss: 1.4259
env0_second_0:                 episode reward: 53.8000,                 loss: 0.9404
env1_first_0:                 episode reward: -57.5500,                 loss: nan
env1_second_0:                 episode reward: 57.5500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 284.4,                last time consumption/overall running time: 259.4363s / 69461.6203 s
env0_first_0:                 episode reward: -80.9000,                 loss: 1.3030
env0_second_0:                 episode reward: 80.9000,                 loss: 0.9477
env1_first_0:                 episode reward: -66.1000,                 loss: nan
env1_second_0:                 episode reward: 66.1000,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 276.8,                last time consumption/overall running time: 251.8056s / 69713.4259 s
env0_first_0:                 episode reward: -73.7500,                 loss: 1.3402
env0_second_0:                 episode reward: 73.7500,                 loss: 0.9853
env1_first_0:                 episode reward: -67.9000,                 loss: nan
env1_second_0:                 episode reward: 67.9000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 259.3,                last time consumption/overall running time: 236.1264s / 69949.5522 s
env0_first_0:                 episode reward: -46.8000,                 loss: 1.4333
env0_second_0:                 episode reward: 46.8000,                 loss: 1.0377
env1_first_0:                 episode reward: -47.3000,                 loss: nan
env1_second_0:                 episode reward: 47.3000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 280.75,                last time consumption/overall running time: 256.2417s / 70205.7939 s
env0_first_0:                 episode reward: -20.5500,                 loss: 1.4312
env0_second_0:                 episode reward: 20.5500,                 loss: 1.0508
env1_first_0:                 episode reward: -61.7500,                 loss: nan
env1_second_0:                 episode reward: 61.7500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 430.05,                last time consumption/overall running time: 392.1330s / 70597.9269 s
env0_first_0:                 episode reward: -68.1500,                 loss: 1.4380
env0_second_0:                 episode reward: 68.1500,                 loss: 1.0440
env1_first_0:                 episode reward: -58.8000,                 loss: nan
env1_second_0:                 episode reward: 58.8000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 254.4,                last time consumption/overall running time: 232.7737s / 70830.7006 s
env0_first_0:                 episode reward: -60.0000,                 loss: 1.4412
env0_second_0:                 episode reward: 60.0000,                 loss: 0.9756
env1_first_0:                 episode reward: -82.3000,                 loss: nan
env1_second_0:                 episode reward: 82.3000,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 269.85,                last time consumption/overall running time: 247.2671s / 71077.9677 s
env0_first_0:                 episode reward: -73.9500,                 loss: 1.5622
env0_second_0:                 episode reward: 73.9500,                 loss: 0.9676
env1_first_0:                 episode reward: -57.9500,                 loss: nan
env1_second_0:                 episode reward: 57.9500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 302.9,                last time consumption/overall running time: 276.1453s / 71354.1130 s
env0_first_0:                 episode reward: -42.7000,                 loss: 1.5061
env0_second_0:                 episode reward: 42.7000,                 loss: 1.0452
env1_first_0:                 episode reward: -51.4000,                 loss: nan
env1_second_0:                 episode reward: 51.4000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 298.45,                last time consumption/overall running time: 272.8369s / 71626.9500 s
env0_first_0:                 episode reward: -67.6000,                 loss: 1.4925
env0_second_0:                 episode reward: 67.6000,                 loss: 1.0263
env1_first_0:                 episode reward: -59.2500,                 loss: nan
env1_second_0:                 episode reward: 59.2500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 290.0,                last time consumption/overall running time: 265.2133s / 71892.1633 s
env0_first_0:                 episode reward: -50.1500,                 loss: 1.4409
env0_second_0:                 episode reward: 50.1500,                 loss: 1.0242
env1_first_0:                 episode reward: -49.8000,                 loss: nan
env1_second_0:                 episode reward: 49.8000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 545.35,                last time consumption/overall running time: 497.6109s / 72389.7742 s
env0_first_0:                 episode reward: -42.1500,                 loss: 1.4286
env0_second_0:                 episode reward: 42.1500,                 loss: 0.9769
env1_first_0:                 episode reward: -34.8500,                 loss: nan
env1_second_0:                 episode reward: 34.8500,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 286.75,                last time consumption/overall running time: 261.0906s / 72650.8648 s
env0_first_0:                 episode reward: -51.5500,                 loss: 1.4817
env0_second_0:                 episode reward: 51.5500,                 loss: 0.9469
env1_first_0:                 episode reward: -71.5500,                 loss: nan
env1_second_0:                 episode reward: 71.5500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 349.05,                last time consumption/overall running time: 317.9823s / 72968.8471 s
env0_first_0:                 episode reward: -49.4500,                 loss: 1.6313
env0_second_0:                 episode reward: 49.4500,                 loss: 0.9806
env1_first_0:                 episode reward: -73.5500,                 loss: nan
env1_second_0:                 episode reward: 73.5500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 447.4,                last time consumption/overall running time: 406.8299s / 73375.6770 s
env0_first_0:                 episode reward: -50.2500,                 loss: 1.6553
env0_second_0:                 episode reward: 50.2500,                 loss: 0.9846
env1_first_0:                 episode reward: -52.9000,                 loss: nan
env1_second_0:                 episode reward: 52.9000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 279.7,                last time consumption/overall running time: 254.8028s / 73630.4797 s
env0_first_0:                 episode reward: -80.9500,                 loss: 1.5209
env0_second_0:                 episode reward: 80.9500,                 loss: 0.8935
env1_first_0:                 episode reward: -75.6000,                 loss: nan
env1_second_0:                 episode reward: 75.6000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 282.95,                last time consumption/overall running time: 257.8821s / 73888.3618 s
env0_first_0:                 episode reward: -71.3500,                 loss: 1.5526
env0_second_0:                 episode reward: 71.3500,                 loss: 0.9163
env1_first_0:                 episode reward: -72.0500,                 loss: nan
env1_second_0:                 episode reward: 72.0500,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 306.05,                last time consumption/overall running time: 278.4630s / 74166.8248 s
env0_first_0:                 episode reward: -58.8500,                 loss: 1.5269
env0_second_0:                 episode reward: 58.8500,                 loss: 0.8917
env1_first_0:                 episode reward: -45.9500,                 loss: nan
env1_second_0:                 episode reward: 45.9500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 260.1,                last time consumption/overall running time: 237.5505s / 74404.3753 s
env0_first_0:                 episode reward: -64.3000,                 loss: 1.3746
env0_second_0:                 episode reward: 64.3000,                 loss: 0.9014
env1_first_0:                 episode reward: -79.4000,                 loss: nan
env1_second_0:                 episode reward: 79.4000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 340.7,                last time consumption/overall running time: 310.0728s / 74714.4481 s
env0_first_0:                 episode reward: -19.0000,                 loss: 1.4200
env0_second_0:                 episode reward: 19.0000,                 loss: 0.9697
env1_first_0:                 episode reward: -37.5500,                 loss: nan
env1_second_0:                 episode reward: 37.5500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 334.15,                last time consumption/overall running time: 305.5302s / 75019.9782 s
env0_first_0:                 episode reward: -28.5000,                 loss: 1.4083
env0_second_0:                 episode reward: 28.5000,                 loss: 0.9389
env1_first_0:                 episode reward: -41.7500,                 loss: nan
env1_second_0:                 episode reward: 41.7500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 287.55,                last time consumption/overall running time: 262.6492s / 75282.6274 s
env0_first_0:                 episode reward: -49.6000,                 loss: 1.3388
env0_second_0:                 episode reward: 49.6000,                 loss: 0.9558
env1_first_0:                 episode reward: -48.2500,                 loss: nan
env1_second_0:                 episode reward: 48.2500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 268.4,                last time consumption/overall running time: 245.8058s / 75528.4332 s
env0_first_0:                 episode reward: -47.0500,                 loss: 1.3698
env0_second_0:                 episode reward: 47.0500,                 loss: 0.9824
env1_first_0:                 episode reward: -43.5000,                 loss: nan
env1_second_0:                 episode reward: 43.5000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 281.9,                last time consumption/overall running time: 258.3915s / 75786.8247 s
env0_first_0:                 episode reward: -27.7000,                 loss: 1.4313
env0_second_0:                 episode reward: 27.7000,                 loss: 1.0121
env1_first_0:                 episode reward: -40.8500,                 loss: nan
env1_second_0:                 episode reward: 40.8500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 291.6,                last time consumption/overall running time: 266.3146s / 76053.1393 s
env0_first_0:                 episode reward: -37.5500,                 loss: 1.4697
env0_second_0:                 episode reward: 37.5500,                 loss: 1.0767
env1_first_0:                 episode reward: -35.2500,                 loss: nan
env1_second_0:                 episode reward: 35.2500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 306.85,                last time consumption/overall running time: 279.9545s / 76333.0938 s
env0_first_0:                 episode reward: -45.8500,                 loss: 1.5387
env0_second_0:                 episode reward: 45.8500,                 loss: 1.0923
env1_first_0:                 episode reward: -57.5500,                 loss: nan
env1_second_0:                 episode reward: 57.5500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 284.5,                last time consumption/overall running time: 259.9883s / 76593.0821 s
env0_first_0:                 episode reward: -77.5000,                 loss: 1.5752
env0_second_0:                 episode reward: 77.5000,                 loss: 1.0806
env1_first_0:                 episode reward: -58.7000,                 loss: nan
env1_second_0:                 episode reward: 58.7000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 243.95,                last time consumption/overall running time: 223.4731s / 76816.5553 s
env0_first_0:                 episode reward: -79.7000,                 loss: 1.5843
env0_second_0:                 episode reward: 79.7000,                 loss: 1.1093
env1_first_0:                 episode reward: -81.9000,                 loss: nan
env1_second_0:                 episode reward: 81.9000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 319.15,                last time consumption/overall running time: 291.7514s / 77108.3066 s
env0_first_0:                 episode reward: -61.2000,                 loss: 1.6380
env0_second_0:                 episode reward: 61.2000,                 loss: 1.1785
env1_first_0:                 episode reward: -67.6000,                 loss: nan
env1_second_0:                 episode reward: 67.6000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 265.9,                last time consumption/overall running time: 243.1111s / 77351.4178 s
env0_first_0:                 episode reward: -29.5500,                 loss: 1.7344
env0_second_0:                 episode reward: 29.5500,                 loss: 1.2522
env1_first_0:                 episode reward: -30.8500,                 loss: nan
env1_second_0:                 episode reward: 30.8500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 260.9,                last time consumption/overall running time: 238.2957s / 77589.7135 s
env0_first_0:                 episode reward: -53.9000,                 loss: 1.8133
env0_second_0:                 episode reward: 53.9000,                 loss: 1.2983
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 293.05,                last time consumption/overall running time: 267.6583s / 77857.3718 s
env0_first_0:                 episode reward: -0.2500,                 loss: 1.8692
env0_second_0:                 episode reward: 0.2500,                 loss: 1.3293
env1_first_0:                 episode reward: 15.4500,                 loss: nan
env1_second_0:                 episode reward: -15.4500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 285.9,                last time consumption/overall running time: 260.7993s / 78118.1710 s
env0_first_0:                 episode reward: -48.7500,                 loss: 1.8331
env0_second_0:                 episode reward: 48.7500,                 loss: 1.3869
env1_first_0:                 episode reward: -57.3000,                 loss: nan
env1_second_0:                 episode reward: 57.3000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 276.4,                last time consumption/overall running time: 252.3484s / 78370.5195 s
env0_first_0:                 episode reward: -15.0000,                 loss: 1.7855
env0_second_0:                 episode reward: 15.0000,                 loss: 1.3224
env1_first_0:                 episode reward: -26.1000,                 loss: nan
env1_second_0:                 episode reward: 26.1000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 289.7,                last time consumption/overall running time: 264.4490s / 78634.9684 s
env0_first_0:                 episode reward: -31.2000,                 loss: 1.8543
env0_second_0:                 episode reward: 31.2000,                 loss: 1.3731
env1_first_0:                 episode reward: -44.7000,                 loss: nan
env1_second_0:                 episode reward: 44.7000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 251.9,                last time consumption/overall running time: 230.1747s / 78865.1431 s
env0_first_0:                 episode reward: -83.8500,                 loss: 1.8708
env0_second_0:                 episode reward: 83.8500,                 loss: 1.3481
env1_first_0:                 episode reward: -84.5000,                 loss: nan
env1_second_0:                 episode reward: 84.5000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 276.0,                last time consumption/overall running time: 252.1180s / 79117.2611 s
env0_first_0:                 episode reward: -73.7000,                 loss: 1.8665
env0_second_0:                 episode reward: 73.7000,                 loss: 1.3683
env1_first_0:                 episode reward: -76.1500,                 loss: nan
env1_second_0:                 episode reward: 76.1500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 313.45,                last time consumption/overall running time: 285.3343s / 79402.5954 s
env0_first_0:                 episode reward: -60.2500,                 loss: 1.8070
env0_second_0:                 episode reward: 60.2500,                 loss: 1.3119
env1_first_0:                 episode reward: -69.7500,                 loss: nan
env1_second_0:                 episode reward: 69.7500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 252.7,                last time consumption/overall running time: 230.4400s / 79633.0354 s
env0_first_0:                 episode reward: -66.8000,                 loss: 1.7472
env0_second_0:                 episode reward: 66.8000,                 loss: 1.2041
env1_first_0:                 episode reward: -69.1500,                 loss: nan
env1_second_0:                 episode reward: 69.1500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 314.6,                last time consumption/overall running time: 287.0762s / 79920.1116 s
env0_first_0:                 episode reward: -78.9000,                 loss: 1.7274
env0_second_0:                 episode reward: 78.9000,                 loss: 1.1013
env1_first_0:                 episode reward: -83.4000,                 loss: nan
env1_second_0:                 episode reward: 83.4000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 249.1,                last time consumption/overall running time: 227.8782s / 80147.9898 s
env0_first_0:                 episode reward: -86.5000,                 loss: 1.7017
env0_second_0:                 episode reward: 86.5000,                 loss: 1.0482
env1_first_0:                 episode reward: -81.8000,                 loss: nan
env1_second_0:                 episode reward: 81.8000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 248.9,                last time consumption/overall running time: 227.9657s / 80375.9555 s
env0_first_0:                 episode reward: -84.7500,                 loss: 1.7116
env0_second_0:                 episode reward: 84.7500,                 loss: 0.9820
env1_first_0:                 episode reward: -72.1500,                 loss: nan
env1_second_0:                 episode reward: 72.1500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 250.8,                last time consumption/overall running time: 229.0071s / 80604.9626 s
env0_first_0:                 episode reward: -90.9500,                 loss: 1.7464
env0_second_0:                 episode reward: 90.9500,                 loss: 0.8872
env1_first_0:                 episode reward: -85.1000,                 loss: nan
env1_second_0:                 episode reward: 85.1000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 272.25,                last time consumption/overall running time: 248.9530s / 80853.9156 s
env0_first_0:                 episode reward: -65.3500,                 loss: 1.8871
env0_second_0:                 episode reward: 65.3500,                 loss: 0.8421
env1_first_0:                 episode reward: -69.5000,                 loss: nan
env1_second_0:                 episode reward: 69.5000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 238.35,                last time consumption/overall running time: 218.1565s / 81072.0721 s
env0_first_0:                 episode reward: -89.3000,                 loss: 1.9207
env0_second_0:                 episode reward: 89.3000,                 loss: 0.8730
env1_first_0:                 episode reward: -83.6000,                 loss: nan
env1_second_0:                 episode reward: 83.6000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 254.35,                last time consumption/overall running time: 232.7136s / 81304.7857 s
env0_first_0:                 episode reward: -89.6000,                 loss: 1.8574
env0_second_0:                 episode reward: 89.6000,                 loss: 0.8868
env1_first_0:                 episode reward: -82.7500,                 loss: nan
env1_second_0:                 episode reward: 82.7500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 278.85,                last time consumption/overall running time: 255.3566s / 81560.1422 s
env0_first_0:                 episode reward: -73.5000,                 loss: 1.7923
env0_second_0:                 episode reward: 73.5000,                 loss: 0.8679
env1_first_0:                 episode reward: -69.9000,                 loss: nan
env1_second_0:                 episode reward: 69.9000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 272.1,                last time consumption/overall running time: 248.2138s / 81808.3560 s
env0_first_0:                 episode reward: -68.7500,                 loss: 1.7901
env0_second_0:                 episode reward: 68.7500,                 loss: 0.8806
env1_first_0:                 episode reward: -56.0500,                 loss: nan
env1_second_0:                 episode reward: 56.0500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 280.1,                last time consumption/overall running time: 255.6973s / 82064.0533 s
env0_first_0:                 episode reward: -44.7500,                 loss: 1.9358
env0_second_0:                 episode reward: 44.7500,                 loss: 0.9311
env1_first_0:                 episode reward: -51.9500,                 loss: nan
env1_second_0:                 episode reward: 51.9500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 335.75,                last time consumption/overall running time: 306.2892s / 82370.3425 s
env0_first_0:                 episode reward: -32.7000,                 loss: 2.0489
env0_second_0:                 episode reward: 32.7000,                 loss: 1.0080
env1_first_0:                 episode reward: -29.1500,                 loss: nan
env1_second_0:                 episode reward: 29.1500,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 336.25,                last time consumption/overall running time: 307.2454s / 82677.5879 s
env0_first_0:                 episode reward: -36.5500,                 loss: 2.0758
env0_second_0:                 episode reward: 36.5500,                 loss: 1.0724
env1_first_0:                 episode reward: -41.8000,                 loss: nan
env1_second_0:                 episode reward: 41.8000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 257.4,                last time consumption/overall running time: 235.2198s / 82912.8077 s
env0_first_0:                 episode reward: -74.5000,                 loss: 1.9705
env0_second_0:                 episode reward: 74.5000,                 loss: 1.1108
env1_first_0:                 episode reward: -57.3500,                 loss: nan
env1_second_0:                 episode reward: 57.3500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 442.45,                last time consumption/overall running time: 403.7379s / 83316.5456 s
env0_first_0:                 episode reward: -27.2000,                 loss: 1.9497
env0_second_0:                 episode reward: 27.2000,                 loss: 1.1340
env1_first_0:                 episode reward: -39.2500,                 loss: nan
env1_second_0:                 episode reward: 39.2500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 360.0,                last time consumption/overall running time: 328.2320s / 83644.7776 s
env0_first_0:                 episode reward: -66.0000,                 loss: 1.9962
env0_second_0:                 episode reward: 66.0000,                 loss: 1.1566
env1_first_0:                 episode reward: -55.9500,                 loss: nan
env1_second_0:                 episode reward: 55.9500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 265.8,                last time consumption/overall running time: 243.0843s / 83887.8619 s
env0_first_0:                 episode reward: -71.3500,                 loss: 2.0400
env0_second_0:                 episode reward: 71.3500,                 loss: 1.1777
env1_first_0:                 episode reward: -58.3000,                 loss: nan
env1_second_0:                 episode reward: 58.3000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 299.55,                last time consumption/overall running time: 273.3804s / 84161.2422 s
env0_first_0:                 episode reward: -65.8000,                 loss: 2.1008
env0_second_0:                 episode reward: 65.8000,                 loss: 1.2520
env1_first_0:                 episode reward: -68.8000,                 loss: nan
env1_second_0:                 episode reward: 68.8000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 259.05,                last time consumption/overall running time: 236.2081s / 84397.4503 s
env0_first_0:                 episode reward: -69.9000,                 loss: 2.0034
env0_second_0:                 episode reward: 69.9000,                 loss: 1.1927
env1_first_0:                 episode reward: -70.1500,                 loss: nan
env1_second_0:                 episode reward: 70.1500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 247.7,                last time consumption/overall running time: 226.0441s / 84623.4944 s
env0_first_0:                 episode reward: -59.9500,                 loss: 2.0270
env0_second_0:                 episode reward: 59.9500,                 loss: 1.1604
env1_first_0:                 episode reward: -70.5500,                 loss: nan
env1_second_0:                 episode reward: 70.5500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 239.9,                last time consumption/overall running time: 219.2083s / 84842.7027 s
env0_first_0:                 episode reward: -60.2500,                 loss: 1.8836
env0_second_0:                 episode reward: 60.2500,                 loss: 1.0900
env1_first_0:                 episode reward: -68.0500,                 loss: nan
env1_second_0:                 episode reward: 68.0500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 476.3,                last time consumption/overall running time: 433.9303s / 85276.6330 s
env0_first_0:                 episode reward: -58.4000,                 loss: 1.6460
env0_second_0:                 episode reward: 58.4000,                 loss: 0.9201
env1_first_0:                 episode reward: -28.3500,                 loss: nan
env1_second_0:                 episode reward: 28.3500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 294.4,                last time consumption/overall running time: 268.1363s / 85544.7692 s
env0_first_0:                 episode reward: -60.0500,                 loss: 1.5943
env0_second_0:                 episode reward: 60.0500,                 loss: 0.9411
env1_first_0:                 episode reward: -56.0000,                 loss: nan
env1_second_0:                 episode reward: 56.0000,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 289.8,                last time consumption/overall running time: 264.9567s / 85809.7260 s
env0_first_0:                 episode reward: -81.4500,                 loss: 1.6207
env0_second_0:                 episode reward: 81.4500,                 loss: 0.9447
env1_first_0:                 episode reward: -49.7500,                 loss: nan
env1_second_0:                 episode reward: 49.7500,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 298.45,                last time consumption/overall running time: 273.2999s / 86083.0258 s
env0_first_0:                 episode reward: -62.8000,                 loss: 1.6801
env0_second_0:                 episode reward: 62.8000,                 loss: 0.9962
env1_first_0:                 episode reward: -66.3000,                 loss: nan
env1_second_0:                 episode reward: 66.3000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 289.7,                last time consumption/overall running time: 264.8239s / 86347.8498 s
env0_first_0:                 episode reward: -34.3000,                 loss: 1.6373
env0_second_0:                 episode reward: 34.3000,                 loss: 1.0078
env1_first_0:                 episode reward: -44.8500,                 loss: nan
env1_second_0:                 episode reward: 44.8500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 298.15,                last time consumption/overall running time: 272.4841s / 86620.3339 s
env0_first_0:                 episode reward: -67.9500,                 loss: 1.6552
env0_second_0:                 episode reward: 67.9500,                 loss: 0.9852
env1_first_0:                 episode reward: -43.3500,                 loss: nan
env1_second_0:                 episode reward: 43.3500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 299.45,                last time consumption/overall running time: 273.8755s / 86894.2094 s
env0_first_0:                 episode reward: -47.9000,                 loss: 1.5634
env0_second_0:                 episode reward: 47.9000,                 loss: 0.9665
env1_first_0:                 episode reward: -46.6000,                 loss: nan
env1_second_0:                 episode reward: 46.6000,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 259.5,                last time consumption/overall running time: 237.2020s / 87131.4114 s
env0_first_0:                 episode reward: -42.0000,                 loss: 1.7214
env0_second_0:                 episode reward: 42.0000,                 loss: 0.9884
env1_first_0:                 episode reward: -55.7000,                 loss: nan
env1_second_0:                 episode reward: 55.7000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 253.95,                last time consumption/overall running time: 231.9372s / 87363.3486 s
env0_first_0:                 episode reward: -60.6500,                 loss: 1.8398
env0_second_0:                 episode reward: 60.6500,                 loss: 1.0170
env1_first_0:                 episode reward: -64.6500,                 loss: nan
env1_second_0:                 episode reward: 64.6500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 262.45,                last time consumption/overall running time: 239.9152s / 87603.2638 s
env0_first_0:                 episode reward: -88.2000,                 loss: 1.9460
env0_second_0:                 episode reward: 88.2000,                 loss: 1.0262
env1_first_0:                 episode reward: -61.0000,                 loss: nan
env1_second_0:                 episode reward: 61.0000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 266.25,                last time consumption/overall running time: 243.9944s / 87847.2583 s
env0_first_0:                 episode reward: -66.4500,                 loss: 1.8072
env0_second_0:                 episode reward: 66.4500,                 loss: 1.0072
env1_first_0:                 episode reward: -50.8000,                 loss: nan
env1_second_0:                 episode reward: 50.8000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 254.15,                last time consumption/overall running time: 232.5909s / 88079.8492 s
env0_first_0:                 episode reward: -47.8000,                 loss: 1.7726
env0_second_0:                 episode reward: 47.8000,                 loss: 0.9902
env1_first_0:                 episode reward: -44.6000,                 loss: nan
env1_second_0:                 episode reward: 44.6000,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 292.45,                last time consumption/overall running time: 267.4435s / 88347.2927 s
env0_first_0:                 episode reward: -68.4000,                 loss: 1.7826
env0_second_0:                 episode reward: 68.4000,                 loss: 1.0146
env1_first_0:                 episode reward: -72.9000,                 loss: nan
env1_second_0:                 episode reward: 72.9000,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 274.45,                last time consumption/overall running time: 250.3624s / 88597.6551 s
env0_first_0:                 episode reward: -41.4000,                 loss: 1.7798
env0_second_0:                 episode reward: 41.4000,                 loss: 0.9850
env1_first_0:                 episode reward: -38.4500,                 loss: nan
env1_second_0:                 episode reward: 38.4500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 278.65,                last time consumption/overall running time: 253.9142s / 88851.5693 s
env0_first_0:                 episode reward: 28.1000,                 loss: 1.7827
env0_second_0:                 episode reward: -28.1000,                 loss: 1.0114
env1_first_0:                 episode reward: 5.7000,                 loss: nan
env1_second_0:                 episode reward: -5.7000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 266.45,                last time consumption/overall running time: 243.2087s / 89094.7780 s
env0_first_0:                 episode reward: -52.3000,                 loss: 1.7648
env0_second_0:                 episode reward: 52.3000,                 loss: 1.0730
env1_first_0:                 episode reward: -62.9000,                 loss: nan
env1_second_0:                 episode reward: 62.9000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 266.2,                last time consumption/overall running time: 243.0701s / 89337.8481 s
env0_first_0:                 episode reward: 3.8500,                 loss: 1.7599
env0_second_0:                 episode reward: -3.8500,                 loss: 1.0964
env1_first_0:                 episode reward: -20.7000,                 loss: nan
env1_second_0:                 episode reward: 20.7000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 263.9,                last time consumption/overall running time: 241.1358s / 89578.9839 s
env0_first_0:                 episode reward: -59.6500,                 loss: 1.7991
env0_second_0:                 episode reward: 59.6500,                 loss: 1.1238
env1_first_0:                 episode reward: -65.7500,                 loss: nan
env1_second_0:                 episode reward: 65.7500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 292.05,                last time consumption/overall running time: 265.8809s / 89844.8648 s
env0_first_0:                 episode reward: -39.0500,                 loss: 1.8375
env0_second_0:                 episode reward: 39.0500,                 loss: 1.1561
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 282.25,                last time consumption/overall running time: 257.6027s / 90102.4675 s
env0_first_0:                 episode reward: -60.5000,                 loss: 1.7818
env0_second_0:                 episode reward: 60.5000,                 loss: 1.1686
env1_first_0:                 episode reward: -33.1000,                 loss: nan
env1_second_0:                 episode reward: 33.1000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 272.5,                last time consumption/overall running time: 248.6858s / 90351.1533 s
env0_first_0:                 episode reward: -45.0500,                 loss: 1.8647
env0_second_0:                 episode reward: 45.0500,                 loss: 1.2155
env1_first_0:                 episode reward: -74.5500,                 loss: nan
env1_second_0:                 episode reward: 74.5500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 284.65,                last time consumption/overall running time: 259.6693s / 90610.8226 s
env0_first_0:                 episode reward: -68.2500,                 loss: 1.9864
env0_second_0:                 episode reward: 68.2500,                 loss: 1.2834
env1_first_0:                 episode reward: -53.4000,                 loss: nan
env1_second_0:                 episode reward: 53.4000,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 274.2,                last time consumption/overall running time: 250.2519s / 90861.0744 s
env0_first_0:                 episode reward: -58.8500,                 loss: 1.8767
env0_second_0:                 episode reward: 58.8500,                 loss: 1.2803
env1_first_0:                 episode reward: -51.3000,                 loss: nan
env1_second_0:                 episode reward: 51.3000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 275.9,                last time consumption/overall running time: 251.7147s / 91112.7892 s
env0_first_0:                 episode reward: -66.3500,                 loss: 1.7808
env0_second_0:                 episode reward: 66.3500,                 loss: 1.2648
env1_first_0:                 episode reward: -43.0000,                 loss: nan
env1_second_0:                 episode reward: 43.0000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 253.95,                last time consumption/overall running time: 232.3346s / 91345.1238 s
env0_first_0:                 episode reward: -51.5500,                 loss: 1.8012
env0_second_0:                 episode reward: 51.5500,                 loss: 1.2174
env1_first_0:                 episode reward: -58.9000,                 loss: nan
env1_second_0:                 episode reward: 58.9000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 240.55,                last time consumption/overall running time: 219.7720s / 91564.8958 s
env0_first_0:                 episode reward: -82.1000,                 loss: 1.8945
env0_second_0:                 episode reward: 82.1000,                 loss: 1.1780
env1_first_0:                 episode reward: -83.8000,                 loss: nan
env1_second_0:                 episode reward: 83.8000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 262.7,                last time consumption/overall running time: 240.4108s / 91805.3065 s
env0_first_0:                 episode reward: -44.2500,                 loss: 2.0206
env0_second_0:                 episode reward: 44.2500,                 loss: 1.1435
env1_first_0:                 episode reward: -46.6000,                 loss: nan
env1_second_0:                 episode reward: 46.6000,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 318.1,                last time consumption/overall running time: 290.3779s / 92095.6844 s
env0_first_0:                 episode reward: -39.7000,                 loss: 2.0515
env0_second_0:                 episode reward: 39.7000,                 loss: 1.0610
env1_first_0:                 episode reward: -27.3000,                 loss: nan
env1_second_0:                 episode reward: 27.3000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 318.6,                last time consumption/overall running time: 290.9612s / 92386.6455 s
env0_first_0:                 episode reward: -44.9500,                 loss: 2.0515
env0_second_0:                 episode reward: 44.9500,                 loss: 1.0368
env1_first_0:                 episode reward: -45.3500,                 loss: nan
env1_second_0:                 episode reward: 45.3500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 284.5,                last time consumption/overall running time: 259.4725s / 92646.1181 s
env0_first_0:                 episode reward: -67.3500,                 loss: 1.9492
env0_second_0:                 episode reward: 67.3500,                 loss: 1.0446
env1_first_0:                 episode reward: -55.1500,                 loss: nan
env1_second_0:                 episode reward: 55.1500,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 298.55,                last time consumption/overall running time: 272.3693s / 92918.4874 s
env0_first_0:                 episode reward: -54.3000,                 loss: 1.8713
env0_second_0:                 episode reward: 54.3000,                 loss: 0.9587
env1_first_0:                 episode reward: -51.4500,                 loss: nan
env1_second_0:                 episode reward: 51.4500,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 333.95,                last time consumption/overall running time: 304.4834s / 93222.9708 s
env0_first_0:                 episode reward: -47.5000,                 loss: 1.9098
env0_second_0:                 episode reward: 47.5000,                 loss: 1.0021
env1_first_0:                 episode reward: -70.6500,                 loss: nan
env1_second_0:                 episode reward: 70.6500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 322.4,                last time consumption/overall running time: 293.6535s / 93516.6243 s
env0_first_0:                 episode reward: -67.4000,                 loss: 1.8934
env0_second_0:                 episode reward: 67.4000,                 loss: 0.9882
env1_first_0:                 episode reward: -53.8000,                 loss: nan
env1_second_0:                 episode reward: 53.8000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 299.65,                last time consumption/overall running time: 273.0318s / 93789.6561 s
env0_first_0:                 episode reward: -30.0000,                 loss: 1.9259
env0_second_0:                 episode reward: 30.0000,                 loss: 1.0637
env1_first_0:                 episode reward: -53.4000,                 loss: nan
env1_second_0:                 episode reward: 53.4000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 294.05,                last time consumption/overall running time: 266.8446s / 94056.5007 s
env0_first_0:                 episode reward: -66.8500,                 loss: 1.9888
env0_second_0:                 episode reward: 66.8500,                 loss: 1.1025
env1_first_0:                 episode reward: -67.6000,                 loss: nan
env1_second_0:                 episode reward: 67.6000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 259.4,                last time consumption/overall running time: 236.3824s / 94292.8830 s
env0_first_0:                 episode reward: -58.3500,                 loss: 2.0162
env0_second_0:                 episode reward: 58.3500,                 loss: 1.1091
env1_first_0:                 episode reward: -80.3500,                 loss: nan
env1_second_0:                 episode reward: 80.3500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 267.6,                last time consumption/overall running time: 243.4235s / 94536.3066 s
env0_first_0:                 episode reward: -76.0000,                 loss: 2.2154
env0_second_0:                 episode reward: 76.0000,                 loss: 1.1563
env1_first_0:                 episode reward: -74.0500,                 loss: nan
env1_second_0:                 episode reward: 74.0500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 247.85,                last time consumption/overall running time: 225.7498s / 94762.0564 s
env0_first_0:                 episode reward: -78.2500,                 loss: 2.0500
env0_second_0:                 episode reward: 78.2500,                 loss: 1.0755
env1_first_0:                 episode reward: -91.3500,                 loss: nan
env1_second_0:                 episode reward: 91.3500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 254.85,                last time consumption/overall running time: 232.1375s / 94994.1939 s
env0_first_0:                 episode reward: -81.2000,                 loss: 2.0955
env0_second_0:                 episode reward: 81.2000,                 loss: 1.0442
env1_first_0:                 episode reward: -81.3000,                 loss: nan
env1_second_0:                 episode reward: 81.3000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 320.95,                last time consumption/overall running time: 292.7247s / 95286.9186 s
env0_first_0:                 episode reward: -76.9500,                 loss: 1.9955
env0_second_0:                 episode reward: 76.9500,                 loss: 1.0457
env1_first_0:                 episode reward: -83.8000,                 loss: nan
env1_second_0:                 episode reward: 83.8000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 343.55,                last time consumption/overall running time: 312.3748s / 95599.2933 s
env0_first_0:                 episode reward: -76.4000,                 loss: 1.7994
env0_second_0:                 episode reward: 76.4000,                 loss: 0.9344
env1_first_0:                 episode reward: -72.8500,                 loss: nan
env1_second_0:                 episode reward: 72.8500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 354.45,                last time consumption/overall running time: 322.0234s / 95921.3167 s
env0_first_0:                 episode reward: -56.0000,                 loss: 1.7151
env0_second_0:                 episode reward: 56.0000,                 loss: 0.8523
env1_first_0:                 episode reward: -51.1000,                 loss: nan
env1_second_0:                 episode reward: 51.1000,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 326.2,                last time consumption/overall running time: 296.6031s / 96217.9198 s
env0_first_0:                 episode reward: -56.9000,                 loss: 1.7534
env0_second_0:                 episode reward: 56.9000,                 loss: 0.7740
env1_first_0:                 episode reward: -36.6000,                 loss: nan
env1_second_0:                 episode reward: 36.6000,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 400.75,                last time consumption/overall running time: 364.1057s / 96582.0255 s
env0_first_0:                 episode reward: -44.0000,                 loss: 1.7589
env0_second_0:                 episode reward: 44.0000,                 loss: 0.7688
env1_first_0:                 episode reward: -25.1500,                 loss: nan
env1_second_0:                 episode reward: 25.1500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 490.6,                last time consumption/overall running time: 444.9016s / 97026.9271 s
env0_first_0:                 episode reward: -16.2500,                 loss: 1.6763
env0_second_0:                 episode reward: 16.2500,                 loss: 0.7980
env1_first_0:                 episode reward: -25.1000,                 loss: nan
env1_second_0:                 episode reward: 25.1000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 573.7,                last time consumption/overall running time: 519.7943s / 97546.7214 s
env0_first_0:                 episode reward: -30.7000,                 loss: 1.5419
env0_second_0:                 episode reward: 30.7000,                 loss: 0.8021
env1_first_0:                 episode reward: -30.8500,                 loss: nan
env1_second_0:                 episode reward: 30.8500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 427.75,                last time consumption/overall running time: 388.0989s / 97934.8203 s
env0_first_0:                 episode reward: -34.5500,                 loss: 1.4924
env0_second_0:                 episode reward: 34.5500,                 loss: 0.8209
env1_first_0:                 episode reward: -63.1000,                 loss: nan
env1_second_0:                 episode reward: 63.1000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 892.4,                last time consumption/overall running time: 807.5810s / 98742.4013 s
env0_first_0:                 episode reward: -40.8000,                 loss: 1.2402
env0_second_0:                 episode reward: 40.8000,                 loss: 0.7059
env1_first_0:                 episode reward: -44.1500,                 loss: nan
env1_second_0:                 episode reward: 44.1500,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 503.95,                last time consumption/overall running time: 457.3499s / 99199.7512 s
env0_first_0:                 episode reward: -83.7500,                 loss: 1.1158
env0_second_0:                 episode reward: 83.7500,                 loss: 0.4730
env1_first_0:                 episode reward: -64.0000,                 loss: nan
env1_second_0:                 episode reward: 64.0000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 347.5,                last time consumption/overall running time: 315.8738s / 99515.6249 s
env0_first_0:                 episode reward: -84.5500,                 loss: 1.1443
env0_second_0:                 episode reward: 84.5500,                 loss: 0.4276
env1_first_0:                 episode reward: -81.9000,                 loss: nan
env1_second_0:                 episode reward: 81.9000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 342.9,                last time consumption/overall running time: 311.2777s / 99826.9027 s
env0_first_0:                 episode reward: -79.1000,                 loss: 1.1813
env0_second_0:                 episode reward: 79.1000,                 loss: 0.3912
env1_first_0:                 episode reward: -73.6000,                 loss: nan
env1_second_0:                 episode reward: 73.6000,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 426.45,                last time consumption/overall running time: 386.1802s / 100213.0829 s
env0_first_0:                 episode reward: -77.7500,                 loss: 1.4878
env0_second_0:                 episode reward: 77.7500,                 loss: 0.4028
env1_first_0:                 episode reward: -66.7000,                 loss: nan
env1_second_0:                 episode reward: 66.7000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 303.6,                last time consumption/overall running time: 275.4239s / 100488.5068 s
env0_first_0:                 episode reward: -74.6000,                 loss: 1.6885
env0_second_0:                 episode reward: 74.6000,                 loss: 0.4392
env1_first_0:                 episode reward: -67.3500,                 loss: nan
env1_second_0:                 episode reward: 67.3500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 462.95,                last time consumption/overall running time: 420.6004s / 100909.1072 s
env0_first_0:                 episode reward: -72.8000,                 loss: 1.7836
env0_second_0:                 episode reward: 72.8000,                 loss: 0.4248
env1_first_0:                 episode reward: -75.9500,                 loss: nan
env1_second_0:                 episode reward: 75.9500,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 463.55,                last time consumption/overall running time: 420.0460s / 101329.1532 s
env0_first_0:                 episode reward: -42.1000,                 loss: 1.8841
env0_second_0:                 episode reward: 42.1000,                 loss: 0.4655
env1_first_0:                 episode reward: -36.5000,                 loss: nan
env1_second_0:                 episode reward: 36.5000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 399.55,                last time consumption/overall running time: 362.5438s / 101691.6970 s
env0_first_0:                 episode reward: -58.6500,                 loss: 1.9423
env0_second_0:                 episode reward: 58.6500,                 loss: 0.5010
env1_first_0:                 episode reward: -63.9500,                 loss: nan
env1_second_0:                 episode reward: 63.9500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 273.75,                last time consumption/overall running time: 249.1856s / 101940.8826 s
env0_first_0:                 episode reward: -70.8000,                 loss: 1.9033
env0_second_0:                 episode reward: 70.8000,                 loss: 0.5427
env1_first_0:                 episode reward: -54.1500,                 loss: nan
env1_second_0:                 episode reward: 54.1500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 301.15,                last time consumption/overall running time: 273.8891s / 102214.7717 s
env0_first_0:                 episode reward: -40.9500,                 loss: 1.9574
env0_second_0:                 episode reward: 40.9500,                 loss: 0.6101
env1_first_0:                 episode reward: -27.0500,                 loss: nan
env1_second_0:                 episode reward: 27.0500,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 242.0,                last time consumption/overall running time: 220.4057s / 102435.1774 s
env0_first_0:                 episode reward: -84.0000,                 loss: 1.8981
env0_second_0:                 episode reward: 84.0000,                 loss: 0.6016
env1_first_0:                 episode reward: -76.7500,                 loss: nan
env1_second_0:                 episode reward: 76.7500,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 279.15,                last time consumption/overall running time: 254.0866s / 102689.2640 s
env0_first_0:                 episode reward: -69.0500,                 loss: 1.7757
env0_second_0:                 episode reward: 69.0500,                 loss: 0.6464
env1_first_0:                 episode reward: -53.5500,                 loss: nan
env1_second_0:                 episode reward: 53.5500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 257.8,                last time consumption/overall running time: 234.4421s / 102923.7061 s
env0_first_0:                 episode reward: -73.6000,                 loss: 1.7994
env0_second_0:                 episode reward: 73.6000,                 loss: 0.6667
env1_first_0:                 episode reward: -60.5500,                 loss: nan
env1_second_0:                 episode reward: 60.5500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 307.6,                last time consumption/overall running time: 279.1900s / 103202.8960 s
env0_first_0:                 episode reward: -57.1500,                 loss: 1.8129
env0_second_0:                 episode reward: 57.1500,                 loss: 0.7450
env1_first_0:                 episode reward: -71.2500,                 loss: nan
env1_second_0:                 episode reward: 71.2500,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 278.8,                last time consumption/overall running time: 254.3303s / 103457.2263 s
env0_first_0:                 episode reward: -62.2500,                 loss: 1.7247
env0_second_0:                 episode reward: 62.2500,                 loss: 0.7418
env1_first_0:                 episode reward: -61.4000,                 loss: nan
env1_second_0:                 episode reward: 61.4000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 306.7,                last time consumption/overall running time: 278.9657s / 103736.1920 s
env0_first_0:                 episode reward: -52.5000,                 loss: 1.8008
env0_second_0:                 episode reward: 52.5000,                 loss: 0.7625
env1_first_0:                 episode reward: -62.1500,                 loss: nan
env1_second_0:                 episode reward: 62.1500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 295.75,                last time consumption/overall running time: 268.5163s / 104004.7083 s
env0_first_0:                 episode reward: -59.3000,                 loss: 1.9901
env0_second_0:                 episode reward: 59.3000,                 loss: 0.8392
env1_first_0:                 episode reward: -57.8500,                 loss: nan
env1_second_0:                 episode reward: 57.8500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 289.35,                last time consumption/overall running time: 262.5296s / 104267.2379 s
env0_first_0:                 episode reward: -19.3000,                 loss: 2.1269
env0_second_0:                 episode reward: 19.3000,                 loss: 0.8918
env1_first_0:                 episode reward: -35.8500,                 loss: nan
env1_second_0:                 episode reward: 35.8500,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 306.35,                last time consumption/overall running time: 278.6877s / 104545.9256 s
env0_first_0:                 episode reward: -17.1500,                 loss: 2.1634
env0_second_0:                 episode reward: 17.1500,                 loss: 0.9283
env1_first_0:                 episode reward: -54.3500,                 loss: nan
env1_second_0:                 episode reward: 54.3500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 301.8,                last time consumption/overall running time: 273.6161s / 104819.5417 s
env0_first_0:                 episode reward: -1.9500,                 loss: 2.1433
env0_second_0:                 episode reward: 1.9500,                 loss: 0.9322
env1_first_0:                 episode reward: -29.0500,                 loss: nan
env1_second_0:                 episode reward: 29.0500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 266.7,                last time consumption/overall running time: 242.4252s / 105061.9669 s
env0_first_0:                 episode reward: -41.6500,                 loss: 2.2136
env0_second_0:                 episode reward: 41.6500,                 loss: 0.9481
env1_first_0:                 episode reward: -42.2500,                 loss: nan
env1_second_0:                 episode reward: 42.2500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 259.8,                last time consumption/overall running time: 236.0779s / 105298.0448 s
env0_first_0:                 episode reward: -44.3000,                 loss: 2.2271
env0_second_0:                 episode reward: 44.3000,                 loss: 0.9897
env1_first_0:                 episode reward: -50.9000,                 loss: nan
env1_second_0:                 episode reward: 50.9000,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 274.0,                last time consumption/overall running time: 249.1600s / 105547.2049 s
env0_first_0:                 episode reward: -62.3500,                 loss: 2.2343
env0_second_0:                 episode reward: 62.3500,                 loss: 1.0618
env1_first_0:                 episode reward: -52.5000,                 loss: nan
env1_second_0:                 episode reward: 52.5000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 246.1,                last time consumption/overall running time: 224.5242s / 105771.7291 s
env0_first_0:                 episode reward: -89.6000,                 loss: 2.2274
env0_second_0:                 episode reward: 89.6000,                 loss: 1.0950
env1_first_0:                 episode reward: -89.1000,                 loss: nan
env1_second_0:                 episode reward: 89.1000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 266.5,                last time consumption/overall running time: 242.7376s / 106014.4667 s
env0_first_0:                 episode reward: -38.1000,                 loss: 2.1154
env0_second_0:                 episode reward: 38.1000,                 loss: 1.0639
env1_first_0:                 episode reward: -58.2000,                 loss: nan
env1_second_0:                 episode reward: 58.2000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 253.35,                last time consumption/overall running time: 230.5973s / 106245.0639 s
env0_first_0:                 episode reward: -86.2500,                 loss: 2.0004
env0_second_0:                 episode reward: 86.2500,                 loss: 1.0556
env1_first_0:                 episode reward: -81.0500,                 loss: nan
env1_second_0:                 episode reward: 81.0500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 242.6,                last time consumption/overall running time: 220.6528s / 106465.7167 s
env0_first_0:                 episode reward: -73.5000,                 loss: 1.8403
env0_second_0:                 episode reward: 73.5000,                 loss: 1.0699
env1_first_0:                 episode reward: -71.9500,                 loss: nan
env1_second_0:                 episode reward: 71.9500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 259.25,                last time consumption/overall running time: 236.7557s / 106702.4724 s
env0_first_0:                 episode reward: -84.5000,                 loss: 1.8130
env0_second_0:                 episode reward: 84.5000,                 loss: 1.0575
env1_first_0:                 episode reward: -65.2500,                 loss: nan
env1_second_0:                 episode reward: 65.2500,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 270.8,                last time consumption/overall running time: 246.0338s / 106948.5062 s
env0_first_0:                 episode reward: -63.1500,                 loss: 1.8133
env0_second_0:                 episode reward: 63.1500,                 loss: 1.0479
env1_first_0:                 episode reward: -70.2000,                 loss: nan
env1_second_0:                 episode reward: 70.2000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 428.15,                last time consumption/overall running time: 389.8335s / 107338.3397 s
env0_first_0:                 episode reward: -68.6500,                 loss: 1.6872
env0_second_0:                 episode reward: 68.6500,                 loss: 1.0035
env1_first_0:                 episode reward: -64.4500,                 loss: nan
env1_second_0:                 episode reward: 64.4500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 272.1,                last time consumption/overall running time: 248.0425s / 107586.3822 s
env0_first_0:                 episode reward: -73.2500,                 loss: 1.7382
env0_second_0:                 episode reward: 73.2500,                 loss: 0.9401
env1_first_0:                 episode reward: -63.0000,                 loss: nan
env1_second_0:                 episode reward: 63.0000,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 785.4,                last time consumption/overall running time: 713.0904s / 108299.4726 s
env0_first_0:                 episode reward: -37.6500,                 loss: 1.6064
env0_second_0:                 episode reward: 37.6500,                 loss: 0.8832
env1_first_0:                 episode reward: -35.6000,                 loss: nan
env1_second_0:                 episode reward: 35.6000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 391.55,                last time consumption/overall running time: 354.8585s / 108654.3312 s
env0_first_0:                 episode reward: -36.1500,                 loss: 1.5452
env0_second_0:                 episode reward: 36.1500,                 loss: 0.7600
env1_first_0:                 episode reward: -53.8500,                 loss: nan
env1_second_0:                 episode reward: 53.8500,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 296.45,                last time consumption/overall running time: 269.3496s / 108923.6808 s
env0_first_0:                 episode reward: -71.5500,                 loss: 1.6575
env0_second_0:                 episode reward: 71.5500,                 loss: 0.7730
env1_first_0:                 episode reward: -46.0500,                 loss: nan
env1_second_0:                 episode reward: 46.0500,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 277.9,                last time consumption/overall running time: 252.5290s / 109176.2098 s
env0_first_0:                 episode reward: -60.9000,                 loss: 1.7728
env0_second_0:                 episode reward: 60.9000,                 loss: 0.7660
env1_first_0:                 episode reward: -46.7000,                 loss: nan
env1_second_0:                 episode reward: 46.7000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 276.2,                last time consumption/overall running time: 252.2733s / 109428.4831 s
env0_first_0:                 episode reward: -67.8500,                 loss: 1.9172
env0_second_0:                 episode reward: 67.8500,                 loss: 0.7870
env1_first_0:                 episode reward: -49.9000,                 loss: nan
env1_second_0:                 episode reward: 49.9000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 255.35,                last time consumption/overall running time: 232.6794s / 109661.1626 s
env0_first_0:                 episode reward: -23.6000,                 loss: 1.8755
env0_second_0:                 episode reward: 23.6000,                 loss: 0.8384
env1_first_0:                 episode reward: -36.7000,                 loss: nan
env1_second_0:                 episode reward: 36.7000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 249.85,                last time consumption/overall running time: 227.0362s / 109888.1987 s
env0_first_0:                 episode reward: -50.8500,                 loss: 1.8554
env0_second_0:                 episode reward: 50.8500,                 loss: 0.8860
env1_first_0:                 episode reward: -51.0000,                 loss: nan
env1_second_0:                 episode reward: 51.0000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 273.35,                last time consumption/overall running time: 248.6598s / 110136.8585 s
env0_first_0:                 episode reward: -57.0000,                 loss: 1.9957
env0_second_0:                 episode reward: 57.0000,                 loss: 0.9540
env1_first_0:                 episode reward: -65.7000,                 loss: nan
env1_second_0:                 episode reward: 65.7000,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 273.65,                last time consumption/overall running time: 248.8729s / 110385.7314 s
env0_first_0:                 episode reward: -48.6500,                 loss: 2.0652
env0_second_0:                 episode reward: 48.6500,                 loss: 1.0086
env1_first_0:                 episode reward: -58.5500,                 loss: nan
env1_second_0:                 episode reward: 58.5500,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 265.75,                last time consumption/overall running time: 241.9343s / 110627.6657 s
env0_first_0:                 episode reward: -35.1500,                 loss: 2.2088
env0_second_0:                 episode reward: 35.1500,                 loss: 1.0867
env1_first_0:                 episode reward: -19.7000,                 loss: nan
env1_second_0:                 episode reward: 19.7000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 380.75,                last time consumption/overall running time: 345.6148s / 110973.2804 s
env0_first_0:                 episode reward: -50.6500,                 loss: 2.2567
env0_second_0:                 episode reward: 50.6500,                 loss: 1.1691
env1_first_0:                 episode reward: -37.5000,                 loss: nan
env1_second_0:                 episode reward: 37.5000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 289.45,                last time consumption/overall running time: 262.9391s / 111236.2195 s
env0_first_0:                 episode reward: -58.2500,                 loss: 2.2363
env0_second_0:                 episode reward: 58.2500,                 loss: 1.1426
env1_first_0:                 episode reward: -54.9500,                 loss: nan
env1_second_0:                 episode reward: 54.9500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 295.65,                last time consumption/overall running time: 268.9486s / 111505.1682 s
env0_first_0:                 episode reward: -54.6000,                 loss: 2.3320
env0_second_0:                 episode reward: 54.6000,                 loss: 1.0847
env1_first_0:                 episode reward: -45.0500,                 loss: nan
env1_second_0:                 episode reward: 45.0500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 280.35,                last time consumption/overall running time: 254.8135s / 111759.9817 s
env0_first_0:                 episode reward: -52.9500,                 loss: 2.2722
env0_second_0:                 episode reward: 52.9500,                 loss: 1.0743
env1_first_0:                 episode reward: -49.7000,                 loss: nan
env1_second_0:                 episode reward: 49.7000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 364.9,                last time consumption/overall running time: 330.6982s / 112090.6799 s
env0_first_0:                 episode reward: -52.7000,                 loss: 2.3328
env0_second_0:                 episode reward: 52.7000,                 loss: 1.1817
env1_first_0:                 episode reward: -61.2500,                 loss: nan
env1_second_0:                 episode reward: 61.2500,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 351.75,                last time consumption/overall running time: 319.5250s / 112410.2049 s
env0_first_0:                 episode reward: -59.9500,                 loss: 2.2351
env0_second_0:                 episode reward: 59.9500,                 loss: 1.1893
env1_first_0:                 episode reward: -52.1500,                 loss: nan
env1_second_0:                 episode reward: 52.1500,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 341.8,                last time consumption/overall running time: 310.4009s / 112720.6058 s
env0_first_0:                 episode reward: -35.0500,                 loss: 2.2569
env0_second_0:                 episode reward: 35.0500,                 loss: 1.2236
env1_first_0:                 episode reward: -54.8000,                 loss: nan
env1_second_0:                 episode reward: 54.8000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 282.1,                last time consumption/overall running time: 257.2632s / 112977.8690 s
env0_first_0:                 episode reward: -50.0500,                 loss: 2.2958
env0_second_0:                 episode reward: 50.0500,                 loss: 1.2661
env1_first_0:                 episode reward: -74.0500,                 loss: nan
env1_second_0:                 episode reward: 74.0500,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 312.1,                last time consumption/overall running time: 283.3622s / 113261.2312 s
env0_first_0:                 episode reward: -48.6500,                 loss: 2.2882
env0_second_0:                 episode reward: 48.6500,                 loss: 1.2750
env1_first_0:                 episode reward: -63.6500,                 loss: nan
env1_second_0:                 episode reward: 63.6500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 299.7,                last time consumption/overall running time: 271.9390s / 113533.1703 s
env0_first_0:                 episode reward: -65.2500,                 loss: 2.4278
env0_second_0:                 episode reward: 65.2500,                 loss: 1.3437
env1_first_0:                 episode reward: -45.8000,                 loss: nan
env1_second_0:                 episode reward: 45.8000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 315.85,                last time consumption/overall running time: 285.5753s / 113818.7456 s
env0_first_0:                 episode reward: -28.7500,                 loss: 2.4845
env0_second_0:                 episode reward: 28.7500,                 loss: 1.4046
env1_first_0:                 episode reward: -16.4000,                 loss: nan
env1_second_0:                 episode reward: 16.4000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 297.75,                last time consumption/overall running time: 270.5179s / 114089.2635 s
env0_first_0:                 episode reward: -41.1000,                 loss: 2.4976
env0_second_0:                 episode reward: 41.1000,                 loss: 1.3859
env1_first_0:                 episode reward: -23.7500,                 loss: nan
env1_second_0:                 episode reward: 23.7500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 260.8,                last time consumption/overall running time: 237.3419s / 114326.6054 s
env0_first_0:                 episode reward: -41.1000,                 loss: 2.4445
env0_second_0:                 episode reward: 41.1000,                 loss: 1.3326
env1_first_0:                 episode reward: -72.8500,                 loss: nan
env1_second_0:                 episode reward: 72.8500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 268.0,                last time consumption/overall running time: 244.6014s / 114571.2069 s
env0_first_0:                 episode reward: -31.9000,                 loss: 2.3675
env0_second_0:                 episode reward: 31.9000,                 loss: 1.3568
env1_first_0:                 episode reward: -26.6000,                 loss: nan
env1_second_0:                 episode reward: 26.6000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 260.7,                last time consumption/overall running time: 237.5710s / 114808.7779 s
env0_first_0:                 episode reward: -40.9500,                 loss: 2.2864
env0_second_0:                 episode reward: 40.9500,                 loss: 1.2853
env1_first_0:                 episode reward: -51.9500,                 loss: nan
env1_second_0:                 episode reward: 51.9500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 282.05,                last time consumption/overall running time: 256.4299s / 115065.2078 s
env0_first_0:                 episode reward: -48.2000,                 loss: 2.2061
env0_second_0:                 episode reward: 48.2000,                 loss: 1.3459
env1_first_0:                 episode reward: -35.7500,                 loss: nan
env1_second_0:                 episode reward: 35.7500,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 298.65,                last time consumption/overall running time: 270.8258s / 115336.0336 s
env0_first_0:                 episode reward: -64.0500,                 loss: 2.2079
env0_second_0:                 episode reward: 64.0500,                 loss: 1.2797
env1_first_0:                 episode reward: -42.0500,                 loss: nan
env1_second_0:                 episode reward: 42.0500,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 252.55,                last time consumption/overall running time: 230.3922s / 115566.4258 s
env0_first_0:                 episode reward: -43.0000,                 loss: 2.1349
env0_second_0:                 episode reward: 43.0000,                 loss: 1.3030
env1_first_0:                 episode reward: -33.4500,                 loss: nan
env1_second_0:                 episode reward: 33.4500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 276.7,                last time consumption/overall running time: 252.6675s / 115819.0932 s
env0_first_0:                 episode reward: -38.5500,                 loss: 2.0276
env0_second_0:                 episode reward: 38.5500,                 loss: 1.2705
env1_first_0:                 episode reward: -28.8000,                 loss: nan
env1_second_0:                 episode reward: 28.8000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 272.35,                last time consumption/overall running time: 247.5399s / 116066.6332 s
env0_first_0:                 episode reward: -58.1500,                 loss: 2.0261
env0_second_0:                 episode reward: 58.1500,                 loss: 1.2922
env1_first_0:                 episode reward: -61.7500,                 loss: nan
env1_second_0:                 episode reward: 61.7500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 265.25,                last time consumption/overall running time: 240.9188s / 116307.5519 s
env0_first_0:                 episode reward: -83.9000,                 loss: 2.0322
env0_second_0:                 episode reward: 83.9000,                 loss: 1.2268
env1_first_0:                 episode reward: -81.1000,                 loss: nan
env1_second_0:                 episode reward: 81.1000,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 289.2,                last time consumption/overall running time: 262.8011s / 116570.3531 s
env0_first_0:                 episode reward: -41.8500,                 loss: 1.9773
env0_second_0:                 episode reward: 41.8500,                 loss: 1.1753
env1_first_0:                 episode reward: -48.1000,                 loss: nan
env1_second_0:                 episode reward: 48.1000,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 256.35,                last time consumption/overall running time: 233.6836s / 116804.0367 s
env0_first_0:                 episode reward: -50.4000,                 loss: 1.9873
env0_second_0:                 episode reward: 50.4000,                 loss: 1.1418
env1_first_0:                 episode reward: -81.5000,                 loss: nan
env1_second_0:                 episode reward: 81.5000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 284.1,                last time consumption/overall running time: 258.9276s / 117062.9643 s
env0_first_0:                 episode reward: -72.8500,                 loss: 1.9862
env0_second_0:                 episode reward: 72.8500,                 loss: 1.1687
env1_first_0:                 episode reward: -63.5000,                 loss: nan
env1_second_0:                 episode reward: 63.5000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 245.65,                last time consumption/overall running time: 222.8623s / 117285.8266 s
env0_first_0:                 episode reward: -80.4000,                 loss: 1.9362
env0_second_0:                 episode reward: 80.4000,                 loss: 1.1088
env1_first_0:                 episode reward: -81.1000,                 loss: nan
env1_second_0:                 episode reward: 81.1000,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 327.6,                last time consumption/overall running time: 297.7779s / 117583.6045 s
env0_first_0:                 episode reward: -76.5500,                 loss: 1.9065
env0_second_0:                 episode reward: 76.5500,                 loss: 1.0913
env1_first_0:                 episode reward: -51.5500,                 loss: nan
env1_second_0:                 episode reward: 51.5500,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 269.35,                last time consumption/overall running time: 243.9028s / 117827.5074 s
env0_first_0:                 episode reward: -84.3000,                 loss: 1.8168
env0_second_0:                 episode reward: 84.3000,                 loss: 1.0318
env1_first_0:                 episode reward: -83.8000,                 loss: nan
env1_second_0:                 episode reward: 83.8000,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 259.0,                last time consumption/overall running time: 235.0339s / 118062.5412 s
env0_first_0:                 episode reward: -44.8500,                 loss: 1.7287
env0_second_0:                 episode reward: 44.8500,                 loss: 0.9922
env1_first_0:                 episode reward: -66.1500,                 loss: nan
env1_second_0:                 episode reward: 66.1500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 257.95,                last time consumption/overall running time: 234.6526s / 118297.1938 s
env0_first_0:                 episode reward: -73.4500,                 loss: 1.6785
env0_second_0:                 episode reward: 73.4500,                 loss: 0.9775
env1_first_0:                 episode reward: -78.5500,                 loss: nan
env1_second_0:                 episode reward: 78.5500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 590.5,                last time consumption/overall running time: 536.9730s / 118834.1668 s
env0_first_0:                 episode reward: -29.4500,                 loss: 1.6113
env0_second_0:                 episode reward: 29.4500,                 loss: 0.8203
env1_first_0:                 episode reward: -49.3000,                 loss: nan
env1_second_0:                 episode reward: 49.3000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 510.55,                last time consumption/overall running time: 464.2597s / 119298.4265 s
env0_first_0:                 episode reward: -40.5500,                 loss: 1.5351
env0_second_0:                 episode reward: 40.5500,                 loss: 0.6484
env1_first_0:                 episode reward: -35.5500,                 loss: nan
env1_second_0:                 episode reward: 35.5500,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 287.4,                last time consumption/overall running time: 261.6290s / 119560.0556 s
env0_first_0:                 episode reward: -65.7000,                 loss: 1.4738
env0_second_0:                 episode reward: 65.7000,                 loss: 0.6432
env1_first_0:                 episode reward: -36.1000,                 loss: nan
env1_second_0:                 episode reward: 36.1000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 285.75,                last time consumption/overall running time: 259.9093s / 119819.9649 s
env0_first_0:                 episode reward: 1.7000,                 loss: 1.6123
env0_second_0:                 episode reward: -1.7000,                 loss: 0.7245
env1_first_0:                 episode reward: -37.2500,                 loss: nan
env1_second_0:                 episode reward: 37.2500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 302.4,                last time consumption/overall running time: 275.2222s / 120095.1870 s
env0_first_0:                 episode reward: -53.2500,                 loss: 1.6651
env0_second_0:                 episode reward: 53.2500,                 loss: 0.8098
env1_first_0:                 episode reward: -28.1500,                 loss: nan
env1_second_0:                 episode reward: 28.1500,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 295.8,                last time consumption/overall running time: 269.4657s / 120364.6527 s
env0_first_0:                 episode reward: -52.3000,                 loss: 1.8132
env0_second_0:                 episode reward: 52.3000,                 loss: 0.8700
env1_first_0:                 episode reward: -36.7500,                 loss: nan
env1_second_0:                 episode reward: 36.7500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 400.2,                last time consumption/overall running time: 363.8636s / 120728.5163 s
env0_first_0:                 episode reward: -37.9000,                 loss: 2.0602
env0_second_0:                 episode reward: 37.9000,                 loss: 0.9392
env1_first_0:                 episode reward: -55.1000,                 loss: nan
env1_second_0:                 episode reward: 55.1000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 692.1,                last time consumption/overall running time: 628.4935s / 121357.0098 s
env0_first_0:                 episode reward: -63.1000,                 loss: 2.0269
env0_second_0:                 episode reward: 63.1000,                 loss: 0.9413
env1_first_0:                 episode reward: -73.6500,                 loss: nan
env1_second_0:                 episode reward: 73.6500,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 698.35,                last time consumption/overall running time: 633.4998s / 121990.5095 s
env0_first_0:                 episode reward: -65.9000,                 loss: 1.7548
env0_second_0:                 episode reward: 65.9000,                 loss: 0.8089
env1_first_0:                 episode reward: -69.2500,                 loss: nan
env1_second_0:                 episode reward: 69.2500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 431.75,                last time consumption/overall running time: 391.5797s / 122382.0893 s
env0_first_0:                 episode reward: -50.0500,                 loss: 1.3699
env0_second_0:                 episode reward: 50.0500,                 loss: 0.6474
env1_first_0:                 episode reward: -63.1000,                 loss: nan
env1_second_0:                 episode reward: 63.1000,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 414.25,                last time consumption/overall running time: 375.8764s / 122757.9657 s
env0_first_0:                 episode reward: -60.7000,                 loss: 1.4213
env0_second_0:                 episode reward: 60.7000,                 loss: 0.5627
env1_first_0:                 episode reward: -60.0500,                 loss: nan
env1_second_0:                 episode reward: 60.0500,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 445.65,                last time consumption/overall running time: 406.2749s / 123164.2406 s
env0_first_0:                 episode reward: -65.0500,                 loss: 1.5346
env0_second_0:                 episode reward: 65.0500,                 loss: 0.5247
env1_first_0:                 episode reward: -62.8500,                 loss: nan
env1_second_0:                 episode reward: 62.8500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 507.05,                last time consumption/overall running time: 460.2280s / 123624.4686 s
env0_first_0:                 episode reward: -46.8000,                 loss: 1.7210
env0_second_0:                 episode reward: 46.8000,                 loss: 0.5550
env1_first_0:                 episode reward: -54.6500,                 loss: nan
env1_second_0:                 episode reward: 54.6500,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 309.45,                last time consumption/overall running time: 281.9031s / 123906.3717 s
env0_first_0:                 episode reward: -62.1500,                 loss: 1.8587
env0_second_0:                 episode reward: 62.1500,                 loss: 0.6762
env1_first_0:                 episode reward: -70.6500,                 loss: nan
env1_second_0:                 episode reward: 70.6500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 301.6,                last time consumption/overall running time: 274.0049s / 124180.3766 s
env0_first_0:                 episode reward: -65.6000,                 loss: 2.1794
env0_second_0:                 episode reward: 65.6000,                 loss: 0.7994
env1_first_0:                 episode reward: -58.7500,                 loss: nan
env1_second_0:                 episode reward: 58.7500,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 270.3,                last time consumption/overall running time: 245.4082s / 124425.7848 s
env0_first_0:                 episode reward: -62.0500,                 loss: 2.4392
env0_second_0:                 episode reward: 62.0500,                 loss: 0.8512
env1_first_0:                 episode reward: -69.8000,                 loss: nan
env1_second_0:                 episode reward: 69.8000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 289.95,                last time consumption/overall running time: 262.9775s / 124688.7623 s
env0_first_0:                 episode reward: -58.5500,                 loss: 2.4331
env0_second_0:                 episode reward: 58.5500,                 loss: 0.8866
env1_first_0:                 episode reward: -53.4000,                 loss: nan
env1_second_0:                 episode reward: 53.4000,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 240.75,                last time consumption/overall running time: 218.3852s / 124907.1475 s
env0_first_0:                 episode reward: -75.4500,                 loss: 2.3344
env0_second_0:                 episode reward: 75.4500,                 loss: 0.8691
env1_first_0:                 episode reward: -54.9500,                 loss: nan
env1_second_0:                 episode reward: 54.9500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 259.8,                last time consumption/overall running time: 235.3548s / 125142.5022 s
env0_first_0:                 episode reward: -78.4000,                 loss: 2.2471
env0_second_0:                 episode reward: 78.4000,                 loss: 0.8385
env1_first_0:                 episode reward: -77.5500,                 loss: nan
env1_second_0:                 episode reward: 77.5500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 277.3,                last time consumption/overall running time: 251.4529s / 125393.9552 s
env0_first_0:                 episode reward: -72.3500,                 loss: 2.3190
env0_second_0:                 episode reward: 72.3500,                 loss: 0.7935
env1_first_0:                 episode reward: -61.3500,                 loss: nan
env1_second_0:                 episode reward: 61.3500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 383.8,                last time consumption/overall running time: 347.9406s / 125741.8957 s
env0_first_0:                 episode reward: -56.2000,                 loss: 2.2554
env0_second_0:                 episode reward: 56.2000,                 loss: 0.8285
env1_first_0:                 episode reward: -55.2500,                 loss: nan
env1_second_0:                 episode reward: 55.2500,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 265.1,                last time consumption/overall running time: 240.1944s / 125982.0901 s
env0_first_0:                 episode reward: -64.6000,                 loss: 1.9130
env0_second_0:                 episode reward: 64.6000,                 loss: 0.8128
env1_first_0:                 episode reward: -69.8500,                 loss: nan
env1_second_0:                 episode reward: 69.8500,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 280.9,                last time consumption/overall running time: 254.7117s / 126236.8018 s
env0_first_0:                 episode reward: -43.3000,                 loss: 1.7191
env0_second_0:                 episode reward: 43.3000,                 loss: 0.7879
env1_first_0:                 episode reward: -54.2500,                 loss: nan
env1_second_0:                 episode reward: 54.2500,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 372.7,                last time consumption/overall running time: 337.8625s / 126574.6644 s
env0_first_0:                 episode reward: -39.2500,                 loss: 1.6592
env0_second_0:                 episode reward: 39.2500,                 loss: 0.7802
env1_first_0:                 episode reward: -41.2500,                 loss: nan
env1_second_0:                 episode reward: 41.2500,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 300.7,                last time consumption/overall running time: 273.6573s / 126848.3217 s
env0_first_0:                 episode reward: -54.1000,                 loss: 1.6211
env0_second_0:                 episode reward: 54.1000,                 loss: 0.8013
env1_first_0:                 episode reward: -50.8000,                 loss: nan
env1_second_0:                 episode reward: 50.8000,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 249.8,                last time consumption/overall running time: 227.2485s / 127075.5701 s
env0_first_0:                 episode reward: -76.8500,                 loss: 1.6375
env0_second_0:                 episode reward: 76.8500,                 loss: 0.8312
env1_first_0:                 episode reward: -66.1500,                 loss: nan
env1_second_0:                 episode reward: 66.1500,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 351.5,                last time consumption/overall running time: 319.6911s / 127395.2612 s
env0_first_0:                 episode reward: -61.9000,                 loss: 1.5910
env0_second_0:                 episode reward: 61.9000,                 loss: 0.8231
env1_first_0:                 episode reward: -52.6500,                 loss: nan
env1_second_0:                 episode reward: 52.6500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 260.25,                last time consumption/overall running time: 236.7655s / 127632.0267 s
env0_first_0:                 episode reward: -42.1000,                 loss: 1.4756
env0_second_0:                 episode reward: 42.1000,                 loss: 0.8583
env1_first_0:                 episode reward: -55.6500,                 loss: nan
env1_second_0:                 episode reward: 55.6500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 272.35,                last time consumption/overall running time: 247.6027s / 127879.6294 s
env0_first_0:                 episode reward: -61.9000,                 loss: 1.3914
env0_second_0:                 episode reward: 61.9000,                 loss: 0.8455
env1_first_0:                 episode reward: -57.3000,                 loss: nan
env1_second_0:                 episode reward: 57.3000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 269.75,                last time consumption/overall running time: 245.0457s / 128124.6751 s
env0_first_0:                 episode reward: -43.2500,                 loss: 1.5223
env0_second_0:                 episode reward: 43.2500,                 loss: 0.8672
env1_first_0:                 episode reward: -18.4000,                 loss: nan
env1_second_0:                 episode reward: 18.4000,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 266.65,                last time consumption/overall running time: 242.1762s / 128366.8513 s
env0_first_0:                 episode reward: -52.4000,                 loss: 1.6736
env0_second_0:                 episode reward: 52.4000,                 loss: 0.9237
env1_first_0:                 episode reward: -52.8000,                 loss: nan
env1_second_0:                 episode reward: 52.8000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 247.55,                last time consumption/overall running time: 225.1573s / 128592.0086 s
env0_first_0:                 episode reward: -69.3500,                 loss: 1.5953
env0_second_0:                 episode reward: 69.3500,                 loss: 0.9037
env1_first_0:                 episode reward: -59.4500,                 loss: nan
env1_second_0:                 episode reward: 59.4500,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 284.05,                last time consumption/overall running time: 257.7201s / 128849.7287 s
env0_first_0:                 episode reward: -61.5000,                 loss: 1.5748
env0_second_0:                 episode reward: 61.5000,                 loss: 0.8764
env1_first_0:                 episode reward: -78.7000,                 loss: nan
env1_second_0:                 episode reward: 78.7000,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 271.95,                last time consumption/overall running time: 247.1445s / 129096.8732 s
env0_first_0:                 episode reward: -66.2500,                 loss: 1.3814
env0_second_0:                 episode reward: 66.2500,                 loss: 0.8902
env1_first_0:                 episode reward: -74.6000,                 loss: nan
env1_second_0:                 episode reward: 74.6000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 381.85,                last time consumption/overall running time: 346.8507s / 129443.7239 s
env0_first_0:                 episode reward: -61.5500,                 loss: 1.3837
env0_second_0:                 episode reward: 61.5500,                 loss: 0.8256
env1_first_0:                 episode reward: -72.8500,                 loss: nan
env1_second_0:                 episode reward: 72.8500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 275.85,                last time consumption/overall running time: 250.6847s / 129694.4086 s
env0_first_0:                 episode reward: -72.7000,                 loss: 1.3463
env0_second_0:                 episode reward: 72.7000,                 loss: 0.7861
env1_first_0:                 episode reward: -81.4500,                 loss: nan
env1_second_0:                 episode reward: 81.4500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 249.85,                last time consumption/overall running time: 226.8122s / 129921.2208 s
env0_first_0:                 episode reward: -72.0000,                 loss: 1.4435
env0_second_0:                 episode reward: 72.0000,                 loss: 0.8382
env1_first_0:                 episode reward: -84.7500,                 loss: nan
env1_second_0:                 episode reward: 84.7500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 271.45,                last time consumption/overall running time: 246.4540s / 130167.6748 s
env0_first_0:                 episode reward: -82.8000,                 loss: 1.4329
env0_second_0:                 episode reward: 82.8000,                 loss: 0.8072
env1_first_0:                 episode reward: -87.3000,                 loss: nan
env1_second_0:                 episode reward: 87.3000,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 331.65,                last time consumption/overall running time: 300.3167s / 130467.9915 s
env0_first_0:                 episode reward: -82.5500,                 loss: 1.4415
env0_second_0:                 episode reward: 82.5500,                 loss: 0.7680
env1_first_0:                 episode reward: -74.1000,                 loss: nan
env1_second_0:                 episode reward: 74.1000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 360.45,                last time consumption/overall running time: 326.6636s / 130794.6551 s
env0_first_0:                 episode reward: -72.0500,                 loss: 1.3556
env0_second_0:                 episode reward: 72.0500,                 loss: 0.6768
env1_first_0:                 episode reward: -69.0500,                 loss: nan
env1_second_0:                 episode reward: 69.0500,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 474.65,                last time consumption/overall running time: 430.3163s / 131224.9714 s
env0_first_0:                 episode reward: -17.3500,                 loss: 1.4257
env0_second_0:                 episode reward: 17.3500,                 loss: 0.6589
env1_first_0:                 episode reward: -45.9000,                 loss: nan
env1_second_0:                 episode reward: 45.9000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 273.35,                last time consumption/overall running time: 248.9628s / 131473.9341 s
env0_first_0:                 episode reward: -71.6500,                 loss: 1.5025
env0_second_0:                 episode reward: 71.6500,                 loss: 0.7544
env1_first_0:                 episode reward: -80.0000,                 loss: nan
env1_second_0:                 episode reward: 80.0000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 264.35,                last time consumption/overall running time: 240.9270s / 131714.8611 s
env0_first_0:                 episode reward: -77.4500,                 loss: 1.7164
env0_second_0:                 episode reward: 77.4500,                 loss: 0.7814
env1_first_0:                 episode reward: -67.6000,                 loss: nan
env1_second_0:                 episode reward: 67.6000,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 269.45,                last time consumption/overall running time: 244.7580s / 131959.6191 s
env0_first_0:                 episode reward: -69.8000,                 loss: 1.8096
env0_second_0:                 episode reward: 69.8000,                 loss: 0.8564
env1_first_0:                 episode reward: -69.6500,                 loss: nan
env1_second_0:                 episode reward: 69.6500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 302.55,                last time consumption/overall running time: 274.0091s / 132233.6282 s
env0_first_0:                 episode reward: -73.8000,                 loss: 1.7608
env0_second_0:                 episode reward: 73.8000,                 loss: 0.8390
env1_first_0:                 episode reward: -73.6000,                 loss: nan
env1_second_0:                 episode reward: 73.6000,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 427.35,                last time consumption/overall running time: 386.6090s / 132620.2372 s
env0_first_0:                 episode reward: -55.0000,                 loss: 1.6823
env0_second_0:                 episode reward: 55.0000,                 loss: 0.8127
env1_first_0:                 episode reward: -49.2500,                 loss: nan
env1_second_0:                 episode reward: 49.2500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 357.55,                last time consumption/overall running time: 324.0575s / 132944.2946 s
env0_first_0:                 episode reward: -31.0500,                 loss: 1.7858
env0_second_0:                 episode reward: 31.0500,                 loss: 0.8550
env1_first_0:                 episode reward: -51.7500,                 loss: nan
env1_second_0:                 episode reward: 51.7500,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 300.75,                last time consumption/overall running time: 271.5381s / 133215.8327 s
env0_first_0:                 episode reward: -41.0000,                 loss: 1.8824
env0_second_0:                 episode reward: 41.0000,                 loss: 0.9816
env1_first_0:                 episode reward: -49.3000,                 loss: nan
env1_second_0:                 episode reward: 49.3000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 296.65,                last time consumption/overall running time: 269.2298s / 133485.0625 s
env0_first_0:                 episode reward: -52.5500,                 loss: 1.9838
env0_second_0:                 episode reward: 52.5500,                 loss: 1.0893
env1_first_0:                 episode reward: -40.6500,                 loss: nan
env1_second_0:                 episode reward: 40.6500,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 255.85,                last time consumption/overall running time: 231.3829s / 133716.4454 s
env0_first_0:                 episode reward: -56.4500,                 loss: 1.8970
env0_second_0:                 episode reward: 56.4500,                 loss: 1.0150
env1_first_0:                 episode reward: -53.1000,                 loss: nan
env1_second_0:                 episode reward: 53.1000,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 264.0,                last time consumption/overall running time: 240.0288s / 133956.4743 s
env0_first_0:                 episode reward: -81.2000,                 loss: 1.8476
env0_second_0:                 episode reward: 81.2000,                 loss: 1.0638
env1_first_0:                 episode reward: -55.6000,                 loss: nan
env1_second_0:                 episode reward: 55.6000,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 281.35,                last time consumption/overall running time: 256.1021s / 134212.5764 s
env0_first_0:                 episode reward: -69.7500,                 loss: 1.8288
env0_second_0:                 episode reward: 69.7500,                 loss: 1.0131
env1_first_0:                 episode reward: -36.1500,                 loss: nan
env1_second_0:                 episode reward: 36.1500,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 260.55,                last time consumption/overall running time: 237.2078s / 134449.7842 s
env0_first_0:                 episode reward: -83.8000,                 loss: 1.9005
env0_second_0:                 episode reward: 83.8000,                 loss: 1.0355
env1_first_0:                 episode reward: -69.7000,                 loss: nan
env1_second_0:                 episode reward: 69.7000,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 291.55,                last time consumption/overall running time: 264.7262s / 134714.5104 s
env0_first_0:                 episode reward: -63.1500,                 loss: 1.8576
env0_second_0:                 episode reward: 63.1500,                 loss: 1.0242
env1_first_0:                 episode reward: -62.8000,                 loss: nan
env1_second_0:                 episode reward: 62.8000,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 264.1,                last time consumption/overall running time: 240.5240s / 134955.0345 s
env0_first_0:                 episode reward: -73.0500,                 loss: 1.9255
env0_second_0:                 episode reward: 73.0500,                 loss: 1.0621
env1_first_0:                 episode reward: -72.2000,                 loss: nan
env1_second_0:                 episode reward: 72.2000,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 311.1,                last time consumption/overall running time: 282.2097s / 135237.2441 s
env0_first_0:                 episode reward: -59.1500,                 loss: 1.8093
env0_second_0:                 episode reward: 59.1500,                 loss: 1.0263
env1_first_0:                 episode reward: -64.6000,                 loss: nan
env1_second_0:                 episode reward: 64.6000,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 327.6,                last time consumption/overall running time: 297.4821s / 135534.7262 s
env0_first_0:                 episode reward: -73.4500,                 loss: 1.7803
env0_second_0:                 episode reward: 73.4500,                 loss: 0.9184
env1_first_0:                 episode reward: -82.9000,                 loss: nan
env1_second_0:                 episode reward: 82.9000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 325.55,                last time consumption/overall running time: 295.8907s / 135830.6169 s
env0_first_0:                 episode reward: -51.0000,                 loss: 1.7876
env0_second_0:                 episode reward: 51.0000,                 loss: 0.9401
env1_first_0:                 episode reward: -65.4000,                 loss: nan
env1_second_0:                 episode reward: 65.4000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 264.85,                last time consumption/overall running time: 240.6313s / 136071.2481 s
env0_first_0:                 episode reward: -64.0500,                 loss: 1.8683
env0_second_0:                 episode reward: 64.0500,                 loss: 1.0370
env1_first_0:                 episode reward: -51.8500,                 loss: nan
env1_second_0:                 episode reward: 51.8500,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 350.3,                last time consumption/overall running time: 318.0284s / 136389.2766 s
env0_first_0:                 episode reward: -75.3000,                 loss: 1.7603
env0_second_0:                 episode reward: 75.3000,                 loss: 0.9406
env1_first_0:                 episode reward: -60.0500,                 loss: nan
env1_second_0:                 episode reward: 60.0500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 456.9,                last time consumption/overall running time: 414.0507s / 136803.3273 s
env0_first_0:                 episode reward: -72.3000,                 loss: 1.6683
env0_second_0:                 episode reward: 72.3000,                 loss: 0.9008
env1_first_0:                 episode reward: -50.1500,                 loss: nan
env1_second_0:                 episode reward: 50.1500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 343.85,                last time consumption/overall running time: 312.2702s / 137115.5975 s
env0_first_0:                 episode reward: -64.2500,                 loss: 1.8457
env0_second_0:                 episode reward: 64.2500,                 loss: 0.8880
env1_first_0:                 episode reward: -49.2500,                 loss: nan
env1_second_0:                 episode reward: 49.2500,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 279.6,                last time consumption/overall running time: 254.2530s / 137369.8505 s
env0_first_0:                 episode reward: -59.8500,                 loss: 1.9165
env0_second_0:                 episode reward: 59.8500,                 loss: 0.9471
env1_first_0:                 episode reward: -60.5500,                 loss: nan
env1_second_0:                 episode reward: 60.5500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 274.6,                last time consumption/overall running time: 249.9256s / 137619.7761 s
env0_first_0:                 episode reward: -44.7500,                 loss: 2.1334
env0_second_0:                 episode reward: 44.7500,                 loss: 0.9723
env1_first_0:                 episode reward: -67.0000,                 loss: nan
env1_second_0:                 episode reward: 67.0000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 302.85,                last time consumption/overall running time: 275.2650s / 137895.0411 s
env0_first_0:                 episode reward: -46.6500,                 loss: 2.0174
env0_second_0:                 episode reward: 46.6500,                 loss: 1.0044
env1_first_0:                 episode reward: -26.0000,                 loss: nan
env1_second_0:                 episode reward: 26.0000,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 235.6,                last time consumption/overall running time: 214.4071s / 138109.4482 s
env0_first_0:                 episode reward: -32.8000,                 loss: 1.9151
env0_second_0:                 episode reward: 32.8000,                 loss: 0.9489
env1_first_0:                 episode reward: -52.7000,                 loss: nan
env1_second_0:                 episode reward: 52.7000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 262.05,                last time consumption/overall running time: 238.4795s / 138347.9277 s
env0_first_0:                 episode reward: -49.0000,                 loss: 1.8235
env0_second_0:                 episode reward: 49.0000,                 loss: 0.8946
env1_first_0:                 episode reward: -61.0500,                 loss: nan
env1_second_0:                 episode reward: 61.0500,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 275.35,                last time consumption/overall running time: 250.1627s / 138598.0904 s
env0_first_0:                 episode reward: -19.1000,                 loss: 1.9062
env0_second_0:                 episode reward: 19.1000,                 loss: 0.9193
env1_first_0:                 episode reward: -44.4000,                 loss: nan
env1_second_0:                 episode reward: 44.4000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 290.45,                last time consumption/overall running time: 263.7630s / 138861.8535 s
env0_first_0:                 episode reward: -54.9000,                 loss: 1.9188
env0_second_0:                 episode reward: 54.9000,                 loss: 1.0332
env1_first_0:                 episode reward: -50.2000,                 loss: nan
env1_second_0:                 episode reward: 50.2000,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 376.3,                last time consumption/overall running time: 341.3221s / 139203.1755 s
env0_first_0:                 episode reward: -50.2000,                 loss: 1.9077
env0_second_0:                 episode reward: 50.2000,                 loss: 1.0861
env1_first_0:                 episode reward: -54.4000,                 loss: nan
env1_second_0:                 episode reward: 54.4000,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 270.6,                last time consumption/overall running time: 245.9340s / 139449.1096 s
env0_first_0:                 episode reward: -47.3000,                 loss: 1.7228
env0_second_0:                 episode reward: 47.3000,                 loss: 1.1018
env1_first_0:                 episode reward: -29.7500,                 loss: nan
env1_second_0:                 episode reward: 29.7500,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 457.7,                last time consumption/overall running time: 415.7026s / 139864.8122 s
env0_first_0:                 episode reward: -44.1500,                 loss: 1.4949
env0_second_0:                 episode reward: 44.1500,                 loss: 0.9896
env1_first_0:                 episode reward: -38.9500,                 loss: nan
env1_second_0:                 episode reward: 38.9500,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 267.1,                last time consumption/overall running time: 242.1834s / 140106.9956 s
env0_first_0:                 episode reward: -44.8000,                 loss: 1.5005
env0_second_0:                 episode reward: 44.8000,                 loss: 1.0035
env1_first_0:                 episode reward: -34.7500,                 loss: nan
env1_second_0:                 episode reward: 34.7500,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 292.8,                last time consumption/overall running time: 265.6591s / 140372.6547 s
env0_first_0:                 episode reward: -39.7500,                 loss: 1.5410
env0_second_0:                 episode reward: 39.7500,                 loss: 1.0401
env1_first_0:                 episode reward: -68.0000,                 loss: nan
env1_second_0:                 episode reward: 68.0000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 271.5,                last time consumption/overall running time: 246.4979s / 140619.1526 s
env0_first_0:                 episode reward: -68.5500,                 loss: 1.5892
env0_second_0:                 episode reward: 68.5500,                 loss: 1.0889
env1_first_0:                 episode reward: -69.0000,                 loss: nan
env1_second_0:                 episode reward: 69.0000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 239.2,                last time consumption/overall running time: 218.8088s / 140837.9615 s
env0_first_0:                 episode reward: -79.2500,                 loss: 1.5803
env0_second_0:                 episode reward: 79.2500,                 loss: 1.0597
env1_first_0:                 episode reward: -77.2000,                 loss: nan
env1_second_0:                 episode reward: 77.2000,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 258.45,                last time consumption/overall running time: 235.4278s / 141073.3893 s
env0_first_0:                 episode reward: -58.5000,                 loss: 1.6680
env0_second_0:                 episode reward: 58.5000,                 loss: 0.9858
env1_first_0:                 episode reward: -58.9500,                 loss: nan
env1_second_0:                 episode reward: 58.9500,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 256.35,                last time consumption/overall running time: 232.9826s / 141306.3719 s
env0_first_0:                 episode reward: -57.3000,                 loss: 1.6476
env0_second_0:                 episode reward: 57.3000,                 loss: 0.9915
env1_first_0:                 episode reward: -50.4500,                 loss: nan
env1_second_0:                 episode reward: 50.4500,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 272.55,                last time consumption/overall running time: 247.3516s / 141553.7235 s
env0_first_0:                 episode reward: -45.2500,                 loss: 1.6919
env0_second_0:                 episode reward: 45.2500,                 loss: 1.0153
env1_first_0:                 episode reward: -44.0500,                 loss: nan
env1_second_0:                 episode reward: 44.0500,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 251.5,                last time consumption/overall running time: 228.1538s / 141781.8772 s
env0_first_0:                 episode reward: -66.2000,                 loss: 1.7942
env0_second_0:                 episode reward: 66.2000,                 loss: 1.0790
env1_first_0:                 episode reward: -76.7500,                 loss: nan
env1_second_0:                 episode reward: 76.7500,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 258.15,                last time consumption/overall running time: 234.8731s / 142016.7503 s
env0_first_0:                 episode reward: -52.5500,                 loss: 1.7692
env0_second_0:                 episode reward: 52.5500,                 loss: 1.0534
env1_first_0:                 episode reward: -74.1500,                 loss: nan
env1_second_0:                 episode reward: 74.1500,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 275.45,                last time consumption/overall running time: 249.6202s / 142266.3705 s
env0_first_0:                 episode reward: -22.5500,                 loss: 1.7673
env0_second_0:                 episode reward: 22.5500,                 loss: 1.0750
env1_first_0:                 episode reward: -50.7500,                 loss: nan
env1_second_0:                 episode reward: 50.7500,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 287.95,                last time consumption/overall running time: 262.2311s / 142528.6016 sLoad boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
/home/zihan/research/MARS/mars/rollout.py:21: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rollout_normal(env, model, save_id, args)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/shape_base.py:420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arrays = [asanyarray(arr) for arr in arrays]
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: -58.5500,                 loss: 1.8583
env0_second_0:                 episode reward: 58.5500,                 loss: 1.1440
env1_first_0:                 episode reward: -40.7000,                 loss: nan
env1_second_0:                 episode reward: 40.7000,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 252.1,                last time consumption/overall running time: 228.8607s / 142757.4624 s
env0_first_0:                 episode reward: -63.5000,                 loss: 1.6946
env0_second_0:                 episode reward: 63.5000,                 loss: 1.1651
env1_first_0:                 episode reward: -71.4500,                 loss: nan
env1_second_0:                 episode reward: 71.4500,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 255.45,                last time consumption/overall running time: 232.1172s / 142989.5796 s
env0_first_0:                 episode reward: -54.4500,                 loss: 1.6714
env0_second_0:                 episode reward: 54.4500,                 loss: 1.1221
env1_first_0:                 episode reward: -68.5500,                 loss: nan
env1_second_0:                 episode reward: 68.5500,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 278.1,                last time consumption/overall running time: 253.2887s / 143242.8683 s
env0_first_0:                 episode reward: -63.8500,                 loss: 1.8630
env0_second_0:                 episode reward: 63.8500,                 loss: 1.1749
env1_first_0:                 episode reward: -44.3000,                 loss: nan
env1_second_0:                 episode reward: 44.3000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 310.15,                last time consumption/overall running time: 281.5069s / 143524.3752 s
env0_first_0:                 episode reward: -14.8000,                 loss: 1.8601
env0_second_0:                 episode reward: 14.8000,                 loss: 1.1728
env1_first_0:                 episode reward: -40.1500,                 loss: nan
env1_second_0:                 episode reward: 40.1500,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 339.45,                last time consumption/overall running time: 308.6507s / 143833.0259 s
env0_first_0:                 episode reward: -59.9500,                 loss: 1.9811
env0_second_0:                 episode reward: 59.9500,                 loss: 1.1718
env1_first_0:                 episode reward: -72.5500,                 loss: nan
env1_second_0:                 episode reward: 72.5500,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 251.35,                last time consumption/overall running time: 228.7528s / 144061.7787 s
env0_first_0:                 episode reward: -55.6000,                 loss: 1.9328
env0_second_0:                 episode reward: 55.6000,                 loss: 1.1323
env1_first_0:                 episode reward: -41.2000,                 loss: nan
env1_second_0:                 episode reward: 41.2000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 276.35,                last time consumption/overall running time: 240.0489s / 144301.8276 s
env0_first_0:                 episode reward: -46.2500,                 loss: 1.9312
env0_second_0:                 episode reward: 46.2500,                 loss: 1.0665
env1_first_0:                 episode reward: -25.9000,                 loss: nan
env1_second_0:                 episode reward: 25.9000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 280.15,                last time consumption/overall running time: 241.7579s / 144543.5855 s
env0_first_0:                 episode reward: -61.9500,                 loss: 1.9279
env0_second_0:                 episode reward: 61.9500,                 loss: 1.1267
env1_first_0:                 episode reward: -64.2000,                 loss: nan
env1_second_0:                 episode reward: 64.2000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 320.8,                last time consumption/overall running time: 277.0203s / 144820.6059 s
env0_first_0:                 episode reward: -39.5000,                 loss: 1.9517
env0_second_0:                 episode reward: 39.5000,                 loss: 1.1391
env1_first_0:                 episode reward: -34.2500,                 loss: nan
env1_second_0:                 episode reward: 34.2500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 249.5,                last time consumption/overall running time: 215.9966s / 145036.6025 s
env0_first_0:                 episode reward: -56.5000,                 loss: 1.8855
env0_second_0:                 episode reward: 56.5000,                 loss: 1.1485
env1_first_0:                 episode reward: -79.9000,                 loss: nan
env1_second_0:                 episode reward: 79.9000,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 256.05,                last time consumption/overall running time: 221.4352s / 145258.0377 s
env0_first_0:                 episode reward: -67.2500,                 loss: 2.0068
env0_second_0:                 episode reward: 67.2500,                 loss: 1.1866
env1_first_0:                 episode reward: -76.1500,                 loss: nan
env1_second_0:                 episode reward: 76.1500,                 loss: nan
