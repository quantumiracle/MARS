pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fdda581ac50>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518033032/mdp_arbitrary_mdp_nfsp/10000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518033032/mdp_arbitrary_mdp_nfsp/10000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518033032_exploit_10000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518033032_exploit_10000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6818s / 0.6818 s
agent0:                 episode reward: -1.2083,                 loss: nan
agent1:                 episode reward: 1.2083,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2051s / 0.8869 s
agent0:                 episode reward: -0.0123,                 loss: nan
agent1:                 episode reward: 0.0123,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 1.0859 s
agent0:                 episode reward: 0.1490,                 loss: nan
agent1:                 episode reward: -0.1490,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 1.2884 s
agent0:                 episode reward: 0.3227,                 loss: nan
agent1:                 episode reward: -0.3227,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 1.4881 s
agent0:                 episode reward: 0.2189,                 loss: nan
agent1:                 episode reward: -0.2189,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 1.6869 s
agent0:                 episode reward: -0.0734,                 loss: nan
agent1:                 episode reward: 0.0734,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2028s / 1.8897 s
agent0:                 episode reward: 0.0411,                 loss: nan
agent1:                 episode reward: -0.0411,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 2.0896 s
agent0:                 episode reward: 0.3751,                 loss: nan
agent1:                 episode reward: -0.3751,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1956s / 2.2851 s
agent0:                 episode reward: 0.5353,                 loss: nan
agent1:                 episode reward: -0.5353,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 2.4839 s
agent0:                 episode reward: -0.1466,                 loss: nan
agent1:                 episode reward: 0.1466,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1926s / 2.6766 s
agent0:                 episode reward: 0.2395,                 loss: nan
agent1:                 episode reward: -0.2395,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1883s / 2.8648 s
agent0:                 episode reward: 0.3167,                 loss: nan
agent1:                 episode reward: -0.3167,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 3.0659 s
agent0:                 episode reward: -0.4287,                 loss: nan
agent1:                 episode reward: 0.4287,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 3.2618 s
agent0:                 episode reward: 0.1377,                 loss: nan
agent1:                 episode reward: -0.1377,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1933s / 3.4550 s
agent0:                 episode reward: -0.1980,                 loss: nan
agent1:                 episode reward: 0.1980,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 3.6551 s
agent0:                 episode reward: -0.1804,                 loss: nan
agent1:                 episode reward: 0.1804,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 3.8509 s
agent0:                 episode reward: 0.2639,                 loss: nan
agent1:                 episode reward: -0.2639,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 4.0473 s
agent0:                 episode reward: 0.2001,                 loss: nan
agent1:                 episode reward: -0.2001,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 4.2481 s
agent0:                 episode reward: 0.2932,                 loss: nan
agent1:                 episode reward: -0.2932,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 4.4478 s
agent0:                 episode reward: 0.4071,                 loss: nan
agent1:                 episode reward: -0.4071,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 4.6470 s
agent0:                 episode reward: -0.0613,                 loss: nan
agent1:                 episode reward: 0.0613,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 4.8462 s
agent0:                 episode reward: -0.0225,                 loss: nan
agent1:                 episode reward: 0.0225,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 5.0434 s
agent0:                 episode reward: 0.1917,                 loss: nan
agent1:                 episode reward: -0.1917,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 5.2423 s
agent0:                 episode reward: -0.2104,                 loss: nan
agent1:                 episode reward: 0.2104,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 5.4409 s
agent0:                 episode reward: 0.1686,                 loss: nan
agent1:                 episode reward: -0.1686,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 5.6392 s
agent0:                 episode reward: -0.1431,                 loss: nan
agent1:                 episode reward: 0.1431,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 5.8396 s
agent0:                 episode reward: 0.0711,                 loss: nan
agent1:                 episode reward: -0.0711,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 6.0413 s
agent0:                 episode reward: 0.2982,                 loss: nan
agent1:                 episode reward: -0.2982,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 6.2372 s
agent0:                 episode reward: -0.0164,                 loss: nan
agent1:                 episode reward: 0.0164,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 6.4330 s
agent0:                 episode reward: 0.1239,                 loss: nan
agent1:                 episode reward: -0.1239,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 6.6292 s
agent0:                 episode reward: 0.2904,                 loss: nan
agent1:                 episode reward: -0.2904,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 6.8240 s
agent0:                 episode reward: -0.0350,                 loss: nan
agent1:                 episode reward: 0.0350,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 7.0262 s
agent0:                 episode reward: 0.2863,                 loss: nan
agent1:                 episode reward: -0.2863,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 7.2240 s
agent0:                 episode reward: 0.2256,                 loss: nan
agent1:                 episode reward: -0.2256,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 7.4204 s
agent0:                 episode reward: 0.2175,                 loss: nan
agent1:                 episode reward: -0.2175,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 7.6195 s
agent0:                 episode reward: -0.3859,                 loss: nan
agent1:                 episode reward: 0.3859,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2048s / 7.8243 s
agent0:                 episode reward: 0.1922,                 loss: nan
agent1:                 episode reward: -0.1922,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 8.0264 s
agent0:                 episode reward: -0.1314,                 loss: nan
agent1:                 episode reward: 0.1314,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 8.2290 s
agent0:                 episode reward: 0.0182,                 loss: nan
agent1:                 episode reward: -0.0182,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 8.4285 s
agent0:                 episode reward: 0.1471,                 loss: nan
agent1:                 episode reward: -0.1471,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 8.6232 s
agent0:                 episode reward: 0.1695,                 loss: nan
agent1:                 episode reward: -0.1695,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 8.8232 s
agent0:                 episode reward: 0.1041,                 loss: nan
agent1:                 episode reward: -0.1041,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 9.0185 s
agent0:                 episode reward: 0.1262,                 loss: nan
agent1:                 episode reward: -0.1262,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 9.2180 s
agent0:                 episode reward: 0.1950,                 loss: nan
agent1:                 episode reward: -0.1950,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 9.4151 s
agent0:                 episode reward: 0.0845,                 loss: nan
agent1:                 episode reward: -0.0845,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 9.6118 s
agent0:                 episode reward: 0.2440,                 loss: nan
agent1:                 episode reward: -0.2440,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 9.8107 s
agent0:                 episode reward: -0.3225,                 loss: nan
agent1:                 episode reward: 0.3225,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2020s / 10.0127 s
agent0:                 episode reward: 0.4368,                 loss: nan
agent1:                 episode reward: -0.4368,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 10.2104 s
agent0:                 episode reward: -0.4345,                 loss: nan
agent1:                 episode reward: 0.4345,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 10.4063 s
agent0:                 episode reward: 0.0016,                 loss: nan
agent1:                 episode reward: -0.0016,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 10.6063 s
agent0:                 episode reward: 0.0719,                 loss: nan
agent1:                 episode reward: -0.0719,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 10.8078 s
agent0:                 episode reward: 0.3292,                 loss: nan
agent1:                 episode reward: -0.3292,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 11.0072 s
agent0:                 episode reward: 0.2737,                 loss: nan
agent1:                 episode reward: -0.2737,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2029s / 11.2102 s
agent0:                 episode reward: -0.1267,                 loss: nan
agent1:                 episode reward: 0.1267,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2105s / 11.4206 s
agent0:                 episode reward: 0.0973,                 loss: nan
agent1:                 episode reward: -0.0973,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 11.6168 s
agent0:                 episode reward: 0.0691,                 loss: nan
agent1:                 episode reward: -0.0691,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 11.8160 s
agent0:                 episode reward: -0.1456,                 loss: nan
agent1:                 episode reward: 0.1456,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1943s / 12.0103 s
agent0:                 episode reward: 0.2504,                 loss: nan
agent1:                 episode reward: -0.2504,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2044s / 12.2147 s
agent0:                 episode reward: 0.0552,                 loss: nan
agent1:                 episode reward: -0.0552,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 12.4144 s
agent0:                 episode reward: 0.0556,                 loss: nan
agent1:                 episode reward: -0.0556,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 12.6137 s
agent0:                 episode reward: -0.2059,                 loss: nan
agent1:                 episode reward: 0.2059,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 12.8135 s
agent0:                 episode reward: 0.0405,                 loss: nan
agent1:                 episode reward: -0.0405,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 13.0107 s
agent0:                 episode reward: 0.0064,                 loss: nan
agent1:                 episode reward: -0.0064,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 13.2077 s
agent0:                 episode reward: 0.2553,                 loss: nan
agent1:                 episode reward: -0.2553,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 13.4035 s
agent0:                 episode reward: 0.2107,                 loss: nan
agent1:                 episode reward: -0.2107,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 13.6006 s
agent0:                 episode reward: -0.1354,                 loss: nan
agent1:                 episode reward: 0.1354,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 13.7963 s
agent0:                 episode reward: -0.3053,                 loss: nan
agent1:                 episode reward: 0.3053,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 13.9904 s
agent0:                 episode reward: 0.4689,                 loss: nan
agent1:                 episode reward: -0.4689,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 14.1902 s
agent0:                 episode reward: 0.2130,                 loss: nan
agent1:                 episode reward: -0.2130,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 14.3871 s
agent0:                 episode reward: 0.1706,                 loss: nan
agent1:                 episode reward: -0.1706,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 14.5831 s
agent0:                 episode reward: -0.0928,                 loss: nan
agent1:                 episode reward: 0.0928,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1935s / 14.7766 s
agent0:                 episode reward: 0.1181,                 loss: nan
agent1:                 episode reward: -0.1181,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 14.9749 s
agent0:                 episode reward: 0.0504,                 loss: nan
agent1:                 episode reward: -0.0504,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 15.1774 s
agent0:                 episode reward: 0.0336,                 loss: nan
agent1:                 episode reward: -0.0336,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2020s / 15.3794 s
agent0:                 episode reward: 0.2838,                 loss: nan
agent1:                 episode reward: -0.2838,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 15.5777 s
agent0:                 episode reward: -0.0777,                 loss: nan
agent1:                 episode reward: 0.0777,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 15.7796 s
agent0:                 episode reward: 0.1355,                 loss: nan
agent1:                 episode reward: -0.1355,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 15.9781 s
agent0:                 episode reward: -0.3420,                 loss: nan
agent1:                 episode reward: 0.3420,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 16.1804 s
agent0:                 episode reward: 0.3876,                 loss: nan
agent1:                 episode reward: -0.3876,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 16.3746 s
agent0:                 episode reward: 0.4139,                 loss: nan
agent1:                 episode reward: -0.4139,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 16.5750 s
agent0:                 episode reward: 0.3313,                 loss: nan
agent1:                 episode reward: -0.3313,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 16.7783 s
agent0:                 episode reward: 0.1008,                 loss: nan
agent1:                 episode reward: -0.1008,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1938s / 16.9721 s
agent0:                 episode reward: 0.3856,                 loss: nan
agent1:                 episode reward: -0.3856,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 17.1731 s
agent0:                 episode reward: -0.1444,                 loss: nan
agent1:                 episode reward: 0.1444,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 17.3727 s
agent0:                 episode reward: 0.1423,                 loss: nan
agent1:                 episode reward: -0.1423,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 17.5735 s
agent0:                 episode reward: 0.2545,                 loss: nan
agent1:                 episode reward: -0.2545,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1946s / 17.7681 s
agent0:                 episode reward: 0.2806,                 loss: nan
agent1:                 episode reward: -0.2806,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 17.9703 s
agent0:                 episode reward: 0.1354,                 loss: nan
agent1:                 episode reward: -0.1354,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 18.1659 s
agent0:                 episode reward: 0.1181,                 loss: nan
agent1:                 episode reward: -0.1181,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 18.3638 s
agent0:                 episode reward: 0.4892,                 loss: nan
agent1:                 episode reward: -0.4892,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 18.5605 s
agent0:                 episode reward: -0.1925,                 loss: nan
agent1:                 episode reward: 0.1925,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 18.7578 s
agent0:                 episode reward: 0.2836,                 loss: nan
agent1:                 episode reward: -0.2836,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 18.9570 s
agent0:                 episode reward: -0.4218,                 loss: nan
agent1:                 episode reward: 0.4218,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 19.1553 s
agent0:                 episode reward: 0.4175,                 loss: nan
agent1:                 episode reward: -0.4175,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 19.3555 s
agent0:                 episode reward: 0.2485,                 loss: nan
agent1:                 episode reward: -0.2485,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 19.5540 s
agent0:                 episode reward: 0.0758,                 loss: nan
agent1:                 episode reward: -0.0758,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 19.7542 s
agent0:                 episode reward: 0.0078,                 loss: nan
agent1:                 episode reward: -0.0078,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 19.9538 s
agent0:                 episode reward: -0.0524,                 loss: nan
agent1:                 episode reward: 0.0524,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1928s / 20.1467 s
agent0:                 episode reward: 0.1013,                 loss: nan
agent1:                 episode reward: -0.1013,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 20.3436 s
agent0:                 episode reward: 0.2873,                 loss: nan
agent1:                 episode reward: -0.2873,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2029s / 20.5464 s
agent0:                 episode reward: 0.3118,                 loss: nan
agent1:                 episode reward: -0.3118,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2059s / 20.7523 s
agent0:                 episode reward: -0.0477,                 loss: nan
agent1:                 episode reward: 0.0477,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 20.9500 s
agent0:                 episode reward: -0.4819,                 loss: nan
agent1:                 episode reward: 0.4819,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1938s / 21.1439 s
agent0:                 episode reward: 0.0313,                 loss: nan
agent1:                 episode reward: -0.0313,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 21.3445 s
agent0:                 episode reward: 0.3227,                 loss: nan
agent1:                 episode reward: -0.3227,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 21.5404 s
agent0:                 episode reward: 0.0872,                 loss: nan
agent1:                 episode reward: -0.0872,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1937s / 21.7341 s
agent0:                 episode reward: 0.0169,                 loss: nan
agent1:                 episode reward: -0.0169,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 21.9338 s
agent0:                 episode reward: 0.0534,                 loss: nan
agent1:                 episode reward: -0.0534,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 22.1318 s
agent0:                 episode reward: 0.0106,                 loss: nan
agent1:                 episode reward: -0.0106,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 22.3318 s
agent0:                 episode reward: 0.0919,                 loss: nan
agent1:                 episode reward: -0.0919,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 22.5326 s
agent0:                 episode reward: -0.2282,                 loss: nan
agent1:                 episode reward: 0.2282,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 22.7309 s
agent0:                 episode reward: 0.0669,                 loss: nan
agent1:                 episode reward: -0.0669,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 22.9268 s
agent0:                 episode reward: 0.1999,                 loss: nan
agent1:                 episode reward: -0.1999,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 23.1257 s
agent0:                 episode reward: 0.1034,                 loss: nan
agent1:                 episode reward: -0.1034,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 23.3224 s
agent0:                 episode reward: 0.0960,                 loss: nan
agent1:                 episode reward: -0.0960,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 23.5207 s
agent0:                 episode reward: -0.0579,                 loss: nan
agent1:                 episode reward: 0.0579,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 23.7154 s
agent0:                 episode reward: 0.2229,                 loss: nan
agent1:                 episode reward: -0.2229,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 23.9119 s
agent0:                 episode reward: 0.3683,                 loss: nan
agent1:                 episode reward: -0.3683,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 24.1096 s
agent0:                 episode reward: -0.3260,                 loss: nan
agent1:                 episode reward: 0.3260,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 24.3076 s
agent0:                 episode reward: 0.1238,                 loss: nan
agent1:                 episode reward: -0.1238,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 24.5062 s
agent0:                 episode reward: 0.0167,                 loss: nan
agent1:                 episode reward: -0.0167,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 24.7080 s
agent0:                 episode reward: 0.0560,                 loss: nan
agent1:                 episode reward: -0.0560,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 24.9047 s
agent0:                 episode reward: -0.3359,                 loss: nan
agent1:                 episode reward: 0.3359,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 25.1023 s
agent0:                 episode reward: -0.4080,                 loss: nan
agent1:                 episode reward: 0.4080,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2032s / 25.3055 s
agent0:                 episode reward: -0.1089,                 loss: nan
agent1:                 episode reward: 0.1089,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 25.5041 s
agent0:                 episode reward: 0.0690,                 loss: nan
agent1:                 episode reward: -0.0690,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 25.6994 s
agent0:                 episode reward: 0.0075,                 loss: nan
agent1:                 episode reward: -0.0075,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 25.8967 s
agent0:                 episode reward: -0.0198,                 loss: nan
agent1:                 episode reward: 0.0198,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 26.0966 s
agent0:                 episode reward: 0.4070,                 loss: nan
agent1:                 episode reward: -0.4070,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 26.2979 s
agent0:                 episode reward: 0.0615,                 loss: nan
agent1:                 episode reward: -0.0615,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1921s / 26.4900 s
agent0:                 episode reward: -0.1672,                 loss: nan
agent1:                 episode reward: 0.1672,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 26.6888 s
agent0:                 episode reward: -0.0928,                 loss: nan
agent1:                 episode reward: 0.0928,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1929s / 26.8816 s
agent0:                 episode reward: 0.3427,                 loss: nan
agent1:                 episode reward: -0.3427,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1808s / 27.0624 s
agent0:                 episode reward: -0.1549,                 loss: nan
agent1:                 episode reward: 0.1549,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 27.2596 s
agent0:                 episode reward: 0.1418,                 loss: nan
agent1:                 episode reward: -0.1418,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 27.4594 s
agent0:                 episode reward: 0.2947,                 loss: nan
agent1:                 episode reward: -0.2947,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 27.6591 s
agent0:                 episode reward: 0.4498,                 loss: nan
agent1:                 episode reward: -0.4498,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 27.8544 s
agent0:                 episode reward: 0.1240,                 loss: nan
agent1:                 episode reward: -0.1240,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2354s / 28.0898 s
agent0:                 episode reward: -0.1347,                 loss: nan
agent1:                 episode reward: 0.1347,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2031s / 28.2929 s
agent0:                 episode reward: 0.3307,                 loss: nan
agent1:                 episode reward: -0.3307,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 28.4941 s
agent0:                 episode reward: 0.1198,                 loss: nan
agent1:                 episode reward: -0.1198,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 28.6927 s
agent0:                 episode reward: -0.4590,                 loss: nan
agent1:                 episode reward: 0.4590,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 28.8917 s
agent0:                 episode reward: -0.3828,                 loss: nan
agent1:                 episode reward: 0.3828,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 29.0891 s
agent0:                 episode reward: 0.2685,                 loss: nan
agent1:                 episode reward: -0.2685,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 29.2879 s
agent0:                 episode reward: 0.0991,                 loss: nan
agent1:                 episode reward: -0.0991,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 29.4858 s
agent0:                 episode reward: 0.1505,                 loss: nan
agent1:                 episode reward: -0.1505,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 29.6844 s
agent0:                 episode reward: -0.2449,                 loss: nan
agent1:                 episode reward: 0.2449,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1944s / 29.8788 s
agent0:                 episode reward: -0.1510,                 loss: nan
agent1:                 episode reward: 0.1510,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 30.0780 s
agent0:                 episode reward: 0.2882,                 loss: nan
agent1:                 episode reward: -0.2882,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 30.2756 s
agent0:                 episode reward: 0.4796,                 loss: nan
agent1:                 episode reward: -0.4796,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 30.4695 s
agent0:                 episode reward: 0.1579,                 loss: nan
agent1:                 episode reward: -0.1579,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 30.6686 s
agent0:                 episode reward: 0.3568,                 loss: nan
agent1:                 episode reward: -0.3568,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 30.8667 s
agent0:                 episode reward: 0.0810,                 loss: nan
agent1:                 episode reward: -0.0810,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 31.0658 s
agent0:                 episode reward: -0.2834,                 loss: nan
agent1:                 episode reward: 0.2834,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 31.2648 s
agent0:                 episode reward: 0.1839,                 loss: nan
agent1:                 episode reward: -0.1839,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 31.4608 s
agent0:                 episode reward: 0.2151,                 loss: nan
agent1:                 episode reward: -0.2151,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 31.6592 s
agent0:                 episode reward: 0.0525,                 loss: nan
agent1:                 episode reward: -0.0525,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 31.8580 s
agent0:                 episode reward: 0.1380,                 loss: nan
agent1:                 episode reward: -0.1380,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 32.0572 s
agent0:                 episode reward: 0.0152,                 loss: nan
agent1:                 episode reward: -0.0152,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 32.2532 s
agent0:                 episode reward: -0.0541,                 loss: nan
agent1:                 episode reward: 0.0541,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 32.4516 s
agent0:                 episode reward: 0.0610,                 loss: nan
agent1:                 episode reward: -0.0610,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1932s / 32.6448 s
agent0:                 episode reward: 0.0311,                 loss: nan
agent1:                 episode reward: -0.0311,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1956s / 32.8403 s
agent0:                 episode reward: -0.0416,                 loss: nan
agent1:                 episode reward: 0.0416,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1918s / 33.0321 s
agent0:                 episode reward: 0.1798,                 loss: nan
agent1:                 episode reward: -0.1798,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1927s / 33.2248 s
agent0:                 episode reward: -0.0778,                 loss: nan
agent1:                 episode reward: 0.0778,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1928s / 33.4176 s
agent0:                 episode reward: 0.1002,                 loss: nan
agent1:                 episode reward: -0.1002,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1938s / 33.6114 s
agent0:                 episode reward: 0.2652,                 loss: nan
agent1:                 episode reward: -0.2652,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3481s / 33.9595 s
agent0:                 episode reward: -0.0280,                 loss: nan
agent1:                 episode reward: 0.0280,                 loss: 0.4474
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5800s / 34.5395 s
agent0:                 episode reward: -0.2938,                 loss: nan
agent1:                 episode reward: 0.2938,                 loss: 0.4395
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5851s / 35.1246 s
agent0:                 episode reward: 0.4419,                 loss: nan
agent1:                 episode reward: -0.4419,                 loss: 0.4320
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5866s / 35.7112 s
agent0:                 episode reward: 0.0402,                 loss: nan
agent1:                 episode reward: -0.0402,                 loss: 0.4244
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5854s / 36.2966 s
agent0:                 episode reward: -0.0325,                 loss: nan
agent1:                 episode reward: 0.0325,                 loss: 0.4160
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5810s / 36.8776 s
agent0:                 episode reward: 0.0700,                 loss: nan
agent1:                 episode reward: -0.0700,                 loss: 0.4069
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5790s / 37.4565 s
agent0:                 episode reward: 0.0043,                 loss: nan
agent1:                 episode reward: -0.0043,                 loss: 0.3990
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5840s / 38.0406 s
agent0:                 episode reward: -0.3832,                 loss: nan
agent1:                 episode reward: 0.3832,                 loss: 0.3943
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5829s / 38.6235 s
agent0:                 episode reward: -0.0532,                 loss: nan
agent1:                 episode reward: 0.0532,                 loss: 0.3927
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5798s / 39.2033 s
agent0:                 episode reward: -0.3405,                 loss: nan
agent1:                 episode reward: 0.3405,                 loss: 0.3870
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5832s / 39.7864 s
agent0:                 episode reward: -0.0085,                 loss: nan
agent1:                 episode reward: 0.0085,                 loss: 0.3864
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5849s / 40.3713 s
agent0:                 episode reward: -0.1733,                 loss: nan
agent1:                 episode reward: 0.1733,                 loss: 0.3844
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5806s / 40.9519 s
agent0:                 episode reward: -0.3661,                 loss: nan
agent1:                 episode reward: 0.3661,                 loss: 0.3843
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5859s / 41.5377 s
agent0:                 episode reward: 0.1654,                 loss: nan
agent1:                 episode reward: -0.1654,                 loss: 0.3840
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5790s / 42.1168 s
agent0:                 episode reward: -0.4644,                 loss: nan
agent1:                 episode reward: 0.4644,                 loss: 0.3805
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5932s / 42.7099 s
agent0:                 episode reward: 0.2149,                 loss: nan
agent1:                 episode reward: -0.2149,                 loss: 0.3820
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5941s / 43.3040 s
agent0:                 episode reward: -0.0084,                 loss: nan
agent1:                 episode reward: 0.0084,                 loss: 0.3780
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 43.8934 s
agent0:                 episode reward: -0.1451,                 loss: nan
agent1:                 episode reward: 0.1451,                 loss: 0.3746
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5888s / 44.4821 s
agent0:                 episode reward: -0.3924,                 loss: nan
agent1:                 episode reward: 0.3924,                 loss: 0.3625
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5888s / 45.0709 s
agent0:                 episode reward: -0.5251,                 loss: nan
agent1:                 episode reward: 0.5251,                 loss: 0.3605
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5817s / 45.6526 s
agent0:                 episode reward: 0.1252,                 loss: nan
agent1:                 episode reward: -0.1252,                 loss: 0.3584
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 46.2385 s
agent0:                 episode reward: -0.5557,                 loss: nan
agent1:                 episode reward: 0.5557,                 loss: 0.3546
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5831s / 46.8216 s
agent0:                 episode reward: -0.1742,                 loss: nan
agent1:                 episode reward: 0.1742,                 loss: 0.3511
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5850s / 47.4066 s
agent0:                 episode reward: -0.5805,                 loss: nan
agent1:                 episode reward: 0.5805,                 loss: 0.3489
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5860s / 47.9926 s
agent0:                 episode reward: -0.6031,                 loss: nan
agent1:                 episode reward: 0.6031,                 loss: 0.3485
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5878s / 48.5804 s
agent0:                 episode reward: -0.5535,                 loss: nan
agent1:                 episode reward: 0.5535,                 loss: 0.3419
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5864s / 49.1668 s
agent0:                 episode reward: -0.7758,                 loss: nan
agent1:                 episode reward: 0.7758,                 loss: 0.3431
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5816s / 49.7484 s
agent0:                 episode reward: -0.6255,                 loss: nan
agent1:                 episode reward: 0.6255,                 loss: 0.3424
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 50.3342 s
agent0:                 episode reward: -0.3622,                 loss: nan
agent1:                 episode reward: 0.3622,                 loss: 0.3356
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5787s / 50.9129 s
agent0:                 episode reward: -0.5669,                 loss: nan
agent1:                 episode reward: 0.5669,                 loss: 0.3360
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 51.5006 s
agent0:                 episode reward: -0.9755,                 loss: nan
agent1:                 episode reward: 0.9755,                 loss: 0.3316
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 52.0900 s
agent0:                 episode reward: -0.9018,                 loss: nan
agent1:                 episode reward: 0.9018,                 loss: 0.3295
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5836s / 52.6736 s
agent0:                 episode reward: -0.1545,                 loss: nan
agent1:                 episode reward: 0.1545,                 loss: 0.3243
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5919s / 53.2655 s
agent0:                 episode reward: -0.4103,                 loss: nan
agent1:                 episode reward: 0.4103,                 loss: 0.3249
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 53.8609 s
agent0:                 episode reward: -0.5426,                 loss: nan
agent1:                 episode reward: 0.5426,                 loss: 0.3288
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5913s / 54.4522 s
agent0:                 episode reward: -0.4262,                 loss: nan
agent1:                 episode reward: 0.4262,                 loss: 0.3214
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5859s / 55.0381 s
agent0:                 episode reward: -0.1570,                 loss: nan
agent1:                 episode reward: 0.1570,                 loss: 0.3179
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 55.6274 s
agent0:                 episode reward: -0.8765,                 loss: nan
agent1:                 episode reward: 0.8765,                 loss: 0.3157
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5833s / 56.2107 s
agent0:                 episode reward: -0.8346,                 loss: nan
agent1:                 episode reward: 0.8346,                 loss: 0.3178
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5901s / 56.8008 s
agent0:                 episode reward: -0.4235,                 loss: nan
agent1:                 episode reward: 0.4235,                 loss: 0.3143
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5808s / 57.3816 s
agent0:                 episode reward: -0.2604,                 loss: nan
agent1:                 episode reward: 0.2604,                 loss: 0.3120
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5831s / 57.9647 s
agent0:                 episode reward: -0.6680,                 loss: nan
agent1:                 episode reward: 0.6680,                 loss: 0.3104
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5844s / 58.5492 s
agent0:                 episode reward: -0.2960,                 loss: nan
agent1:                 episode reward: 0.2960,                 loss: 0.3157
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5800s / 59.1292 s
agent0:                 episode reward: -0.5892,                 loss: nan
agent1:                 episode reward: 0.5892,                 loss: 0.3103
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5913s / 59.7205 s
agent0:                 episode reward: -0.3318,                 loss: nan
agent1:                 episode reward: 0.3318,                 loss: 0.3081
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 60.3082 s
agent0:                 episode reward: -0.1656,                 loss: nan
agent1:                 episode reward: 0.1656,                 loss: 0.3084
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 60.9016 s
agent0:                 episode reward: -0.1494,                 loss: nan
agent1:                 episode reward: 0.1494,                 loss: 0.3071
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5907s / 61.4923 s
agent0:                 episode reward: -0.8827,                 loss: nan
agent1:                 episode reward: 0.8827,                 loss: 0.3089
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5830s / 62.0752 s
agent0:                 episode reward: -0.4078,                 loss: nan
agent1:                 episode reward: 0.4078,                 loss: 0.3114
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 62.6677 s
agent0:                 episode reward: -0.4291,                 loss: nan
agent1:                 episode reward: 0.4291,                 loss: 0.3062
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 63.2556 s
agent0:                 episode reward: -0.5283,                 loss: nan
agent1:                 episode reward: 0.5283,                 loss: 0.3057
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 63.8452 s
agent0:                 episode reward: -0.2090,                 loss: nan
agent1:                 episode reward: 0.2090,                 loss: 0.2808
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5857s / 64.4310 s
agent0:                 episode reward: -0.6994,                 loss: nan
agent1:                 episode reward: 0.6994,                 loss: 0.2815
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5823s / 65.0133 s
agent0:                 episode reward: -0.5343,                 loss: nan
agent1:                 episode reward: 0.5343,                 loss: 0.2828
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5818s / 65.5951 s
agent0:                 episode reward: -0.6759,                 loss: nan
agent1:                 episode reward: 0.6759,                 loss: 0.2799
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5783s / 66.1733 s
agent0:                 episode reward: -0.5815,                 loss: nan
agent1:                 episode reward: 0.5815,                 loss: 0.2827
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 66.7553 s
agent0:                 episode reward: -0.0872,                 loss: nan
agent1:                 episode reward: 0.0872,                 loss: 0.2810
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5847s / 67.3399 s
agent0:                 episode reward: -0.3360,                 loss: nan
agent1:                 episode reward: 0.3360,                 loss: 0.2794
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5891s / 67.9291 s
agent0:                 episode reward: -0.5437,                 loss: nan
agent1:                 episode reward: 0.5437,                 loss: 0.2792
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5810s / 68.5101 s
agent0:                 episode reward: -0.4994,                 loss: nan
agent1:                 episode reward: 0.4994,                 loss: 0.2819
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5856s / 69.0957 s
agent0:                 episode reward: -0.5750,                 loss: nan
agent1:                 episode reward: 0.5750,                 loss: 0.2813
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5859s / 69.6816 s
agent0:                 episode reward: -0.4447,                 loss: nan
agent1:                 episode reward: 0.4447,                 loss: 0.2797
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5870s / 70.2686 s
agent0:                 episode reward: -0.5215,                 loss: nan
agent1:                 episode reward: 0.5215,                 loss: 0.2778
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5830s / 70.8517 s
agent0:                 episode reward: -0.5934,                 loss: nan
agent1:                 episode reward: 0.5934,                 loss: 0.2790
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 71.4418 s
agent0:                 episode reward: -0.5470,                 loss: nan
agent1:                 episode reward: 0.5470,                 loss: 0.2783
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5856s / 72.0274 s
agent0:                 episode reward: -0.4320,                 loss: nan
agent1:                 episode reward: 0.4320,                 loss: 0.2792
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 72.6157 s
agent0:                 episode reward: -0.3139,                 loss: nan
agent1:                 episode reward: 0.3139,                 loss: 0.2800
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5903s / 73.2059 s
agent0:                 episode reward: -0.6847,                 loss: nan
agent1:                 episode reward: 0.6847,                 loss: 0.3050
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 73.7993 s
agent0:                 episode reward: -0.5597,                 loss: nan
agent1:                 episode reward: 0.5597,                 loss: 0.3092
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5865s / 74.3858 s
agent0:                 episode reward: -0.8006,                 loss: nan
agent1:                 episode reward: 0.8006,                 loss: 0.3095
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5837s / 74.9695 s
agent0:                 episode reward: -0.6723,                 loss: nan
agent1:                 episode reward: 0.6723,                 loss: 0.3102
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5814s / 75.5509 s
agent0:                 episode reward: -0.7376,                 loss: nan
agent1:                 episode reward: 0.7376,                 loss: 0.3122
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5857s / 76.1366 s
agent0:                 episode reward: -0.6259,                 loss: nan
agent1:                 episode reward: 0.6259,                 loss: 0.3098
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5846s / 76.7212 s
agent0:                 episode reward: -0.5645,                 loss: nan
agent1:                 episode reward: 0.5645,                 loss: 0.3107
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5911s / 77.3123 s
agent0:                 episode reward: -0.2660,                 loss: nan
agent1:                 episode reward: 0.2660,                 loss: 0.3086
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5856s / 77.8979 s
agent0:                 episode reward: -0.3756,                 loss: nan
agent1:                 episode reward: 0.3756,                 loss: 0.3105
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 78.4877 s
agent0:                 episode reward: -0.2930,                 loss: nan
agent1:                 episode reward: 0.2930,                 loss: 0.3117
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5852s / 79.0729 s
agent0:                 episode reward: -0.4613,                 loss: nan
agent1:                 episode reward: 0.4613,                 loss: 0.3125
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5827s / 79.6556 s
agent0:                 episode reward: -0.2308,                 loss: nan
agent1:                 episode reward: 0.2308,                 loss: 0.3121
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5804s / 80.2361 s
agent0:                 episode reward: -0.2879,                 loss: nan
agent1:                 episode reward: 0.2879,                 loss: 0.3116
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5845s / 80.8206 s
agent0:                 episode reward: -0.2524,                 loss: nan
agent1:                 episode reward: 0.2524,                 loss: 0.3101
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5859s / 81.4065 s
agent0:                 episode reward: -0.4089,                 loss: nan
agent1:                 episode reward: 0.4089,                 loss: 0.3113
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5845s / 81.9910 s
agent0:                 episode reward: -0.2677,                 loss: nan
agent1:                 episode reward: 0.2677,                 loss: 0.3099
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5888s / 82.5798 s
agent0:                 episode reward: -0.6663,                 loss: nan
agent1:                 episode reward: 0.6663,                 loss: 0.3072
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5884s / 83.1682 s
agent0:                 episode reward: -0.1797,                 loss: nan
agent1:                 episode reward: 0.1797,                 loss: 0.3052
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 83.7592 s
agent0:                 episode reward: -0.3974,                 loss: nan
agent1:                 episode reward: 0.3974,                 loss: 0.3051
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5817s / 84.3409 s
agent0:                 episode reward: -0.5266,                 loss: nan
agent1:                 episode reward: 0.5266,                 loss: 0.2999
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5857s / 84.9267 s
agent0:                 episode reward: -0.6005,                 loss: nan
agent1:                 episode reward: 0.6005,                 loss: 0.3043
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 85.5217 s
agent0:                 episode reward: -0.3407,                 loss: nan
agent1:                 episode reward: 0.3407,                 loss: 0.3082
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5874s / 86.1092 s
agent0:                 episode reward: -0.3881,                 loss: nan
agent1:                 episode reward: 0.3881,                 loss: 0.3038
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5999s / 86.7091 s
agent0:                 episode reward: -0.5895,                 loss: nan
agent1:                 episode reward: 0.5895,                 loss: 0.3080
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5867s / 87.2958 s
agent0:                 episode reward: -0.9673,                 loss: nan
agent1:                 episode reward: 0.9673,                 loss: 0.3080
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5929s / 87.8887 s
agent0:                 episode reward: -0.4199,                 loss: nan
agent1:                 episode reward: 0.4199,                 loss: 0.3061
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 88.4855 s
agent0:                 episode reward: -1.0222,                 loss: nan
agent1:                 episode reward: 1.0222,                 loss: 0.3086
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5802s / 89.0657 s
agent0:                 episode reward: -0.3815,                 loss: nan
agent1:                 episode reward: 0.3815,                 loss: 0.3060
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5972s / 89.6628 s
agent0:                 episode reward: -0.6715,                 loss: nan
agent1:                 episode reward: 0.6715,                 loss: 0.3070
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 90.2507 s
agent0:                 episode reward: -0.6244,                 loss: nan
agent1:                 episode reward: 0.6244,                 loss: 0.3058
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5938s / 90.8445 s
agent0:                 episode reward: -0.5644,                 loss: nan
agent1:                 episode reward: 0.5644,                 loss: 0.3062
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5831s / 91.4276 s
agent0:                 episode reward: -0.5855,                 loss: nan
agent1:                 episode reward: 0.5855,                 loss: 0.3059
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5970s / 92.0246 s
agent0:                 episode reward: -1.0593,                 loss: nan
agent1:                 episode reward: 1.0593,                 loss: 0.3074
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5991s / 92.6237 s
agent0:                 episode reward: -0.7313,                 loss: nan
agent1:                 episode reward: 0.7313,                 loss: 0.3010
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 93.2164 s
agent0:                 episode reward: -0.3413,                 loss: nan
agent1:                 episode reward: 0.3413,                 loss: 0.2943
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 93.8022 s
agent0:                 episode reward: -0.6951,                 loss: nan
agent1:                 episode reward: 0.6951,                 loss: 0.2962
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 94.3936 s
agent0:                 episode reward: -0.8209,                 loss: nan
agent1:                 episode reward: 0.8209,                 loss: 0.2986
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5865s / 94.9801 s
agent0:                 episode reward: -0.8302,                 loss: nan
agent1:                 episode reward: 0.8302,                 loss: 0.2957
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 95.5748 s
agent0:                 episode reward: -0.3470,                 loss: nan
agent1:                 episode reward: 0.3470,                 loss: 0.2968
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 96.1684 s
agent0:                 episode reward: -0.5384,                 loss: nan
agent1:                 episode reward: 0.5384,                 loss: 0.2938
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 96.7621 s
agent0:                 episode reward: -0.2588,                 loss: nan
agent1:                 episode reward: 0.2588,                 loss: 0.2982
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 97.3523 s
agent0:                 episode reward: -0.6081,                 loss: nan
agent1:                 episode reward: 0.6081,                 loss: 0.2940
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5914s / 97.9437 s
agent0:                 episode reward: -0.5668,                 loss: nan
agent1:                 episode reward: 0.5668,                 loss: 0.2960
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5948s / 98.5385 s
agent0:                 episode reward: -0.2070,                 loss: nan
agent1:                 episode reward: 0.2070,                 loss: 0.2980
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6009s / 99.1394 s
agent0:                 episode reward: -0.5524,                 loss: nan
agent1:                 episode reward: 0.5524,                 loss: 0.2952
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5888s / 99.7282 s
agent0:                 episode reward: -0.6148,                 loss: nan
agent1:                 episode reward: 0.6148,                 loss: 0.2930
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 100.3204 s
agent0:                 episode reward: -0.2911,                 loss: nan
agent1:                 episode reward: 0.2911,                 loss: 0.2983
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5908s / 100.9112 s
agent0:                 episode reward: -0.3339,                 loss: nan
agent1:                 episode reward: 0.3339,                 loss: 0.2924
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5970s / 101.5082 s
agent0:                 episode reward: -0.2081,                 loss: nan
agent1:                 episode reward: 0.2081,                 loss: 0.2958
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5838s / 102.0921 s
agent0:                 episode reward: -0.7402,                 loss: nan
agent1:                 episode reward: 0.7402,                 loss: 0.2961
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 102.6917 s
agent0:                 episode reward: -0.7180,                 loss: nan
agent1:                 episode reward: 0.7180,                 loss: 0.3013
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5912s / 103.2829 s
agent0:                 episode reward: -0.4758,                 loss: nan
agent1:                 episode reward: 0.4758,                 loss: 0.3066
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5906s / 103.8735 s
agent0:                 episode reward: -0.4500,                 loss: nan
agent1:                 episode reward: 0.4500,                 loss: 0.3086
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 104.4674 s
agent0:                 episode reward: -0.1930,                 loss: nan
agent1:                 episode reward: 0.1930,                 loss: 0.3074
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5949s / 105.0623 s
agent0:                 episode reward: -0.7557,                 loss: nan
agent1:                 episode reward: 0.7557,                 loss: 0.3076
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5973s / 105.6597 s
agent0:                 episode reward: -0.4206,                 loss: nan
agent1:                 episode reward: 0.4206,                 loss: 0.3063
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5863s / 106.2460 s
agent0:                 episode reward: -0.5443,                 loss: nan
agent1:                 episode reward: 0.5443,                 loss: 0.3087
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6004s / 106.8464 s
agent0:                 episode reward: -0.6998,                 loss: nan
agent1:                 episode reward: 0.6998,                 loss: 0.3075
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5897s / 107.4361 s
agent0:                 episode reward: -0.5769,                 loss: nan
agent1:                 episode reward: 0.5769,                 loss: 0.3068
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5924s / 108.0285 s
agent0:                 episode reward: -0.4836,                 loss: nan
agent1:                 episode reward: 0.4836,                 loss: 0.3076
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5873s / 108.6157 s
agent0:                 episode reward: -0.3609,                 loss: nan
agent1:                 episode reward: 0.3609,                 loss: 0.3080
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5855s / 109.2012 s
agent0:                 episode reward: -0.4750,                 loss: nan
agent1:                 episode reward: 0.4750,                 loss: 0.3092
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5789s / 109.7801 s
agent0:                 episode reward: -0.4385,                 loss: nan
agent1:                 episode reward: 0.4385,                 loss: 0.3104
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5963s / 110.3764 s
agent0:                 episode reward: -0.5785,                 loss: nan
agent1:                 episode reward: 0.5785,                 loss: 0.3054
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5900s / 110.9665 s
agent0:                 episode reward: -0.4403,                 loss: nan
agent1:                 episode reward: 0.4403,                 loss: 0.3112
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 111.5607 s
agent0:                 episode reward: -1.0579,                 loss: nan
agent1:                 episode reward: 1.0579,                 loss: 0.3092
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5870s / 112.1477 s
agent0:                 episode reward: -0.5646,                 loss: nan
agent1:                 episode reward: 0.5646,                 loss: 0.3057
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5950s / 112.7427 s
agent0:                 episode reward: -0.5120,                 loss: nan
agent1:                 episode reward: 0.5120,                 loss: 0.3037
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5891s / 113.3318 s
agent0:                 episode reward: -0.4109,                 loss: nan
agent1:                 episode reward: 0.4109,                 loss: 0.3064
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5995s / 113.9313 s
agent0:                 episode reward: -0.5381,                 loss: nan
agent1:                 episode reward: 0.5381,                 loss: 0.3076
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 114.5211 s
agent0:                 episode reward: -0.5403,                 loss: nan
agent1:                 episode reward: 0.5403,                 loss: 0.3066
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5887s / 115.1098 s
agent0:                 episode reward: -0.6099,                 loss: nan
agent1:                 episode reward: 0.6099,                 loss: 0.3056
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 115.7080 s
agent0:                 episode reward: -0.4910,                 loss: nan
agent1:                 episode reward: 0.4910,                 loss: 0.3092
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 116.3055 s
agent0:                 episode reward: -0.4769,                 loss: nan
agent1:                 episode reward: 0.4769,                 loss: 0.3063
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 116.8983 s
agent0:                 episode reward: -0.4638,                 loss: nan
agent1:                 episode reward: 0.4638,                 loss: 0.3071
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 117.4901 s
agent0:                 episode reward: -0.6757,                 loss: nan
agent1:                 episode reward: 0.6757,                 loss: 0.3046
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 118.0799 s
agent0:                 episode reward: -0.4347,                 loss: nan
agent1:                 episode reward: 0.4347,                 loss: 0.3067
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5905s / 118.6704 s
agent0:                 episode reward: -0.6830,                 loss: nan
agent1:                 episode reward: 0.6830,                 loss: 0.3067
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5905s / 119.2609 s
agent0:                 episode reward: -0.6335,                 loss: nan
agent1:                 episode reward: 0.6335,                 loss: 0.3052
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5998s / 119.8607 s
agent0:                 episode reward: -0.6541,                 loss: nan
agent1:                 episode reward: 0.6541,                 loss: 0.3017
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 120.4560 s
agent0:                 episode reward: -0.8463,                 loss: nan
agent1:                 episode reward: 0.8463,                 loss: 0.3045
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 121.0500 s
agent0:                 episode reward: -0.5543,                 loss: nan
agent1:                 episode reward: 0.5543,                 loss: 0.3044
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 121.6460 s
agent0:                 episode reward: -0.4290,                 loss: nan
agent1:                 episode reward: 0.4290,                 loss: 0.3038
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 122.2441 s
agent0:                 episode reward: -0.5484,                 loss: nan
agent1:                 episode reward: 0.5484,                 loss: 0.3065
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5890s / 122.8330 s
agent0:                 episode reward: -0.3141,                 loss: nan
agent1:                 episode reward: 0.3141,                 loss: 0.3066
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5946s / 123.4276 s
agent0:                 episode reward: -0.8729,                 loss: nan
agent1:                 episode reward: 0.8729,                 loss: 0.3043
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5977s / 124.0252 s
agent0:                 episode reward: -0.0410,                 loss: nan
agent1:                 episode reward: 0.0410,                 loss: 0.3035
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5945s / 124.6198 s
agent0:                 episode reward: -0.7448,                 loss: nan
agent1:                 episode reward: 0.7448,                 loss: 0.3046
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 125.2077 s
agent0:                 episode reward: -0.7520,                 loss: nan
agent1:                 episode reward: 0.7520,                 loss: 0.3044
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 125.8020 s
agent0:                 episode reward: -0.4901,                 loss: nan
agent1:                 episode reward: 0.4901,                 loss: 0.3040
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 126.4016 s
agent0:                 episode reward: -0.4335,                 loss: nan
agent1:                 episode reward: 0.4335,                 loss: 0.3038
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 126.9959 s
agent0:                 episode reward: -0.6350,                 loss: nan
agent1:                 episode reward: 0.6350,                 loss: 0.3070
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5995s / 127.5955 s
agent0:                 episode reward: -0.2994,                 loss: nan
agent1:                 episode reward: 0.2994,                 loss: 0.2996
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 128.1935 s
agent0:                 episode reward: -0.0860,                 loss: nan
agent1:                 episode reward: 0.0860,                 loss: 0.3044
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5929s / 128.7864 s
agent0:                 episode reward: -0.4427,                 loss: nan
agent1:                 episode reward: 0.4427,                 loss: 0.3061
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 129.3846 s
agent0:                 episode reward: -0.5846,                 loss: nan
agent1:                 episode reward: 0.5846,                 loss: 0.3018
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 129.9867 s
agent0:                 episode reward: -0.6132,                 loss: nan
agent1:                 episode reward: 0.6132,                 loss: 0.3033
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5900s / 130.5767 s
agent0:                 episode reward: -0.8974,                 loss: nan
agent1:                 episode reward: 0.8974,                 loss: 0.3031
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5892s / 131.1658 s
agent0:                 episode reward: -0.5015,                 loss: nan
agent1:                 episode reward: 0.5015,                 loss: 0.3059
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5941s / 131.7599 s
agent0:                 episode reward: -0.9292,                 loss: nan
agent1:                 episode reward: 0.9292,                 loss: 0.3066
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5962s / 132.3562 s
agent0:                 episode reward: -0.1677,                 loss: nan
agent1:                 episode reward: 0.1677,                 loss: 0.3033
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5887s / 132.9448 s
agent0:                 episode reward: -0.5012,                 loss: nan
agent1:                 episode reward: 0.5012,                 loss: 0.3010
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6031s / 133.5479 s
agent0:                 episode reward: -0.7579,                 loss: nan
agent1:                 episode reward: 0.7579,                 loss: 0.3041
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5978s / 134.1457 s
agent0:                 episode reward: -0.4324,                 loss: nan
agent1:                 episode reward: 0.4324,                 loss: 0.3026
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 134.7385 s
agent0:                 episode reward: -0.5202,                 loss: nan
agent1:                 episode reward: 0.5202,                 loss: 0.3064
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5970s / 135.3355 s
agent0:                 episode reward: -0.6064,                 loss: nan
agent1:                 episode reward: 0.6064,                 loss: 0.3043
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5921s / 135.9276 s
agent0:                 episode reward: -0.6261,                 loss: nan
agent1:                 episode reward: 0.6261,                 loss: 0.3052
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6000s / 136.5276 s
agent0:                 episode reward: -0.6090,                 loss: nan
agent1:                 episode reward: 0.6090,                 loss: 0.3048
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5993s / 137.1269 s
agent0:                 episode reward: -0.6998,                 loss: nan
agent1:                 episode reward: 0.6998,                 loss: 0.3042
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 137.7233 s
agent0:                 episode reward: -0.6215,                 loss: nan
agent1:                 episode reward: 0.6215,                 loss: 0.3012
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5875s / 138.3108 s
agent0:                 episode reward: -0.6665,                 loss: nan
agent1:                 episode reward: 0.6665,                 loss: 0.3053
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 138.9055 s
agent0:                 episode reward: -0.6321,                 loss: nan
agent1:                 episode reward: 0.6321,                 loss: 0.3057
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6022s / 139.5077 s
agent0:                 episode reward: -0.5864,                 loss: nan
agent1:                 episode reward: 0.5864,                 loss: 0.3030
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6143s / 140.1220 s
agent0:                 episode reward: -0.4942,                 loss: nan
agent1:                 episode reward: 0.4942,                 loss: 0.3043
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5946s / 140.7166 s
agent0:                 episode reward: -0.3203,                 loss: nan
agent1:                 episode reward: 0.3203,                 loss: 0.3037
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6003s / 141.3169 s
agent0:                 episode reward: -0.2808,                 loss: nan
agent1:                 episode reward: 0.2808,                 loss: 0.3034
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5998s / 141.9167 s
agent0:                 episode reward: -0.4076,                 loss: nan
agent1:                 episode reward: 0.4076,                 loss: 0.3040
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5965s / 142.5132 s
agent0:                 episode reward: -0.0123,                 loss: nan
agent1:                 episode reward: 0.0123,                 loss: 0.3016
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 143.1117 s
agent0:                 episode reward: -0.7599,                 loss: nan
agent1:                 episode reward: 0.7599,                 loss: 0.3022
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5959s / 143.7075 s
agent0:                 episode reward: -0.3826,                 loss: nan
agent1:                 episode reward: 0.3826,                 loss: 0.3031
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6007s / 144.3082 s
agent0:                 episode reward: -0.4222,                 loss: nan
agent1:                 episode reward: 0.4222,                 loss: 0.3036
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 144.9066 s
agent0:                 episode reward: -0.0877,                 loss: nan
agent1:                 episode reward: 0.0877,                 loss: 0.3024
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 145.5025 s
agent0:                 episode reward: -0.2295,                 loss: nan
agent1:                 episode reward: 0.2295,                 loss: 0.3006
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6111s / 146.1136 s
agent0:                 episode reward: -0.4131,                 loss: nan
agent1:                 episode reward: 0.4131,                 loss: 0.2998
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 146.7118 s
agent0:                 episode reward: -0.6794,                 loss: nan
agent1:                 episode reward: 0.6794,                 loss: 0.3027
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 147.3099 s
agent0:                 episode reward: -0.4121,                 loss: nan
agent1:                 episode reward: 0.4121,                 loss: 0.3010
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 147.9042 s
agent0:                 episode reward: -0.3324,                 loss: nan
agent1:                 episode reward: 0.3324,                 loss: 0.3027
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 148.5016 s
agent0:                 episode reward: -0.9402,                 loss: nan
agent1:                 episode reward: 0.9402,                 loss: 0.3039
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5940s / 149.0956 s
agent0:                 episode reward: -0.8399,                 loss: nan
agent1:                 episode reward: 0.8399,                 loss: 0.3039
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 149.6968 s
agent0:                 episode reward: -0.6760,                 loss: nan
agent1:                 episode reward: 0.6760,                 loss: 0.3045
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5907s / 150.2875 s
agent0:                 episode reward: -0.6289,                 loss: nan
agent1:                 episode reward: 0.6289,                 loss: 0.3020
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5979s / 150.8854 s
agent0:                 episode reward: -0.9991,                 loss: nan
agent1:                 episode reward: 0.9991,                 loss: 0.3036
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5945s / 151.4799 s
agent0:                 episode reward: -0.8391,                 loss: nan
agent1:                 episode reward: 0.8391,                 loss: 0.3014
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5871s / 152.0670 s
agent0:                 episode reward: -0.5778,                 loss: nan
agent1:                 episode reward: 0.5778,                 loss: 0.3078
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5971s / 152.6641 s
agent0:                 episode reward: -0.6670,                 loss: nan
agent1:                 episode reward: 0.6670,                 loss: 0.3089
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5963s / 153.2604 s
agent0:                 episode reward: -0.5022,                 loss: nan
agent1:                 episode reward: 0.5022,                 loss: 0.3163
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5893s / 153.8497 s
agent0:                 episode reward: -0.4369,                 loss: nan
agent1:                 episode reward: 0.4369,                 loss: 0.3115
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6028s / 154.4525 s
agent0:                 episode reward: -0.6806,                 loss: nan
agent1:                 episode reward: 0.6806,                 loss: 0.3096
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6063s / 155.0588 s
agent0:                 episode reward: -0.4326,                 loss: nan
agent1:                 episode reward: 0.4326,                 loss: 0.3111
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 155.6601 s
agent0:                 episode reward: -0.3719,                 loss: nan
agent1:                 episode reward: 0.3719,                 loss: 0.3099
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6102s / 156.2704 s
agent0:                 episode reward: -0.4397,                 loss: nan
agent1:                 episode reward: 0.4397,                 loss: 0.3121
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6037s / 156.8740 s
agent0:                 episode reward: -0.3256,                 loss: nan
agent1:                 episode reward: 0.3256,                 loss: 0.3129
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6014s / 157.4754 s
agent0:                 episode reward: -0.7085,                 loss: nan
agent1:                 episode reward: 0.7085,                 loss: 0.3117
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5929s / 158.0683 s
agent0:                 episode reward: -0.7597,                 loss: nan
agent1:                 episode reward: 0.7597,                 loss: 0.3108
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5960s / 158.6643 s
agent0:                 episode reward: -0.7623,                 loss: nan
agent1:                 episode reward: 0.7623,                 loss: 0.3112
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5948s / 159.2590 s
agent0:                 episode reward: -0.5653,                 loss: nan
agent1:                 episode reward: 0.5653,                 loss: 0.3141
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6007s / 159.8598 s
agent0:                 episode reward: -0.5090,                 loss: nan
agent1:                 episode reward: 0.5090,                 loss: 0.3096
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5987s / 160.4585 s
agent0:                 episode reward: -0.4772,                 loss: nan
agent1:                 episode reward: 0.4772,                 loss: 0.3084
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6034s / 161.0619 s
agent0:                 episode reward: -0.8428,                 loss: nan
agent1:                 episode reward: 0.8428,                 loss: 0.3142
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6050s / 161.6669 s
agent0:                 episode reward: -0.9618,                 loss: nan
agent1:                 episode reward: 0.9618,                 loss: 0.3137
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5935s / 162.2604 s
agent0:                 episode reward: -0.5125,                 loss: nan
agent1:                 episode reward: 0.5125,                 loss: 0.3076
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 162.8599 s
agent0:                 episode reward: -0.3846,                 loss: nan
agent1:                 episode reward: 0.3846,                 loss: 0.3074
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 163.4551 s
agent0:                 episode reward: -0.5292,                 loss: nan
agent1:                 episode reward: 0.5292,                 loss: 0.3097
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6068s / 164.0620 s
agent0:                 episode reward: -0.2889,                 loss: nan
agent1:                 episode reward: 0.2889,                 loss: 0.3076
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6000s / 164.6620 s
agent0:                 episode reward: -0.7298,                 loss: nan
agent1:                 episode reward: 0.7298,                 loss: 0.3098
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6053s / 165.2674 s
agent0:                 episode reward: -1.0944,                 loss: nan
agent1:                 episode reward: 1.0944,                 loss: 0.3088
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6029s / 165.8703 s
agent0:                 episode reward: -0.7563,                 loss: nan
agent1:                 episode reward: 0.7563,                 loss: 0.3090
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6020s / 166.4723 s
agent0:                 episode reward: -0.6267,                 loss: nan
agent1:                 episode reward: 0.6267,                 loss: 0.3066
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5978s / 167.0701 s
agent0:                 episode reward: -0.6400,                 loss: nan
agent1:                 episode reward: 0.6400,                 loss: 0.3066
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6065s / 167.6765 s
agent0:                 episode reward: -0.4552,                 loss: nan
agent1:                 episode reward: 0.4552,                 loss: 0.3052
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5999s / 168.2764 s
agent0:                 episode reward: -0.2325,                 loss: nan
agent1:                 episode reward: 0.2325,                 loss: 0.3084
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6066s / 168.8831 s
agent0:                 episode reward: -0.4121,                 loss: nan
agent1:                 episode reward: 0.4121,                 loss: 0.3066
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6137s / 169.4967 s
agent0:                 episode reward: -0.7044,                 loss: nan
agent1:                 episode reward: 0.7044,                 loss: 0.3065
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6089s / 170.1056 s
agent0:                 episode reward: -0.7050,                 loss: nan
agent1:                 episode reward: 0.7050,                 loss: 0.3052
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6022s / 170.7078 s
agent0:                 episode reward: -0.7354,                 loss: nan
agent1:                 episode reward: 0.7354,                 loss: 0.3047
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6120s / 171.3198 s
agent0:                 episode reward: -0.5954,                 loss: nan
agent1:                 episode reward: 0.5954,                 loss: 0.3085
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6110s / 171.9308 s
agent0:                 episode reward: -0.8185,                 loss: nan
agent1:                 episode reward: 0.8185,                 loss: 0.3072
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6132s / 172.5441 s
agent0:                 episode reward: -0.4430,                 loss: nan
agent1:                 episode reward: 0.4430,                 loss: 0.2972
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6052s / 173.1492 s
agent0:                 episode reward: -0.2731,                 loss: nan
agent1:                 episode reward: 0.2731,                 loss: 0.2954
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6142s / 173.7635 s
agent0:                 episode reward: -0.7536,                 loss: nan
agent1:                 episode reward: 0.7536,                 loss: 0.2957
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6088s / 174.3722 s
agent0:                 episode reward: -0.1991,                 loss: nan
agent1:                 episode reward: 0.1991,                 loss: 0.2956
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6016s / 174.9738 s
agent0:                 episode reward: -0.6141,                 loss: nan
agent1:                 episode reward: 0.6141,                 loss: 0.2953
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5971s / 175.5710 s
agent0:                 episode reward: -0.9292,                 loss: nan
agent1:                 episode reward: 0.9292,                 loss: 0.2952
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6040s / 176.1750 s
agent0:                 episode reward: -0.5205,                 loss: nan
agent1:                 episode reward: 0.5205,                 loss: 0.2995
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6099s / 176.7849 s
agent0:                 episode reward: -0.6850,                 loss: nan
agent1:                 episode reward: 0.6850,                 loss: 0.2962
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6170s / 177.4019 s
agent0:                 episode reward: -0.1701,                 loss: nan
agent1:                 episode reward: 0.1701,                 loss: 0.2960
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6050s / 178.0069 s
agent0:                 episode reward: -0.7890,                 loss: nan
agent1:                 episode reward: 0.7890,                 loss: 0.2984
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 178.6065 s
agent0:                 episode reward: -0.3168,                 loss: nan
agent1:                 episode reward: 0.3168,                 loss: 0.2923
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6120s / 179.2184 s
agent0:                 episode reward: -0.6980,                 loss: nan
agent1:                 episode reward: 0.6980,                 loss: 0.2961
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6042s / 179.8226 s
agent0:                 episode reward: -0.3458,                 loss: nan
agent1:                 episode reward: 0.3458,                 loss: 0.2957
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6039s / 180.4265 s
agent0:                 episode reward: -0.8557,                 loss: nan
agent1:                 episode reward: 0.8557,                 loss: 0.2980
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6041s / 181.0305 s
agent0:                 episode reward: -0.8827,                 loss: nan
agent1:                 episode reward: 0.8827,                 loss: 0.2959
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6137s / 181.6442 s
agent0:                 episode reward: -0.5152,                 loss: nan
agent1:                 episode reward: 0.5152,                 loss: 0.2976
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6072s / 182.2514 s
agent0:                 episode reward: -0.6657,                 loss: nan
agent1:                 episode reward: 0.6657,                 loss: 0.3063
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6128s / 182.8642 s
agent0:                 episode reward: -1.0251,                 loss: nan
agent1:                 episode reward: 1.0251,                 loss: 0.3231
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6167s / 183.4809 s
agent0:                 episode reward: -0.9263,                 loss: nan
agent1:                 episode reward: 0.9263,                 loss: 0.3265
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6022s / 184.0831 s
agent0:                 episode reward: -0.2783,                 loss: nan
agent1:                 episode reward: 0.2783,                 loss: 0.3202
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6139s / 184.6970 s
agent0:                 episode reward: -0.4634,                 loss: nan
agent1:                 episode reward: 0.4634,                 loss: 0.3253
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6106s / 185.3076 s
agent0:                 episode reward: -0.2922,                 loss: nan
agent1:                 episode reward: 0.2922,                 loss: 0.3243
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6095s / 185.9171 s
agent0:                 episode reward: -0.3176,                 loss: nan
agent1:                 episode reward: 0.3176,                 loss: 0.3223
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6122s / 186.5294 s
agent0:                 episode reward: -0.7050,                 loss: nan
agent1:                 episode reward: 0.7050,                 loss: 0.3218
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6170s / 187.1463 s
agent0:                 episode reward: -0.5430,                 loss: nan
agent1:                 episode reward: 0.5430,                 loss: 0.3227
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6036s / 187.7499 s
agent0:                 episode reward: -0.5951,                 loss: nan
agent1:                 episode reward: 0.5951,                 loss: 0.3222
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6037s / 188.3536 s
agent0:                 episode reward: -0.5036,                 loss: nan
agent1:                 episode reward: 0.5036,                 loss: 0.3219
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6082s / 188.9619 s
agent0:                 episode reward: -0.4779,                 loss: nan
agent1:                 episode reward: 0.4779,                 loss: 0.3215
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6151s / 189.5770 s
agent0:                 episode reward: -0.3543,                 loss: nan
agent1:                 episode reward: 0.3543,                 loss: 0.3220
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6064s / 190.1834 s
agent0:                 episode reward: -0.2396,                 loss: nan
agent1:                 episode reward: 0.2396,                 loss: 0.3198
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6146s / 190.7981 s
agent0:                 episode reward: -0.2766,                 loss: nan
agent1:                 episode reward: 0.2766,                 loss: 0.3216
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6016s / 191.3997 s
agent0:                 episode reward: -0.0486,                 loss: nan
agent1:                 episode reward: 0.0486,                 loss: 0.3233
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6020s / 192.0017 s
agent0:                 episode reward: -0.6070,                 loss: nan
agent1:                 episode reward: 0.6070,                 loss: 0.3230
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6125s / 192.6142 s
agent0:                 episode reward: -0.4365,                 loss: nan
agent1:                 episode reward: 0.4365,                 loss: 0.3133
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6092s / 193.2234 s
agent0:                 episode reward: -0.4800,                 loss: nan
agent1:                 episode reward: 0.4800,                 loss: 0.3089
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6151s / 193.8385 s
agent0:                 episode reward: -0.3314,                 loss: nan
agent1:                 episode reward: 0.3314,                 loss: 0.3077
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6037s / 194.4422 s
agent0:                 episode reward: -0.8305,                 loss: nan
agent1:                 episode reward: 0.8305,                 loss: 0.3080
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6044s / 195.0466 s
agent0:                 episode reward: -0.5872,                 loss: nan
agent1:                 episode reward: 0.5872,                 loss: 0.3055
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6054s / 195.6520 s
agent0:                 episode reward: -0.5708,                 loss: nan
agent1:                 episode reward: 0.5708,                 loss: 0.3100
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6104s / 196.2625 s
agent0:                 episode reward: -0.3131,                 loss: nan
agent1:                 episode reward: 0.3131,                 loss: 0.3063
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6054s / 196.8679 s
agent0:                 episode reward: -0.3114,                 loss: nan
agent1:                 episode reward: 0.3114,                 loss: 0.3083
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6080s / 197.4759 s
agent0:                 episode reward: -0.5297,                 loss: nan
agent1:                 episode reward: 0.5297,                 loss: 0.3065
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6114s / 198.0872 s
agent0:                 episode reward: -0.5044,                 loss: nan
agent1:                 episode reward: 0.5044,                 loss: 0.3066
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6107s / 198.6980 s
agent0:                 episode reward: -0.8186,                 loss: nan
agent1:                 episode reward: 0.8186,                 loss: 0.3063
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6099s / 199.3078 s
agent0:                 episode reward: -0.5290,                 loss: nan
agent1:                 episode reward: 0.5290,                 loss: 0.3057
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6025s / 199.9103 s
agent0:                 episode reward: -0.6370,                 loss: nan
agent1:                 episode reward: 0.6370,                 loss: 0.3067
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6170s / 200.5273 s
agent0:                 episode reward: -0.8369,                 loss: nan
agent1:                 episode reward: 0.8369,                 loss: 0.3056
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6114s / 201.1387 s
agent0:                 episode reward: -0.3954,                 loss: nan
agent1:                 episode reward: 0.3954,                 loss: 0.3074
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6090s / 201.7477 s
agent0:                 episode reward: -0.7532,                 loss: nan
agent1:                 episode reward: 0.7532,                 loss: 0.3074
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6110s / 202.3587 s
agent0:                 episode reward: -0.6945,                 loss: nan
agent1:                 episode reward: 0.6945,                 loss: 0.3085
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6153s / 202.9740 s
agent0:                 episode reward: -0.3807,                 loss: nan
agent1:                 episode reward: 0.3807,                 loss: 0.3041
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6184s / 203.5924 s
agent0:                 episode reward: -0.7263,                 loss: nan
agent1:                 episode reward: 0.7263,                 loss: 0.3027
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6154s / 204.2078 s
agent0:                 episode reward: -0.8069,                 loss: nan
agent1:                 episode reward: 0.8069,                 loss: 0.3038
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6274s / 204.8352 s
agent0:                 episode reward: -0.3466,                 loss: nan
agent1:                 episode reward: 0.3466,                 loss: 0.3053
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6095s / 205.4447 s
agent0:                 episode reward: -0.6684,                 loss: nan
agent1:                 episode reward: 0.6684,                 loss: 0.3039
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6093s / 206.0540 s
agent0:                 episode reward: -0.6435,                 loss: nan
agent1:                 episode reward: 0.6435,                 loss: 0.3026
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6104s / 206.6644 s
agent0:                 episode reward: -0.5201,                 loss: nan
agent1:                 episode reward: 0.5201,                 loss: 0.3022
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6199s / 207.2843 s
agent0:                 episode reward: -0.4302,                 loss: nan
agent1:                 episode reward: 0.4302,                 loss: 0.3013
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6084s / 207.8928 s
agent0:                 episode reward: -0.8494,                 loss: nan
agent1:                 episode reward: 0.8494,                 loss: 0.3077
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6247s / 208.5175 s
agent0:                 episode reward: -1.1290,                 loss: nan
agent1:                 episode reward: 1.1290,                 loss: 0.3040
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6132s / 209.1308 s
agent0:                 episode reward: -0.4536,                 loss: nan
agent1:                 episode reward: 0.4536,                 loss: 0.3074
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6102s / 209.7409 s
agent0:                 episode reward: -0.5226,                 loss: nan
agent1:                 episode reward: 0.5226,                 loss: 0.3022
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6204s / 210.3613 s
agent0:                 episode reward: -0.0727,                 loss: nan
agent1:                 episode reward: 0.0727,                 loss: 0.3043
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6272s / 210.9885 s
agent0:                 episode reward: -0.8433,                 loss: nan
agent1:                 episode reward: 0.8433,                 loss: 0.3039
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6160s / 211.6045 s
agent0:                 episode reward: -0.2900,                 loss: nan
agent1:                 episode reward: 0.2900,                 loss: 0.3053
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6223s / 212.2268 s
agent0:                 episode reward: -0.2246,                 loss: nan
agent1:                 episode reward: 0.2246,                 loss: 0.3045
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6180s / 212.8448 s
agent0:                 episode reward: -0.3706,                 loss: nan
agent1:                 episode reward: 0.3706,                 loss: 0.3137
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6131s / 213.4579 s
agent0:                 episode reward: -0.6434,                 loss: nan
agent1:                 episode reward: 0.6434,                 loss: 0.3214
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6213s / 214.0792 s
agent0:                 episode reward: -0.5983,                 loss: nan
agent1:                 episode reward: 0.5983,                 loss: 0.3255
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6198s / 214.6990 s
agent0:                 episode reward: -0.7083,                 loss: nan
agent1:                 episode reward: 0.7083,                 loss: 0.3189
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6181s / 215.3171 s
agent0:                 episode reward: -0.4980,                 loss: nan
agent1:                 episode reward: 0.4980,                 loss: 0.3225
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6186s / 215.9357 s
agent0:                 episode reward: -0.0579,                 loss: nan
agent1:                 episode reward: 0.0579,                 loss: 0.3224
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6245s / 216.5602 s
agent0:                 episode reward: -0.8570,                 loss: nan
agent1:                 episode reward: 0.8570,                 loss: 0.3240
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6201s / 217.1803 s
agent0:                 episode reward: -0.7279,                 loss: nan
agent1:                 episode reward: 0.7279,                 loss: 0.3227
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6215s / 217.8018 s
agent0:                 episode reward: -0.7431,                 loss: nan
agent1:                 episode reward: 0.7431,                 loss: 0.3222
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6161s / 218.4179 s
agent0:                 episode reward: -0.3382,                 loss: nan
agent1:                 episode reward: 0.3382,                 loss: 0.3242
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6146s / 219.0324 s
agent0:                 episode reward: -0.5842,                 loss: nan
agent1:                 episode reward: 0.5842,                 loss: 0.3226
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6168s / 219.6492 s
agent0:                 episode reward: -0.4614,                 loss: nan
agent1:                 episode reward: 0.4614,                 loss: 0.3218
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6136s / 220.2628 s
agent0:                 episode reward: -0.7596,                 loss: nan
agent1:                 episode reward: 0.7596,                 loss: 0.3239
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6178s / 220.8806 s
agent0:                 episode reward: -0.6305,                 loss: nan
agent1:                 episode reward: 0.6305,                 loss: 0.3224
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6105s / 221.4912 s
agent0:                 episode reward: -0.7445,                 loss: nan
agent1:                 episode reward: 0.7445,                 loss: 0.3238
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6189s / 222.1100 s
agent0:                 episode reward: -0.7564,                 loss: nan
agent1:                 episode reward: 0.7564,                 loss: 0.3210
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6147s / 222.7248 s
agent0:                 episode reward: -0.7877,                 loss: nan
agent1:                 episode reward: 0.7877,                 loss: 0.3235
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6294s / 223.3542 s
agent0:                 episode reward: -0.5827,                 loss: nan
agent1:                 episode reward: 0.5827,                 loss: 0.3155
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6194s / 223.9735 s
agent0:                 episode reward: -0.8832,                 loss: nan
agent1:                 episode reward: 0.8832,                 loss: 0.3145
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6162s / 224.5898 s
agent0:                 episode reward: -0.4442,                 loss: nan
agent1:                 episode reward: 0.4442,                 loss: 0.3115
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6119s / 225.2016 s
agent0:                 episode reward: -1.0101,                 loss: nan
agent1:                 episode reward: 1.0101,                 loss: 0.3127
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6214s / 225.8230 s
agent0:                 episode reward: -0.4945,                 loss: nan
agent1:                 episode reward: 0.4945,                 loss: 0.3118
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6164s / 226.4394 s
agent0:                 episode reward: -0.6015,                 loss: nan
agent1:                 episode reward: 0.6015,                 loss: 0.3148
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6256s / 227.0650 s
agent0:                 episode reward: -0.3679,                 loss: nan
agent1:                 episode reward: 0.3679,                 loss: 0.3160
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6268s / 227.6918 s
agent0:                 episode reward: -0.3758,                 loss: nan
agent1:                 episode reward: 0.3758,                 loss: 0.3147
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6282s / 228.3200 s
agent0:                 episode reward: -0.3252,                 loss: nan
agent1:                 episode reward: 0.3252,                 loss: 0.3145
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6202s / 228.9402 s
agent0:                 episode reward: -0.4820,                 loss: nan
agent1:                 episode reward: 0.4820,                 loss: 0.3132
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6238s / 229.5640 s
agent0:                 episode reward: -0.6459,                 loss: nan
agent1:                 episode reward: 0.6459,                 loss: 0.3134
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6192s / 230.1832 s
agent0:                 episode reward: -0.1625,                 loss: nan
agent1:                 episode reward: 0.1625,                 loss: 0.3163
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6216s / 230.8048 s
agent0:                 episode reward: -0.6495,                 loss: nan
agent1:                 episode reward: 0.6495,                 loss: 0.3131
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6252s / 231.4300 s
agent0:                 episode reward: -0.4638,                 loss: nan
agent1:                 episode reward: 0.4638,                 loss: 0.3121
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6252s / 232.0552 s
agent0:                 episode reward: -0.5708,                 loss: nan
agent1:                 episode reward: 0.5708,                 loss: 0.3132
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6186s / 232.6738 s
agent0:                 episode reward: -0.6510,                 loss: nan
agent1:                 episode reward: 0.6510,                 loss: 0.3131
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6292s / 233.3030 s
agent0:                 episode reward: -0.6872,                 loss: nan
agent1:                 episode reward: 0.6872,                 loss: 0.3143
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6203s / 233.9233 s
agent0:                 episode reward: -0.4770,                 loss: nan
agent1:                 episode reward: 0.4770,                 loss: 0.3087
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6195s / 234.5428 s
agent0:                 episode reward: -0.4602,                 loss: nan
agent1:                 episode reward: 0.4602,                 loss: 0.3100
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6267s / 235.1695 s
agent0:                 episode reward: -0.4493,                 loss: nan
agent1:                 episode reward: 0.4493,                 loss: 0.3085
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6223s / 235.7918 s
agent0:                 episode reward: -0.5661,                 loss: nan
agent1:                 episode reward: 0.5661,                 loss: 0.3119
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6247s / 236.4165 s
agent0:                 episode reward: -0.9303,                 loss: nan
agent1:                 episode reward: 0.9303,                 loss: 0.3048
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6236s / 237.0400 s
agent0:                 episode reward: -0.3457,                 loss: nan
agent1:                 episode reward: 0.3457,                 loss: 0.3112
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6257s / 237.6657 s
agent0:                 episode reward: -0.9048,                 loss: nan
agent1:                 episode reward: 0.9048,                 loss: 0.3106
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6255s / 238.2912 s
agent0:                 episode reward: -0.5482,                 loss: nan
agent1:                 episode reward: 0.5482,                 loss: 0.3073
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6327s / 238.9239 s
agent0:                 episode reward: -0.6960,                 loss: nan
agent1:                 episode reward: 0.6960,                 loss: 0.3095
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6209s / 239.5449 s
agent0:                 episode reward: -0.6604,                 loss: nan
agent1:                 episode reward: 0.6604,                 loss: 0.3077
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6204s / 240.1653 s
agent0:                 episode reward: -0.9363,                 loss: nan
agent1:                 episode reward: 0.9363,                 loss: 0.3090
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6188s / 240.7841 s
agent0:                 episode reward: -0.5361,                 loss: nan
agent1:                 episode reward: 0.5361,                 loss: 0.3102
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6223s / 241.4064 s
agent0:                 episode reward: -0.6031,                 loss: nan
agent1:                 episode reward: 0.6031,                 loss: 0.3114
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6256s / 242.0320 s
agent0:                 episode reward: -0.7105,                 loss: nan
agent1:                 episode reward: 0.7105,                 loss: 0.3083
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6237s / 242.6557 s
agent0:                 episode reward: -0.3937,                 loss: nan
agent1:                 episode reward: 0.3937,                 loss: 0.3114
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6291s / 243.2848 s
agent0:                 episode reward: -0.8352,                 loss: nan
agent1:                 episode reward: 0.8352,                 loss: 0.3102
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6264s / 243.9112 s
agent0:                 episode reward: -0.4302,                 loss: nan
agent1:                 episode reward: 0.4302,                 loss: 0.3152
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6151s / 244.5263 s
agent0:                 episode reward: -0.4543,                 loss: nan
agent1:                 episode reward: 0.4543,                 loss: 0.3204
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6202s / 245.1465 s
agent0:                 episode reward: -0.3070,                 loss: nan
agent1:                 episode reward: 0.3070,                 loss: 0.3197
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6231s / 245.7696 s
agent0:                 episode reward: -0.7577,                 loss: nan
agent1:                 episode reward: 0.7577,                 loss: 0.3220
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6179s / 246.3875 s
agent0:                 episode reward: -0.4428,                 loss: nan
agent1:                 episode reward: 0.4428,                 loss: 0.3229
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6234s / 247.0109 s
agent0:                 episode reward: -0.5405,                 loss: nan
agent1:                 episode reward: 0.5405,                 loss: 0.3249
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6384s / 247.6493 s
agent0:                 episode reward: -0.6084,                 loss: nan
agent1:                 episode reward: 0.6084,                 loss: 0.3239
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6226s / 248.2718 s
agent0:                 episode reward: -0.2799,                 loss: nan
agent1:                 episode reward: 0.2799,                 loss: 0.3246
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6259s / 248.8978 s
agent0:                 episode reward: -0.4803,                 loss: nan
agent1:                 episode reward: 0.4803,                 loss: 0.3227
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6223s / 249.5201 s
agent0:                 episode reward: -0.5506,                 loss: nan
agent1:                 episode reward: 0.5506,                 loss: 0.3248
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6176s / 250.1376 s
agent0:                 episode reward: -0.4145,                 loss: nan
agent1:                 episode reward: 0.4145,                 loss: 0.3194
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6279s / 250.7655 s
agent0:                 episode reward: -0.6537,                 loss: nan
agent1:                 episode reward: 0.6537,                 loss: 0.3231
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6238s / 251.3893 s
agent0:                 episode reward: -0.4540,                 loss: nan
agent1:                 episode reward: 0.4540,                 loss: 0.3221
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6233s / 252.0126 s
agent0:                 episode reward: -0.6160,                 loss: nan
agent1:                 episode reward: 0.6160,                 loss: 0.3238
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6275s / 252.6401 s
agent0:                 episode reward: -0.3577,                 loss: nan
agent1:                 episode reward: 0.3577,                 loss: 0.3200
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6280s / 253.2681 s
agent0:                 episode reward: -0.3496,                 loss: nan
agent1:                 episode reward: 0.3496,                 loss: 0.3209
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6281s / 253.8962 s
agent0:                 episode reward: -0.6104,                 loss: nan
agent1:                 episode reward: 0.6104,                 loss: 0.3225
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6232s / 254.5194 s
agent0:                 episode reward: -0.8193,                 loss: nan
agent1:                 episode reward: 0.8193,                 loss: 0.3251
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6266s / 255.1460 s
agent0:                 episode reward: -0.4964,                 loss: nan
agent1:                 episode reward: 0.4964,                 loss: 0.3229
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6224s / 255.7684 s
agent0:                 episode reward: -0.6763,                 loss: nan
agent1:                 episode reward: 0.6763,                 loss: 0.3236
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6270s / 256.3953 s
agent0:                 episode reward: -0.3543,                 loss: nan
agent1:                 episode reward: 0.3543,                 loss: 0.3251
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6315s / 257.0268 s
agent0:                 episode reward: -0.3045,                 loss: nan
agent1:                 episode reward: 0.3045,                 loss: 0.3225
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6329s / 257.6597 s
agent0:                 episode reward: -0.5838,                 loss: nan
agent1:                 episode reward: 0.5838,                 loss: 0.3222
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6259s / 258.2857 s
agent0:                 episode reward: -0.3263,                 loss: nan
agent1:                 episode reward: 0.3263,                 loss: 0.3252
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6286s / 258.9143 s
agent0:                 episode reward: -0.2351,                 loss: nan
agent1:                 episode reward: 0.2351,                 loss: 0.3243
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6337s / 259.5480 s
agent0:                 episode reward: -0.2519,                 loss: nan
agent1:                 episode reward: 0.2519,                 loss: 0.3251
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6301s / 260.1782 s
agent0:                 episode reward: -0.6238,                 loss: nan
agent1:                 episode reward: 0.6238,                 loss: 0.3249
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6334s / 260.8116 s
agent0:                 episode reward: -0.6793,                 loss: nan
agent1:                 episode reward: 0.6793,                 loss: 0.3261
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6268s / 261.4384 s
agent0:                 episode reward: -0.4656,                 loss: nan
agent1:                 episode reward: 0.4656,                 loss: 0.3232
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6215s / 262.0598 s
agent0:                 episode reward: -0.2353,                 loss: nan
agent1:                 episode reward: 0.2353,                 loss: 0.3244
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6277s / 262.6876 s
agent0:                 episode reward: -0.4863,                 loss: nan
agent1:                 episode reward: 0.4863,                 loss: 0.3200
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6320s / 263.3196 s
agent0:                 episode reward: -0.5750,                 loss: nan
agent1:                 episode reward: 0.5750,                 loss: 0.3201
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6283s / 263.9479 s
agent0:                 episode reward: -0.7024,                 loss: nan
agent1:                 episode reward: 0.7024,                 loss: 0.3242
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6261s / 264.5740 s
agent0:                 episode reward: -0.3974,                 loss: nan
agent1:                 episode reward: 0.3974,                 loss: 0.3236
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6275s / 265.2015 s
agent0:                 episode reward: -0.6634,                 loss: nan
agent1:                 episode reward: 0.6634,                 loss: 0.3058
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6391s / 265.8406 s
agent0:                 episode reward: -0.5656,                 loss: nan
agent1:                 episode reward: 0.5656,                 loss: 0.3058
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6288s / 266.4694 s
agent0:                 episode reward: -0.4314,                 loss: nan
agent1:                 episode reward: 0.4314,                 loss: 0.3042
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6383s / 267.1077 s
agent0:                 episode reward: -0.3853,                 loss: nan
agent1:                 episode reward: 0.3853,                 loss: 0.3043
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6282s / 267.7360 s
agent0:                 episode reward: -0.4427,                 loss: nan
agent1:                 episode reward: 0.4427,                 loss: 0.3049
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6217s / 268.3576 s
agent0:                 episode reward: -0.2335,                 loss: nan
agent1:                 episode reward: 0.2335,                 loss: 0.3034
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6315s / 268.9891 s
agent0:                 episode reward: -0.9548,                 loss: nan
agent1:                 episode reward: 0.9548,                 loss: 0.3043
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6455s / 269.6346 s
agent0:                 episode reward: -0.2469,                 loss: nan
agent1:                 episode reward: 0.2469,                 loss: 0.3068
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6321s / 270.2667 s
agent0:                 episode reward: -0.8998,                 loss: nan
agent1:                 episode reward: 0.8998,                 loss: 0.3074
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6321s / 270.8988 s
agent0:                 episode reward: -0.5050,                 loss: nan
agent1:                 episode reward: 0.5050,                 loss: 0.3053
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6400s / 271.5388 s
agent0:                 episode reward: -0.3831,                 loss: nan
agent1:                 episode reward: 0.3831,                 loss: 0.3053
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6429s / 272.1817 s
agent0:                 episode reward: -0.3301,                 loss: nan
agent1:                 episode reward: 0.3301,                 loss: 0.3040
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6397s / 272.8214 s
agent0:                 episode reward: -0.5763,                 loss: nan
agent1:                 episode reward: 0.5763,                 loss: 0.3050
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6373s / 273.4587 s
agent0:                 episode reward: -0.8095,                 loss: nan
agent1:                 episode reward: 0.8095,                 loss: 0.3043
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6323s / 274.0910 s
agent0:                 episode reward: -0.4530,                 loss: nan
agent1:                 episode reward: 0.4530,                 loss: 0.3015
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6389s / 274.7299 s
agent0:                 episode reward: -0.4362,                 loss: nan
agent1:                 episode reward: 0.4362,                 loss: 0.3049
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6434s / 275.3734 s
agent0:                 episode reward: -0.9053,                 loss: nan
agent1:                 episode reward: 0.9053,                 loss: 0.3132
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6335s / 276.0069 s
agent0:                 episode reward: -0.6723,                 loss: nan
agent1:                 episode reward: 0.6723,                 loss: 0.3234
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6383s / 276.6452 s
agent0:                 episode reward: -0.5132,                 loss: nan
agent1:                 episode reward: 0.5132,                 loss: 0.3249
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6341s / 277.2793 s
agent0:                 episode reward: -0.4234,                 loss: nan
agent1:                 episode reward: 0.4234,                 loss: 0.3233
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6314s / 277.9107 s
agent0:                 episode reward: -0.5299,                 loss: nan
agent1:                 episode reward: 0.5299,                 loss: 0.3259
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6317s / 278.5424 s
agent0:                 episode reward: -0.7292,                 loss: nan
agent1:                 episode reward: 0.7292,                 loss: 0.3255
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6506s / 279.1930 s
agent0:                 episode reward: -0.2152,                 loss: nan
agent1:                 episode reward: 0.2152,                 loss: 0.3215
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6370s / 279.8300 s
agent0:                 episode reward: -0.3240,                 loss: nan
agent1:                 episode reward: 0.3240,                 loss: 0.3234
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6398s / 280.4698 s
agent0:                 episode reward: -0.4775,                 loss: nan
agent1:                 episode reward: 0.4775,                 loss: 0.3242
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6366s / 281.1064 s
agent0:                 episode reward: -0.6950,                 loss: nan
agent1:                 episode reward: 0.6950,                 loss: 0.3231
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6293s / 281.7356 s
agent0:                 episode reward: -0.5232,                 loss: nan
agent1:                 episode reward: 0.5232,                 loss: 0.3229
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6398s / 282.3755 s
agent0:                 episode reward: -0.9920,                 loss: nan
agent1:                 episode reward: 0.9920,                 loss: 0.3263
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6447s / 283.0201 s
agent0:                 episode reward: -0.4519,                 loss: nan
agent1:                 episode reward: 0.4519,                 loss: 0.3231
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6383s / 283.6585 s
agent0:                 episode reward: -0.3725,                 loss: nan
agent1:                 episode reward: 0.3725,                 loss: 0.3242
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6431s / 284.3016 s
agent0:                 episode reward: -0.8252,                 loss: nan
agent1:                 episode reward: 0.8252,                 loss: 0.3245
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6388s / 284.9404 s
agent0:                 episode reward: -0.0929,                 loss: nan
agent1:                 episode reward: 0.0929,                 loss: 0.3244
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6423s / 285.5827 s
agent0:                 episode reward: -0.7397,                 loss: nan
agent1:                 episode reward: 0.7397,                 loss: 0.3239
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6435s / 286.2262 s
agent0:                 episode reward: -0.6843,                 loss: nan
agent1:                 episode reward: 0.6843,                 loss: 0.3243
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6501s / 286.8763 s
agent0:                 episode reward: -0.3043,                 loss: nan
agent1:                 episode reward: 0.3043,                 loss: 0.3237
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6409s / 287.5173 s
agent0:                 episode reward: -0.3295,                 loss: nan
agent1:                 episode reward: 0.3295,                 loss: 0.3225
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6515s / 288.1688 s
agent0:                 episode reward: -0.7977,                 loss: nan
agent1:                 episode reward: 0.7977,                 loss: 0.3210
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6511s / 288.8199 s
agent0:                 episode reward: -0.4101,                 loss: nan
agent1:                 episode reward: 0.4101,                 loss: 0.3232
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6448s / 289.4647 s
agent0:                 episode reward: -0.4037,                 loss: nan
agent1:                 episode reward: 0.4037,                 loss: 0.3239
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6399s / 290.1046 s
agent0:                 episode reward: -1.0616,                 loss: nan
agent1:                 episode reward: 1.0616,                 loss: 0.3238
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6346s / 290.7392 s
agent0:                 episode reward: -0.5415,                 loss: nan
agent1:                 episode reward: 0.5415,                 loss: 0.3240
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6412s / 291.3804 s
agent0:                 episode reward: -0.7348,                 loss: nan
agent1:                 episode reward: 0.7348,                 loss: 0.3259
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6480s / 292.0283 s
agent0:                 episode reward: -0.4865,                 loss: nan
agent1:                 episode reward: 0.4865,                 loss: 0.3207
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6403s / 292.6686 s
agent0:                 episode reward: -0.4262,                 loss: nan
agent1:                 episode reward: 0.4262,                 loss: 0.3242
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6385s / 293.3071 s
agent0:                 episode reward: -0.6992,                 loss: nan
agent1:                 episode reward: 0.6992,                 loss: 0.3261
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6433s / 293.9505 s
agent0:                 episode reward: -0.9086,                 loss: nan
agent1:                 episode reward: 0.9086,                 loss: 0.3250
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6419s / 294.5923 s
agent0:                 episode reward: -0.5056,                 loss: nan
agent1:                 episode reward: 0.5056,                 loss: 0.3247
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6481s / 295.2404 s
agent0:                 episode reward: -0.2605,                 loss: nan
agent1:                 episode reward: 0.2605,                 loss: 0.3257
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6497s / 295.8902 s
agent0:                 episode reward: -0.7349,                 loss: nan
agent1:                 episode reward: 0.7349,                 loss: 0.3247
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6380s / 296.5281 s
agent0:                 episode reward: -0.3986,                 loss: nan
agent1:                 episode reward: 0.3986,                 loss: 0.3226
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6511s / 297.1793 s
agent0:                 episode reward: -0.4898,                 loss: nan
agent1:                 episode reward: 0.4898,                 loss: 0.3167
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6772s / 297.8565 s
agent0:                 episode reward: -0.5068,                 loss: nan
agent1:                 episode reward: 0.5068,                 loss: 0.3190
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6346s / 298.4910 s
agent0:                 episode reward: -0.6714,                 loss: nan
agent1:                 episode reward: 0.6714,                 loss: 0.3176
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6399s / 299.1309 s
agent0:                 episode reward: -0.7572,                 loss: nan
agent1:                 episode reward: 0.7572,                 loss: 0.3186
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6387s / 299.7696 s
agent0:                 episode reward: -0.6022,                 loss: nan
agent1:                 episode reward: 0.6022,                 loss: 0.3205
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6418s / 300.4114 s
agent0:                 episode reward: -0.7183,                 loss: nan
agent1:                 episode reward: 0.7183,                 loss: 0.3184
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6445s / 301.0559 s
agent0:                 episode reward: -0.4488,                 loss: nan
agent1:                 episode reward: 0.4488,                 loss: 0.3165
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6479s / 301.7038 s
agent0:                 episode reward: -0.6053,                 loss: nan
agent1:                 episode reward: 0.6053,                 loss: 0.3154
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6516s / 302.3554 s
agent0:                 episode reward: -0.6084,                 loss: nan
agent1:                 episode reward: 0.6084,                 loss: 0.3171
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6417s / 302.9972 s
agent0:                 episode reward: -0.7808,                 loss: nan
agent1:                 episode reward: 0.7808,                 loss: 0.3169
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6413s / 303.6385 s
agent0:                 episode reward: -0.5427,                 loss: nan
agent1:                 episode reward: 0.5427,                 loss: 0.3165
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6369s / 304.2754 s
agent0:                 episode reward: -0.2071,                 loss: nan
agent1:                 episode reward: 0.2071,                 loss: 0.3178
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6375s / 304.9129 s
agent0:                 episode reward: -0.1739,                 loss: nan
agent1:                 episode reward: 0.1739,                 loss: 0.3166
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6437s / 305.5566 s
agent0:                 episode reward: -0.7876,                 loss: nan
agent1:                 episode reward: 0.7876,                 loss: 0.3214
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6667s / 306.2233 s
agent0:                 episode reward: -0.5906,                 loss: nan
agent1:                 episode reward: 0.5906,                 loss: 0.3160
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6363s / 306.8596 s
agent0:                 episode reward: 0.0420,                 loss: nan
agent1:                 episode reward: -0.0420,                 loss: 0.3181
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6461s / 307.5057 s
agent0:                 episode reward: -1.0483,                 loss: nan
agent1:                 episode reward: 1.0483,                 loss: 0.3206
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6495s / 308.1552 s
agent0:                 episode reward: -0.5147,                 loss: nan
agent1:                 episode reward: 0.5147,                 loss: 0.3239
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6534s / 308.8086 s
agent0:                 episode reward: -0.8093,                 loss: nan
agent1:                 episode reward: 0.8093,                 loss: 0.3238
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6431s / 309.4517 s
agent0:                 episode reward: -1.0386,                 loss: nan
agent1:                 episode reward: 1.0386,                 loss: 0.3225
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6461s / 310.0978 s
agent0:                 episode reward: -0.6752,                 loss: nan
agent1:                 episode reward: 0.6752,                 loss: 0.3225
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6377s / 310.7355 s
agent0:                 episode reward: -0.8584,                 loss: nan
agent1:                 episode reward: 0.8584,                 loss: 0.3221
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6382s / 311.3737 s
agent0:                 episode reward: -0.7930,                 loss: nan
agent1:                 episode reward: 0.7930,                 loss: 0.3231
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6399s / 312.0136 s
agent0:                 episode reward: -0.3911,                 loss: nan
agent1:                 episode reward: 0.3911,                 loss: 0.3204
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6392s / 312.6528 s
agent0:                 episode reward: -1.2098,                 loss: nan
agent1:                 episode reward: 1.2098,                 loss: 0.3241
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6392s / 313.2920 s
agent0:                 episode reward: -0.6746,                 loss: nan
agent1:                 episode reward: 0.6746,                 loss: 0.3263
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6434s / 313.9354 s
agent0:                 episode reward: -0.6248,                 loss: nan
agent1:                 episode reward: 0.6248,                 loss: 0.3247
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6493s / 314.5846 s
agent0:                 episode reward: -0.3410,                 loss: nan
agent1:                 episode reward: 0.3410,                 loss: 0.3248
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6449s / 315.2295 s
agent0:                 episode reward: -0.6341,                 loss: nan
agent1:                 episode reward: 0.6341,                 loss: 0.3226
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6409s / 315.8705 s
agent0:                 episode reward: -0.5382,                 loss: nan
agent1:                 episode reward: 0.5382,                 loss: 0.3224
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6449s / 316.5154 s
agent0:                 episode reward: -0.0535,                 loss: nan
agent1:                 episode reward: 0.0535,                 loss: 0.3224
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6465s / 317.1619 s
agent0:                 episode reward: -0.3613,                 loss: nan
agent1:                 episode reward: 0.3613,                 loss: 0.3277
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6434s / 317.8053 s
agent0:                 episode reward: -0.7242,                 loss: nan
agent1:                 episode reward: 0.7242,                 loss: 0.3235
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6385s / 318.4438 s
agent0:                 episode reward: -0.3298,                 loss: nan
agent1:                 episode reward: 0.3298,                 loss: 0.3241
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6467s / 319.0905 s
agent0:                 episode reward: -0.0283,                 loss: nan
agent1:                 episode reward: 0.0283,                 loss: 0.3265
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6506s / 319.7411 s
agent0:                 episode reward: -0.1781,                 loss: nan
agent1:                 episode reward: 0.1781,                 loss: 0.3230
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6478s / 320.3889 s
agent0:                 episode reward: -0.5963,                 loss: nan
agent1:                 episode reward: 0.5963,                 loss: 0.3261
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6429s / 321.0318 s
agent0:                 episode reward: -0.4564,                 loss: nan
agent1:                 episode reward: 0.4564,                 loss: 0.3243
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6474s / 321.6792 s
agent0:                 episode reward: -0.4258,                 loss: nan
agent1:                 episode reward: 0.4258,                 loss: 0.3268
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6512s / 322.3304 s
agent0:                 episode reward: -0.8578,                 loss: nan
agent1:                 episode reward: 0.8578,                 loss: 0.3249
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6492s / 322.9796 s
agent0:                 episode reward: -0.3713,                 loss: nan
agent1:                 episode reward: 0.3713,                 loss: 0.3246
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6432s / 323.6227 s
agent0:                 episode reward: -0.4992,                 loss: nan
agent1:                 episode reward: 0.4992,                 loss: 0.3266
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6409s / 324.2637 s
agent0:                 episode reward: -0.1459,                 loss: nan
agent1:                 episode reward: 0.1459,                 loss: 0.3246
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6462s / 324.9099 s
agent0:                 episode reward: -0.5511,                 loss: nan
agent1:                 episode reward: 0.5511,                 loss: 0.3243
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6521s / 325.5621 s
agent0:                 episode reward: -0.6319,                 loss: nan
agent1:                 episode reward: 0.6319,                 loss: 0.3240
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6448s / 326.2068 s
agent0:                 episode reward: -0.3660,                 loss: nan
agent1:                 episode reward: 0.3660,                 loss: 0.3256
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6673s / 326.8742 s
agent0:                 episode reward: -0.9946,                 loss: nan
agent1:                 episode reward: 0.9946,                 loss: 0.3256
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6518s / 327.5260 s
agent0:                 episode reward: -0.3831,                 loss: nan
agent1:                 episode reward: 0.3831,                 loss: 0.3259
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6414s / 328.1674 s
agent0:                 episode reward: -0.4873,                 loss: nan
agent1:                 episode reward: 0.4873,                 loss: 0.3236
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6476s / 328.8150 s
agent0:                 episode reward: -0.5877,                 loss: nan
agent1:                 episode reward: 0.5877,                 loss: 0.3234
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6531s / 329.4681 s
agent0:                 episode reward: -0.3616,                 loss: nan
agent1:                 episode reward: 0.3616,                 loss: 0.3147
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6468s / 330.1148 s
agent0:                 episode reward: -0.5852,                 loss: nan
agent1:                 episode reward: 0.5852,                 loss: 0.3112
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6491s / 330.7640 s
agent0:                 episode reward: -0.6795,                 loss: nan
agent1:                 episode reward: 0.6795,                 loss: 0.3110
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6508s / 331.4148 s
agent0:                 episode reward: -0.7011,                 loss: nan
agent1:                 episode reward: 0.7011,                 loss: 0.3102
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6560s / 332.0707 s
agent0:                 episode reward: -0.3948,                 loss: nan
agent1:                 episode reward: 0.3948,                 loss: 0.3094
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6552s / 332.7259 s
agent0:                 episode reward: -0.8370,                 loss: nan
agent1:                 episode reward: 0.8370,                 loss: 0.3110
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6569s / 333.3828 s
agent0:                 episode reward: -0.3359,                 loss: nan
agent1:                 episode reward: 0.3359,                 loss: 0.3122
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6595s / 334.0423 s
agent0:                 episode reward: -0.5666,                 loss: nan
agent1:                 episode reward: 0.5666,                 loss: 0.3112
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6572s / 334.6996 s
agent0:                 episode reward: -0.6824,                 loss: nan
agent1:                 episode reward: 0.6824,                 loss: 0.3110
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6600s / 335.3596 s
agent0:                 episode reward: -1.0310,                 loss: nan
agent1:                 episode reward: 1.0310,                 loss: 0.3110
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6574s / 336.0169 s
agent0:                 episode reward: -0.5906,                 loss: nan
agent1:                 episode reward: 0.5906,                 loss: 0.3125
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6617s / 336.6786 s
agent0:                 episode reward: -0.4639,                 loss: nan
agent1:                 episode reward: 0.4639,                 loss: 0.3109
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6569s / 337.3356 s
agent0:                 episode reward: -0.6013,                 loss: nan
agent1:                 episode reward: 0.6013,                 loss: 0.3126
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6539s / 337.9895 s
agent0:                 episode reward: -0.6155,                 loss: nan
agent1:                 episode reward: 0.6155,                 loss: 0.3128
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6606s / 338.6501 s
agent0:                 episode reward: -0.5283,                 loss: nan
agent1:                 episode reward: 0.5283,                 loss: 0.3127
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6653s / 339.3155 s
agent0:                 episode reward: -0.4627,                 loss: nan
agent1:                 episode reward: 0.4627,                 loss: 0.3126
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6535s / 339.9690 s
agent0:                 episode reward: -0.6128,                 loss: nan
agent1:                 episode reward: 0.6128,                 loss: 0.3210
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6511s / 340.6201 s
agent0:                 episode reward: -0.1556,                 loss: nan
agent1:                 episode reward: 0.1556,                 loss: 0.3285
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6567s / 341.2768 s
agent0:                 episode reward: -0.5761,                 loss: nan
agent1:                 episode reward: 0.5761,                 loss: 0.3310
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6591s / 341.9359 s
agent0:                 episode reward: -0.6369,                 loss: nan
agent1:                 episode reward: 0.6369,                 loss: 0.3321
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6656s / 342.6016 s
agent0:                 episode reward: -0.2317,                 loss: nan
agent1:                 episode reward: 0.2317,                 loss: 0.3308
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6592s / 343.2607 s
agent0:                 episode reward: -0.9774,                 loss: nan
agent1:                 episode reward: 0.9774,                 loss: 0.3262
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6582s / 343.9190 s
agent0:                 episode reward: -0.4468,                 loss: nan
agent1:                 episode reward: 0.4468,                 loss: 0.3298
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6523s / 344.5713 s
agent0:                 episode reward: -0.6110,                 loss: nan
agent1:                 episode reward: 0.6110,                 loss: 0.3248
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6591s / 345.2304 s
agent0:                 episode reward: -0.5963,                 loss: nan
agent1:                 episode reward: 0.5963,                 loss: 0.3285
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6634s / 345.8938 s
agent0:                 episode reward: -0.5698,                 loss: nan
agent1:                 episode reward: 0.5698,                 loss: 0.3303
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6583s / 346.5521 s
agent0:                 episode reward: -0.7456,                 loss: nan
agent1:                 episode reward: 0.7456,                 loss: 0.3305
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6542s / 347.2063 s
agent0:                 episode reward: -0.3231,                 loss: nan
agent1:                 episode reward: 0.3231,                 loss: 0.3304
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6534s / 347.8597 s
agent0:                 episode reward: -0.5386,                 loss: nan
agent1:                 episode reward: 0.5386,                 loss: 0.3276
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6625s / 348.5222 s
agent0:                 episode reward: -0.8212,                 loss: nan
agent1:                 episode reward: 0.8212,                 loss: 0.3287
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6598s / 349.1820 s
agent0:                 episode reward: -0.9209,                 loss: nan
agent1:                 episode reward: 0.9209,                 loss: 0.3308
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6625s / 349.8446 s
agent0:                 episode reward: -0.9105,                 loss: nan
agent1:                 episode reward: 0.9105,                 loss: 0.3312
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6582s / 350.5028 s
agent0:                 episode reward: -0.9016,                 loss: nan
agent1:                 episode reward: 0.9016,                 loss: 0.3290
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6600s / 351.1628 s
agent0:                 episode reward: -0.7237,                 loss: nan
agent1:                 episode reward: 0.7237,                 loss: 0.3263
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6532s / 351.8160 s
agent0:                 episode reward: -0.6475,                 loss: nan
agent1:                 episode reward: 0.6475,                 loss: 0.3221
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6524s / 352.4683 s
agent0:                 episode reward: -0.3013,                 loss: nan
agent1:                 episode reward: 0.3013,                 loss: 0.3237
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6546s / 353.1229 s
agent0:                 episode reward: -0.5020,                 loss: nan
agent1:                 episode reward: 0.5020,                 loss: 0.3230
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6572s / 353.7801 s
agent0:                 episode reward: -0.4714,                 loss: nan
agent1:                 episode reward: 0.4714,                 loss: 0.3240
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6568s / 354.4369 s
agent0:                 episode reward: -0.8889,                 loss: nan
agent1:                 episode reward: 0.8889,                 loss: 0.3240
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6535s / 355.0904 s
agent0:                 episode reward: -0.5527,                 loss: nan
agent1:                 episode reward: 0.5527,                 loss: 0.3260
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6600s / 355.7504 s
agent0:                 episode reward: -0.7585,                 loss: nan
agent1:                 episode reward: 0.7585,                 loss: 0.3241
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6625s / 356.4129 s
agent0:                 episode reward: -0.9753,                 loss: nan
agent1:                 episode reward: 0.9753,                 loss: 0.3247
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6615s / 357.0744 s
agent0:                 episode reward: -0.7069,                 loss: nan
agent1:                 episode reward: 0.7069,                 loss: 0.3236
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6616s / 357.7360 s
agent0:                 episode reward: -0.4962,                 loss: nan
agent1:                 episode reward: 0.4962,                 loss: 0.3268
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6548s / 358.3907 s
agent0:                 episode reward: -0.2990,                 loss: nan
agent1:                 episode reward: 0.2990,                 loss: 0.3235
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6592s / 359.0500 s
agent0:                 episode reward: -0.4806,                 loss: nan
agent1:                 episode reward: 0.4806,                 loss: 0.3208
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6684s / 359.7184 s
agent0:                 episode reward: -0.7108,                 loss: nan
agent1:                 episode reward: 0.7108,                 loss: 0.3249
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6570s / 360.3754 s
agent0:                 episode reward: -0.5325,                 loss: nan
agent1:                 episode reward: 0.5325,                 loss: 0.3235
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6521s / 361.0275 s
agent0:                 episode reward: -0.8816,                 loss: nan
agent1:                 episode reward: 0.8816,                 loss: 0.3251
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6578s / 361.6853 s
agent0:                 episode reward: -0.5011,                 loss: nan
agent1:                 episode reward: 0.5011,                 loss: 0.3242
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6554s / 362.3407 s
agent0:                 episode reward: -0.3368,                 loss: nan
agent1:                 episode reward: 0.3368,                 loss: 0.3101
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6550s / 362.9957 s
agent0:                 episode reward: -0.4021,                 loss: nan
agent1:                 episode reward: 0.4021,                 loss: 0.3101
Episode: 14061/30000 (46.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6498s / 363.6456 s
agent0:                 episode reward: -0.8076,                 loss: nan
agent1:                 episode reward: 0.8076,                 loss: 0.3074
Episode: 14081/30000 (46.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6606s / 364.3061 s
agent0:                 episode reward: -1.1354,                 loss: nan
agent1:                 episode reward: 1.1354,                 loss: 0.3081
Episode: 14101/30000 (47.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6619s / 364.9680 s
agent0:                 episode reward: -0.5852,                 loss: nan
agent1:                 episode reward: 0.5852,                 loss: 0.3079
Episode: 14121/30000 (47.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6513s / 365.6193 s
agent0:                 episode reward: -0.5540,                 loss: nan
agent1:                 episode reward: 0.5540,                 loss: 0.3092
Episode: 14141/30000 (47.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6446s / 366.2639 s
agent0:                 episode reward: -0.1048,                 loss: nan
agent1:                 episode reward: 0.1048,                 loss: 0.3051
Episode: 14161/30000 (47.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6563s / 366.9202 s
agent0:                 episode reward: -0.6405,                 loss: nan
agent1:                 episode reward: 0.6405,                 loss: 0.3058
Episode: 14181/30000 (47.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6487s / 367.5689 s
agent0:                 episode reward: -0.5184,                 loss: nan
agent1:                 episode reward: 0.5184,                 loss: 0.3073
Episode: 14201/30000 (47.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6626s / 368.2315 s
agent0:                 episode reward: -0.5090,                 loss: nan
agent1:                 episode reward: 0.5090,                 loss: 0.3080
Episode: 14221/30000 (47.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6577s / 368.8892 s
agent0:                 episode reward: -0.5984,                 loss: nan
agent1:                 episode reward: 0.5984,                 loss: 0.3082
Episode: 14241/30000 (47.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6492s / 369.5384 s
agent0:                 episode reward: -0.4566,                 loss: nan
agent1:                 episode reward: 0.4566,                 loss: 0.3073
Episode: 14261/30000 (47.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6586s / 370.1970 s
agent0:                 episode reward: -0.2337,                 loss: nan
agent1:                 episode reward: 0.2337,                 loss: 0.3072
Episode: 14281/30000 (47.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6464s / 370.8434 s
agent0:                 episode reward: -0.5893,                 loss: nan
agent1:                 episode reward: 0.5893,                 loss: 0.3081
Episode: 14301/30000 (47.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6631s / 371.5065 s
agent0:                 episode reward: -0.7275,                 loss: nan
agent1:                 episode reward: 0.7275,                 loss: 0.3065
Episode: 14321/30000 (47.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6629s / 372.1694 s
agent0:                 episode reward: -1.0996,                 loss: nan
agent1:                 episode reward: 1.0996,                 loss: 0.3063
Episode: 14341/30000 (47.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6701s / 372.8396 s
agent0:                 episode reward: -0.5445,                 loss: nan
agent1:                 episode reward: 0.5445,                 loss: 0.3158
Episode: 14361/30000 (47.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6566s / 373.4962 s
agent0:                 episode reward: -0.3125,                 loss: nan
agent1:                 episode reward: 0.3125,                 loss: 0.3301
Episode: 14381/30000 (47.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6616s / 374.1578 s
agent0:                 episode reward: -0.3302,                 loss: nan
agent1:                 episode reward: 0.3302,                 loss: 0.3314
Episode: 14401/30000 (48.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6750s / 374.8328 s
agent0:                 episode reward: -0.2612,                 loss: nan
agent1:                 episode reward: 0.2612,                 loss: 0.3293
Episode: 14421/30000 (48.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6711s / 375.5039 s
agent0:                 episode reward: -0.6228,                 loss: nan
agent1:                 episode reward: 0.6228,                 loss: 0.3298
Episode: 14441/30000 (48.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6610s / 376.1649 s
agent0:                 episode reward: -0.5168,                 loss: nan
agent1:                 episode reward: 0.5168,                 loss: 0.3277
Episode: 14461/30000 (48.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6764s / 376.8413 s
agent0:                 episode reward: -0.9833,                 loss: nan
agent1:                 episode reward: 0.9833,                 loss: 0.3292
Episode: 14481/30000 (48.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6733s / 377.5146 s
agent0:                 episode reward: -0.3365,                 loss: nan
agent1:                 episode reward: 0.3365,                 loss: 0.3300
Episode: 14501/30000 (48.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6839s / 378.1985 s
agent0:                 episode reward: -0.2612,                 loss: nan
agent1:                 episode reward: 0.2612,                 loss: 0.3297
Episode: 14521/30000 (48.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6817s / 378.8802 s
agent0:                 episode reward: -0.5380,                 loss: nan
agent1:                 episode reward: 0.5380,                 loss: 0.3298
Episode: 14541/30000 (48.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6788s / 379.5590 s
agent0:                 episode reward: -0.6591,                 loss: nan
agent1:                 episode reward: 0.6591,                 loss: 0.3301
Episode: 14561/30000 (48.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6741s / 380.2332 s
agent0:                 episode reward: -0.5603,                 loss: nan
agent1:                 episode reward: 0.5603,                 loss: 0.3301
Episode: 14581/30000 (48.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6738s / 380.9070 s
agent0:                 episode reward: -0.6970,                 loss: nan
agent1:                 episode reward: 0.6970,                 loss: 0.3307
Episode: 14601/30000 (48.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6721s / 381.5791 s
agent0:                 episode reward: -0.4029,                 loss: nan
agent1:                 episode reward: 0.4029,                 loss: 0.3272
Episode: 14621/30000 (48.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6743s / 382.2534 s
agent0:                 episode reward: -0.7325,                 loss: nan
agent1:                 episode reward: 0.7325,                 loss: 0.3293
Episode: 14641/30000 (48.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6788s / 382.9322 s
agent0:                 episode reward: -0.1133,                 loss: nan
agent1:                 episode reward: 0.1133,                 loss: 0.3312
Episode: 14661/30000 (48.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6820s / 383.6143 s
agent0:                 episode reward: -0.5107,                 loss: nan
agent1:                 episode reward: 0.5107,                 loss: 0.3321
Episode: 14681/30000 (48.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6706s / 384.2848 s
agent0:                 episode reward: -0.6765,                 loss: nan
agent1:                 episode reward: 0.6765,                 loss: 0.3328
Episode: 14701/30000 (49.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6744s / 384.9592 s
agent0:                 episode reward: -0.5516,                 loss: nan
agent1:                 episode reward: 0.5516,                 loss: 0.3294
Episode: 14721/30000 (49.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6750s / 385.6343 s
agent0:                 episode reward: -0.4473,                 loss: nan
agent1:                 episode reward: 0.4473,                 loss: 0.3329
Episode: 14741/30000 (49.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6780s / 386.3123 s
agent0:                 episode reward: -0.6638,                 loss: nan
agent1:                 episode reward: 0.6638,                 loss: 0.3307
Episode: 14761/30000 (49.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6763s / 386.9886 s
agent0:                 episode reward: -0.5370,                 loss: nan
agent1:                 episode reward: 0.5370,                 loss: 0.3331
Episode: 14781/30000 (49.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6804s / 387.6689 s
agent0:                 episode reward: -0.6253,                 loss: nan
agent1:                 episode reward: 0.6253,                 loss: 0.3287
Episode: 14801/30000 (49.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6757s / 388.3447 s
agent0:                 episode reward: -0.4442,                 loss: nan
agent1:                 episode reward: 0.4442,                 loss: 0.3309
Episode: 14821/30000 (49.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6722s / 389.0168 s
agent0:                 episode reward: -0.7804,                 loss: nan
agent1:                 episode reward: 0.7804,                 loss: 0.3319
Episode: 14841/30000 (49.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6721s / 389.6890 s
agent0:                 episode reward: -0.1716,                 loss: nan
agent1:                 episode reward: 0.1716,                 loss: 0.3274
Episode: 14861/30000 (49.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6787s / 390.3677 s
agent0:                 episode reward: -1.1133,                 loss: nan
agent1:                 episode reward: 1.1133,                 loss: 0.3307
Episode: 14881/30000 (49.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6735s / 391.0411 s
agent0:                 episode reward: -0.5033,                 loss: nan
agent1:                 episode reward: 0.5033,                 loss: 0.3308
Episode: 14901/30000 (49.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6671s / 391.7082 s
agent0:                 episode reward: -0.3408,                 loss: nan
agent1:                 episode reward: 0.3408,                 loss: 0.3294
Episode: 14921/30000 (49.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6651s / 392.3733 s
agent0:                 episode reward: -0.3501,                 loss: nan
agent1:                 episode reward: 0.3501,                 loss: 0.3305
Episode: 14941/30000 (49.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6758s / 393.0491 s
agent0:                 episode reward: -0.6136,                 loss: nan
agent1:                 episode reward: 0.6136,                 loss: 0.3301
Episode: 14961/30000 (49.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6597s / 393.7089 s
agent0:                 episode reward: 0.0514,                 loss: nan
agent1:                 episode reward: -0.0514,                 loss: 0.3321
Episode: 14981/30000 (49.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6618s / 394.3707 s
agent0:                 episode reward: -0.2855,                 loss: nan
agent1:                 episode reward: 0.2855,                 loss: 0.3310
Episode: 15001/30000 (50.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6707s / 395.0415 s
agent0:                 episode reward: -0.3626,                 loss: nan
agent1:                 episode reward: 0.3626,                 loss: 0.3296
Episode: 15021/30000 (50.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6739s / 395.7154 s
agent0:                 episode reward: -0.6386,                 loss: nan
agent1:                 episode reward: 0.6386,                 loss: 0.3151
Episode: 15041/30000 (50.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6618s / 396.3772 s
agent0:                 episode reward: -0.4508,                 loss: nan
agent1:                 episode reward: 0.4508,                 loss: 0.3176
Episode: 15061/30000 (50.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6850s / 397.0622 s
agent0:                 episode reward: -0.8845,                 loss: nan
agent1:                 episode reward: 0.8845,                 loss: 0.3182
Episode: 15081/30000 (50.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6941s / 397.7563 s
agent0:                 episode reward: -0.7148,                 loss: nan
agent1:                 episode reward: 0.7148,                 loss: 0.3148
Episode: 15101/30000 (50.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6769s / 398.4332 s
agent0:                 episode reward: -0.5297,                 loss: nan
agent1:                 episode reward: 0.5297,                 loss: 0.3190
Episode: 15121/30000 (50.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6779s / 399.1112 s
agent0:                 episode reward: -0.6871,                 loss: nan
agent1:                 episode reward: 0.6871,                 loss: 0.3174
Episode: 15141/30000 (50.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6879s / 399.7990 s
agent0:                 episode reward: -0.7454,                 loss: nan
agent1:                 episode reward: 0.7454,                 loss: 0.3169
Episode: 15161/30000 (50.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6801s / 400.4791 s
agent0:                 episode reward: -0.4117,                 loss: nan
agent1:                 episode reward: 0.4117,                 loss: 0.3174
Episode: 15181/30000 (50.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6824s / 401.1615 s
agent0:                 episode reward: -0.3797,                 loss: nan
agent1:                 episode reward: 0.3797,                 loss: 0.3179
Episode: 15201/30000 (50.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6854s / 401.8469 s
agent0:                 episode reward: -0.4945,                 loss: nan
agent1:                 episode reward: 0.4945,                 loss: 0.3148
Episode: 15221/30000 (50.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6845s / 402.5314 s
agent0:                 episode reward: -0.4995,                 loss: nan
agent1:                 episode reward: 0.4995,                 loss: 0.3156
Episode: 15241/30000 (50.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6851s / 403.2165 s
agent0:                 episode reward: -0.5470,                 loss: nan
agent1:                 episode reward: 0.5470,                 loss: 0.3168
Episode: 15261/30000 (50.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6817s / 403.8982 s
agent0:                 episode reward: -0.6250,                 loss: nan
agent1:                 episode reward: 0.6250,                 loss: 0.3170
Episode: 15281/30000 (50.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6767s / 404.5749 s
agent0:                 episode reward: -0.3338,                 loss: nan
agent1:                 episode reward: 0.3338,                 loss: 0.3191
Episode: 15301/30000 (51.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6776s / 405.2525 s
agent0:                 episode reward: -0.4662,                 loss: nan
agent1:                 episode reward: 0.4662,                 loss: 0.3173
Episode: 15321/30000 (51.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6825s / 405.9349 s
agent0:                 episode reward: -0.4935,                 loss: nan
agent1:                 episode reward: 0.4935,                 loss: 0.3139
Episode: 15341/30000 (51.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6763s / 406.6113 s
agent0:                 episode reward: -0.2815,                 loss: nan
agent1:                 episode reward: 0.2815,                 loss: 0.3216
Episode: 15361/30000 (51.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6769s / 407.2881 s
agent0:                 episode reward: -0.4476,                 loss: nan
agent1:                 episode reward: 0.4476,                 loss: 0.3260
Episode: 15381/30000 (51.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6700s / 407.9581 s
agent0:                 episode reward: -0.4229,                 loss: nan
agent1:                 episode reward: 0.4229,                 loss: 0.3290
Episode: 15401/30000 (51.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6808s / 408.6389 s
agent0:                 episode reward: -0.3223,                 loss: nan
agent1:                 episode reward: 0.3223,                 loss: 0.3253
Episode: 15421/30000 (51.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6704s / 409.3093 s
agent0:                 episode reward: -0.2411,                 loss: nan
agent1:                 episode reward: 0.2411,                 loss: 0.3248
Episode: 15441/30000 (51.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6780s / 409.9873 s
agent0:                 episode reward: -0.7380,                 loss: nan
agent1:                 episode reward: 0.7380,                 loss: 0.3275
Episode: 15461/30000 (51.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6892s / 410.6765 s
agent0:                 episode reward: -0.2260,                 loss: nan
agent1:                 episode reward: 0.2260,                 loss: 0.3256
Episode: 15481/30000 (51.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6806s / 411.3571 s
agent0:                 episode reward: -1.0249,                 loss: nan
agent1:                 episode reward: 1.0249,                 loss: 0.3249
Episode: 15501/30000 (51.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6792s / 412.0363 s
agent0:                 episode reward: -0.3993,                 loss: nan
agent1:                 episode reward: 0.3993,                 loss: 0.3280
Episode: 15521/30000 (51.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6830s / 412.7193 s
agent0:                 episode reward: -0.3212,                 loss: nan
agent1:                 episode reward: 0.3212,                 loss: 0.3244
Episode: 15541/30000 (51.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6765s / 413.3958 s
agent0:                 episode reward: -0.4481,                 loss: nan
agent1:                 episode reward: 0.4481,                 loss: 0.3254
Episode: 15561/30000 (51.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6782s / 414.0740 s
agent0:                 episode reward: -0.2848,                 loss: nan
agent1:                 episode reward: 0.2848,                 loss: 0.3262
Episode: 15581/30000 (51.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6800s / 414.7540 s
agent0:                 episode reward: -0.4717,                 loss: nan
agent1:                 episode reward: 0.4717,                 loss: 0.3245
Episode: 15601/30000 (52.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6821s / 415.4361 s
agent0:                 episode reward: -0.7589,                 loss: nan
agent1:                 episode reward: 0.7589,                 loss: 0.3254
Episode: 15621/30000 (52.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6828s / 416.1189 s
agent0:                 episode reward: -0.4029,                 loss: nan
agent1:                 episode reward: 0.4029,                 loss: 0.3276
Episode: 15641/30000 (52.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6857s / 416.8046 s
agent0:                 episode reward: -0.9795,                 loss: nan
agent1:                 episode reward: 0.9795,                 loss: 0.3248
Episode: 15661/30000 (52.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6764s / 417.4810 s
agent0:                 episode reward: -0.5573,                 loss: nan
agent1:                 episode reward: 0.5573,                 loss: 0.3275
Episode: 15681/30000 (52.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6770s / 418.1580 s
agent0:                 episode reward: -0.9095,                 loss: nan
agent1:                 episode reward: 0.9095,                 loss: 0.3246
Episode: 15701/30000 (52.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6697s / 418.8277 s
agent0:                 episode reward: -0.4629,                 loss: nan
agent1:                 episode reward: 0.4629,                 loss: 0.3181
Episode: 15721/30000 (52.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6751s / 419.5028 s
agent0:                 episode reward: -0.6295,                 loss: nan
agent1:                 episode reward: 0.6295,                 loss: 0.3195
Episode: 15741/30000 (52.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6932s / 420.1960 s
agent0:                 episode reward: -0.4558,                 loss: nan
agent1:                 episode reward: 0.4558,                 loss: 0.3187
Episode: 15761/30000 (52.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6989s / 420.8949 s
agent0:                 episode reward: -0.5116,                 loss: nan
agent1:                 episode reward: 0.5116,                 loss: 0.3162
Episode: 15781/30000 (52.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6776s / 421.5725 s
agent0:                 episode reward: -0.6924,                 loss: nan
agent1:                 episode reward: 0.6924,                 loss: 0.3176
Episode: 15801/30000 (52.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6905s / 422.2630 s
agent0:                 episode reward: -0.2542,                 loss: nan
agent1:                 episode reward: 0.2542,                 loss: 0.3192
Episode: 15821/30000 (52.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6853s / 422.9483 s
agent0:                 episode reward: -0.6334,                 loss: nan
agent1:                 episode reward: 0.6334,                 loss: 0.3194
Episode: 15841/30000 (52.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6751s / 423.6233 s
agent0:                 episode reward: -0.3075,                 loss: nan
agent1:                 episode reward: 0.3075,                 loss: 0.3179
Episode: 15861/30000 (52.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6758s / 424.2992 s
agent0:                 episode reward: -0.4746,                 loss: nan
agent1:                 episode reward: 0.4746,                 loss: 0.3171
Episode: 15881/30000 (52.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6759s / 424.9751 s
agent0:                 episode reward: -0.4192,                 loss: nan
agent1:                 episode reward: 0.4192,                 loss: 0.3193
Episode: 15901/30000 (53.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6796s / 425.6547 s
agent0:                 episode reward: -0.7898,                 loss: nan
agent1:                 episode reward: 0.7898,                 loss: 0.3196
Episode: 15921/30000 (53.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6832s / 426.3380 s
agent0:                 episode reward: -0.7455,                 loss: nan
agent1:                 episode reward: 0.7455,                 loss: 0.3213
Episode: 15941/30000 (53.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6796s / 427.0176 s
agent0:                 episode reward: -0.5746,                 loss: nan
agent1:                 episode reward: 0.5746,                 loss: 0.3182
Episode: 15961/30000 (53.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6800s / 427.6976 s
agent0:                 episode reward: -0.5540,                 loss: nan
agent1:                 episode reward: 0.5540,                 loss: 0.3202
Episode: 15981/30000 (53.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6849s / 428.3825 s
agent0:                 episode reward: -0.9161,                 loss: nan
agent1:                 episode reward: 0.9161,                 loss: 0.3206
Episode: 16001/30000 (53.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6881s / 429.0706 s
agent0:                 episode reward: -0.4651,                 loss: nan
agent1:                 episode reward: 0.4651,                 loss: 0.3199
Episode: 16021/30000 (53.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6798s / 429.7504 s
agent0:                 episode reward: -0.7431,                 loss: nan
agent1:                 episode reward: 0.7431,                 loss: 0.3275
Episode: 16041/30000 (53.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6812s / 430.4316 s
agent0:                 episode reward: -0.1711,                 loss: nan
agent1:                 episode reward: 0.1711,                 loss: 0.3269
Episode: 16061/30000 (53.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6856s / 431.1172 s
agent0:                 episode reward: -0.5991,                 loss: nan
agent1:                 episode reward: 0.5991,                 loss: 0.3291
Episode: 16081/30000 (53.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6911s / 431.8084 s
agent0:                 episode reward: -0.7207,                 loss: nan
agent1:                 episode reward: 0.7207,                 loss: 0.3297
Episode: 16101/30000 (53.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6905s / 432.4989 s
agent0:                 episode reward: -0.5811,                 loss: nan
agent1:                 episode reward: 0.5811,                 loss: 0.3271
Episode: 16121/30000 (53.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6854s / 433.1843 s
agent0:                 episode reward: -0.4555,                 loss: nan
agent1:                 episode reward: 0.4555,                 loss: 0.3290
Episode: 16141/30000 (53.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7003s / 433.8846 s
agent0:                 episode reward: -0.5442,                 loss: nan
agent1:                 episode reward: 0.5442,                 loss: 0.3262
Episode: 16161/30000 (53.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7010s / 434.5856 s
agent0:                 episode reward: -0.5878,                 loss: nan
agent1:                 episode reward: 0.5878,                 loss: 0.3251
Episode: 16181/30000 (53.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6848s / 435.2704 s
agent0:                 episode reward: -0.3304,                 loss: nan
agent1:                 episode reward: 0.3304,                 loss: 0.3278
Episode: 16201/30000 (54.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6806s / 435.9510 s
agent0:                 episode reward: -0.6395,                 loss: nan
agent1:                 episode reward: 0.6395,                 loss: 0.3285
Episode: 16221/30000 (54.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6919s / 436.6429 s
agent0:                 episode reward: -0.3811,                 loss: nan
agent1:                 episode reward: 0.3811,                 loss: 0.3271
Episode: 16241/30000 (54.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7073s / 437.3502 s
agent0:                 episode reward: -0.4665,                 loss: nan
agent1:                 episode reward: 0.4665,                 loss: 0.3255
Episode: 16261/30000 (54.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6850s / 438.0352 s
agent0:                 episode reward: -0.3166,                 loss: nan
agent1:                 episode reward: 0.3166,                 loss: 0.3280
Episode: 16281/30000 (54.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6946s / 438.7297 s
agent0:                 episode reward: -0.2147,                 loss: nan
agent1:                 episode reward: 0.2147,                 loss: 0.3268
Episode: 16301/30000 (54.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6911s / 439.4208 s
agent0:                 episode reward: -0.3179,                 loss: nan
agent1:                 episode reward: 0.3179,                 loss: 0.3266
Episode: 16321/30000 (54.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6908s / 440.1117 s
agent0:                 episode reward: -0.4969,                 loss: nan
agent1:                 episode reward: 0.4969,                 loss: 0.3291
Episode: 16341/30000 (54.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7045s / 440.8161 s
agent0:                 episode reward: -0.6325,                 loss: nan
agent1:                 episode reward: 0.6325,                 loss: 0.3225
Episode: 16361/30000 (54.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6812s / 441.4974 s
agent0:                 episode reward: -0.5239,                 loss: nan
agent1:                 episode reward: 0.5239,                 loss: 0.3158
Episode: 16381/30000 (54.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7082s / 442.2056 s
agent0:                 episode reward: -0.7984,                 loss: nan
agent1:                 episode reward: 0.7984,                 loss: 0.3180
Episode: 16401/30000 (54.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7013s / 442.9069 s
agent0:                 episode reward: -0.4927,                 loss: nan
agent1:                 episode reward: 0.4927,                 loss: 0.3169
Episode: 16421/30000 (54.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7017s / 443.6085 s
agent0:                 episode reward: -0.3676,                 loss: nan
agent1:                 episode reward: 0.3676,                 loss: 0.3140
Episode: 16441/30000 (54.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6917s / 444.3003 s
agent0:                 episode reward: -1.0538,                 loss: nan
agent1:                 episode reward: 1.0538,                 loss: 0.3176
Episode: 16461/30000 (54.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6963s / 444.9966 s
agent0:                 episode reward: -0.4094,                 loss: nan
agent1:                 episode reward: 0.4094,                 loss: 0.3181
Episode: 16481/30000 (54.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6826s / 445.6792 s
agent0:                 episode reward: -0.6567,                 loss: nan
agent1:                 episode reward: 0.6567,                 loss: 0.3181
Episode: 16501/30000 (55.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6897s / 446.3689 s
agent0:                 episode reward: -0.5921,                 loss: nan
agent1:                 episode reward: 0.5921,                 loss: 0.3190
Episode: 16521/30000 (55.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6900s / 447.0589 s
agent0:                 episode reward: -0.6562,                 loss: nan
agent1:                 episode reward: 0.6562,                 loss: 0.3172
Episode: 16541/30000 (55.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6905s / 447.7494 s
agent0:                 episode reward: -0.3629,                 loss: nan
agent1:                 episode reward: 0.3629,                 loss: 0.3165
Episode: 16561/30000 (55.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6885s / 448.4379 s
agent0:                 episode reward: -0.2998,                 loss: nan
agent1:                 episode reward: 0.2998,                 loss: 0.3197
Episode: 16581/30000 (55.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6912s / 449.1291 s
agent0:                 episode reward: -0.4573,                 loss: nan
agent1:                 episode reward: 0.4573,                 loss: 0.3175
Episode: 16601/30000 (55.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6917s / 449.8208 s
agent0:                 episode reward: -0.6478,                 loss: nan
agent1:                 episode reward: 0.6478,                 loss: 0.3160
Episode: 16621/30000 (55.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7062s / 450.5270 s
agent0:                 episode reward: -0.5289,                 loss: nan
agent1:                 episode reward: 0.5289,                 loss: 0.3156
Episode: 16641/30000 (55.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6858s / 451.2128 s
agent0:                 episode reward: -0.7887,                 loss: nan
agent1:                 episode reward: 0.7887,                 loss: 0.3195
Episode: 16661/30000 (55.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6925s / 451.9053 s
agent0:                 episode reward: -0.0429,                 loss: nan
agent1:                 episode reward: 0.0429,                 loss: 0.3172
Episode: 16681/30000 (55.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6958s / 452.6011 s
agent0:                 episode reward: -1.2921,                 loss: nan
agent1:                 episode reward: 1.2921,                 loss: 0.3252
Episode: 16701/30000 (55.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6903s / 453.2914 s
agent0:                 episode reward: -0.4959,                 loss: nan
agent1:                 episode reward: 0.4959,                 loss: 0.3357
Episode: 16721/30000 (55.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6992s / 453.9906 s
agent0:                 episode reward: -0.4024,                 loss: nan
agent1:                 episode reward: 0.4024,                 loss: 0.3348
Episode: 16741/30000 (55.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6919s / 454.6825 s
agent0:                 episode reward: -0.7213,                 loss: nan
agent1:                 episode reward: 0.7213,                 loss: 0.3340
Episode: 16761/30000 (55.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6989s / 455.3813 s
agent0:                 episode reward: -0.5473,                 loss: nan
agent1:                 episode reward: 0.5473,                 loss: 0.3335
Episode: 16781/30000 (55.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6923s / 456.0737 s
agent0:                 episode reward: -0.3766,                 loss: nan
agent1:                 episode reward: 0.3766,                 loss: 0.3353
Episode: 16801/30000 (56.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7151s / 456.7887 s
agent0:                 episode reward: -0.9202,                 loss: nan
agent1:                 episode reward: 0.9202,                 loss: 0.3289
Episode: 16821/30000 (56.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6979s / 457.4866 s
agent0:                 episode reward: -0.2925,                 loss: nan
agent1:                 episode reward: 0.2925,                 loss: 0.3336
Episode: 16841/30000 (56.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7011s / 458.1877 s
agent0:                 episode reward: -0.4346,                 loss: nan
agent1:                 episode reward: 0.4346,                 loss: 0.3337
Episode: 16861/30000 (56.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6978s / 458.8855 s
agent0:                 episode reward: -0.4617,                 loss: nan
agent1:                 episode reward: 0.4617,                 loss: 0.3332
Episode: 16881/30000 (56.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7048s / 459.5903 s
agent0:                 episode reward: -0.5508,                 loss: nan
agent1:                 episode reward: 0.5508,                 loss: 0.3317
Episode: 16901/30000 (56.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6987s / 460.2889 s
agent0:                 episode reward: -0.4343,                 loss: nan
agent1:                 episode reward: 0.4343,                 loss: 0.3362
Episode: 16921/30000 (56.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7049s / 460.9939 s
agent0:                 episode reward: -0.4223,                 loss: nan
agent1:                 episode reward: 0.4223,                 loss: 0.3350
Episode: 16941/30000 (56.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6934s / 461.6873 s
agent0:                 episode reward: -0.5510,                 loss: nan
agent1:                 episode reward: 0.5510,                 loss: 0.3345
Episode: 16961/30000 (56.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6934s / 462.3806 s
agent0:                 episode reward: -0.7735,                 loss: nan
agent1:                 episode reward: 0.7735,                 loss: 0.3333
Episode: 16981/30000 (56.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7075s / 463.0881 s
agent0:                 episode reward: -0.5818,                 loss: nan
agent1:                 episode reward: 0.5818,                 loss: 0.3334
Episode: 17001/30000 (56.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7012s / 463.7893 s
agent0:                 episode reward: -0.4162,                 loss: nan
agent1:                 episode reward: 0.4162,                 loss: 0.3351
Episode: 17021/30000 (56.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6953s / 464.4846 s
agent0:                 episode reward: -0.4286,                 loss: nan
agent1:                 episode reward: 0.4286,                 loss: 0.3234
Episode: 17041/30000 (56.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6978s / 465.1824 s
agent0:                 episode reward: -0.6445,                 loss: nan
agent1:                 episode reward: 0.6445,                 loss: 0.3242
Episode: 17061/30000 (56.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6912s / 465.8736 s
agent0:                 episode reward: -0.6246,                 loss: nan
agent1:                 episode reward: 0.6246,                 loss: 0.3245
Episode: 17081/30000 (56.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7024s / 466.5760 s
agent0:                 episode reward: -0.3623,                 loss: nan
agent1:                 episode reward: 0.3623,                 loss: 0.3237
Episode: 17101/30000 (57.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7050s / 467.2810 s
agent0:                 episode reward: -0.9190,                 loss: nan
agent1:                 episode reward: 0.9190,                 loss: 0.3205
Episode: 17121/30000 (57.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6966s / 467.9776 s
agent0:                 episode reward: -0.7535,                 loss: nan
agent1:                 episode reward: 0.7535,                 loss: 0.3234
Episode: 17141/30000 (57.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6969s / 468.6745 s
agent0:                 episode reward: -0.4951,                 loss: nan
agent1:                 episode reward: 0.4951,                 loss: 0.3223
Episode: 17161/30000 (57.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6995s / 469.3740 s
agent0:                 episode reward: -0.6890,                 loss: nan
agent1:                 episode reward: 0.6890,                 loss: 0.3229
Episode: 17181/30000 (57.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7042s / 470.0782 s
agent0:                 episode reward: -0.8230,                 loss: nan
agent1:                 episode reward: 0.8230,                 loss: 0.3238
Episode: 17201/30000 (57.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7041s / 470.7822 s
agent0:                 episode reward: -0.7902,                 loss: nan
agent1:                 episode reward: 0.7902,                 loss: 0.3245
Episode: 17221/30000 (57.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7059s / 471.4881 s
agent0:                 episode reward: -0.1343,                 loss: nan
agent1:                 episode reward: 0.1343,                 loss: 0.3200
Episode: 17241/30000 (57.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7036s / 472.1917 s
agent0:                 episode reward: -0.8456,                 loss: nan
agent1:                 episode reward: 0.8456,                 loss: 0.3245
Episode: 17261/30000 (57.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7074s / 472.8991 s
agent0:                 episode reward: -0.4732,                 loss: nan
agent1:                 episode reward: 0.4732,                 loss: 0.3228
Episode: 17281/30000 (57.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7058s / 473.6048 s
agent0:                 episode reward: -0.5465,                 loss: nan
agent1:                 episode reward: 0.5465,                 loss: 0.3218
Episode: 17301/30000 (57.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7053s / 474.3101 s
agent0:                 episode reward: -0.9437,                 loss: nan
agent1:                 episode reward: 0.9437,                 loss: 0.3216
Episode: 17321/30000 (57.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7086s / 475.0187 s
agent0:                 episode reward: -0.4398,                 loss: nan
agent1:                 episode reward: 0.4398,                 loss: 0.3255
Episode: 17341/30000 (57.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7088s / 475.7276 s
agent0:                 episode reward: -0.6405,                 loss: nan
agent1:                 episode reward: 0.6405,                 loss: 0.3240
Episode: 17361/30000 (57.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7103s / 476.4379 s
agent0:                 episode reward: -0.6938,                 loss: nan
agent1:                 episode reward: 0.6938,                 loss: 0.3147
Episode: 17381/30000 (57.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7030s / 477.1409 s
agent0:                 episode reward: -0.4622,                 loss: nan
agent1:                 episode reward: 0.4622,                 loss: 0.3171
Episode: 17401/30000 (58.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7070s / 477.8479 s
agent0:                 episode reward: -0.4571,                 loss: nan
agent1:                 episode reward: 0.4571,                 loss: 0.3141
Episode: 17421/30000 (58.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7090s / 478.5569 s
agent0:                 episode reward: -0.7013,                 loss: nan
agent1:                 episode reward: 0.7013,                 loss: 0.3153
Episode: 17441/30000 (58.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7062s / 479.2631 s
agent0:                 episode reward: -0.3279,                 loss: nan
agent1:                 episode reward: 0.3279,                 loss: 0.3179
Episode: 17461/30000 (58.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7090s / 479.9721 s
agent0:                 episode reward: -0.7382,                 loss: nan
agent1:                 episode reward: 0.7382,                 loss: 0.3149
Episode: 17481/30000 (58.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7134s / 480.6855 s
agent0:                 episode reward: -0.6046,                 loss: nan
agent1:                 episode reward: 0.6046,                 loss: 0.3157
Episode: 17501/30000 (58.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7027s / 481.3882 s
agent0:                 episode reward: -0.5568,                 loss: nan
agent1:                 episode reward: 0.5568,                 loss: 0.3131
Episode: 17521/30000 (58.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7114s / 482.0995 s
agent0:                 episode reward: -0.4659,                 loss: nan
agent1:                 episode reward: 0.4659,                 loss: 0.3160
Episode: 17541/30000 (58.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7077s / 482.8072 s
agent0:                 episode reward: -0.5466,                 loss: nan
agent1:                 episode reward: 0.5466,                 loss: 0.3169
Episode: 17561/30000 (58.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7168s / 483.5240 s
agent0:                 episode reward: -0.5843,                 loss: nan
agent1:                 episode reward: 0.5843,                 loss: 0.3165
Episode: 17581/30000 (58.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7192s / 484.2433 s
agent0:                 episode reward: -0.4582,                 loss: nan
agent1:                 episode reward: 0.4582,                 loss: 0.3136
Episode: 17601/30000 (58.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7103s / 484.9535 s
agent0:                 episode reward: -0.7073,                 loss: nan
agent1:                 episode reward: 0.7073,                 loss: 0.3173
Episode: 17621/30000 (58.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7082s / 485.6618 s
agent0:                 episode reward: -0.6830,                 loss: nan
agent1:                 episode reward: 0.6830,                 loss: 0.3172
Episode: 17641/30000 (58.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7223s / 486.3841 s
agent0:                 episode reward: -0.8147,                 loss: nan
agent1:                 episode reward: 0.8147,                 loss: 0.3145
Episode: 17661/30000 (58.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7220s / 487.1061 s
agent0:                 episode reward: -0.7855,                 loss: nan
agent1:                 episode reward: 0.7855,                 loss: 0.3164
Episode: 17681/30000 (58.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7158s / 487.8219 s
agent0:                 episode reward: -0.5983,                 loss: nan
agent1:                 episode reward: 0.5983,                 loss: 0.3237
Episode: 17701/30000 (59.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7107s / 488.5326 s
agent0:                 episode reward: -0.4432,                 loss: nan
agent1:                 episode reward: 0.4432,                 loss: 0.3275
Episode: 17721/30000 (59.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7190s / 489.2515 s
agent0:                 episode reward: -0.3271,                 loss: nan
agent1:                 episode reward: 0.3271,                 loss: 0.3271
Episode: 17741/30000 (59.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7139s / 489.9655 s
agent0:                 episode reward: -0.3170,                 loss: nan
agent1:                 episode reward: 0.3170,                 loss: 0.3284
Episode: 17761/30000 (59.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7210s / 490.6865 s
agent0:                 episode reward: -0.6399,                 loss: nan
agent1:                 episode reward: 0.6399,                 loss: 0.3270
Episode: 17781/30000 (59.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7231s / 491.4096 s
agent0:                 episode reward: -0.8827,                 loss: nan
agent1:                 episode reward: 0.8827,                 loss: 0.3323
Episode: 17801/30000 (59.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7088s / 492.1184 s
agent0:                 episode reward: -0.7309,                 loss: nan
agent1:                 episode reward: 0.7309,                 loss: 0.3271
Episode: 17821/30000 (59.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7199s / 492.8383 s
agent0:                 episode reward: -0.4847,                 loss: nan
agent1:                 episode reward: 0.4847,                 loss: 0.3261
Episode: 17841/30000 (59.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7173s / 493.5556 s
agent0:                 episode reward: -0.2526,                 loss: nan
agent1:                 episode reward: 0.2526,                 loss: 0.3266
Episode: 17861/30000 (59.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7165s / 494.2721 s
agent0:                 episode reward: -0.6660,                 loss: nan
agent1:                 episode reward: 0.6660,                 loss: 0.3291
Episode: 17881/30000 (59.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7174s / 494.9894 s
agent0:                 episode reward: -0.7119,                 loss: nan
agent1:                 episode reward: 0.7119,                 loss: 0.3273
Episode: 17901/30000 (59.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7082s / 495.6976 s
agent0:                 episode reward: -0.3376,                 loss: nan
agent1:                 episode reward: 0.3376,                 loss: 0.3265
Episode: 17921/30000 (59.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7113s / 496.4089 s
agent0:                 episode reward: -0.5094,                 loss: nan
agent1:                 episode reward: 0.5094,                 loss: 0.3276
Episode: 17941/30000 (59.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7132s / 497.1221 s
agent0:                 episode reward: -0.2803,                 loss: nan
agent1:                 episode reward: 0.2803,                 loss: 0.3291
Episode: 17961/30000 (59.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7174s / 497.8396 s
agent0:                 episode reward: -0.8233,                 loss: nan
agent1:                 episode reward: 0.8233,                 loss: 0.3277
Episode: 17981/30000 (59.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7142s / 498.5537 s
agent0:                 episode reward: -0.8534,                 loss: nan
agent1:                 episode reward: 0.8534,                 loss: 0.3262
Episode: 18001/30000 (60.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7176s / 499.2714 s
agent0:                 episode reward: -0.6058,                 loss: nan
agent1:                 episode reward: 0.6058,                 loss: 0.3279
Episode: 18021/30000 (60.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7205s / 499.9918 s
agent0:                 episode reward: 0.1003,                 loss: nan
agent1:                 episode reward: -0.1003,                 loss: 0.3226
Episode: 18041/30000 (60.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7288s / 500.7206 s
agent0:                 episode reward: -0.8353,                 loss: nan
agent1:                 episode reward: 0.8353,                 loss: 0.3245
Episode: 18061/30000 (60.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7364s / 501.4570 s
agent0:                 episode reward: -0.5899,                 loss: nan
agent1:                 episode reward: 0.5899,                 loss: 0.3205
Episode: 18081/30000 (60.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7188s / 502.1757 s
agent0:                 episode reward: -0.3173,                 loss: nan
agent1:                 episode reward: 0.3173,                 loss: 0.3228
Episode: 18101/30000 (60.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7192s / 502.8949 s
agent0:                 episode reward: -0.9962,                 loss: nan
agent1:                 episode reward: 0.9962,                 loss: 0.3197
Episode: 18121/30000 (60.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7245s / 503.6195 s
agent0:                 episode reward: -0.6413,                 loss: nan
agent1:                 episode reward: 0.6413,                 loss: 0.3223
Episode: 18141/30000 (60.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7282s / 504.3477 s
agent0:                 episode reward: 0.1613,                 loss: nan
agent1:                 episode reward: -0.1613,                 loss: 0.3233
Episode: 18161/30000 (60.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7339s / 505.0816 s
agent0:                 episode reward: -0.5919,                 loss: nan
agent1:                 episode reward: 0.5919,                 loss: 0.3220
Episode: 18181/30000 (60.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7232s / 505.8048 s
agent0:                 episode reward: -0.5748,                 loss: nan
agent1:                 episode reward: 0.5748,                 loss: 0.3224
Episode: 18201/30000 (60.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7306s / 506.5354 s
agent0:                 episode reward: -0.5532,                 loss: nan
agent1:                 episode reward: 0.5532,                 loss: 0.3241
Episode: 18221/30000 (60.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7209s / 507.2564 s
agent0:                 episode reward: -0.4374,                 loss: nan
agent1:                 episode reward: 0.4374,                 loss: 0.3218
Episode: 18241/30000 (60.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7327s / 507.9891 s
agent0:                 episode reward: -0.5081,                 loss: nan
agent1:                 episode reward: 0.5081,                 loss: 0.3247
Episode: 18261/30000 (60.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7340s / 508.7231 s
agent0:                 episode reward: -0.5959,                 loss: nan
agent1:                 episode reward: 0.5959,                 loss: 0.3253
Episode: 18281/30000 (60.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7311s / 509.4542 s
agent0:                 episode reward: -0.2298,                 loss: nan
agent1:                 episode reward: 0.2298,                 loss: 0.3197
Episode: 18301/30000 (61.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7354s / 510.1896 s
agent0:                 episode reward: -0.4857,                 loss: nan
agent1:                 episode reward: 0.4857,                 loss: 0.3225
Episode: 18321/30000 (61.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7313s / 510.9209 s
agent0:                 episode reward: -0.7421,                 loss: nan
agent1:                 episode reward: 0.7421,                 loss: 0.3196
Episode: 18341/30000 (61.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7380s / 511.6589 s
agent0:                 episode reward: -1.0909,                 loss: nan
agent1:                 episode reward: 1.0909,                 loss: 0.3205
Episode: 18361/30000 (61.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7334s / 512.3923 s
agent0:                 episode reward: -0.2276,                 loss: nan
agent1:                 episode reward: 0.2276,                 loss: 0.3263
Episode: 18381/30000 (61.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7273s / 513.1196 s
agent0:                 episode reward: -0.2405,                 loss: nan
agent1:                 episode reward: 0.2405,                 loss: 0.3248
Episode: 18401/30000 (61.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7253s / 513.8449 s
agent0:                 episode reward: -0.3841,                 loss: nan
agent1:                 episode reward: 0.3841,                 loss: 0.3237
Episode: 18421/30000 (61.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7366s / 514.5816 s
agent0:                 episode reward: -0.6378,                 loss: nan
agent1:                 episode reward: 0.6378,                 loss: 0.3248
Episode: 18441/30000 (61.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7464s / 515.3280 s
agent0:                 episode reward: -0.6117,                 loss: nan
agent1:                 episode reward: 0.6117,                 loss: 0.3258
Episode: 18461/30000 (61.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7460s / 516.0740 s
agent0:                 episode reward: -0.4057,                 loss: nan
agent1:                 episode reward: 0.4057,                 loss: 0.3250
Episode: 18481/30000 (61.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7534s / 516.8274 s
agent0:                 episode reward: -0.6091,                 loss: nan
agent1:                 episode reward: 0.6091,                 loss: 0.3208
Episode: 18501/30000 (61.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7371s / 517.5645 s
agent0:                 episode reward: -1.0641,                 loss: nan
agent1:                 episode reward: 1.0641,                 loss: 0.3258
Episode: 18521/30000 (61.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7418s / 518.3063 s
agent0:                 episode reward: -0.6547,                 loss: nan
agent1:                 episode reward: 0.6547,                 loss: 0.3273
Episode: 18541/30000 (61.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7523s / 519.0586 s
agent0:                 episode reward: -0.4692,                 loss: nan
agent1:                 episode reward: 0.4692,                 loss: 0.3256
Episode: 18561/30000 (61.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7287s / 519.7873 s
agent0:                 episode reward: -0.7924,                 loss: nan
agent1:                 episode reward: 0.7924,                 loss: 0.3269
Episode: 18581/30000 (61.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7411s / 520.5284 s
agent0:                 episode reward: -0.5673,                 loss: nan
agent1:                 episode reward: 0.5673,                 loss: 0.3253
Episode: 18601/30000 (62.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7198s / 521.2482 s
agent0:                 episode reward: -0.4835,                 loss: nan
agent1:                 episode reward: 0.4835,                 loss: 0.3249
Episode: 18621/30000 (62.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7186s / 521.9668 s
agent0:                 episode reward: -0.4991,                 loss: nan
agent1:                 episode reward: 0.4991,                 loss: 0.3255
Episode: 18641/30000 (62.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7263s / 522.6931 s
agent0:                 episode reward: -0.8983,                 loss: nan
agent1:                 episode reward: 0.8983,                 loss: 0.3260
Episode: 18661/30000 (62.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7358s / 523.4289 s
agent0:                 episode reward: -0.9534,                 loss: nan
agent1:                 episode reward: 0.9534,                 loss: 0.3262
Episode: 18681/30000 (62.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7247s / 524.1536 s
agent0:                 episode reward: -0.7031,                 loss: nan
agent1:                 episode reward: 0.7031,                 loss: 0.3295
Episode: 18701/30000 (62.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7280s / 524.8817 s
agent0:                 episode reward: -0.6302,                 loss: nan
agent1:                 episode reward: 0.6302,                 loss: 0.3280
Episode: 18721/30000 (62.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7296s / 525.6113 s
agent0:                 episode reward: -0.6964,                 loss: nan
agent1:                 episode reward: 0.6964,                 loss: 0.3308
Episode: 18741/30000 (62.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7186s / 526.3299 s
agent0:                 episode reward: -0.5328,                 loss: nan
agent1:                 episode reward: 0.5328,                 loss: 0.3289
Episode: 18761/30000 (62.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7359s / 527.0658 s
agent0:                 episode reward: -0.7598,                 loss: nan
agent1:                 episode reward: 0.7598,                 loss: 0.3265
Episode: 18781/30000 (62.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7266s / 527.7925 s
agent0:                 episode reward: -0.3781,                 loss: nan
agent1:                 episode reward: 0.3781,                 loss: 0.3311
Episode: 18801/30000 (62.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7438s / 528.5362 s
agent0:                 episode reward: -0.3192,                 loss: nan
agent1:                 episode reward: 0.3192,                 loss: 0.3269
Episode: 18821/30000 (62.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7256s / 529.2619 s
agent0:                 episode reward: -0.2766,                 loss: nan
agent1:                 episode reward: 0.2766,                 loss: 0.3293
Episode: 18841/30000 (62.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7228s / 529.9846 s
agent0:                 episode reward: -0.8623,                 loss: nan
agent1:                 episode reward: 0.8623,                 loss: 0.3282
Episode: 18861/30000 (62.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7289s / 530.7136 s
agent0:                 episode reward: -1.0446,                 loss: nan
agent1:                 episode reward: 1.0446,                 loss: 0.3286
Episode: 18881/30000 (62.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7243s / 531.4378 s
agent0:                 episode reward: -0.7646,                 loss: nan
agent1:                 episode reward: 0.7646,                 loss: 0.3298
Episode: 18901/30000 (63.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7317s / 532.1695 s
agent0:                 episode reward: -0.3941,                 loss: nan
agent1:                 episode reward: 0.3941,                 loss: 0.3289
Episode: 18921/30000 (63.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7377s / 532.9072 s
agent0:                 episode reward: -0.5540,                 loss: nan
agent1:                 episode reward: 0.5540,                 loss: 0.3306
Episode: 18941/30000 (63.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7226s / 533.6299 s
agent0:                 episode reward: -0.7001,                 loss: nan
agent1:                 episode reward: 0.7001,                 loss: 0.3264
Episode: 18961/30000 (63.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7438s / 534.3737 s
agent0:                 episode reward: -0.5618,                 loss: nan
agent1:                 episode reward: 0.5618,                 loss: 0.3297
Episode: 18981/30000 (63.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7369s / 535.1106 s
agent0:                 episode reward: -0.8530,                 loss: nan
agent1:                 episode reward: 0.8530,                 loss: 0.3309
Episode: 19001/30000 (63.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7332s / 535.8438 s
agent0:                 episode reward: -0.4724,                 loss: nan
agent1:                 episode reward: 0.4724,                 loss: 0.3278
Episode: 19021/30000 (63.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7340s / 536.5778 s
agent0:                 episode reward: -0.5166,                 loss: nan
agent1:                 episode reward: 0.5166,                 loss: 0.3212
Episode: 19041/30000 (63.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7269s / 537.3047 s
agent0:                 episode reward: -0.6644,                 loss: nan
agent1:                 episode reward: 0.6644,                 loss: 0.3207
Episode: 19061/30000 (63.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7273s / 538.0320 s
agent0:                 episode reward: -0.6885,                 loss: nan
agent1:                 episode reward: 0.6885,                 loss: 0.3184
Episode: 19081/30000 (63.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7266s / 538.7586 s
agent0:                 episode reward: -0.5068,                 loss: nan
agent1:                 episode reward: 0.5068,                 loss: 0.3212
Episode: 19101/30000 (63.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7414s / 539.5001 s
agent0:                 episode reward: -0.4613,                 loss: nan
agent1:                 episode reward: 0.4613,                 loss: 0.3219
Episode: 19121/30000 (63.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7310s / 540.2311 s
agent0:                 episode reward: -0.2859,                 loss: nan
agent1:                 episode reward: 0.2859,                 loss: 0.3219
Episode: 19141/30000 (63.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7233s / 540.9543 s
agent0:                 episode reward: -0.4029,                 loss: nan
agent1:                 episode reward: 0.4029,                 loss: 0.3218
Episode: 19161/30000 (63.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7373s / 541.6916 s
agent0:                 episode reward: -0.3813,                 loss: nan
agent1:                 episode reward: 0.3813,                 loss: 0.3245
Episode: 19181/30000 (63.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7336s / 542.4253 s
agent0:                 episode reward: -0.8044,                 loss: nan
agent1:                 episode reward: 0.8044,                 loss: 0.3215
Episode: 19201/30000 (64.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7258s / 543.1511 s
agent0:                 episode reward: -0.3216,                 loss: nan
agent1:                 episode reward: 0.3216,                 loss: 0.3195
Episode: 19221/30000 (64.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7095s / 543.8606 s
agent0:                 episode reward: -0.4833,                 loss: nan
agent1:                 episode reward: 0.4833,                 loss: 0.3203
Episode: 19241/30000 (64.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7312s / 544.5918 s
agent0:                 episode reward: -0.5677,                 loss: nan
agent1:                 episode reward: 0.5677,                 loss: 0.3220
Episode: 19261/30000 (64.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7359s / 545.3276 s
agent0:                 episode reward: -0.4796,                 loss: nan
agent1:                 episode reward: 0.4796,                 loss: 0.3193
Episode: 19281/30000 (64.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7451s / 546.0727 s
agent0:                 episode reward: -0.4082,                 loss: nan
agent1:                 episode reward: 0.4082,                 loss: 0.3200
Episode: 19301/30000 (64.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7497s / 546.8224 s
agent0:                 episode reward: -0.5503,                 loss: nan
agent1:                 episode reward: 0.5503,                 loss: 0.3211
Episode: 19321/30000 (64.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7501s / 547.5725 s
agent0:                 episode reward: -0.6233,                 loss: nan
agent1:                 episode reward: 0.6233,                 loss: 0.3213
Episode: 19341/30000 (64.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7535s / 548.3259 s
agent0:                 episode reward: -0.2240,                 loss: nan
agent1:                 episode reward: 0.2240,                 loss: 0.3253
Episode: 19361/30000 (64.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7510s / 549.0769 s
agent0:                 episode reward: -0.8587,                 loss: nan
agent1:                 episode reward: 0.8587,                 loss: 0.3259
Episode: 19381/30000 (64.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7376s / 549.8145 s
agent0:                 episode reward: -0.7360,                 loss: nan
agent1:                 episode reward: 0.7360,                 loss: 0.3241
Episode: 19401/30000 (64.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7410s / 550.5556 s
agent0:                 episode reward: -0.7806,                 loss: nan
agent1:                 episode reward: 0.7806,                 loss: 0.3252
Episode: 19421/30000 (64.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7311s / 551.2867 s
agent0:                 episode reward: -0.7159,                 loss: nan
agent1:                 episode reward: 0.7159,                 loss: 0.3249
Episode: 19441/30000 (64.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7334s / 552.0200 s
agent0:                 episode reward: -0.4973,                 loss: nan
agent1:                 episode reward: 0.4973,                 loss: 0.3248
Episode: 19461/30000 (64.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7406s / 552.7607 s
agent0:                 episode reward: -0.3466,                 loss: nan
agent1:                 episode reward: 0.3466,                 loss: 0.3283
Episode: 19481/30000 (64.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7435s / 553.5042 s
agent0:                 episode reward: -0.8694,                 loss: nan
agent1:                 episode reward: 0.8694,                 loss: 0.3258
Episode: 19501/30000 (65.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7288s / 554.2330 s
agent0:                 episode reward: -0.7965,                 loss: nan
agent1:                 episode reward: 0.7965,                 loss: 0.3279
Episode: 19521/30000 (65.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7377s / 554.9707 s
agent0:                 episode reward: -0.7923,                 loss: nan
agent1:                 episode reward: 0.7923,                 loss: 0.3266
Episode: 19541/30000 (65.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7423s / 555.7130 s
agent0:                 episode reward: -0.5793,                 loss: nan
agent1:                 episode reward: 0.5793,                 loss: 0.3274
Episode: 19561/30000 (65.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7365s / 556.4495 s
agent0:                 episode reward: -0.8460,                 loss: nan
agent1:                 episode reward: 0.8460,                 loss: 0.3279
Episode: 19581/30000 (65.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7524s / 557.2018 s
agent0:                 episode reward: -0.6401,                 loss: nan
agent1:                 episode reward: 0.6401,                 loss: 0.3210
Episode: 19601/30000 (65.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7397s / 557.9415 s
agent0:                 episode reward: -0.4626,                 loss: nan
agent1:                 episode reward: 0.4626,                 loss: 0.3241
Episode: 19621/30000 (65.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7293s / 558.6709 s
agent0:                 episode reward: -0.5083,                 loss: nan
agent1:                 episode reward: 0.5083,                 loss: 0.3271
Episode: 19641/30000 (65.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7371s / 559.4080 s
agent0:                 episode reward: -0.8986,                 loss: nan
agent1:                 episode reward: 0.8986,                 loss: 0.3264
Episode: 19661/30000 (65.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7294s / 560.1374 s
agent0:                 episode reward: -0.4606,                 loss: nan
agent1:                 episode reward: 0.4606,                 loss: 0.3255
Episode: 19681/30000 (65.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7427s / 560.8801 s
agent0:                 episode reward: -0.1094,                 loss: nan
agent1:                 episode reward: 0.1094,                 loss: 0.3265
Episode: 19701/30000 (65.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7323s / 561.6124 s
agent0:                 episode reward: -0.4646,                 loss: nan
agent1:                 episode reward: 0.4646,                 loss: 0.3256
Episode: 19721/30000 (65.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7431s / 562.3555 s
agent0:                 episode reward: -0.3242,                 loss: nan
agent1:                 episode reward: 0.3242,                 loss: 0.3239
Episode: 19741/30000 (65.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7486s / 563.1040 s
agent0:                 episode reward: -0.0616,                 loss: nan
agent1:                 episode reward: 0.0616,                 loss: 0.3268
Episode: 19761/30000 (65.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7570s / 563.8610 s
agent0:                 episode reward: -0.8161,                 loss: nan
agent1:                 episode reward: 0.8161,                 loss: 0.3265
Episode: 19781/30000 (65.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7516s / 564.6126 s
agent0:                 episode reward: -0.7175,                 loss: nan
agent1:                 episode reward: 0.7175,                 loss: 0.3264
Episode: 19801/30000 (66.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7447s / 565.3573 s
agent0:                 episode reward: -0.6441,                 loss: nan
agent1:                 episode reward: 0.6441,                 loss: 0.3257
Episode: 19821/30000 (66.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7488s / 566.1061 s
agent0:                 episode reward: -0.8119,                 loss: nan
agent1:                 episode reward: 0.8119,                 loss: 0.3266
Episode: 19841/30000 (66.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7498s / 566.8559 s
agent0:                 episode reward: -1.0353,                 loss: nan
agent1:                 episode reward: 1.0353,                 loss: 0.3278
Episode: 19861/30000 (66.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7446s / 567.6005 s
agent0:                 episode reward: -0.2327,                 loss: nan
agent1:                 episode reward: 0.2327,                 loss: 0.3277
Episode: 19881/30000 (66.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7484s / 568.3488 s
agent0:                 episode reward: -0.5116,                 loss: nan
agent1:                 episode reward: 0.5116,                 loss: 0.3264
Episode: 19901/30000 (66.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7577s / 569.1065 s
agent0:                 episode reward: -0.5431,                 loss: nan
agent1:                 episode reward: 0.5431,                 loss: 0.3276
Episode: 19921/30000 (66.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7389s / 569.8454 s
agent0:                 episode reward: -0.4755,                 loss: nan
agent1:                 episode reward: 0.4755,                 loss: 0.3296
Episode: 19941/30000 (66.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7482s / 570.5936 s
agent0:                 episode reward: -0.5607,                 loss: nan
agent1:                 episode reward: 0.5607,                 loss: 0.3236
Episode: 19961/30000 (66.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7454s / 571.3390 s
agent0:                 episode reward: -0.6549,                 loss: nan
agent1:                 episode reward: 0.6549,                 loss: 0.3264
Episode: 19981/30000 (66.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7484s / 572.0874 s
agent0:                 episode reward: -0.4638,                 loss: nan
agent1:                 episode reward: 0.4638,                 loss: 0.3217
Episode: 20001/30000 (66.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7514s / 572.8388 s
agent0:                 episode reward: -0.7422,                 loss: nan
agent1:                 episode reward: 0.7422,                 loss: 0.3248
Episode: 20021/30000 (66.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7553s / 573.5941 s
agent0:                 episode reward: -0.5314,                 loss: nan
agent1:                 episode reward: 0.5314,                 loss: 0.3254
Episode: 20041/30000 (66.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7526s / 574.3467 s
agent0:                 episode reward: -0.3278,                 loss: nan
agent1:                 episode reward: 0.3278,                 loss: 0.3285
Episode: 20061/30000 (66.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7420s / 575.0887 s
agent0:                 episode reward: -0.6634,                 loss: nan
agent1:                 episode reward: 0.6634,                 loss: 0.3286
Episode: 20081/30000 (66.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7554s / 575.8441 s
agent0:                 episode reward: -0.7936,                 loss: nan
agent1:                 episode reward: 0.7936,                 loss: 0.3278
Episode: 20101/30000 (67.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7555s / 576.5996 s
agent0:                 episode reward: -0.7538,                 loss: nan
agent1:                 episode reward: 0.7538,                 loss: 0.3294
Episode: 20121/30000 (67.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7476s / 577.3472 s
agent0:                 episode reward: -0.6354,                 loss: nan
agent1:                 episode reward: 0.6354,                 loss: 0.3292
Episode: 20141/30000 (67.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7442s / 578.0914 s
agent0:                 episode reward: -0.5390,                 loss: nan
agent1:                 episode reward: 0.5390,                 loss: 0.3290
Episode: 20161/30000 (67.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7429s / 578.8343 s
agent0:                 episode reward: -0.5309,                 loss: nan
agent1:                 episode reward: 0.5309,                 loss: 0.3262
Episode: 20181/30000 (67.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7531s / 579.5874 s
agent0:                 episode reward: -0.7602,                 loss: nan
agent1:                 episode reward: 0.7602,                 loss: 0.3286
Episode: 20201/30000 (67.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7632s / 580.3507 s
agent0:                 episode reward: -0.5128,                 loss: nan
agent1:                 episode reward: 0.5128,                 loss: 0.3261
Episode: 20221/30000 (67.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7444s / 581.0951 s
agent0:                 episode reward: -0.7858,                 loss: nan
agent1:                 episode reward: 0.7858,                 loss: 0.3267
Episode: 20241/30000 (67.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7535s / 581.8486 s
agent0:                 episode reward: -0.7202,                 loss: nan
agent1:                 episode reward: 0.7202,                 loss: 0.3269
Episode: 20261/30000 (67.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7480s / 582.5965 s
agent0:                 episode reward: -0.4068,                 loss: nan
agent1:                 episode reward: 0.4068,                 loss: 0.3281
Episode: 20281/30000 (67.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7550s / 583.3515 s
agent0:                 episode reward: -0.7583,                 loss: nan
agent1:                 episode reward: 0.7583,                 loss: 0.3261
Episode: 20301/30000 (67.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7470s / 584.0985 s
agent0:                 episode reward: -0.4218,                 loss: nan
agent1:                 episode reward: 0.4218,                 loss: 0.3262
Episode: 20321/30000 (67.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7461s / 584.8446 s
agent0:                 episode reward: -0.8013,                 loss: nan
agent1:                 episode reward: 0.8013,                 loss: 0.3298
Episode: 20341/30000 (67.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7493s / 585.5938 s
agent0:                 episode reward: -0.5436,                 loss: nan
agent1:                 episode reward: 0.5436,                 loss: 0.3256
Episode: 20361/30000 (67.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7548s / 586.3487 s
agent0:                 episode reward: -0.4174,                 loss: nan
agent1:                 episode reward: 0.4174,                 loss: 0.3268
Episode: 20381/30000 (67.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7568s / 587.1055 s
agent0:                 episode reward: -0.6762,                 loss: nan
agent1:                 episode reward: 0.6762,                 loss: 0.3205
Episode: 20401/30000 (68.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7627s / 587.8682 s
agent0:                 episode reward: -0.1193,                 loss: nan
agent1:                 episode reward: 0.1193,                 loss: 0.3257
Episode: 20421/30000 (68.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7462s / 588.6144 s
agent0:                 episode reward: -0.3879,                 loss: nan
agent1:                 episode reward: 0.3879,                 loss: 0.3241
Episode: 20441/30000 (68.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7527s / 589.3670 s
agent0:                 episode reward: -0.4686,                 loss: nan
agent1:                 episode reward: 0.4686,                 loss: 0.3256
Episode: 20461/30000 (68.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7548s / 590.1218 s
agent0:                 episode reward: -0.1565,                 loss: nan
agent1:                 episode reward: 0.1565,                 loss: 0.3262
Episode: 20481/30000 (68.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7529s / 590.8748 s
agent0:                 episode reward: -0.4339,                 loss: nan
agent1:                 episode reward: 0.4339,                 loss: 0.3245
Episode: 20501/30000 (68.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7651s / 591.6399 s
agent0:                 episode reward: -0.9516,                 loss: nan
agent1:                 episode reward: 0.9516,                 loss: 0.3254
Episode: 20521/30000 (68.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7716s / 592.4114 s
agent0:                 episode reward: -1.0383,                 loss: nan
agent1:                 episode reward: 1.0383,                 loss: 0.3255
Episode: 20541/30000 (68.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7675s / 593.1790 s
agent0:                 episode reward: -0.8062,                 loss: nan
agent1:                 episode reward: 0.8062,                 loss: 0.3246
Episode: 20561/30000 (68.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7640s / 593.9430 s
agent0:                 episode reward: -0.4439,                 loss: nan
agent1:                 episode reward: 0.4439,                 loss: 0.3241
Episode: 20581/30000 (68.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7635s / 594.7065 s
agent0:                 episode reward: -0.9279,                 loss: nan
agent1:                 episode reward: 0.9279,                 loss: 0.3231
Episode: 20601/30000 (68.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7513s / 595.4578 s
agent0:                 episode reward: -0.7872,                 loss: nan
agent1:                 episode reward: 0.7872,                 loss: 0.3246
Episode: 20621/30000 (68.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7528s / 596.2106 s
agent0:                 episode reward: -0.3882,                 loss: nan
agent1:                 episode reward: 0.3882,                 loss: 0.3257
Episode: 20641/30000 (68.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7526s / 596.9632 s
agent0:                 episode reward: -0.5684,                 loss: nan
agent1:                 episode reward: 0.5684,                 loss: 0.3228
Episode: 20661/30000 (68.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7527s / 597.7159 s
agent0:                 episode reward: -0.7108,                 loss: nan
agent1:                 episode reward: 0.7108,                 loss: 0.3229
Episode: 20681/30000 (68.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7601s / 598.4760 s
agent0:                 episode reward: -0.4529,                 loss: nan
agent1:                 episode reward: 0.4529,                 loss: 0.3269
Episode: 20701/30000 (69.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7536s / 599.2295 s
agent0:                 episode reward: -0.6911,                 loss: nan
agent1:                 episode reward: 0.6911,                 loss: 0.3292
Episode: 20721/30000 (69.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7615s / 599.9910 s
agent0:                 episode reward: -0.4732,                 loss: nan
agent1:                 episode reward: 0.4732,                 loss: 0.3286
Episode: 20741/30000 (69.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7725s / 600.7635 s
agent0:                 episode reward: -0.4262,                 loss: nan
agent1:                 episode reward: 0.4262,                 loss: 0.3303
Episode: 20761/30000 (69.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7752s / 601.5387 s
agent0:                 episode reward: -0.7672,                 loss: nan
agent1:                 episode reward: 0.7672,                 loss: 0.3298
Episode: 20781/30000 (69.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7551s / 602.2938 s
agent0:                 episode reward: -0.7250,                 loss: nan
agent1:                 episode reward: 0.7250,                 loss: 0.3294
Episode: 20801/30000 (69.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7569s / 603.0507 s
agent0:                 episode reward: -0.3934,                 loss: nan
agent1:                 episode reward: 0.3934,                 loss: 0.3281
Episode: 20821/30000 (69.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7625s / 603.8132 s
agent0:                 episode reward: -0.1873,                 loss: nan
agent1:                 episode reward: 0.1873,                 loss: 0.3302
Episode: 20841/30000 (69.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7675s / 604.5806 s
agent0:                 episode reward: -0.6137,                 loss: nan
agent1:                 episode reward: 0.6137,                 loss: 0.3294
Episode: 20861/30000 (69.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7621s / 605.3428 s
agent0:                 episode reward: -0.5644,                 loss: nan
agent1:                 episode reward: 0.5644,                 loss: 0.3313
Episode: 20881/30000 (69.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7521s / 606.0949 s
agent0:                 episode reward: -0.5700,                 loss: nan
agent1:                 episode reward: 0.5700,                 loss: 0.3284
Episode: 20901/30000 (69.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7627s / 606.8576 s
agent0:                 episode reward: -0.8841,                 loss: nan
agent1:                 episode reward: 0.8841,                 loss: 0.3302
Episode: 20921/30000 (69.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7725s / 607.6301 s
agent0:                 episode reward: -0.1198,                 loss: nan
agent1:                 episode reward: 0.1198,                 loss: 0.3260
Episode: 20941/30000 (69.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7693s / 608.3994 s
agent0:                 episode reward: -0.8605,                 loss: nan
agent1:                 episode reward: 0.8605,                 loss: 0.3296
Episode: 20961/30000 (69.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7755s / 609.1750 s
agent0:                 episode reward: -0.3540,                 loss: nan
agent1:                 episode reward: 0.3540,                 loss: 0.3306
Episode: 20981/30000 (69.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7566s / 609.9315 s
agent0:                 episode reward: -0.6533,                 loss: nan
agent1:                 episode reward: 0.6533,                 loss: 0.3300
Episode: 21001/30000 (70.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7695s / 610.7011 s
agent0:                 episode reward: -0.7299,                 loss: nan
agent1:                 episode reward: 0.7299,                 loss: 0.3298
Episode: 21021/30000 (70.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7594s / 611.4605 s
agent0:                 episode reward: -0.6355,                 loss: nan
agent1:                 episode reward: 0.6355,                 loss: 0.3237
Episode: 21041/30000 (70.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7674s / 612.2278 s
agent0:                 episode reward: -0.5600,                 loss: nan
agent1:                 episode reward: 0.5600,                 loss: 0.3229
Episode: 21061/30000 (70.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7517s / 612.9795 s
agent0:                 episode reward: -0.3445,                 loss: nan
agent1:                 episode reward: 0.3445,                 loss: 0.3227
Episode: 21081/30000 (70.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7590s / 613.7385 s
agent0:                 episode reward: -0.3537,                 loss: nan
agent1:                 episode reward: 0.3537,                 loss: 0.3261
Episode: 21101/30000 (70.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7617s / 614.5002 s
agent0:                 episode reward: -0.6519,                 loss: nan
agent1:                 episode reward: 0.6519,                 loss: 0.3221
Episode: 21121/30000 (70.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7629s / 615.2631 s
agent0:                 episode reward: -0.2645,                 loss: nan
agent1:                 episode reward: 0.2645,                 loss: 0.3242
Episode: 21141/30000 (70.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7663s / 616.0294 s
agent0:                 episode reward: -0.7165,                 loss: nan
agent1:                 episode reward: 0.7165,                 loss: 0.3255
Episode: 21161/30000 (70.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7696s / 616.7990 s
agent0:                 episode reward: -0.6978,                 loss: nan
agent1:                 episode reward: 0.6978,                 loss: 0.3223
Episode: 21181/30000 (70.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7628s / 617.5618 s
agent0:                 episode reward: -0.2107,                 loss: nan
agent1:                 episode reward: 0.2107,                 loss: 0.3254
Episode: 21201/30000 (70.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7656s / 618.3274 s
agent0:                 episode reward: -0.2974,                 loss: nan
agent1:                 episode reward: 0.2974,                 loss: 0.3236
Episode: 21221/30000 (70.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7758s / 619.1031 s
agent0:                 episode reward: -0.7323,                 loss: nan
agent1:                 episode reward: 0.7323,                 loss: 0.3238
Episode: 21241/30000 (70.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7634s / 619.8665 s
agent0:                 episode reward: -0.5158,                 loss: nan
agent1:                 episode reward: 0.5158,                 loss: 0.3236
Episode: 21261/30000 (70.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7647s / 620.6312 s
agent0:                 episode reward: -0.6658,                 loss: nan
agent1:                 episode reward: 0.6658,                 loss: 0.3223
Episode: 21281/30000 (70.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7659s / 621.3971 s
agent0:                 episode reward: -0.6992,                 loss: nan
agent1:                 episode reward: 0.6992,                 loss: 0.3236
Episode: 21301/30000 (71.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7639s / 622.1610 s
agent0:                 episode reward: -0.3118,                 loss: nan
agent1:                 episode reward: 0.3118,                 loss: 0.3227
Episode: 21321/30000 (71.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7884s / 622.9494 s
agent0:                 episode reward: -0.5773,                 loss: nan
agent1:                 episode reward: 0.5773,                 loss: 0.3238
Episode: 21341/30000 (71.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8038s / 623.7533 s
agent0:                 episode reward: -0.5959,                 loss: nan
agent1:                 episode reward: 0.5959,                 loss: 0.3255
Episode: 21361/30000 (71.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7710s / 624.5242 s
agent0:                 episode reward: -0.4492,                 loss: nan
agent1:                 episode reward: 0.4492,                 loss: 0.3213
Episode: 21381/30000 (71.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7717s / 625.2960 s
agent0:                 episode reward: -0.1871,                 loss: nan
agent1:                 episode reward: 0.1871,                 loss: 0.3201
Episode: 21401/30000 (71.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7628s / 626.0587 s
agent0:                 episode reward: -0.3439,                 loss: nan
agent1:                 episode reward: 0.3439,                 loss: 0.3221
Episode: 21421/30000 (71.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7734s / 626.8321 s
agent0:                 episode reward: -0.1761,                 loss: nan
agent1:                 episode reward: 0.1761,                 loss: 0.3242
Episode: 21441/30000 (71.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7727s / 627.6048 s
agent0:                 episode reward: -0.5877,                 loss: nan
agent1:                 episode reward: 0.5877,                 loss: 0.3204
Episode: 21461/30000 (71.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7607s / 628.3655 s
agent0:                 episode reward: -0.6878,                 loss: nan
agent1:                 episode reward: 0.6878,                 loss: 0.3202
Episode: 21481/30000 (71.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7777s / 629.1432 s
agent0:                 episode reward: -0.5711,                 loss: nan
agent1:                 episode reward: 0.5711,                 loss: 0.3221
Episode: 21501/30000 (71.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7881s / 629.9313 s
agent0:                 episode reward: -0.4680,                 loss: nan
agent1:                 episode reward: 0.4680,                 loss: 0.3207
Episode: 21521/30000 (71.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7888s / 630.7201 s
agent0:                 episode reward: -0.4956,                 loss: nan
agent1:                 episode reward: 0.4956,                 loss: 0.3203
Episode: 21541/30000 (71.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7818s / 631.5020 s
agent0:                 episode reward: -0.5157,                 loss: nan
agent1:                 episode reward: 0.5157,                 loss: 0.3196
Episode: 21561/30000 (71.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7765s / 632.2785 s
agent0:                 episode reward: -0.2794,                 loss: nan
agent1:                 episode reward: 0.2794,                 loss: 0.3193
Episode: 21581/30000 (71.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7827s / 633.0612 s
agent0:                 episode reward: -0.4936,                 loss: nan
agent1:                 episode reward: 0.4936,                 loss: 0.3216
Episode: 21601/30000 (72.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7836s / 633.8448 s
agent0:                 episode reward: 0.0380,                 loss: nan
agent1:                 episode reward: -0.0380,                 loss: 0.3224
Episode: 21621/30000 (72.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7686s / 634.6134 s
agent0:                 episode reward: -0.3205,                 loss: nan
agent1:                 episode reward: 0.3205,                 loss: 0.3242
Episode: 21641/30000 (72.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7917s / 635.4051 s
agent0:                 episode reward: -0.5028,                 loss: nan
agent1:                 episode reward: 0.5028,                 loss: 0.3194
Episode: 21661/30000 (72.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7784s / 636.1835 s
agent0:                 episode reward: -0.5938,                 loss: nan
agent1:                 episode reward: 0.5938,                 loss: 0.3221
Episode: 21681/30000 (72.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7744s / 636.9579 s
agent0:                 episode reward: -0.6539,                 loss: nan
agent1:                 episode reward: 0.6539,                 loss: 0.3306
Episode: 21701/30000 (72.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7749s / 637.7328 s
agent0:                 episode reward: -0.7765,                 loss: nan
agent1:                 episode reward: 0.7765,                 loss: 0.3306
Episode: 21721/30000 (72.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7797s / 638.5125 s
agent0:                 episode reward: -0.4638,                 loss: nan
agent1:                 episode reward: 0.4638,                 loss: 0.3375
Episode: 21741/30000 (72.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7819s / 639.2944 s
agent0:                 episode reward: -0.3820,                 loss: nan
agent1:                 episode reward: 0.3820,                 loss: 0.3326
Episode: 21761/30000 (72.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7873s / 640.0817 s
agent0:                 episode reward: -0.1068,                 loss: nan
agent1:                 episode reward: 0.1068,                 loss: 0.3354
Episode: 21781/30000 (72.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7788s / 640.8604 s
agent0:                 episode reward: -0.8762,                 loss: nan
agent1:                 episode reward: 0.8762,                 loss: 0.3339
Episode: 21801/30000 (72.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7788s / 641.6392 s
agent0:                 episode reward: -0.3023,                 loss: nan
agent1:                 episode reward: 0.3023,                 loss: 0.3332
Episode: 21821/30000 (72.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8001s / 642.4393 s
agent0:                 episode reward: -0.6235,                 loss: nan
agent1:                 episode reward: 0.6235,                 loss: 0.3366
Episode: 21841/30000 (72.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8029s / 643.2422 s
agent0:                 episode reward: -0.7097,                 loss: nan
agent1:                 episode reward: 0.7097,                 loss: 0.3329
Episode: 21861/30000 (72.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7911s / 644.0333 s
agent0:                 episode reward: -0.7393,                 loss: nan
agent1:                 episode reward: 0.7393,                 loss: 0.3322
Episode: 21881/30000 (72.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7736s / 644.8069 s
agent0:                 episode reward: -0.1679,                 loss: nan
agent1:                 episode reward: 0.1679,                 loss: 0.3328
Episode: 21901/30000 (73.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7703s / 645.5772 s
agent0:                 episode reward: -0.7928,                 loss: nan
agent1:                 episode reward: 0.7928,                 loss: 0.3321
Episode: 21921/30000 (73.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7696s / 646.3468 s
agent0:                 episode reward: -0.5823,                 loss: nan
agent1:                 episode reward: 0.5823,                 loss: 0.3346
Episode: 21941/30000 (73.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7802s / 647.1270 s
agent0:                 episode reward: -0.6083,                 loss: nan
agent1:                 episode reward: 0.6083,                 loss: 0.3344
Episode: 21961/30000 (73.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7771s / 647.9041 s
agent0:                 episode reward: -0.6511,                 loss: nan
agent1:                 episode reward: 0.6511,                 loss: 0.3347
Episode: 21981/30000 (73.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7792s / 648.6833 s
agent0:                 episode reward: -0.1690,                 loss: nan
agent1:                 episode reward: 0.1690,                 loss: 0.3306
Episode: 22001/30000 (73.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7841s / 649.4674 s
agent0:                 episode reward: -0.7092,                 loss: nan
agent1:                 episode reward: 0.7092,                 loss: 0.3341
Episode: 22021/30000 (73.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7911s / 650.2585 s
agent0:                 episode reward: -0.4569,                 loss: nan
agent1:                 episode reward: 0.4569,                 loss: 0.3125
Episode: 22041/30000 (73.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8044s / 651.0629 s
agent0:                 episode reward: -0.7550,                 loss: nan
agent1:                 episode reward: 0.7550,                 loss: 0.3114
Episode: 22061/30000 (73.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7997s / 651.8626 s
agent0:                 episode reward: -0.5112,                 loss: nan
agent1:                 episode reward: 0.5112,                 loss: 0.3138
Episode: 22081/30000 (73.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7768s / 652.6394 s
agent0:                 episode reward: -0.5288,                 loss: nan
agent1:                 episode reward: 0.5288,                 loss: 0.3124
Episode: 22101/30000 (73.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7683s / 653.4077 s
agent0:                 episode reward: -1.0373,                 loss: nan
agent1:                 episode reward: 1.0373,                 loss: 0.3126
Episode: 22121/30000 (73.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7888s / 654.1965 s
agent0:                 episode reward: -0.3911,                 loss: nan
agent1:                 episode reward: 0.3911,                 loss: 0.3142
Episode: 22141/30000 (73.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7887s / 654.9853 s
agent0:                 episode reward: -0.3031,                 loss: nan
agent1:                 episode reward: 0.3031,                 loss: 0.3123
Episode: 22161/30000 (73.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7806s / 655.7658 s
agent0:                 episode reward: -0.7885,                 loss: nan
agent1:                 episode reward: 0.7885,                 loss: 0.3124
Episode: 22181/30000 (73.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7758s / 656.5416 s
agent0:                 episode reward: -0.8052,                 loss: nan
agent1:                 episode reward: 0.8052,                 loss: 0.3105
Episode: 22201/30000 (74.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7977s / 657.3393 s
agent0:                 episode reward: -0.6327,                 loss: nan
agent1:                 episode reward: 0.6327,                 loss: 0.3131
Episode: 22221/30000 (74.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7940s / 658.1333 s
agent0:                 episode reward: -0.3499,                 loss: nan
agent1:                 episode reward: 0.3499,                 loss: 0.3123
Episode: 22241/30000 (74.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7841s / 658.9174 s
agent0:                 episode reward: -0.9432,                 loss: nan
agent1:                 episode reward: 0.9432,                 loss: 0.3086
Episode: 22261/30000 (74.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7843s / 659.7017 s
agent0:                 episode reward: -0.6629,                 loss: nan
agent1:                 episode reward: 0.6629,                 loss: 0.3126
Episode: 22281/30000 (74.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7844s / 660.4862 s
agent0:                 episode reward: -0.5531,                 loss: nan
agent1:                 episode reward: 0.5531,                 loss: 0.3103
Episode: 22301/30000 (74.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7714s / 661.2576 s
agent0:                 episode reward: -0.4735,                 loss: nan
agent1:                 episode reward: 0.4735,                 loss: 0.3124
Episode: 22321/30000 (74.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7811s / 662.0387 s
agent0:                 episode reward: -0.2470,                 loss: nan
agent1:                 episode reward: 0.2470,                 loss: 0.3132
Episode: 22341/30000 (74.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7815s / 662.8203 s
agent0:                 episode reward: -0.6816,                 loss: nan
agent1:                 episode reward: 0.6816,                 loss: 0.3224
Episode: 22361/30000 (74.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7796s / 663.5999 s
agent0:                 episode reward: -0.5016,                 loss: nan
agent1:                 episode reward: 0.5016,                 loss: 0.3339
Episode: 22381/30000 (74.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8072s / 664.4071 s
agent0:                 episode reward: -0.4188,                 loss: nan
agent1:                 episode reward: 0.4188,                 loss: 0.3339
Episode: 22401/30000 (74.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8148s / 665.2219 s
agent0:                 episode reward: -0.2919,                 loss: nan
agent1:                 episode reward: 0.2919,                 loss: 0.3340
Episode: 22421/30000 (74.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7909s / 666.0128 s
agent0:                 episode reward: -0.6658,                 loss: nan
agent1:                 episode reward: 0.6658,                 loss: 0.3357
Episode: 22441/30000 (74.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7857s / 666.7985 s
agent0:                 episode reward: -0.4641,                 loss: nan
agent1:                 episode reward: 0.4641,                 loss: 0.3357
Episode: 22461/30000 (74.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7819s / 667.5804 s
agent0:                 episode reward: -0.6784,                 loss: nan
agent1:                 episode reward: 0.6784,                 loss: 0.3334
Episode: 22481/30000 (74.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7831s / 668.3635 s
agent0:                 episode reward: -0.3785,                 loss: nan
agent1:                 episode reward: 0.3785,                 loss: 0.3337
Episode: 22501/30000 (75.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7880s / 669.1515 s
agent0:                 episode reward: -0.1545,                 loss: nan
agent1:                 episode reward: 0.1545,                 loss: 0.3326
Episode: 22521/30000 (75.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7954s / 669.9469 s
agent0:                 episode reward: -0.3980,                 loss: nan
agent1:                 episode reward: 0.3980,                 loss: 0.3296
Episode: 22541/30000 (75.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7941s / 670.7410 s
agent0:                 episode reward: -0.6902,                 loss: nan
agent1:                 episode reward: 0.6902,                 loss: 0.3349
Episode: 22561/30000 (75.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7862s / 671.5272 s
agent0:                 episode reward: -0.8058,                 loss: nan
agent1:                 episode reward: 0.8058,                 loss: 0.3334
Episode: 22581/30000 (75.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7823s / 672.3095 s
agent0:                 episode reward: -0.1970,                 loss: nan
agent1:                 episode reward: 0.1970,                 loss: 0.3339
Episode: 22601/30000 (75.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7866s / 673.0962 s
agent0:                 episode reward: -0.7587,                 loss: nan
agent1:                 episode reward: 0.7587,                 loss: 0.3381
Episode: 22621/30000 (75.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7980s / 673.8942 s
agent0:                 episode reward: -0.4841,                 loss: nan
agent1:                 episode reward: 0.4841,                 loss: 0.3328
Episode: 22641/30000 (75.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7822s / 674.6764 s
agent0:                 episode reward: -0.6555,                 loss: nan
agent1:                 episode reward: 0.6555,                 loss: 0.3313
Episode: 22661/30000 (75.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7931s / 675.4695 s
agent0:                 episode reward: -0.6246,                 loss: nan
agent1:                 episode reward: 0.6246,                 loss: 0.3339
Episode: 22681/30000 (75.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7933s / 676.2628 s
agent0:                 episode reward: -0.6123,                 loss: nan
agent1:                 episode reward: 0.6123,                 loss: 0.3300
Episode: 22701/30000 (75.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7900s / 677.0528 s
agent0:                 episode reward: -0.5718,                 loss: nan
agent1:                 episode reward: 0.5718,                 loss: 0.3271
Episode: 22721/30000 (75.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8016s / 677.8544 s
agent0:                 episode reward: -0.4199,                 loss: nan
agent1:                 episode reward: 0.4199,                 loss: 0.3251
Episode: 22741/30000 (75.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7967s / 678.6511 s
agent0:                 episode reward: -0.3568,                 loss: nan
agent1:                 episode reward: 0.3568,                 loss: 0.3270
Episode: 22761/30000 (75.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8030s / 679.4541 s
agent0:                 episode reward: -0.6709,                 loss: nan
agent1:                 episode reward: 0.6709,                 loss: 0.3280
Episode: 22781/30000 (75.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8070s / 680.2611 s
agent0:                 episode reward: -0.7273,                 loss: nan
agent1:                 episode reward: 0.7273,                 loss: 0.3275
Episode: 22801/30000 (76.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8116s / 681.0727 s
agent0:                 episode reward: -0.5666,                 loss: nan
agent1:                 episode reward: 0.5666,                 loss: 0.3261
Episode: 22821/30000 (76.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8055s / 681.8782 s
agent0:                 episode reward: -0.7641,                 loss: nan
agent1:                 episode reward: 0.7641,                 loss: 0.3229
Episode: 22841/30000 (76.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8030s / 682.6813 s
agent0:                 episode reward: -0.4534,                 loss: nan
agent1:                 episode reward: 0.4534,                 loss: 0.3281
Episode: 22861/30000 (76.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7917s / 683.4730 s
agent0:                 episode reward: -0.7609,                 loss: nan
agent1:                 episode reward: 0.7609,                 loss: 0.3263
Episode: 22881/30000 (76.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8038s / 684.2768 s
agent0:                 episode reward: -0.8211,                 loss: nan
agent1:                 episode reward: 0.8211,                 loss: 0.3271
Episode: 22901/30000 (76.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7971s / 685.0739 s
agent0:                 episode reward: -0.5544,                 loss: nan
agent1:                 episode reward: 0.5544,                 loss: 0.3286
Episode: 22921/30000 (76.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8009s / 685.8747 s
agent0:                 episode reward: -0.4125,                 loss: nan
agent1:                 episode reward: 0.4125,                 loss: 0.3262
Episode: 22941/30000 (76.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8175s / 686.6922 s
agent0:                 episode reward: -0.4254,                 loss: nan
agent1:                 episode reward: 0.4254,                 loss: 0.3263
Episode: 22961/30000 (76.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7961s / 687.4883 s
agent0:                 episode reward: -0.7785,                 loss: nan
agent1:                 episode reward: 0.7785,                 loss: 0.3271
Episode: 22981/30000 (76.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8001s / 688.2885 s
agent0:                 episode reward: -0.7266,                 loss: nan
agent1:                 episode reward: 0.7266,                 loss: 0.3234
Episode: 23001/30000 (76.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8017s / 689.0902 s
agent0:                 episode reward: -0.4374,                 loss: nan
agent1:                 episode reward: 0.4374,                 loss: 0.3282
Episode: 23021/30000 (76.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7935s / 689.8837 s
agent0:                 episode reward: -0.6516,                 loss: nan
agent1:                 episode reward: 0.6516,                 loss: 0.3260
Episode: 23041/30000 (76.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8052s / 690.6889 s
agent0:                 episode reward: -0.6103,                 loss: nan
agent1:                 episode reward: 0.6103,                 loss: 0.3260
Episode: 23061/30000 (76.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8047s / 691.4936 s
agent0:                 episode reward: -0.7470,                 loss: nan
agent1:                 episode reward: 0.7470,                 loss: 0.3282
Episode: 23081/30000 (76.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7978s / 692.2913 s
agent0:                 episode reward: -0.5115,                 loss: nan
agent1:                 episode reward: 0.5115,                 loss: 0.3262
Episode: 23101/30000 (77.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7941s / 693.0854 s
agent0:                 episode reward: -0.6123,                 loss: nan
agent1:                 episode reward: 0.6123,                 loss: 0.3268
Episode: 23121/30000 (77.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7990s / 693.8845 s
agent0:                 episode reward: -0.0741,                 loss: nan
agent1:                 episode reward: 0.0741,                 loss: 0.3273
Episode: 23141/30000 (77.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8147s / 694.6992 s
agent0:                 episode reward: -0.6740,                 loss: nan
agent1:                 episode reward: 0.6740,                 loss: 0.3252
Episode: 23161/30000 (77.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7981s / 695.4973 s
agent0:                 episode reward: -0.5398,                 loss: nan
agent1:                 episode reward: 0.5398,                 loss: 0.3290
Episode: 23181/30000 (77.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8118s / 696.3091 s
agent0:                 episode reward: -0.8484,                 loss: nan
agent1:                 episode reward: 0.8484,                 loss: 0.3246
Episode: 23201/30000 (77.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8021s / 697.1112 s
agent0:                 episode reward: -0.1767,                 loss: nan
agent1:                 episode reward: 0.1767,                 loss: 0.3266
Episode: 23221/30000 (77.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8088s / 697.9200 s
agent0:                 episode reward: -0.4879,                 loss: nan
agent1:                 episode reward: 0.4879,                 loss: 0.3254
Episode: 23241/30000 (77.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8212s / 698.7412 s
agent0:                 episode reward: -0.8111,                 loss: nan
agent1:                 episode reward: 0.8111,                 loss: 0.3273
Episode: 23261/30000 (77.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8255s / 699.5667 s
agent0:                 episode reward: -0.7521,                 loss: nan
agent1:                 episode reward: 0.7521,                 loss: 0.3251
Episode: 23281/30000 (77.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8289s / 700.3957 s
agent0:                 episode reward: -0.3712,                 loss: nan
agent1:                 episode reward: 0.3712,                 loss: 0.3298
Episode: 23301/30000 (77.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8049s / 701.2006 s
agent0:                 episode reward: -0.8466,                 loss: nan
agent1:                 episode reward: 0.8466,                 loss: 0.3264
Episode: 23321/30000 (77.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8203s / 702.0209 s
agent0:                 episode reward: -0.5046,                 loss: nan
agent1:                 episode reward: 0.5046,                 loss: 0.3295
Episode: 23341/30000 (77.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8172s / 702.8381 s
agent0:                 episode reward: -0.8301,                 loss: nan
agent1:                 episode reward: 0.8301,                 loss: 0.3291
Episode: 23361/30000 (77.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7961s / 703.6342 s
agent0:                 episode reward: -0.5659,                 loss: nan
agent1:                 episode reward: 0.5659,                 loss: 0.3275
Episode: 23381/30000 (77.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7964s / 704.4306 s
agent0:                 episode reward: -0.3096,                 loss: nan
agent1:                 episode reward: 0.3096,                 loss: 0.3289
Episode: 23401/30000 (78.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7941s / 705.2246 s
agent0:                 episode reward: -0.7068,                 loss: nan
agent1:                 episode reward: 0.7068,                 loss: 0.3296
Episode: 23421/30000 (78.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8062s / 706.0308 s
agent0:                 episode reward: -0.1944,                 loss: nan
agent1:                 episode reward: 0.1944,                 loss: 0.3287
Episode: 23441/30000 (78.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8000s / 706.8308 s
agent0:                 episode reward: -0.5405,                 loss: nan
agent1:                 episode reward: 0.5405,                 loss: 0.3278
Episode: 23461/30000 (78.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7975s / 707.6284 s
agent0:                 episode reward: -0.6755,                 loss: nan
agent1:                 episode reward: 0.6755,                 loss: 0.3288
Episode: 23481/30000 (78.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8108s / 708.4392 s
agent0:                 episode reward: -0.4317,                 loss: nan
agent1:                 episode reward: 0.4317,                 loss: 0.3265
Episode: 23501/30000 (78.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8111s / 709.2502 s
agent0:                 episode reward: -0.2474,                 loss: nan
agent1:                 episode reward: 0.2474,                 loss: 0.3308
Episode: 23521/30000 (78.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8404s / 710.0907 s
agent0:                 episode reward: -0.7088,                 loss: nan
agent1:                 episode reward: 0.7088,                 loss: 0.3300
Episode: 23541/30000 (78.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8205s / 710.9112 s
agent0:                 episode reward: -0.8276,                 loss: nan
agent1:                 episode reward: 0.8276,                 loss: 0.3307
Episode: 23561/30000 (78.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8084s / 711.7196 s
agent0:                 episode reward: -0.7826,                 loss: nan
agent1:                 episode reward: 0.7826,                 loss: 0.3282
Episode: 23581/30000 (78.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8240s / 712.5436 s
agent0:                 episode reward: -0.5639,                 loss: nan
agent1:                 episode reward: 0.5639,                 loss: 0.3278
Episode: 23601/30000 (78.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8098s / 713.3534 s
agent0:                 episode reward: -1.0682,                 loss: nan
agent1:                 episode reward: 1.0682,                 loss: 0.3310
Episode: 23621/30000 (78.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8157s / 714.1691 s
agent0:                 episode reward: -0.4219,                 loss: nan
agent1:                 episode reward: 0.4219,                 loss: 0.3301
Episode: 23641/30000 (78.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8113s / 714.9804 s
agent0:                 episode reward: -0.6258,                 loss: nan
agent1:                 episode reward: 0.6258,                 loss: 0.3299
Episode: 23661/30000 (78.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8162s / 715.7966 s
agent0:                 episode reward: -0.7167,                 loss: nan
agent1:                 episode reward: 0.7167,                 loss: 0.3290
Episode: 23681/30000 (78.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8079s / 716.6045 s
agent0:                 episode reward: -0.2876,                 loss: nan
agent1:                 episode reward: 0.2876,                 loss: 0.3276
Episode: 23701/30000 (79.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8231s / 717.4276 s
agent0:                 episode reward: -0.4843,                 loss: nan
agent1:                 episode reward: 0.4843,                 loss: 0.3288
Episode: 23721/30000 (79.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8069s / 718.2345 s
agent0:                 episode reward: -0.7605,                 loss: nan
agent1:                 episode reward: 0.7605,                 loss: 0.3308
Episode: 23741/30000 (79.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8157s / 719.0502 s
agent0:                 episode reward: -0.5881,                 loss: nan
agent1:                 episode reward: 0.5881,                 loss: 0.3287
Episode: 23761/30000 (79.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8209s / 719.8711 s
agent0:                 episode reward: -0.8146,                 loss: nan
agent1:                 episode reward: 0.8146,                 loss: 0.3295
Episode: 23781/30000 (79.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8362s / 720.7073 s
agent0:                 episode reward: -0.7522,                 loss: nan
agent1:                 episode reward: 0.7522,                 loss: 0.3300
Episode: 23801/30000 (79.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8157s / 721.5230 s
agent0:                 episode reward: -0.8821,                 loss: nan
agent1:                 episode reward: 0.8821,                 loss: 0.3278
Episode: 23821/30000 (79.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8252s / 722.3482 s
agent0:                 episode reward: -0.6161,                 loss: nan
agent1:                 episode reward: 0.6161,                 loss: 0.3312
Episode: 23841/30000 (79.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8246s / 723.1728 s
agent0:                 episode reward: -0.7972,                 loss: nan
agent1:                 episode reward: 0.7972,                 loss: 0.3276
Episode: 23861/30000 (79.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8245s / 723.9973 s
agent0:                 episode reward: -0.6354,                 loss: nan
agent1:                 episode reward: 0.6354,                 loss: 0.3260
Episode: 23881/30000 (79.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8239s / 724.8212 s
agent0:                 episode reward: -0.6790,                 loss: nan
agent1:                 episode reward: 0.6790,                 loss: 0.3288
Episode: 23901/30000 (79.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8302s / 725.6513 s
agent0:                 episode reward: -0.4915,                 loss: nan
agent1:                 episode reward: 0.4915,                 loss: 0.3284
Episode: 23921/30000 (79.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8338s / 726.4852 s
agent0:                 episode reward: -0.6242,                 loss: nan
agent1:                 episode reward: 0.6242,                 loss: 0.3292
Episode: 23941/30000 (79.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8155s / 727.3007 s
agent0:                 episode reward: -0.0473,                 loss: nan
agent1:                 episode reward: 0.0473,                 loss: 0.3289
Episode: 23961/30000 (79.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8141s / 728.1148 s
agent0:                 episode reward: -0.7375,                 loss: nan
agent1:                 episode reward: 0.7375,                 loss: 0.3286
Episode: 23981/30000 (79.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8288s / 728.9436 s
agent0:                 episode reward: -0.4587,                 loss: nan
agent1:                 episode reward: 0.4587,                 loss: 0.3273
Episode: 24001/30000 (80.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8255s / 729.7691 s
agent0:                 episode reward: -0.7048,                 loss: nan
agent1:                 episode reward: 0.7048,                 loss: 0.3286
Episode: 24021/30000 (80.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8229s / 730.5920 s
agent0:                 episode reward: -0.7518,                 loss: nan
agent1:                 episode reward: 0.7518,                 loss: 0.3281
Episode: 24041/30000 (80.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8335s / 731.4255 s
agent0:                 episode reward: -0.3307,                 loss: nan
agent1:                 episode reward: 0.3307,                 loss: 0.3272
Episode: 24061/30000 (80.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8242s / 732.2496 s
agent0:                 episode reward: -0.7449,                 loss: nan
agent1:                 episode reward: 0.7449,                 loss: 0.3257
Episode: 24081/30000 (80.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8123s / 733.0619 s
agent0:                 episode reward: -0.2628,                 loss: nan
agent1:                 episode reward: 0.2628,                 loss: 0.3245
Episode: 24101/30000 (80.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8204s / 733.8823 s
agent0:                 episode reward: -0.9094,                 loss: nan
agent1:                 episode reward: 0.9094,                 loss: 0.3231
Episode: 24121/30000 (80.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8218s / 734.7041 s
agent0:                 episode reward: -0.5121,                 loss: nan
agent1:                 episode reward: 0.5121,                 loss: 0.3237
Episode: 24141/30000 (80.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8169s / 735.5210 s
agent0:                 episode reward: -0.3429,                 loss: nan
agent1:                 episode reward: 0.3429,                 loss: 0.3269
Episode: 24161/30000 (80.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8184s / 736.3394 s
agent0:                 episode reward: -0.6053,                 loss: nan
agent1:                 episode reward: 0.6053,                 loss: 0.3283
Episode: 24181/30000 (80.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8411s / 737.1805 s
agent0:                 episode reward: -0.5561,                 loss: nan
agent1:                 episode reward: 0.5561,                 loss: 0.3269
Episode: 24201/30000 (80.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8235s / 738.0040 s
agent0:                 episode reward: -0.6403,                 loss: nan
agent1:                 episode reward: 0.6403,                 loss: 0.3229
Episode: 24221/30000 (80.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8266s / 738.8306 s
agent0:                 episode reward: -0.6428,                 loss: nan
agent1:                 episode reward: 0.6428,                 loss: 0.3287
Episode: 24241/30000 (80.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8389s / 739.6695 s
agent0:                 episode reward: -0.3651,                 loss: nan
agent1:                 episode reward: 0.3651,                 loss: 0.3295
Episode: 24261/30000 (80.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8311s / 740.5007 s
agent0:                 episode reward: -0.8310,                 loss: nan
agent1:                 episode reward: 0.8310,                 loss: 0.3243
Episode: 24281/30000 (80.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8273s / 741.3279 s
agent0:                 episode reward: -0.6687,                 loss: nan
agent1:                 episode reward: 0.6687,                 loss: 0.3249
Episode: 24301/30000 (81.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8230s / 742.1510 s
agent0:                 episode reward: -0.7688,                 loss: nan
agent1:                 episode reward: 0.7688,                 loss: 0.3259
Episode: 24321/30000 (81.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8243s / 742.9753 s
agent0:                 episode reward: -0.1272,                 loss: nan
agent1:                 episode reward: 0.1272,                 loss: 0.3279
Episode: 24341/30000 (81.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8415s / 743.8168 s
agent0:                 episode reward: -0.2728,                 loss: nan
agent1:                 episode reward: 0.2728,                 loss: 0.3298
Episode: 24361/30000 (81.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8247s / 744.6415 s
agent0:                 episode reward: -0.7351,                 loss: nan
agent1:                 episode reward: 0.7351,                 loss: 0.3325
Episode: 24381/30000 (81.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8291s / 745.4706 s
agent0:                 episode reward: -0.7690,                 loss: nan
agent1:                 episode reward: 0.7690,                 loss: 0.3363
Episode: 24401/30000 (81.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8285s / 746.2991 s
agent0:                 episode reward: -0.3355,                 loss: nan
agent1:                 episode reward: 0.3355,                 loss: 0.3347
Episode: 24421/30000 (81.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8329s / 747.1320 s
agent0:                 episode reward: -0.5933,                 loss: nan
agent1:                 episode reward: 0.5933,                 loss: 0.3324
Episode: 24441/30000 (81.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8390s / 747.9710 s
agent0:                 episode reward: -0.5777,                 loss: nan
agent1:                 episode reward: 0.5777,                 loss: 0.3360
Episode: 24461/30000 (81.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8225s / 748.7935 s
agent0:                 episode reward: -0.6741,                 loss: nan
agent1:                 episode reward: 0.6741,                 loss: 0.3337
Episode: 24481/30000 (81.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8334s / 749.6268 s
agent0:                 episode reward: -1.1827,                 loss: nan
agent1:                 episode reward: 1.1827,                 loss: 0.3356
Episode: 24501/30000 (81.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8267s / 750.4535 s
agent0:                 episode reward: -0.6283,                 loss: nan
agent1:                 episode reward: 0.6283,                 loss: 0.3325
Episode: 24521/30000 (81.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8274s / 751.2809 s
agent0:                 episode reward: -0.4524,                 loss: nan
agent1:                 episode reward: 0.4524,                 loss: 0.3312
Episode: 24541/30000 (81.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8212s / 752.1022 s
agent0:                 episode reward: -0.4769,                 loss: nan
agent1:                 episode reward: 0.4769,                 loss: 0.3328
Episode: 24561/30000 (81.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8284s / 752.9305 s
agent0:                 episode reward: -0.4740,                 loss: nan
agent1:                 episode reward: 0.4740,                 loss: 0.3326
Episode: 24581/30000 (81.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8307s / 753.7612 s
agent0:                 episode reward: -0.3977,                 loss: nan
agent1:                 episode reward: 0.3977,                 loss: 0.3324
Episode: 24601/30000 (82.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8298s / 754.5911 s
agent0:                 episode reward: -0.5561,                 loss: nan
agent1:                 episode reward: 0.5561,                 loss: 0.3356
Episode: 24621/30000 (82.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8272s / 755.4182 s
agent0:                 episode reward: -0.5794,                 loss: nan
agent1:                 episode reward: 0.5794,                 loss: 0.3325
Episode: 24641/30000 (82.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8464s / 756.2646 s
agent0:                 episode reward: -0.3916,                 loss: nan
agent1:                 episode reward: 0.3916,                 loss: 0.3337
Episode: 24661/30000 (82.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8236s / 757.0882 s
agent0:                 episode reward: -0.8086,                 loss: nan
agent1:                 episode reward: 0.8086,                 loss: 0.3347
Episode: 24681/30000 (82.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8294s / 757.9176 s
agent0:                 episode reward: -0.5453,                 loss: nan
agent1:                 episode reward: 0.5453,                 loss: 0.3287
Episode: 24701/30000 (82.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8324s / 758.7501 s
agent0:                 episode reward: -0.6610,                 loss: nan
agent1:                 episode reward: 0.6610,                 loss: 0.3243
Episode: 24721/30000 (82.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8270s / 759.5771 s
agent0:                 episode reward: -0.5753,                 loss: nan
agent1:                 episode reward: 0.5753,                 loss: 0.3265
Episode: 24741/30000 (82.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8293s / 760.4064 s
agent0:                 episode reward: -0.4616,                 loss: nan
agent1:                 episode reward: 0.4616,                 loss: 0.3262
Episode: 24761/30000 (82.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8283s / 761.2348 s
agent0:                 episode reward: -0.5822,                 loss: nan
agent1:                 episode reward: 0.5822,                 loss: 0.3269
Episode: 24781/30000 (82.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8283s / 762.0630 s
agent0:                 episode reward: -0.8071,                 loss: nan
agent1:                 episode reward: 0.8071,                 loss: 0.3265
Episode: 24801/30000 (82.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8238s / 762.8869 s
agent0:                 episode reward: -0.8642,                 loss: nan
agent1:                 episode reward: 0.8642,                 loss: 0.3270
Episode: 24821/30000 (82.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8352s / 763.7220 s
agent0:                 episode reward: -0.7105,                 loss: nan
agent1:                 episode reward: 0.7105,                 loss: 0.3263
Episode: 24841/30000 (82.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8418s / 764.5638 s
agent0:                 episode reward: -0.5570,                 loss: nan
agent1:                 episode reward: 0.5570,                 loss: 0.3265
Episode: 24861/30000 (82.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8346s / 765.3984 s
agent0:                 episode reward: -0.6192,                 loss: nan
agent1:                 episode reward: 0.6192,                 loss: 0.3288
Episode: 24881/30000 (82.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8309s / 766.2293 s
agent0:                 episode reward: -0.1306,                 loss: nan
agent1:                 episode reward: 0.1306,                 loss: 0.3268
Episode: 24901/30000 (83.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8292s / 767.0585 s
agent0:                 episode reward: -0.8383,                 loss: nan
agent1:                 episode reward: 0.8383,                 loss: 0.3288
Episode: 24921/30000 (83.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8335s / 767.8920 s
agent0:                 episode reward: -0.4996,                 loss: nan
agent1:                 episode reward: 0.4996,                 loss: 0.3274
Episode: 24941/30000 (83.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8362s / 768.7281 s
agent0:                 episode reward: -0.5863,                 loss: nan
agent1:                 episode reward: 0.5863,                 loss: 0.3270
Episode: 24961/30000 (83.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8373s / 769.5654 s
agent0:                 episode reward: -0.4788,                 loss: nan
agent1:                 episode reward: 0.4788,                 loss: 0.3257
Episode: 24981/30000 (83.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8388s / 770.4042 s
agent0:                 episode reward: -0.5732,                 loss: nan
agent1:                 episode reward: 0.5732,                 loss: 0.3287
Episode: 25001/30000 (83.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8191s / 771.2234 s
agent0:                 episode reward: -0.5866,                 loss: nan
agent1:                 episode reward: 0.5866,                 loss: 0.3268
Episode: 25021/30000 (83.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8299s / 772.0533 s
agent0:                 episode reward: -0.5663,                 loss: nan
agent1:                 episode reward: 0.5663,                 loss: 0.3316
Episode: 25041/30000 (83.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8337s / 772.8869 s
agent0:                 episode reward: -0.5871,                 loss: nan
agent1:                 episode reward: 0.5871,                 loss: 0.3294
Episode: 25061/30000 (83.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8376s / 773.7245 s
agent0:                 episode reward: -0.2986,                 loss: nan
agent1:                 episode reward: 0.2986,                 loss: 0.3293
Episode: 25081/30000 (83.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8251s / 774.5496 s
agent0:                 episode reward: -0.1187,                 loss: nan
agent1:                 episode reward: 0.1187,                 loss: 0.3306
Episode: 25101/30000 (83.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8302s / 775.3798 s
agent0:                 episode reward: -0.6701,                 loss: nan
agent1:                 episode reward: 0.6701,                 loss: 0.3286
Episode: 25121/30000 (83.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8339s / 776.2137 s
agent0:                 episode reward: -0.7352,                 loss: nan
agent1:                 episode reward: 0.7352,                 loss: 0.3280
Episode: 25141/30000 (83.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8367s / 777.0504 s
agent0:                 episode reward: -0.4930,                 loss: nan
agent1:                 episode reward: 0.4930,                 loss: 0.3281
Episode: 25161/30000 (83.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8338s / 777.8842 s
agent0:                 episode reward: -0.5153,                 loss: nan
agent1:                 episode reward: 0.5153,                 loss: 0.3289
Episode: 25181/30000 (83.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8430s / 778.7273 s
agent0:                 episode reward: -0.4337,                 loss: nan
agent1:                 episode reward: 0.4337,                 loss: 0.3305
Episode: 25201/30000 (84.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8414s / 779.5687 s
agent0:                 episode reward: -0.2899,                 loss: nan
agent1:                 episode reward: 0.2899,                 loss: 0.3270
Episode: 25221/30000 (84.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8410s / 780.4097 s
agent0:                 episode reward: -0.3785,                 loss: nan
agent1:                 episode reward: 0.3785,                 loss: 0.3289
Episode: 25241/30000 (84.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8549s / 781.2647 s
agent0:                 episode reward: -0.5143,                 loss: nan
agent1:                 episode reward: 0.5143,                 loss: 0.3305
Episode: 25261/30000 (84.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8598s / 782.1245 s
agent0:                 episode reward: -0.3764,                 loss: nan
agent1:                 episode reward: 0.3764,                 loss: 0.3262
Episode: 25281/30000 (84.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8539s / 782.9784 s
agent0:                 episode reward: -0.3615,                 loss: nan
agent1:                 episode reward: 0.3615,                 loss: 0.3277
Episode: 25301/30000 (84.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8673s / 783.8456 s
agent0:                 episode reward: -0.7415,                 loss: nan
agent1:                 episode reward: 0.7415,                 loss: 0.3295
Episode: 25321/30000 (84.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8485s / 784.6941 s
agent0:                 episode reward: -0.1893,                 loss: nan
agent1:                 episode reward: 0.1893,                 loss: 0.3301
Episode: 25341/30000 (84.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8490s / 785.5431 s
agent0:                 episode reward: -0.4788,                 loss: nan
agent1:                 episode reward: 0.4788,                 loss: 0.3301
Episode: 25361/30000 (84.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8475s / 786.3907 s
agent0:                 episode reward: -0.5587,                 loss: nan
agent1:                 episode reward: 0.5587,                 loss: 0.3300
Episode: 25381/30000 (84.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8736s / 787.2642 s
agent0:                 episode reward: -0.5480,                 loss: nan
agent1:                 episode reward: 0.5480,                 loss: 0.3343
Episode: 25401/30000 (84.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8565s / 788.1207 s
agent0:                 episode reward: -0.7184,                 loss: nan
agent1:                 episode reward: 0.7184,                 loss: 0.3300
Episode: 25421/30000 (84.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8565s / 788.9772 s
agent0:                 episode reward: -0.3342,                 loss: nan
agent1:                 episode reward: 0.3342,                 loss: 0.3287
Episode: 25441/30000 (84.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8631s / 789.8403 s
agent0:                 episode reward: -0.7272,                 loss: nan
agent1:                 episode reward: 0.7272,                 loss: 0.3314
Episode: 25461/30000 (84.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8522s / 790.6924 s
agent0:                 episode reward: -0.3021,                 loss: nan
agent1:                 episode reward: 0.3021,                 loss: 0.3307
Episode: 25481/30000 (84.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8566s / 791.5490 s
agent0:                 episode reward: -0.6629,                 loss: nan
agent1:                 episode reward: 0.6629,                 loss: 0.3319
Episode: 25501/30000 (85.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8447s / 792.3937 s
agent0:                 episode reward: -0.5961,                 loss: nan
agent1:                 episode reward: 0.5961,                 loss: 0.3297
Episode: 25521/30000 (85.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8616s / 793.2552 s
agent0:                 episode reward: -0.8063,                 loss: nan
agent1:                 episode reward: 0.8063,                 loss: 0.3283
Episode: 25541/30000 (85.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8577s / 794.1130 s
agent0:                 episode reward: -0.7260,                 loss: nan
agent1:                 episode reward: 0.7260,                 loss: 0.3310
Episode: 25561/30000 (85.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8559s / 794.9689 s
agent0:                 episode reward: -0.8152,                 loss: nan
agent1:                 episode reward: 0.8152,                 loss: 0.3289
Episode: 25581/30000 (85.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8534s / 795.8222 s
agent0:                 episode reward: -0.4325,                 loss: nan
agent1:                 episode reward: 0.4325,                 loss: 0.3300
Episode: 25601/30000 (85.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8594s / 796.6816 s
agent0:                 episode reward: -0.2050,                 loss: nan
agent1:                 episode reward: 0.2050,                 loss: 0.3319
Episode: 25621/30000 (85.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8542s / 797.5358 s
agent0:                 episode reward: -0.8361,                 loss: nan
agent1:                 episode reward: 0.8361,                 loss: 0.3343
Episode: 25641/30000 (85.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8575s / 798.3933 s
agent0:                 episode reward: -0.2023,                 loss: nan
agent1:                 episode reward: 0.2023,                 loss: 0.3278
Episode: 25661/30000 (85.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8516s / 799.2448 s
agent0:                 episode reward: -0.2165,                 loss: nan
agent1:                 episode reward: 0.2165,                 loss: 0.3321
Episode: 25681/30000 (85.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8568s / 800.1017 s
agent0:                 episode reward: -0.5112,                 loss: nan
agent1:                 episode reward: 0.5112,                 loss: 0.3265
Episode: 25701/30000 (85.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8595s / 800.9611 s
agent0:                 episode reward: -0.3106,                 loss: nan
agent1:                 episode reward: 0.3106,                 loss: 0.3284
Episode: 25721/30000 (85.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8592s / 801.8203 s
agent0:                 episode reward: -0.5829,                 loss: nan
agent1:                 episode reward: 0.5829,                 loss: 0.3246
Episode: 25741/30000 (85.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8549s / 802.6752 s
agent0:                 episode reward: -0.7723,                 loss: nan
agent1:                 episode reward: 0.7723,                 loss: 0.3288
Episode: 25761/30000 (85.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8517s / 803.5269 s
agent0:                 episode reward: -0.3771,                 loss: nan
agent1:                 episode reward: 0.3771,                 loss: 0.3279
Episode: 25781/30000 (85.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8556s / 804.3825 s
agent0:                 episode reward: -0.2478,                 loss: nan
agent1:                 episode reward: 0.2478,                 loss: 0.3293
Episode: 25801/30000 (86.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8594s / 805.2419 s
agent0:                 episode reward: -0.5128,                 loss: nan
agent1:                 episode reward: 0.5128,                 loss: 0.3275
Episode: 25821/30000 (86.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8520s / 806.0939 s
agent0:                 episode reward: -0.5802,                 loss: nan
agent1:                 episode reward: 0.5802,                 loss: 0.3293
Episode: 25841/30000 (86.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8521s / 806.9460 s
agent0:                 episode reward: -0.4742,                 loss: nan
agent1:                 episode reward: 0.4742,                 loss: 0.3256
Episode: 25861/30000 (86.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8640s / 807.8100 s
agent0:                 episode reward: -0.5638,                 loss: nan
agent1:                 episode reward: 0.5638,                 loss: 0.3240
Episode: 25881/30000 (86.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8725s / 808.6826 s
agent0:                 episode reward: -0.8487,                 loss: nan
agent1:                 episode reward: 0.8487,                 loss: 0.3281
Episode: 25901/30000 (86.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8538s / 809.5364 s
agent0:                 episode reward: -0.3584,                 loss: nan
agent1:                 episode reward: 0.3584,                 loss: 0.3265
Episode: 25921/30000 (86.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8534s / 810.3898 s
agent0:                 episode reward: -0.6174,                 loss: nan
agent1:                 episode reward: 0.6174,                 loss: 0.3274
Episode: 25941/30000 (86.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8625s / 811.2523 s
agent0:                 episode reward: -0.4338,                 loss: nan
agent1:                 episode reward: 0.4338,                 loss: 0.3253
Episode: 25961/30000 (86.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8574s / 812.1097 s
agent0:                 episode reward: -0.5252,                 loss: nan
agent1:                 episode reward: 0.5252,                 loss: 0.3256
Episode: 25981/30000 (86.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8669s / 812.9766 s
agent0:                 episode reward: -0.5725,                 loss: nan
agent1:                 episode reward: 0.5725,                 loss: 0.3241
Episode: 26001/30000 (86.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8563s / 813.8329 s
agent0:                 episode reward: 0.1009,                 loss: nan
agent1:                 episode reward: -0.1009,                 loss: 0.3256
Episode: 26021/30000 (86.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8635s / 814.6964 s
agent0:                 episode reward: -0.4036,                 loss: nan
agent1:                 episode reward: 0.4036,                 loss: 0.3353
Episode: 26041/30000 (86.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8548s / 815.5511 s
agent0:                 episode reward: -1.0447,                 loss: nan
agent1:                 episode reward: 1.0447,                 loss: 0.3381
Episode: 26061/30000 (86.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8545s / 816.4056 s
agent0:                 episode reward: -0.4851,                 loss: nan
agent1:                 episode reward: 0.4851,                 loss: 0.3404
Episode: 26081/30000 (86.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8575s / 817.2632 s
agent0:                 episode reward: -0.9407,                 loss: nan
agent1:                 episode reward: 0.9407,                 loss: 0.3387
Episode: 26101/30000 (87.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8525s / 818.1157 s
agent0:                 episode reward: -1.0206,                 loss: nan
agent1:                 episode reward: 1.0206,                 loss: 0.3368
Episode: 26121/30000 (87.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8745s / 818.9901 s
agent0:                 episode reward: -0.8525,                 loss: nan
agent1:                 episode reward: 0.8525,                 loss: 0.3402
Episode: 26141/30000 (87.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8521s / 819.8423 s
agent0:                 episode reward: -0.3288,                 loss: nan
agent1:                 episode reward: 0.3288,                 loss: 0.3379
Episode: 26161/30000 (87.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8692s / 820.7114 s
agent0:                 episode reward: -0.6688,                 loss: nan
agent1:                 episode reward: 0.6688,                 loss: 0.3383
Episode: 26181/30000 (87.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8530s / 821.5644 s
agent0:                 episode reward: -0.7097,                 loss: nan
agent1:                 episode reward: 0.7097,                 loss: 0.3345
Episode: 26201/30000 (87.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8632s / 822.4276 s
agent0:                 episode reward: -0.6046,                 loss: nan
agent1:                 episode reward: 0.6046,                 loss: 0.3381
Episode: 26221/30000 (87.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8649s / 823.2925 s
agent0:                 episode reward: -0.8118,                 loss: nan
agent1:                 episode reward: 0.8118,                 loss: 0.3348
Episode: 26241/30000 (87.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8580s / 824.1505 s
agent0:                 episode reward: -0.5362,                 loss: nan
agent1:                 episode reward: 0.5362,                 loss: 0.3396
Episode: 26261/30000 (87.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8521s / 825.0026 s
agent0:                 episode reward: -0.2210,                 loss: nan
agent1:                 episode reward: 0.2210,                 loss: 0.3396
Episode: 26281/30000 (87.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8576s / 825.8601 s
agent0:                 episode reward: -0.3819,                 loss: nan
agent1:                 episode reward: 0.3819,                 loss: 0.3369
Episode: 26301/30000 (87.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8689s / 826.7291 s
agent0:                 episode reward: -0.8125,                 loss: nan
agent1:                 episode reward: 0.8125,                 loss: 0.3370
Episode: 26321/30000 (87.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8616s / 827.5907 s
agent0:                 episode reward: -0.6472,                 loss: nan
agent1:                 episode reward: 0.6472,                 loss: 0.3349
Episode: 26341/30000 (87.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8892s / 828.4799 s
agent0:                 episode reward: -0.6376,                 loss: nan
agent1:                 episode reward: 0.6376,                 loss: 0.3309
Episode: 26361/30000 (87.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8774s / 829.3573 s
agent0:                 episode reward: -0.7229,                 loss: nan
agent1:                 episode reward: 0.7229,                 loss: 0.3239
Episode: 26381/30000 (87.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8649s / 830.2222 s
agent0:                 episode reward: 0.0968,                 loss: nan
agent1:                 episode reward: -0.0968,                 loss: 0.3223
Episode: 26401/30000 (88.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8742s / 831.0964 s
agent0:                 episode reward: -0.4038,                 loss: nan
agent1:                 episode reward: 0.4038,                 loss: 0.3212
Episode: 26421/30000 (88.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8668s / 831.9632 s
agent0:                 episode reward: -1.0380,                 loss: nan
agent1:                 episode reward: 1.0380,                 loss: 0.3224
Episode: 26441/30000 (88.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8706s / 832.8337 s
agent0:                 episode reward: -0.5406,                 loss: nan
agent1:                 episode reward: 0.5406,                 loss: 0.3248
Episode: 26461/30000 (88.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8677s / 833.7015 s
agent0:                 episode reward: -0.9928,                 loss: nan
agent1:                 episode reward: 0.9928,                 loss: 0.3190
Episode: 26481/30000 (88.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8754s / 834.5769 s
agent0:                 episode reward: -0.6579,                 loss: nan
agent1:                 episode reward: 0.6579,                 loss: 0.3192
Episode: 26501/30000 (88.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8812s / 835.4581 s
agent0:                 episode reward: -0.3055,                 loss: nan
agent1:                 episode reward: 0.3055,                 loss: 0.3257
Episode: 26521/30000 (88.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8725s / 836.3306 s
agent0:                 episode reward: -0.3988,                 loss: nan
agent1:                 episode reward: 0.3988,                 loss: 0.3189
Episode: 26541/30000 (88.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8789s / 837.2095 s
agent0:                 episode reward: -0.4425,                 loss: nan
agent1:                 episode reward: 0.4425,                 loss: 0.3199
Episode: 26561/30000 (88.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8808s / 838.0903 s
agent0:                 episode reward: -0.5840,                 loss: nan
agent1:                 episode reward: 0.5840,                 loss: 0.3246
Episode: 26581/30000 (88.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8846s / 838.9749 s
agent0:                 episode reward: -0.0619,                 loss: nan
agent1:                 episode reward: 0.0619,                 loss: 0.3210
Episode: 26601/30000 (88.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8676s / 839.8425 s
agent0:                 episode reward: -0.5015,                 loss: nan
agent1:                 episode reward: 0.5015,                 loss: 0.3212
Episode: 26621/30000 (88.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8866s / 840.7291 s
agent0:                 episode reward: -0.4444,                 loss: nan
agent1:                 episode reward: 0.4444,                 loss: 0.3240
Episode: 26641/30000 (88.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8606s / 841.5897 s
agent0:                 episode reward: -0.6660,                 loss: nan
agent1:                 episode reward: 0.6660,                 loss: 0.3217
Episode: 26661/30000 (88.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8763s / 842.4660 s
agent0:                 episode reward: -0.3753,                 loss: nan
agent1:                 episode reward: 0.3753,                 loss: 0.3211
Episode: 26681/30000 (88.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8663s / 843.3323 s
agent0:                 episode reward: -0.1720,                 loss: nan
agent1:                 episode reward: 0.1720,                 loss: 0.3272
Episode: 26701/30000 (89.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8879s / 844.2202 s
agent0:                 episode reward: -0.3103,                 loss: nan
agent1:                 episode reward: 0.3103,                 loss: 0.3271
Episode: 26721/30000 (89.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8905s / 845.1107 s
agent0:                 episode reward: -0.5775,                 loss: nan
agent1:                 episode reward: 0.5775,                 loss: 0.3269
Episode: 26741/30000 (89.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8797s / 845.9904 s
agent0:                 episode reward: -0.3444,                 loss: nan
agent1:                 episode reward: 0.3444,                 loss: 0.3304
Episode: 26761/30000 (89.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8652s / 846.8555 s
agent0:                 episode reward: -0.8151,                 loss: nan
agent1:                 episode reward: 0.8151,                 loss: 0.3284
Episode: 26781/30000 (89.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8784s / 847.7339 s
agent0:                 episode reward: -0.7632,                 loss: nan
agent1:                 episode reward: 0.7632,                 loss: 0.3278
Episode: 26801/30000 (89.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8817s / 848.6156 s
agent0:                 episode reward: -0.5490,                 loss: nan
agent1:                 episode reward: 0.5490,                 loss: 0.3265
Episode: 26821/30000 (89.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8754s / 849.4910 s
agent0:                 episode reward: -0.7095,                 loss: nan
agent1:                 episode reward: 0.7095,                 loss: 0.3249
Episode: 26841/30000 (89.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8807s / 850.3718 s
agent0:                 episode reward: -0.6180,                 loss: nan
agent1:                 episode reward: 0.6180,                 loss: 0.3269
Episode: 26861/30000 (89.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8760s / 851.2477 s
agent0:                 episode reward: -0.7510,                 loss: nan
agent1:                 episode reward: 0.7510,                 loss: 0.3302
Episode: 26881/30000 (89.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8908s / 852.1386 s
agent0:                 episode reward: -0.5869,                 loss: nan
agent1:                 episode reward: 0.5869,                 loss: 0.3290
Episode: 26901/30000 (89.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8976s / 853.0362 s
agent0:                 episode reward: -0.3922,                 loss: nan
agent1:                 episode reward: 0.3922,                 loss: 0.3239
Episode: 26921/30000 (89.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8749s / 853.9111 s
agent0:                 episode reward: -0.3952,                 loss: nan
agent1:                 episode reward: 0.3952,                 loss: 0.3307
Episode: 26941/30000 (89.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8814s / 854.7925 s
agent0:                 episode reward: -1.1141,                 loss: nan
agent1:                 episode reward: 1.1141,                 loss: 0.3283
Episode: 26961/30000 (89.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8783s / 855.6708 s
agent0:                 episode reward: -0.5199,                 loss: nan
agent1:                 episode reward: 0.5199,                 loss: 0.3280
Episode: 26981/30000 (89.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8801s / 856.5509 s
agent0:                 episode reward: -0.4245,                 loss: nan
agent1:                 episode reward: 0.4245,                 loss: 0.3281
Episode: 27001/30000 (90.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8775s / 857.4284 s
agent0:                 episode reward: -0.7392,                 loss: nan
agent1:                 episode reward: 0.7392,                 loss: 0.3268
Episode: 27021/30000 (90.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8840s / 858.3124 s
agent0:                 episode reward: -0.7562,                 loss: nan
agent1:                 episode reward: 0.7562,                 loss: 0.3381
Episode: 27041/30000 (90.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8811s / 859.1935 s
agent0:                 episode reward: -0.6529,                 loss: nan
agent1:                 episode reward: 0.6529,                 loss: 0.3356
Episode: 27061/30000 (90.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8865s / 860.0800 s
agent0:                 episode reward: 0.1525,                 loss: nan
agent1:                 episode reward: -0.1525,                 loss: 0.3345
Episode: 27081/30000 (90.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8799s / 860.9599 s
agent0:                 episode reward: -0.6934,                 loss: nan
agent1:                 episode reward: 0.6934,                 loss: 0.3357
Episode: 27101/30000 (90.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8758s / 861.8357 s
agent0:                 episode reward: -0.4034,                 loss: nan
agent1:                 episode reward: 0.4034,                 loss: 0.3358
Episode: 27121/30000 (90.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8879s / 862.7236 s
agent0:                 episode reward: -0.1533,                 loss: nan
agent1:                 episode reward: 0.1533,                 loss: 0.3376
Episode: 27141/30000 (90.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8728s / 863.5964 s
agent0:                 episode reward: -0.1410,                 loss: nan
agent1:                 episode reward: 0.1410,                 loss: 0.3371
Episode: 27161/30000 (90.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8779s / 864.4742 s
agent0:                 episode reward: -1.0216,                 loss: nan
agent1:                 episode reward: 1.0216,                 loss: 0.3333
Episode: 27181/30000 (90.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8950s / 865.3693 s
agent0:                 episode reward: -0.8221,                 loss: nan
agent1:                 episode reward: 0.8221,                 loss: 0.3348
Episode: 27201/30000 (90.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8861s / 866.2553 s
agent0:                 episode reward: -0.4133,                 loss: nan
agent1:                 episode reward: 0.4133,                 loss: 0.3352
Episode: 27221/30000 (90.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8776s / 867.1330 s
agent0:                 episode reward: -0.2805,                 loss: nan
agent1:                 episode reward: 0.2805,                 loss: 0.3366
Episode: 27241/30000 (90.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8818s / 868.0148 s
agent0:                 episode reward: -0.3575,                 loss: nan
agent1:                 episode reward: 0.3575,                 loss: 0.3368
Episode: 27261/30000 (90.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8741s / 868.8889 s
agent0:                 episode reward: -0.7438,                 loss: nan
agent1:                 episode reward: 0.7438,                 loss: 0.3363
Episode: 27281/30000 (90.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8979s / 869.7868 s
agent0:                 episode reward: -0.4660,                 loss: nan
agent1:                 episode reward: 0.4660,                 loss: 0.3363
Episode: 27301/30000 (91.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8789s / 870.6657 s
agent0:                 episode reward: -0.8111,                 loss: nan
agent1:                 episode reward: 0.8111,                 loss: 0.3380
Episode: 27321/30000 (91.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9060s / 871.5717 s
agent0:                 episode reward: -0.4717,                 loss: nan
agent1:                 episode reward: 0.4717,                 loss: 0.3329
Episode: 27341/30000 (91.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9015s / 872.4732 s
agent0:                 episode reward: -0.8337,                 loss: nan
agent1:                 episode reward: 0.8337,                 loss: 0.3322
Episode: 27361/30000 (91.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8825s / 873.3557 s
agent0:                 episode reward: -0.5871,                 loss: nan
agent1:                 episode reward: 0.5871,                 loss: 0.3243
Episode: 27381/30000 (91.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8937s / 874.2493 s
agent0:                 episode reward: -0.5438,                 loss: nan
agent1:                 episode reward: 0.5438,                 loss: 0.3245
Episode: 27401/30000 (91.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8912s / 875.1405 s
agent0:                 episode reward: -1.0794,                 loss: nan
agent1:                 episode reward: 1.0794,                 loss: 0.3230
Episode: 27421/30000 (91.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8949s / 876.0354 s
agent0:                 episode reward: -0.1428,                 loss: nan
agent1:                 episode reward: 0.1428,                 loss: 0.3259
Episode: 27441/30000 (91.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8946s / 876.9300 s
agent0:                 episode reward: -0.4096,                 loss: nan
agent1:                 episode reward: 0.4096,                 loss: 0.3248
Episode: 27461/30000 (91.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8898s / 877.8199 s
agent0:                 episode reward: -0.5340,                 loss: nan
agent1:                 episode reward: 0.5340,                 loss: 0.3240
Episode: 27481/30000 (91.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8880s / 878.7079 s
agent0:                 episode reward: -0.6804,                 loss: nan
agent1:                 episode reward: 0.6804,                 loss: 0.3254
Episode: 27501/30000 (91.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8881s / 879.5960 s
agent0:                 episode reward: -0.5283,                 loss: nan
agent1:                 episode reward: 0.5283,                 loss: 0.3242
Episode: 27521/30000 (91.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8848s / 880.4808 s
agent0:                 episode reward: -0.7189,                 loss: nan
agent1:                 episode reward: 0.7189,                 loss: 0.3225
Episode: 27541/30000 (91.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8934s / 881.3742 s
agent0:                 episode reward: -0.6121,                 loss: nan
agent1:                 episode reward: 0.6121,                 loss: 0.3260
Episode: 27561/30000 (91.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8857s / 882.2600 s
agent0:                 episode reward: -0.4442,                 loss: nan
agent1:                 episode reward: 0.4442,                 loss: 0.3243
Episode: 27581/30000 (91.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8956s / 883.1556 s
agent0:                 episode reward: -0.2831,                 loss: nan
agent1:                 episode reward: 0.2831,                 loss: 0.3259
Episode: 27601/30000 (92.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8806s / 884.0362 s
agent0:                 episode reward: -1.0769,                 loss: nan
agent1:                 episode reward: 1.0769,                 loss: 0.3266
Episode: 27621/30000 (92.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8847s / 884.9209 s
agent0:                 episode reward: -0.5113,                 loss: nan
agent1:                 episode reward: 0.5113,                 loss: 0.3229
Episode: 27641/30000 (92.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8998s / 885.8206 s
agent0:                 episode reward: -0.5023,                 loss: nan
agent1:                 episode reward: 0.5023,                 loss: 0.3276
Episode: 27661/30000 (92.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9041s / 886.7248 s
agent0:                 episode reward: -0.1124,                 loss: nan
agent1:                 episode reward: 0.1124,                 loss: 0.3249
Episode: 27681/30000 (92.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8828s / 887.6076 s
agent0:                 episode reward: -0.6151,                 loss: nan
agent1:                 episode reward: 0.6151,                 loss: 0.3268
Episode: 27701/30000 (92.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9090s / 888.5166 s
agent0:                 episode reward: -1.0464,                 loss: nan
agent1:                 episode reward: 1.0464,                 loss: 0.3274
Episode: 27721/30000 (92.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8946s / 889.4112 s
agent0:                 episode reward: -0.5611,                 loss: nan
agent1:                 episode reward: 0.5611,                 loss: 0.3310
Episode: 27741/30000 (92.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9136s / 890.3248 s
agent0:                 episode reward: -0.1327,                 loss: nan
agent1:                 episode reward: 0.1327,                 loss: 0.3279
Episode: 27761/30000 (92.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9093s / 891.2340 s
agent0:                 episode reward: -0.3161,                 loss: nan
agent1:                 episode reward: 0.3161,                 loss: 0.3251
Episode: 27781/30000 (92.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8953s / 892.1293 s
agent0:                 episode reward: -0.7433,                 loss: nan
agent1:                 episode reward: 0.7433,                 loss: 0.3293
Episode: 27801/30000 (92.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9015s / 893.0308 s
agent0:                 episode reward: -0.4776,                 loss: nan
agent1:                 episode reward: 0.4776,                 loss: 0.3255
Episode: 27821/30000 (92.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9110s / 893.9418 s
agent0:                 episode reward: -0.4073,                 loss: nan
agent1:                 episode reward: 0.4073,                 loss: 0.3281
Episode: 27841/30000 (92.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9084s / 894.8503 s
agent0:                 episode reward: -0.8024,                 loss: nan
agent1:                 episode reward: 0.8024,                 loss: 0.3270
Episode: 27861/30000 (92.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9068s / 895.7571 s
agent0:                 episode reward: -0.5855,                 loss: nan
agent1:                 episode reward: 0.5855,                 loss: 0.3293
Episode: 27881/30000 (92.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8957s / 896.6529 s
agent0:                 episode reward: -1.1213,                 loss: nan
agent1:                 episode reward: 1.1213,                 loss: 0.3282
Episode: 27901/30000 (93.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8992s / 897.5521 s
agent0:                 episode reward: -0.1820,                 loss: nan
agent1:                 episode reward: 0.1820,                 loss: 0.3289
Episode: 27921/30000 (93.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9027s / 898.4548 s
agent0:                 episode reward: -0.3433,                 loss: nan
agent1:                 episode reward: 0.3433,                 loss: 0.3293
Episode: 27941/30000 (93.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8913s / 899.3461 s
agent0:                 episode reward: -0.5961,                 loss: nan
agent1:                 episode reward: 0.5961,                 loss: 0.3276
Episode: 27961/30000 (93.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8982s / 900.2443 s
agent0:                 episode reward: -0.3129,                 loss: nan
agent1:                 episode reward: 0.3129,                 loss: 0.3313
Episode: 27981/30000 (93.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9021s / 901.1465 s
agent0:                 episode reward: -0.6979,                 loss: nan
agent1:                 episode reward: 0.6979,                 loss: 0.3268
Episode: 28001/30000 (93.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9086s / 902.0551 s
agent0:                 episode reward: -0.5316,                 loss: nan
agent1:                 episode reward: 0.5316,                 loss: 0.3266
Episode: 28021/30000 (93.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9209s / 902.9759 s
agent0:                 episode reward: -0.6647,                 loss: nan
agent1:                 episode reward: 0.6647,                 loss: 0.3337
Episode: 28041/30000 (93.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9062s / 903.8821 s
agent0:                 episode reward: -0.5811,                 loss: nan
agent1:                 episode reward: 0.5811,                 loss: 0.3321
Episode: 28061/30000 (93.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8985s / 904.7806 s
agent0:                 episode reward: -0.6793,                 loss: nan
agent1:                 episode reward: 0.6793,                 loss: 0.3335
Episode: 28081/30000 (93.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8995s / 905.6801 s
agent0:                 episode reward: -0.5473,                 loss: nan
agent1:                 episode reward: 0.5473,                 loss: 0.3341
Episode: 28101/30000 (93.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8944s / 906.5745 s
agent0:                 episode reward: -0.5690,                 loss: nan
agent1:                 episode reward: 0.5690,                 loss: 0.3349
Episode: 28121/30000 (93.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8839s / 907.4584 s
agent0:                 episode reward: -0.1612,                 loss: nan
agent1:                 episode reward: 0.1612,                 loss: 0.3347
Episode: 28141/30000 (93.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9044s / 908.3628 s
agent0:                 episode reward: -0.8139,                 loss: nan
agent1:                 episode reward: 0.8139,                 loss: 0.3338
Episode: 28161/30000 (93.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9024s / 909.2652 s
agent0:                 episode reward: -0.3606,                 loss: nan
agent1:                 episode reward: 0.3606,                 loss: 0.3339
Episode: 28181/30000 (93.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9084s / 910.1736 s
agent0:                 episode reward: -0.2628,                 loss: nan
agent1:                 episode reward: 0.2628,                 loss: 0.3327
Episode: 28201/30000 (94.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9266s / 911.1002 s
agent0:                 episode reward: -0.6902,                 loss: nan
agent1:                 episode reward: 0.6902,                 loss: 0.3346
Episode: 28221/30000 (94.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8861s / 911.9863 s
agent0:                 episode reward: -0.3710,                 loss: nan
agent1:                 episode reward: 0.3710,                 loss: 0.3357
Episode: 28241/30000 (94.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9016s / 912.8879 s
agent0:                 episode reward: -0.7322,                 loss: nan
agent1:                 episode reward: 0.7322,                 loss: 0.3318
Episode: 28261/30000 (94.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9231s / 913.8110 s
agent0:                 episode reward: -0.4071,                 loss: nan
agent1:                 episode reward: 0.4071,                 loss: 0.3333
Episode: 28281/30000 (94.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9260s / 914.7370 s
agent0:                 episode reward: -0.4480,                 loss: nan
agent1:                 episode reward: 0.4480,                 loss: 0.3299
Episode: 28301/30000 (94.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9111s / 915.6481 s
agent0:                 episode reward: -0.6331,                 loss: nan
agent1:                 episode reward: 0.6331,                 loss: 0.3316
Episode: 28321/30000 (94.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9174s / 916.5655 s
agent0:                 episode reward: -0.5838,                 loss: nan
agent1:                 episode reward: 0.5838,                 loss: 0.3356
Episode: 28341/30000 (94.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9206s / 917.4861 s
agent0:                 episode reward: -0.1664,                 loss: nan
agent1:                 episode reward: 0.1664,                 loss: 0.3295
Episode: 28361/30000 (94.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9127s / 918.3988 s
agent0:                 episode reward: -0.4188,                 loss: nan
agent1:                 episode reward: 0.4188,                 loss: 0.3279
Episode: 28381/30000 (94.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9091s / 919.3078 s
agent0:                 episode reward: -0.2992,                 loss: nan
agent1:                 episode reward: 0.2992,                 loss: 0.3265
Episode: 28401/30000 (94.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9022s / 920.2101 s
agent0:                 episode reward: -0.5600,                 loss: nan
agent1:                 episode reward: 0.5600,                 loss: 0.3244
Episode: 28421/30000 (94.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9051s / 921.1152 s
agent0:                 episode reward: -0.5360,                 loss: nan
agent1:                 episode reward: 0.5360,                 loss: 0.3269
Episode: 28441/30000 (94.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9126s / 922.0278 s
agent0:                 episode reward: -0.4746,                 loss: nan
agent1:                 episode reward: 0.4746,                 loss: 0.3249
Episode: 28461/30000 (94.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9099s / 922.9377 s
agent0:                 episode reward: -0.4713,                 loss: nan
agent1:                 episode reward: 0.4713,                 loss: 0.3253
Episode: 28481/30000 (94.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8931s / 923.8308 s
agent0:                 episode reward: -0.5019,                 loss: nan
agent1:                 episode reward: 0.5019,                 loss: 0.3287
Episode: 28501/30000 (95.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8976s / 924.7284 s
agent0:                 episode reward: -0.4383,                 loss: nan
agent1:                 episode reward: 0.4383,                 loss: 0.3264
Episode: 28521/30000 (95.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8990s / 925.6274 s
agent0:                 episode reward: -0.7131,                 loss: nan
agent1:                 episode reward: 0.7131,                 loss: 0.3264
Episode: 28541/30000 (95.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9133s / 926.5407 s
agent0:                 episode reward: -0.5364,                 loss: nan
agent1:                 episode reward: 0.5364,                 loss: 0.3288
Episode: 28561/30000 (95.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9344s / 927.4751 s
agent0:                 episode reward: -0.6018,                 loss: nan
agent1:                 episode reward: 0.6018,                 loss: 0.3252
Episode: 28581/30000 (95.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9151s / 928.3902 s
agent0:                 episode reward: -0.5011,                 loss: nan
agent1:                 episode reward: 0.5011,                 loss: 0.3277
Episode: 28601/30000 (95.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9053s / 929.2955 s
agent0:                 episode reward: -0.4829,                 loss: nan
agent1:                 episode reward: 0.4829,                 loss: 0.3274
Episode: 28621/30000 (95.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9154s / 930.2109 s
agent0:                 episode reward: -0.6223,                 loss: nan
agent1:                 episode reward: 0.6223,                 loss: 0.3259
Episode: 28641/30000 (95.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9238s / 931.1347 s
agent0:                 episode reward: -0.3814,                 loss: nan
agent1:                 episode reward: 0.3814,                 loss: 0.3274
Episode: 28661/30000 (95.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9170s / 932.0517 s
agent0:                 episode reward: -0.6004,                 loss: nan
agent1:                 episode reward: 0.6004,                 loss: 0.3283
Episode: 28681/30000 (95.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9273s / 932.9789 s
agent0:                 episode reward: -0.6827,                 loss: nan
agent1:                 episode reward: 0.6827,                 loss: 0.3307
Episode: 28701/30000 (95.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9198s / 933.8987 s
agent0:                 episode reward: -0.6701,                 loss: nan
agent1:                 episode reward: 0.6701,                 loss: 0.3342
Episode: 28721/30000 (95.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9206s / 934.8193 s
agent0:                 episode reward: -0.8235,                 loss: nan
agent1:                 episode reward: 0.8235,                 loss: 0.3352
Episode: 28741/30000 (95.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9243s / 935.7437 s
agent0:                 episode reward: -0.4188,                 loss: nan
agent1:                 episode reward: 0.4188,                 loss: 0.3344
Episode: 28761/30000 (95.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9108s / 936.6544 s
agent0:                 episode reward: -0.7103,                 loss: nan
agent1:                 episode reward: 0.7103,                 loss: 0.3343
Episode: 28781/30000 (95.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9520s / 937.6064 s
agent0:                 episode reward: -0.5841,                 loss: nan
agent1:                 episode reward: 0.5841,                 loss: 0.3314
Episode: 28801/30000 (96.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9313s / 938.5377 s
agent0:                 episode reward: -0.5066,                 loss: nan
agent1:                 episode reward: 0.5066,                 loss: 0.3332
Episode: 28821/30000 (96.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9275s / 939.4653 s
agent0:                 episode reward: -0.5411,                 loss: nan
agent1:                 episode reward: 0.5411,                 loss: 0.3300
Episode: 28841/30000 (96.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9214s / 940.3867 s
agent0:                 episode reward: -0.0541,                 loss: nan
agent1:                 episode reward: 0.0541,                 loss: 0.3330
Episode: 28861/30000 (96.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9365s / 941.3232 s
agent0:                 episode reward: -0.4476,                 loss: nan
agent1:                 episode reward: 0.4476,                 loss: 0.3318
Episode: 28881/30000 (96.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9295s / 942.2527 s
agent0:                 episode reward: -0.9263,                 loss: nan
agent1:                 episode reward: 0.9263,                 loss: 0.3359
Episode: 28901/30000 (96.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9337s / 943.1864 s
agent0:                 episode reward: -0.4624,                 loss: nan
agent1:                 episode reward: 0.4624,                 loss: 0.3292
Episode: 28921/30000 (96.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9176s / 944.1040 s
agent0:                 episode reward: -0.4576,                 loss: nan
agent1:                 episode reward: 0.4576,                 loss: 0.3339
Episode: 28941/30000 (96.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9177s / 945.0217 s
agent0:                 episode reward: -0.8562,                 loss: nan
agent1:                 episode reward: 0.8562,                 loss: 0.3314
Episode: 28961/30000 (96.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9107s / 945.9324 s
agent0:                 episode reward: -0.6065,                 loss: nan
agent1:                 episode reward: 0.6065,                 loss: 0.3305
Episode: 28981/30000 (96.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9186s / 946.8510 s
agent0:                 episode reward: -0.4476,                 loss: nan
agent1:                 episode reward: 0.4476,                 loss: 0.3334
Episode: 29001/30000 (96.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9361s / 947.7872 s
agent0:                 episode reward: -0.7971,                 loss: nan
agent1:                 episode reward: 0.7971,                 loss: 0.3343
Episode: 29021/30000 (96.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9334s / 948.7205 s
agent0:                 episode reward: -0.3882,                 loss: nan
agent1:                 episode reward: 0.3882,                 loss: 0.3297
Episode: 29041/30000 (96.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9222s / 949.6427 s
agent0:                 episode reward: -0.9062,                 loss: nan
agent1:                 episode reward: 0.9062,                 loss: 0.3272
Episode: 29061/30000 (96.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9280s / 950.5707 s
agent0:                 episode reward: -0.7860,                 loss: nan
agent1:                 episode reward: 0.7860,                 loss: 0.3267
Episode: 29081/30000 (96.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9200s / 951.4907 s
agent0:                 episode reward: -0.5536,                 loss: nan
agent1:                 episode reward: 0.5536,                 loss: 0.3284
Episode: 29101/30000 (97.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9473s / 952.4381 s
agent0:                 episode reward: -0.7791,                 loss: nan
agent1:                 episode reward: 0.7791,                 loss: 0.3275
Episode: 29121/30000 (97.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9165s / 953.3546 s
agent0:                 episode reward: -1.0399,                 loss: nan
agent1:                 episode reward: 1.0399,                 loss: 0.3262
Episode: 29141/30000 (97.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9267s / 954.2813 s
agent0:                 episode reward: -0.2339,                 loss: nan
agent1:                 episode reward: 0.2339,                 loss: 0.3311
Episode: 29161/30000 (97.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9296s / 955.2109 s
agent0:                 episode reward: -0.5020,                 loss: nan
agent1:                 episode reward: 0.5020,                 loss: 0.3268
Episode: 29181/30000 (97.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9264s / 956.1372 s
agent0:                 episode reward: -0.7283,                 loss: nan
agent1:                 episode reward: 0.7283,                 loss: 0.3266
Episode: 29201/30000 (97.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9288s / 957.0660 s
agent0:                 episode reward: -0.3331,                 loss: nan
agent1:                 episode reward: 0.3331,                 loss: 0.3276
Episode: 29221/30000 (97.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9337s / 957.9997 s
agent0:                 episode reward: -0.6294,                 loss: nan
agent1:                 episode reward: 0.6294,                 loss: 0.3295
Episode: 29241/30000 (97.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9405s / 958.9402 s
agent0:                 episode reward: -0.5442,                 loss: nan
agent1:                 episode reward: 0.5442,                 loss: 0.3277
Episode: 29261/30000 (97.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9474s / 959.8876 s
agent0:                 episode reward: -0.6490,                 loss: nan
agent1:                 episode reward: 0.6490,                 loss: 0.3263
Episode: 29281/30000 (97.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9427s / 960.8303 s
agent0:                 episode reward: -0.5527,                 loss: nan
agent1:                 episode reward: 0.5527,                 loss: 0.3292
Episode: 29301/30000 (97.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9191s / 961.7494 s
agent0:                 episode reward: -0.6810,                 loss: nan
agent1:                 episode reward: 0.6810,                 loss: 0.3286
Episode: 29321/30000 (97.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9673s / 962.7167 s
agent0:                 episode reward: -0.8286,                 loss: nan
agent1:                 episode reward: 0.8286,                 loss: 0.3278
Episode: 29341/30000 (97.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9461s / 963.6628 s
agent0:                 episode reward: -0.8326,                 loss: nan
agent1:                 episode reward: 0.8326,                 loss: 0.3286
Episode: 29361/30000 (97.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9290s / 964.5918 s
agent0:                 episode reward: -0.9985,                 loss: nan
agent1:                 episode reward: 0.9985,                 loss: 0.3308
Episode: 29381/30000 (97.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9367s / 965.5285 s
agent0:                 episode reward: -0.8252,                 loss: nan
agent1:                 episode reward: 0.8252,                 loss: 0.3314
Episode: 29401/30000 (98.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9503s / 966.4788 s
agent0:                 episode reward: -0.4916,                 loss: nan
agent1:                 episode reward: 0.4916,                 loss: 0.3308
Episode: 29421/30000 (98.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9269s / 967.4056 s
agent0:                 episode reward: -0.4184,                 loss: nan
agent1:                 episode reward: 0.4184,                 loss: 0.3305
Episode: 29441/30000 (98.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9274s / 968.3330 s
agent0:                 episode reward: -0.4282,                 loss: nan
agent1:                 episode reward: 0.4282,                 loss: 0.3294
Episode: 29461/30000 (98.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9414s / 969.2744 s
agent0:                 episode reward: -0.2766,                 loss: nan
agent1:                 episode reward: 0.2766,                 loss: 0.3324
Episode: 29481/30000 (98.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9267s / 970.2011 s
agent0:                 episode reward: -0.5388,                 loss: nan
agent1:                 episode reward: 0.5388,                 loss: 0.3296
Episode: 29501/30000 (98.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9383s / 971.1394 s
agent0:                 episode reward: -0.7878,                 loss: nan
agent1:                 episode reward: 0.7878,                 loss: 0.3320
Episode: 29521/30000 (98.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9414s / 972.0808 s
agent0:                 episode reward: -0.4781,                 loss: nan
agent1:                 episode reward: 0.4781,                 loss: 0.3310
Episode: 29541/30000 (98.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9436s / 973.0244 s
agent0:                 episode reward: -0.4062,                 loss: nan
agent1:                 episode reward: 0.4062,                 loss: 0.3314
Episode: 29561/30000 (98.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9313s / 973.9557 s
agent0:                 episode reward: -0.5001,                 loss: nan
agent1:                 episode reward: 0.5001,                 loss: 0.3307
Episode: 29581/30000 (98.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9389s / 974.8947 s
agent0:                 episode reward: -0.8230,                 loss: nan
agent1:                 episode reward: 0.8230,                 loss: 0.3323
Episode: 29601/30000 (98.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9441s / 975.8388 s
agent0:                 episode reward: -0.7493,                 loss: nan
agent1:                 episode reward: 0.7493,                 loss: 0.3309
Episode: 29621/30000 (98.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9351s / 976.7739 s
agent0:                 episode reward: -0.4795,                 loss: nan
agent1:                 episode reward: 0.4795,                 loss: 0.3305/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 29641/30000 (98.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9471s / 977.7211 s
agent0:                 episode reward: -0.7118,                 loss: nan
agent1:                 episode reward: 0.7118,                 loss: 0.3340
Episode: 29661/30000 (98.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9345s / 978.6556 s
agent0:                 episode reward: -0.8193,                 loss: nan
agent1:                 episode reward: 0.8193,                 loss: 0.3304
Episode: 29681/30000 (98.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9414s / 979.5969 s
agent0:                 episode reward: -0.1708,                 loss: nan
agent1:                 episode reward: 0.1708,                 loss: 0.3320
Episode: 29701/30000 (99.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9477s / 980.5446 s
agent0:                 episode reward: -0.6320,                 loss: nan
agent1:                 episode reward: 0.6320,                 loss: 0.3335
Episode: 29721/30000 (99.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9408s / 981.4854 s
agent0:                 episode reward: -0.7422,                 loss: nan
agent1:                 episode reward: 0.7422,                 loss: 0.3313
Episode: 29741/30000 (99.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9715s / 982.4569 s
agent0:                 episode reward: -0.7541,                 loss: nan
agent1:                 episode reward: 0.7541,                 loss: 0.3282
Episode: 29761/30000 (99.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9644s / 983.4213 s
agent0:                 episode reward: -0.8679,                 loss: nan
agent1:                 episode reward: 0.8679,                 loss: 0.3313
Episode: 29781/30000 (99.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9254s / 984.3467 s
agent0:                 episode reward: -0.6178,                 loss: nan
agent1:                 episode reward: 0.6178,                 loss: 0.3304
Episode: 29801/30000 (99.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9350s / 985.2817 s
agent0:                 episode reward: -0.1705,                 loss: nan
agent1:                 episode reward: 0.1705,                 loss: 0.3319
Episode: 29821/30000 (99.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9414s / 986.2231 s
agent0:                 episode reward: -0.5741,                 loss: nan
agent1:                 episode reward: 0.5741,                 loss: 0.3328
Episode: 29841/30000 (99.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9675s / 987.1906 s
agent0:                 episode reward: -0.5234,                 loss: nan
agent1:                 episode reward: 0.5234,                 loss: 0.3328
Episode: 29861/30000 (99.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9430s / 988.1336 s
agent0:                 episode reward: -0.4257,                 loss: nan
agent1:                 episode reward: 0.4257,                 loss: 0.3334
Episode: 29881/30000 (99.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9486s / 989.0822 s
agent0:                 episode reward: -0.5016,                 loss: nan
agent1:                 episode reward: 0.5016,                 loss: 0.3315
Episode: 29901/30000 (99.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9486s / 990.0308 s
agent0:                 episode reward: -0.5717,                 loss: nan
agent1:                 episode reward: 0.5717,                 loss: 0.3304
Episode: 29921/30000 (99.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9561s / 990.9869 s
agent0:                 episode reward: -0.2076,                 loss: nan
agent1:                 episode reward: 0.2076,                 loss: 0.3275
Episode: 29941/30000 (99.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9484s / 991.9353 s
agent0:                 episode reward: -0.7314,                 loss: nan
agent1:                 episode reward: 0.7314,                 loss: 0.3324
Episode: 29961/30000 (99.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9509s / 992.8862 s
agent0:                 episode reward: -0.7044,                 loss: nan
agent1:                 episode reward: 0.7044,                 loss: 0.3320
Episode: 29981/30000 (99.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9384s / 993.8246 s
agent0:                 episode reward: -0.6632,                 loss: nan
agent1:                 episode reward: 0.6632,                 loss: 0.3297
