pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
surround_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [51, 18]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'surround_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220115_0159/pettingzoo_surround_v1_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220115_0159/pettingzoo_surround_v1_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 1751.0,                last time consumption/overall running time: 14.9004s / 14.9004 s
env0_first_0:                 episode reward: 2.0000,                 loss: -0.0123
env0_second_0:                 episode reward: -2.0000,                 loss: -0.0225
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 1499.95,                last time consumption/overall running time: 225.7270s / 240.6274 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.0301
env0_second_0:                 episode reward: 0.2500,                 loss: -0.0315
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 1456.55,                last time consumption/overall running time: 220.0273s / 460.6547 s
env0_first_0:                 episode reward: -0.9000,                 loss: -0.0292
env0_second_0:                 episode reward: 0.9000,                 loss: -0.0293
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 1365.6,                last time consumption/overall running time: 204.5193s / 665.1740 s
env0_first_0:                 episode reward: 0.8000,                 loss: -0.0375
env0_second_0:                 episode reward: -0.8000,                 loss: -0.0405
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 1462.85,                last time consumption/overall running time: 221.0433s / 886.2173 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0305
env0_second_0:                 episode reward: 0.2000,                 loss: -0.0342
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 1436.15,                last time consumption/overall running time: 214.6097s / 1100.8270 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.0461
env0_second_0:                 episode reward: 0.2500,                 loss: -0.0467
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 1386.2,                last time consumption/overall running time: 207.4671s / 1308.2940 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.0341
env0_second_0:                 episode reward: 0.3000,                 loss: -0.0357
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 1398.1,                last time consumption/overall running time: 209.2181s / 1517.5122 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.0409
env0_second_0:                 episode reward: -0.7500,                 loss: -0.0420
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 1476.75,                last time consumption/overall running time: 224.0004s / 1741.5126 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0560
env0_second_0:                 episode reward: 0.0000,                 loss: -0.0561
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 1443.95,                last time consumption/overall running time: 215.8651s / 1957.3777 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.0348
env0_second_0:                 episode reward: 0.1000,                 loss: -0.0351
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 1381.4,                last time consumption/overall running time: 207.9374s / 2165.3151 s
env0_first_0:                 episode reward: -1.0000,                 loss: -0.0435
env0_second_0:                 episode reward: 1.0000,                 loss: -0.0428
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 1379.6,                last time consumption/overall running time: 209.5247s / 2374.8398 s
env0_first_0:                 episode reward: -0.8000,                 loss: -0.0304
env0_second_0:                 episode reward: 0.8000,                 loss: -0.0319
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 1470.4,                last time consumption/overall running time: 223.5142s / 2598.3541 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0408
env0_second_0:                 episode reward: 0.2000,                 loss: -0.0417
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 1398.75,                last time consumption/overall running time: 209.6972s / 2808.0513 s
env0_first_0:                 episode reward: -2.3500,                 loss: -0.0525
env0_second_0:                 episode reward: 2.3500,                 loss: -0.0541
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 1447.65,                last time consumption/overall running time: 216.9870s / 3025.0383 s
env0_first_0:                 episode reward: 1.5500,                 loss: -0.0319
env0_second_0:                 episode reward: -1.5500,                 loss: -0.0346
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 1435.2,                last time consumption/overall running time: 215.7355s / 3240.7738 s
env0_first_0:                 episode reward: 1.2500,                 loss: -0.0382
env0_second_0:                 episode reward: -1.2500,                 loss: -0.0402
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 1432.45,                last time consumption/overall running time: 217.0046s / 3457.7784 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.0478
env0_second_0:                 episode reward: 0.7000,                 loss: -0.0488
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 1397.9,                last time consumption/overall running time: 207.9913s / 3665.7698 s
env0_first_0:                 episode reward: 0.8000,                 loss: -0.0432
env0_second_0:                 episode reward: -0.8000,                 loss: -0.0435
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 1410.75,                last time consumption/overall running time: 212.1238s / 3877.8935 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0447
env0_second_0:                 episode reward: -0.2000,                 loss: -0.0449
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 1375.6,                last time consumption/overall running time: 204.5353s / 4082.4288 s
env0_first_0:                 episode reward: -0.8000,                 loss: -0.0527
env0_second_0:                 episode reward: 0.8000,                 loss: -0.0505
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 1473.75,                last time consumption/overall running time: 219.0209s / 4301.4497 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.0470
env0_second_0:                 episode reward: 0.2500,                 loss: -0.0391
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 1437.45,                last time consumption/overall running time: 214.1655s / 4515.6152 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.0548
env0_second_0:                 episode reward: -0.4500,                 loss: -0.0536
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 1410.9,                last time consumption/overall running time: 211.8888s / 4727.5040 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.0522
env0_second_0:                 episode reward: 0.7000,                 loss: -0.0546
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 1322.5,                last time consumption/overall running time: 198.2638s / 4925.7678 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.0592
env0_second_0:                 episode reward: 0.5500,                 loss: -0.0510
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 1424.4,                last time consumption/overall running time: 213.4452s / 5139.2130 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.0601
env0_second_0:                 episode reward: -0.5000,                 loss: -0.0590
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 1406.1,                last time consumption/overall running time: 212.1591s / 5351.3721 s
env0_first_0:                 episode reward: -2.0500,                 loss: -0.0547
env0_second_0:                 episode reward: 2.0500,                 loss: -0.0569
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 1422.05,                last time consumption/overall running time: 213.8448s / 5565.2169 s
env0_first_0:                 episode reward: -0.9500,                 loss: -0.0461
env0_second_0:                 episode reward: 0.9500,                 loss: -0.0481
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 1375.1,                last time consumption/overall running time: 206.8892s / 5772.1060 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.0519
env0_second_0:                 episode reward: 0.3500,                 loss: -0.0515
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 1444.65,                last time consumption/overall running time: 217.6454s / 5989.7515 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0577
env0_second_0:                 episode reward: 0.0000,                 loss: -0.0491
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 1421.35,                last time consumption/overall running time: 214.3349s / 6204.0864 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0650
env0_second_0:                 episode reward: -0.1000,                 loss: -0.0622
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 1431.35,                last time consumption/overall running time: 213.8449s / 6417.9313 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0790
env0_second_0:                 episode reward: 0.0000,                 loss: -0.0765
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 1451.4,                last time consumption/overall running time: 219.1043s / 6637.0356 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.0718
env0_second_0:                 episode reward: 0.7500,                 loss: -0.0614
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 1454.85,                last time consumption/overall running time: 216.4292s / 6853.4648 s
env0_first_0:                 episode reward: 1.4000,                 loss: -0.0702
env0_second_0:                 episode reward: -1.4000,                 loss: -0.0564
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 1363.7,                last time consumption/overall running time: 206.9171s / 7060.3819 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0662
env0_second_0:                 episode reward: 0.0000,                 loss: -0.0735
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 1429.25,                last time consumption/overall running time: 216.9185s / 7277.3004 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.0868
env0_second_0:                 episode reward: -0.5000,                 loss: -0.0882
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 1445.35,                last time consumption/overall running time: 218.5116s / 7495.8120 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.0744
env0_second_0:                 episode reward: 0.4000,                 loss: -0.0600
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 1374.2,                last time consumption/overall running time: 205.9115s / 7701.7235 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.0442
env0_second_0:                 episode reward: 0.4000,                 loss: -0.0632
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 1396.75,                last time consumption/overall running time: 211.4790s / 7913.2025 s
env0_first_0:                 episode reward: -1.7000,                 loss: -0.0513
env0_second_0:                 episode reward: 1.7000,                 loss: -0.0766
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 1418.45,                last time consumption/overall running time: 215.5934s / 8128.7959 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0625
env0_second_0:                 episode reward: -0.2000,                 loss: -0.0565
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 1460.85,                last time consumption/overall running time: 219.7684s / 8348.5643 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.0614
env0_second_0:                 episode reward: -0.9500,                 loss: -0.0656
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 1356.9,                last time consumption/overall running time: 207.8204s / 8556.3847 s
env0_first_0:                 episode reward: -0.6500,                 loss: -0.0564
env0_second_0:                 episode reward: 0.6500,                 loss: -0.0624
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 1444.25,                last time consumption/overall running time: 215.9861s / 8772.3708 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.0709
env0_second_0:                 episode reward: 0.5000,                 loss: -0.0628
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 1398.35,                last time consumption/overall running time: 211.3859s / 8983.7567 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.0846
env0_second_0:                 episode reward: 0.4500,                 loss: -0.0601
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 1424.8,                last time consumption/overall running time: 215.1168s / 9198.8735 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0705
env0_second_0:                 episode reward: 0.2000,                 loss: -0.0666
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 1432.55,                last time consumption/overall running time: 217.1378s / 9416.0113 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.0790
env0_second_0:                 episode reward: -0.1500,                 loss: -0.0621
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 1392.75,                last time consumption/overall running time: 212.4731s / 9628.4845 s
env0_first_0:                 episode reward: -2.5000,                 loss: -0.0920
env0_second_0:                 episode reward: 2.5000,                 loss: -0.0841
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 1404.1,                last time consumption/overall running time: 210.1347s / 9838.6192 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0719
env0_second_0:                 episode reward: -0.1000,                 loss: -0.0523
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 1453.95,                last time consumption/overall running time: 220.0557s / 10058.6748 s
env0_first_0:                 episode reward: -1.4500,                 loss: -0.0646
env0_second_0:                 episode reward: 1.4500,                 loss: -0.0626
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 1496.7,                last time consumption/overall running time: 225.3867s / 10284.0615 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.0682
env0_second_0:                 episode reward: -0.7000,                 loss: -0.0482
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 1433.2,                last time consumption/overall running time: 218.5467s / 10502.6083 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0513
env0_second_0:                 episode reward: -0.0500,                 loss: -0.0495
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 1451.1,                last time consumption/overall running time: 219.9741s / 10722.5824 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.0544
env0_second_0:                 episode reward: 0.3000,                 loss: -0.0608
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 1362.45,                last time consumption/overall running time: 204.6506s / 10927.2330 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.0609
env0_second_0:                 episode reward: 0.1500,                 loss: -0.0645
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 1427.7,                last time consumption/overall running time: 215.0014s / 11142.2344 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0647
env0_second_0:                 episode reward: -0.1000,                 loss: -0.0795
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 1454.6,                last time consumption/overall running time: 217.0527s / 11359.2871 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.0749
env0_second_0:                 episode reward: 0.5000,                 loss: -0.0683
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 1464.1,                last time consumption/overall running time: 219.3538s / 11578.6409 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.0705
env0_second_0:                 episode reward: -0.2500,                 loss: -0.0566
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 1399.4,                last time consumption/overall running time: 211.3192s / 11789.9601 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0576
env0_second_0:                 episode reward: 0.2000,                 loss: -0.0565
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 1381.75,                last time consumption/overall running time: 209.2144s / 11999.1745 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.0731
env0_second_0:                 episode reward: 0.4500,                 loss: -0.0541
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 1435.85,                last time consumption/overall running time: 215.1674s / 12214.3419 s
env0_first_0:                 episode reward: -1.1500,                 loss: -0.0773
env0_second_0:                 episode reward: 1.1500,                 loss: -0.0599
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 1337.2,                last time consumption/overall running time: 203.6352s / 12417.9771 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.0477
env0_second_0:                 episode reward: 0.6000,                 loss: -0.0478
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 1339.35,                last time consumption/overall running time: 201.1653s / 12619.1424 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.0830
env0_second_0:                 episode reward: -0.5000,                 loss: -0.0700
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 1496.0,                last time consumption/overall running time: 223.0394s / 12842.1818 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.0619
env0_second_0:                 episode reward: -1.1500,                 loss: -0.0744
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 1444.8,                last time consumption/overall running time: 217.6639s / 13059.8457 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0729
env0_second_0:                 episode reward: -0.1000,                 loss: -0.0589
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 1496.4,                last time consumption/overall running time: 225.7560s / 13285.6017 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.0734
env0_second_0:                 episode reward: -0.2500,                 loss: -0.0581
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 1428.45,                last time consumption/overall running time: 214.7673s / 13500.3690 s
env0_first_0:                 episode reward: -1.9000,                 loss: -0.0873
env0_second_0:                 episode reward: 1.9000,                 loss: -0.0899
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 1453.55,                last time consumption/overall running time: 218.0541s / 13718.4231 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0875
env0_second_0:                 episode reward: -0.0500,                 loss: -0.0781
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 1389.85,                last time consumption/overall running time: 210.4539s / 13928.8770 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0575
env0_second_0:                 episode reward: 0.2000,                 loss: -0.0543
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 1454.15,                last time consumption/overall running time: 218.5360s / 14147.4130 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.0854
env0_second_0:                 episode reward: -0.6000,                 loss: -0.0763
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 1467.3,                last time consumption/overall running time: 222.6406s / 14370.0536 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.0607
env0_second_0:                 episode reward: -0.7000,                 loss: -0.0844
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 1445.5,                last time consumption/overall running time: 217.4413s / 14587.4948 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0672
env0_second_0:                 episode reward: -0.1000,                 loss: -0.0744
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 1518.05,                last time consumption/overall running time: 228.8971s / 14816.3919 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.0723
env0_second_0:                 episode reward: -0.1500,                 loss: -0.0729
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 1541.25,                last time consumption/overall running time: 233.5643s / 15049.9562 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0668
env0_second_0:                 episode reward: 0.2000,                 loss: -0.0653
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 1378.6,                last time consumption/overall running time: 210.4637s / 15260.4199 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0738
env0_second_0:                 episode reward: 0.0000,                 loss: -0.0720
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 1402.85,                last time consumption/overall running time: 211.6078s / 15472.0276 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.0735
env0_second_0:                 episode reward: -0.2500,                 loss: -0.0924
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 1438.6,                last time consumption/overall running time: 217.7436s / 15689.7712 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0674
env0_second_0:                 episode reward: -0.2000,                 loss: -0.0740
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 1440.5,                last time consumption/overall running time: 216.8227s / 15906.5940 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.0740
env0_second_0:                 episode reward: -0.5000,                 loss: -0.0753
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 1487.15,                last time consumption/overall running time: 224.5888s / 16131.1827 s
env0_first_0:                 episode reward: 0.8000,                 loss: -0.0627
env0_second_0:                 episode reward: -0.8000,                 loss: -0.0764
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 1434.5,                last time consumption/overall running time: 216.7714s / 16347.9541 s
env0_first_0:                 episode reward: 1.5500,                 loss: -0.0810
env0_second_0:                 episode reward: -1.5500,                 loss: -0.0647
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 1405.5,                last time consumption/overall running time: 211.8510s / 16559.8051 s
env0_first_0:                 episode reward: 0.8000,                 loss: -0.0920
env0_second_0:                 episode reward: -0.8000,                 loss: -0.0801
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 1375.55,                last time consumption/overall running time: 208.6168s / 16768.4219 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0658
env0_second_0:                 episode reward: -0.0500,                 loss: -0.0670
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 1500.55,                last time consumption/overall running time: 228.1914s / 16996.6133 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.0846
env0_second_0:                 episode reward: -0.5500,                 loss: -0.0757
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 1473.1,                last time consumption/overall running time: 221.7580s / 17218.3713 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.0859
env0_second_0:                 episode reward: -0.3000,                 loss: -0.0924
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 1458.05,                last time consumption/overall running time: 219.3499s / 17437.7212 s
env0_first_0:                 episode reward: -0.6500,                 loss: -0.0916
env0_second_0:                 episode reward: 0.6500,                 loss: -0.0896
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 1500.55,                last time consumption/overall running time: 224.6467s / 17662.3679 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.0819
env0_second_0:                 episode reward: -0.7000,                 loss: -0.0916
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 1459.15,                last time consumption/overall running time: 220.0987s / 17882.4666 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.0923
env0_second_0:                 episode reward: 0.6000,                 loss: -0.0954
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 1414.0,                last time consumption/overall running time: 213.8145s / 18096.2811 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.0830
env0_second_0:                 episode reward: -0.6000,                 loss: -0.0604
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 1498.75,                last time consumption/overall running time: 228.0364s / 18324.3175 s
env0_first_0:                 episode reward: -0.9500,                 loss: -0.0900
env0_second_0:                 episode reward: 0.9500,                 loss: -0.0671
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 1415.6,                last time consumption/overall running time: 212.4523s / 18536.7698 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.0786
env0_second_0:                 episode reward: 0.5500,                 loss: -0.0729
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 1440.9,                last time consumption/overall running time: 219.4681s / 18756.2379 s
env0_first_0:                 episode reward: 1.2000,                 loss: -0.0696
env0_second_0:                 episode reward: -1.2000,                 loss: -0.0674
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 1401.85,                last time consumption/overall running time: 212.1171s / 18968.3550 s
env0_first_0:                 episode reward: -0.9500,                 loss: -0.0730
env0_second_0:                 episode reward: 0.9500,                 loss: -0.0843
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 1526.15,                last time consumption/overall running time: 227.5558s / 19195.9108 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.0569
env0_second_0:                 episode reward: -0.6000,                 loss: -0.0594
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 1415.75,                last time consumption/overall running time: 214.3038s / 19410.2145 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.0849
env0_second_0:                 episode reward: 0.0500,                 loss: -0.0868
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 1465.85,                last time consumption/overall running time: 220.8598s / 19631.0744 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.0713
env0_second_0:                 episode reward: 0.6000,                 loss: -0.0631
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 1416.5,                last time consumption/overall running time: 213.6165s / 19844.6909 s
env0_first_0:                 episode reward: -0.6500,                 loss: -0.0932
env0_second_0:                 episode reward: 0.6500,                 loss: -0.0674
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 1442.4,                last time consumption/overall running time: 216.3372s / 20061.0281 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.0736
env0_second_0:                 episode reward: 0.7000,                 loss: -0.0739
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 1383.25,                last time consumption/overall running time: 209.3381s / 20270.3662 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.0939
env0_second_0:                 episode reward: 0.3000,                 loss: -0.0914
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 1391.7,                last time consumption/overall running time: 210.8893s / 20481.2556 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.0603
env0_second_0:                 episode reward: -0.6500,                 loss: -0.0727
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 1495.7,                last time consumption/overall running time: 226.1912s / 20707.4467 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.0904
env0_second_0:                 episode reward: -0.3000,                 loss: -0.0777
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 1431.35,                last time consumption/overall running time: 214.0201s / 20921.4669 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.0743
env0_second_0:                 episode reward: 0.3000,                 loss: -0.0835
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 1418.5,                last time consumption/overall running time: 212.6491s / 21134.1160 s
env0_first_0:                 episode reward: -1.7500,                 loss: -0.0831
env0_second_0:                 episode reward: 1.7500,                 loss: -0.0941
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 1381.4,                last time consumption/overall running time: 212.1842s / 21346.3002 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.0712
env0_second_0:                 episode reward: -0.2500,                 loss: -0.0752
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 1446.5,                last time consumption/overall running time: 216.8829s / 21563.1831 s
env0_first_0:                 episode reward: -1.0500,                 loss: -0.0551
env0_second_0:                 episode reward: 1.0500,                 loss: -0.0713
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 1411.9,                last time consumption/overall running time: 213.2658s / 21776.4489 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.1013
env0_second_0:                 episode reward: -0.3000,                 loss: -0.0875
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 1490.1,                last time consumption/overall running time: 226.3864s / 22002.8353 s
env0_first_0:                 episode reward: -0.8500,                 loss: -0.0830
env0_second_0:                 episode reward: 0.8500,                 loss: -0.0834
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 1455.65,                last time consumption/overall running time: 217.0007s / 22219.8360 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0604
env0_second_0:                 episode reward: -0.0500,                 loss: -0.0802
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 1495.75,                last time consumption/overall running time: 224.7995s / 22444.6355 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0660
env0_second_0:                 episode reward: 0.2000,                 loss: -0.0931
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 1423.1,                last time consumption/overall running time: 214.6407s / 22659.2762 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.0814
env0_second_0:                 episode reward: 0.5500,                 loss: -0.0892
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 1400.25,                last time consumption/overall running time: 209.3332s / 22868.6094 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.0641
env0_second_0:                 episode reward: -0.4000,                 loss: -0.0710
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 1465.3,                last time consumption/overall running time: 220.0765s / 23088.6859 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0865
env0_second_0:                 episode reward: -0.2000,                 loss: -0.0754
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 1432.1,                last time consumption/overall running time: 215.0814s / 23303.7673 s
env0_first_0:                 episode reward: 0.8000,                 loss: -0.0730
env0_second_0:                 episode reward: -0.8000,                 loss: -0.1010
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 1364.7,                last time consumption/overall running time: 204.4303s / 23508.1976 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0837
env0_second_0:                 episode reward: -0.0500,                 loss: -0.0865
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 1458.3,                last time consumption/overall running time: 218.4974s / 23726.6950 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0743
env0_second_0:                 episode reward: -0.0500,                 loss: -0.0619
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 1386.1,                last time consumption/overall running time: 208.7499s / 23935.4450 s
env0_first_0:                 episode reward: -1.4500,                 loss: -0.0911
env0_second_0:                 episode reward: 1.4500,                 loss: -0.0800
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 1365.35,                last time consumption/overall running time: 206.1253s / 24141.5702 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0691
env0_second_0:                 episode reward: 0.2000,                 loss: -0.0674
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 1438.4,                last time consumption/overall running time: 218.8604s / 24360.4307 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.0718
env0_second_0:                 episode reward: 0.7000,                 loss: -0.0736
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 1491.85,                last time consumption/overall running time: 220.7113s / 24581.1420 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.0594
env0_second_0:                 episode reward: 0.2500,                 loss: -0.0621
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 1465.85,                last time consumption/overall running time: 220.6200s / 24801.7620 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.0769
env0_second_0:                 episode reward: 0.5000,                 loss: -0.0788
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 1407.7,                last time consumption/overall running time: 211.4760s / 25013.2381 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.0929
env0_second_0:                 episode reward: -0.1500,                 loss: -0.0820
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 1468.3,                last time consumption/overall running time: 219.9957s / 25233.2338 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.0902
env0_second_0:                 episode reward: 0.3500,                 loss: -0.0807
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 1446.35,                last time consumption/overall running time: 217.3480s / 25450.5818 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.0806
env0_second_0:                 episode reward: 0.1000,                 loss: -0.0781
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 1450.5,                last time consumption/overall running time: 219.3903s / 25669.9721 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0724
env0_second_0:                 episode reward: -0.1000,                 loss: -0.0780
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 1448.5,                last time consumption/overall running time: 218.3353s / 25888.3074 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.0652
env0_second_0:                 episode reward: -0.6500,                 loss: -0.0822
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 1405.1,                last time consumption/overall running time: 212.1870s / 26100.4944 s
env0_first_0:                 episode reward: 1.7500,                 loss: -0.0586
env0_second_0:                 episode reward: -1.7500,                 loss: -0.0649
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 1417.75,                last time consumption/overall running time: 214.7535s / 26315.2479 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.0597
env0_second_0:                 episode reward: 0.7000,                 loss: -0.0704
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 1412.65,                last time consumption/overall running time: 213.5848s / 26528.8327 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.0557
env0_second_0:                 episode reward: -0.4500,                 loss: -0.0613
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 1473.85,                last time consumption/overall running time: 221.7752s / 26750.6079 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.0850
env0_second_0:                 episode reward: -0.3000,                 loss: -0.0736
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 1410.55,                last time consumption/overall running time: 213.4857s / 26964.0936 s
env0_first_0:                 episode reward: -2.0000,                 loss: -0.0824
env0_second_0:                 episode reward: 2.0000,                 loss: -0.0763
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 1325.95,                last time consumption/overall running time: 197.6665s / 27161.7601 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.0778
env0_second_0:                 episode reward: 0.1000,                 loss: -0.0780
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 1439.8,                last time consumption/overall running time: 214.2404s / 27376.0005 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.0760
env0_second_0:                 episode reward: -0.5500,                 loss: -0.0849
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 1459.6,                last time consumption/overall running time: 221.6842s / 27597.6846 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.0756
env0_second_0:                 episode reward: -0.7000,                 loss: -0.0847
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 1468.55,                last time consumption/overall running time: 219.0194s / 27816.7040 s
env0_first_0:                 episode reward: 1.6500,                 loss: -0.0807
env0_second_0:                 episode reward: -1.6500,                 loss: -0.0840
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 1513.95,                last time consumption/overall running time: 228.0026s / 28044.7066 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.0654
env0_second_0:                 episode reward: -0.9500,                 loss: -0.0691
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 1399.9,                last time consumption/overall running time: 213.8245s / 28258.5311 s
env0_first_0:                 episode reward: -1.4500,                 loss: -0.0723
env0_second_0:                 episode reward: 1.4500,                 loss: -0.0832
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 1384.6,                last time consumption/overall running time: 210.0055s / 28468.5366 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.0747
env0_second_0:                 episode reward: -0.7500,                 loss: -0.0885
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 1445.6,                last time consumption/overall running time: 220.3694s / 28688.9060 s
env0_first_0:                 episode reward: -1.4500,                 loss: -0.0839
env0_second_0:                 episode reward: 1.4500,                 loss: -0.0867
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 1392.1,                last time consumption/overall running time: 209.6610s / 28898.5670 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.0643
env0_second_0:                 episode reward: -0.4500,                 loss: -0.0855
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 1407.5,                last time consumption/overall running time: 212.3569s / 29110.9240 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.0784
env0_second_0:                 episode reward: -0.3500,                 loss: -0.0742
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 1473.35,                last time consumption/overall running time: 220.9340s / 29331.8579 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.0971
env0_second_0:                 episode reward: -0.4000,                 loss: -0.0793
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 1340.3,                last time consumption/overall running time: 203.4126s / 29535.2705 s
env0_first_0:                 episode reward: -1.7500,                 loss: -0.0750
env0_second_0:                 episode reward: 1.7500,                 loss: -0.0855
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 1345.9,                last time consumption/overall running time: 203.5421s / 29738.8126 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.0875
env0_second_0:                 episode reward: -0.1500,                 loss: -0.0946
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 1386.2,                last time consumption/overall running time: 209.0141s / 29947.8267 s
env0_first_0:                 episode reward: 0.9000,                 loss: -0.0828
env0_second_0:                 episode reward: -0.9000,                 loss: -0.0805
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 1419.75,                last time consumption/overall running time: 213.4742s / 30161.3009 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0879
env0_second_0:                 episode reward: 0.0000,                 loss: -0.0947
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 1428.15,                last time consumption/overall running time: 218.0363s / 30379.3373 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.0955
env0_second_0:                 episode reward: 0.3500,                 loss: -0.0983
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 1374.05,                last time consumption/overall running time: 208.4758s / 30587.8130 s
env0_first_0:                 episode reward: -0.6500,                 loss: -0.0881
env0_second_0:                 episode reward: 0.6500,                 loss: -0.0815
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 1496.1,                last time consumption/overall running time: 225.5584s / 30813.3715 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.0861
env0_second_0:                 episode reward: -0.4500,                 loss: -0.0901
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 1437.45,                last time consumption/overall running time: 215.6884s / 31029.0599 s
env0_first_0:                 episode reward: -0.6500,                 loss: -0.0710
env0_second_0:                 episode reward: 0.6500,                 loss: -0.0736
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 1425.25,                last time consumption/overall running time: 216.4564s / 31245.5162 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.0920
env0_second_0:                 episode reward: 0.1500,                 loss: -0.0716
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 1461.1,                last time consumption/overall running time: 217.8607s / 31463.3770 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.0888
env0_second_0:                 episode reward: 0.4500,                 loss: -0.0876
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 1375.65,                last time consumption/overall running time: 207.0370s / 31670.4139 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.1005
env0_second_0:                 episode reward: -0.2500,                 loss: -0.0819
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 1436.85,                last time consumption/overall running time: 217.3919s / 31887.8059 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.1005
env0_second_0:                 episode reward: 0.5000,                 loss: -0.0834
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 1448.15,                last time consumption/overall running time: 218.7840s / 32106.5899 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.1061
env0_second_0:                 episode reward: -0.6500,                 loss: -0.0917
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 1375.8,                last time consumption/overall running time: 208.4491s / 32315.0390 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.0853
env0_second_0:                 episode reward: 0.3000,                 loss: -0.0710
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 1427.95,                last time consumption/overall running time: 216.1199s / 32531.1589 s
env0_first_0:                 episode reward: -1.0000,                 loss: -0.0799
env0_second_0:                 episode reward: 1.0000,                 loss: -0.0696
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 1497.0,                last time consumption/overall running time: 224.8048s / 32755.9637 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0881
env0_second_0:                 episode reward: -0.0500,                 loss: -0.0602
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 1492.35,                last time consumption/overall running time: 225.1220s / 32981.0857 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.0892
env0_second_0:                 episode reward: -0.1500,                 loss: -0.0565
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 1398.5,                last time consumption/overall running time: 208.3947s / 33189.4803 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0808
env0_second_0:                 episode reward: 0.2000,                 loss: -0.0580
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 1404.35,                last time consumption/overall running time: 213.3068s / 33402.7871 s
env0_first_0:                 episode reward: -1.3000,                 loss: -0.0728
env0_second_0:                 episode reward: 1.3000,                 loss: -0.0696
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 1395.95,                last time consumption/overall running time: 209.6946s / 33612.4817 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0570
env0_second_0:                 episode reward: 0.2000,                 loss: -0.0703
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 1457.85,                last time consumption/overall running time: 219.2453s / 33831.7270 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.0796
env0_second_0:                 episode reward: -0.1500,                 loss: -0.0634
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 1498.55,                last time consumption/overall running time: 223.0685s / 34054.7955 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0845
env0_second_0:                 episode reward: -0.2000,                 loss: -0.0657
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 1497.1,                last time consumption/overall running time: 227.3033s / 34282.0988 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0905
env0_second_0:                 episode reward: 0.2000,                 loss: -0.0821
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 1437.35,                last time consumption/overall running time: 213.9504s / 34496.0491 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.0955
env0_second_0:                 episode reward: -0.7000,                 loss: -0.0776
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 1392.1,                last time consumption/overall running time: 211.9252s / 34707.9743 s
env0_first_0:                 episode reward: 1.5000,                 loss: -0.0905
env0_second_0:                 episode reward: -1.5000,                 loss: -0.0832
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 1416.25,                last time consumption/overall running time: 215.5843s / 34923.5586 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.0825
env0_second_0:                 episode reward: 0.6000,                 loss: -0.0660
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 1437.3,                last time consumption/overall running time: 216.3515s / 35139.9102 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.0826
env0_second_0:                 episode reward: -0.1500,                 loss: -0.0851
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 1373.05,                last time consumption/overall running time: 185.6757s / 35325.5859 s
env0_first_0:                 episode reward: -1.9500,                 loss: -0.0578
env0_second_0:                 episode reward: 1.9500,                 loss: -0.0676
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 1505.3,                last time consumption/overall running time: 210.0654s / 35535.6512 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.0894
env0_second_0:                 episode reward: 0.3500,                 loss: -0.0743
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 1500.1,                last time consumption/overall running time: 203.5042s / 35739.1555 s
env0_first_0:                 episode reward: 0.8500,                 loss: -0.0728
env0_second_0:                 episode reward: -0.8500,                 loss: -0.0680
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 1451.4,                last time consumption/overall running time: 198.4308s / 35937.5863 s
env0_first_0:                 episode reward: -1.4500,                 loss: -0.0861
env0_second_0:                 episode reward: 1.4500,                 loss: -0.0702
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 1411.75,                last time consumption/overall running time: 187.9564s / 36125.5426 s
env0_first_0:                 episode reward: 2.1500,                 loss: -0.0874
env0_second_0:                 episode reward: -2.1500,                 loss: -0.0867
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 1431.4,                last time consumption/overall running time: 193.3468s / 36318.8894 s
env0_first_0:                 episode reward: -1.6000,                 loss: -0.0844
env0_second_0:                 episode reward: 1.6000,                 loss: -0.0837
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 1375.95,                last time consumption/overall running time: 186.9961s / 36505.8855 s
env0_first_0:                 episode reward: -1.2500,                 loss: -0.0602
env0_second_0:                 episode reward: 1.2500,                 loss: -0.0719
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 1381.1,                last time consumption/overall running time: 188.4412s / 36694.3267 s
env0_first_0:                 episode reward: -1.9500,                 loss: -0.0737
env0_second_0:                 episode reward: 1.9500,                 loss: -0.0918
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 1442.5,                last time consumption/overall running time: 193.2027s / 36887.5294 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0673
env0_second_0:                 episode reward: -0.0500,                 loss: -0.0813
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 1432.55,                last time consumption/overall running time: 190.3010s / 37077.8304 s
env0_first_0:                 episode reward: 0.8500,                 loss: -0.0834
env0_second_0:                 episode reward: -0.8500,                 loss: -0.0614
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 1402.35,                last time consumption/overall running time: 190.8795s / 37268.7098 s
env0_first_0:                 episode reward: 1.0500,                 loss: -0.0979
env0_second_0:                 episode reward: -1.0500,                 loss: -0.0813
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 1412.45,                last time consumption/overall running time: 190.0142s / 37458.7241 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.0838
env0_second_0:                 episode reward: 0.4000,                 loss: -0.0760
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 1339.7,                last time consumption/overall running time: 179.4758s / 37638.1999 s
env0_first_0:                 episode reward: -1.1500,                 loss: -0.0843
env0_second_0:                 episode reward: 1.1500,                 loss: -0.0897
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 1404.2,                last time consumption/overall running time: 186.8942s / 37825.0941 s
env0_first_0:                 episode reward: -0.9000,                 loss: -0.0862
env0_second_0:                 episode reward: 0.9000,                 loss: -0.0867
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 1426.5,                last time consumption/overall running time: 193.1612s / 38018.2553 s
env0_first_0:                 episode reward: -0.8000,                 loss: -0.0929
env0_second_0:                 episode reward: 0.8000,                 loss: -0.0860
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 1429.3,                last time consumption/overall running time: 192.3992s / 38210.6545 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0795
env0_second_0:                 episode reward: -0.2000,                 loss: -0.0716
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 1370.15,                last time consumption/overall running time: 185.2638s / 38395.9183 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0794
env0_second_0:                 episode reward: 0.0000,                 loss: -0.0683
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 1469.4,                last time consumption/overall running time: 195.9310s / 38591.8494 s
env0_first_0:                 episode reward: 1.0000,                 loss: -0.0965
env0_second_0:                 episode reward: -1.0000,                 loss: -0.0906
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 1416.9,                last time consumption/overall running time: 195.8017s / 38787.6510 s
env0_first_0:                 episode reward: 0.8500,                 loss: -0.0760
env0_second_0:                 episode reward: -0.8500,                 loss: -0.0850
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 1380.7,                last time consumption/overall running time: 187.0293s / 38974.6804 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0843
env0_second_0:                 episode reward: 0.2000,                 loss: -0.0834
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 1458.3,                last time consumption/overall running time: 196.3563s / 39171.0366 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.1037
env0_second_0:                 episode reward: 0.7000,                 loss: -0.0899
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 1439.3,                last time consumption/overall running time: 194.5264s / 39365.5630 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.0924
env0_second_0:                 episode reward: 0.1500,                 loss: -0.0941
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 1448.65,                last time consumption/overall running time: 194.8278s / 39560.3909 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.0799
env0_second_0:                 episode reward: 0.6000,                 loss: -0.0925
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 1428.75,                last time consumption/overall running time: 194.9313s / 39755.3221 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0763
env0_second_0:                 episode reward: 0.0000,                 loss: -0.0858
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 1472.85,                last time consumption/overall running time: 199.1574s / 39954.4795 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.0639
env0_second_0:                 episode reward: -0.7000,                 loss: -0.0867
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 1433.05,                last time consumption/overall running time: 192.5396s / 40147.0191 s
env0_first_0:                 episode reward: -3.0000,                 loss: -0.0597
env0_second_0:                 episode reward: 3.0000,                 loss: -0.0765
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 1465.5,                last time consumption/overall running time: 197.7692s / 40344.7883 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.0682
env0_second_0:                 episode reward: 0.3500,                 loss: -0.0837
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 1454.9,                last time consumption/overall running time: 196.1034s / 40540.8916 s
env0_first_0:                 episode reward: 1.5000,                 loss: -0.0794
env0_second_0:                 episode reward: -1.5000,                 loss: -0.0826
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 1469.4,                last time consumption/overall running time: 195.3477s / 40736.2393 s
env0_first_0:                 episode reward: -1.9500,                 loss: -0.0787
env0_second_0:                 episode reward: 1.9500,                 loss: -0.0899
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 1451.15,                last time consumption/overall running time: 191.9497s / 40928.1890 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0664
env0_second_0:                 episode reward: -0.0500,                 loss: -0.0804
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 1480.3,                last time consumption/overall running time: 195.1677s / 41123.3566 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.0779
env0_second_0:                 episode reward: 0.3000,                 loss: -0.0754
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 1408.05,                last time consumption/overall running time: 188.9783s / 41312.3349 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.0659
env0_second_0:                 episode reward: 0.7000,                 loss: -0.0847
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 1441.0,                last time consumption/overall running time: 193.1890s / 41505.5239 s
env0_first_0:                 episode reward: 0.8500,                 loss: -0.0761
env0_second_0:                 episode reward: -0.8500,                 loss: -0.0760
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 1450.5,                last time consumption/overall running time: 196.5817s / 41702.1056 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.0757
env0_second_0:                 episode reward: 0.7000,                 loss: -0.0808
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 1408.05,                last time consumption/overall running time: 187.3239s / 41889.4295 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.0778
env0_second_0:                 episode reward: -0.9500,                 loss: -0.0772
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 1387.9,                last time consumption/overall running time: 186.9297s / 42076.3593 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.0680
env0_second_0:                 episode reward: -0.3000,                 loss: -0.0765
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 1428.75,                last time consumption/overall running time: 198.4908s / 42274.8500 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.0888
env0_second_0:                 episode reward: -0.3500,                 loss: -0.0867
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 1432.95,                last time consumption/overall running time: 193.4720s / 42468.3220 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0959
env0_second_0:                 episode reward: -0.2000,                 loss: -0.0868
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 1497.3,                last time consumption/overall running time: 207.0350s / 42675.3571 s
env0_first_0:                 episode reward: -2.1000,                 loss: -0.0691
env0_second_0:                 episode reward: 2.1000,                 loss: -0.0580
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 1447.7,                last time consumption/overall running time: 196.9647s / 42872.3218 s
env0_first_0:                 episode reward: -0.9500,                 loss: -0.0685
env0_second_0:                 episode reward: 0.9500,                 loss: -0.0560
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 1479.6,                last time consumption/overall running time: 202.6591s / 43074.9809 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0850
env0_second_0:                 episode reward: -0.1000,                 loss: -0.0730
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 1466.3,                last time consumption/overall running time: 198.7717s / 43273.7526 s
env0_first_0:                 episode reward: 1.1000,                 loss: -0.0774
env0_second_0:                 episode reward: -1.1000,                 loss: -0.0788
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 1511.1,                last time consumption/overall running time: 204.5756s / 43478.3282 s
env0_first_0:                 episode reward: -1.5000,                 loss: -0.0958
env0_second_0:                 episode reward: 1.5000,                 loss: -0.0942
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 1548.45,                last time consumption/overall running time: 209.1781s / 43687.5063 s
env0_first_0:                 episode reward: -1.7000,                 loss: -0.0844
env0_second_0:                 episode reward: 1.7000,                 loss: -0.0818
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 1393.4,                last time consumption/overall running time: 187.0275s / 43874.5338 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.0799
env0_second_0:                 episode reward: 0.7500,                 loss: -0.0781
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 1403.95,                last time consumption/overall running time: 189.4895s / 44064.0233 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.0926
env0_second_0:                 episode reward: 0.5500,                 loss: -0.0871
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 1390.55,                last time consumption/overall running time: 188.8562s / 44252.8795 s
env0_first_0:                 episode reward: -1.1000,                 loss: -0.0617
env0_second_0:                 episode reward: 1.1000,                 loss: -0.0788
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 1469.5,                last time consumption/overall running time: 197.0201s / 44449.8996 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.0699
env0_second_0:                 episode reward: 0.7500,                 loss: -0.0838
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 1408.1,                last time consumption/overall running time: 187.2840s / 44637.1835 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.0792
env0_second_0:                 episode reward: 0.5000,                 loss: -0.0925
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 1432.5,                last time consumption/overall running time: 193.3796s / 44830.5632 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.0800
env0_second_0:                 episode reward: 0.5000,                 loss: -0.0938
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 1389.25,                last time consumption/overall running time: 186.0998s / 45016.6630 s
env0_first_0:                 episode reward: -1.0500,                 loss: -0.0678
env0_second_0:                 episode reward: 1.0500,                 loss: -0.0803
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 1430.8,                last time consumption/overall running time: 193.0973s / 45209.7602 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.0750
env0_second_0:                 episode reward: 0.6000,                 loss: -0.0929
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 1487.6,                last time consumption/overall running time: 199.2159s / 45408.9762 s
env0_first_0:                 episode reward: 1.0000,                 loss: -0.0822
env0_second_0:                 episode reward: -1.0000,                 loss: -0.0946
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 1382.8,                last time consumption/overall running time: 185.0910s / 45594.0672 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0837
env0_second_0:                 episode reward: 0.2000,                 loss: -0.0865
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 1519.2,                last time consumption/overall running time: 204.6580s / 45798.7252 s
env0_first_0:                 episode reward: 1.1000,                 loss: -0.0950
env0_second_0:                 episode reward: -1.1000,                 loss: -0.0736
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 1427.2,                last time consumption/overall running time: 195.0015s / 45993.7267 s
env0_first_0:                 episode reward: 1.0000,                 loss: -0.0716
env0_second_0:                 episode reward: -1.0000,                 loss: -0.0855
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 1393.15,                last time consumption/overall running time: 187.3442s / 46181.0709 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.0666
env0_second_0:                 episode reward: -0.3000,                 loss: -0.0784
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 1321.1,                last time consumption/overall running time: 184.0554s / 46365.1263 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.0809
env0_second_0:                 episode reward: -0.5500,                 loss: -0.0803
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 1451.15,                last time consumption/overall running time: 196.6009s / 46561.7272 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0655
env0_second_0:                 episode reward: 0.2000,                 loss: -0.0847
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 1468.35,                last time consumption/overall running time: 199.5009s / 46761.2282 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.0747
env0_second_0:                 episode reward: 0.7000,                 loss: -0.0822
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 1551.25,                last time consumption/overall running time: 206.5530s / 46967.7811 s
env0_first_0:                 episode reward: -0.8500,                 loss: -0.0728
env0_second_0:                 episode reward: 0.8500,                 loss: -0.0812
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 1487.1,                last time consumption/overall running time: 200.4280s / 47168.2092 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.0727
env0_second_0:                 episode reward: 0.4000,                 loss: -0.0741
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 1460.75,                last time consumption/overall running time: 200.2505s / 47368.4597 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.0748
env0_second_0:                 episode reward: -0.1500,                 loss: -0.0680
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 1442.95,                last time consumption/overall running time: 197.2674s / 47565.7271 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.0932
env0_second_0:                 episode reward: 0.6000,                 loss: -0.0712
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 1491.7,                last time consumption/overall running time: 205.8139s / 47771.5410 s
env0_first_0:                 episode reward: -1.1000,                 loss: -0.0907
env0_second_0:                 episode reward: 1.1000,                 loss: -0.0716
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 1407.1,                last time consumption/overall running time: 190.9863s / 47962.5273 s
env0_first_0:                 episode reward: -1.7000,                 loss: -0.0789
env0_second_0:                 episode reward: 1.7000,                 loss: -0.0670
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 1468.3,                last time consumption/overall running time: 203.6641s / 48166.1914 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.1028
env0_second_0:                 episode reward: -0.4500,                 loss: -0.0963
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 1442.1,                last time consumption/overall running time: 193.7564s / 48359.9478 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.0501
env0_second_0:                 episode reward: -0.7500,                 loss: -0.0509
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 1462.7,                last time consumption/overall running time: 194.9488s / 48554.8966 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0850
env0_second_0:                 episode reward: -0.2000,                 loss: -0.0811
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 1467.75,                last time consumption/overall running time: 202.0523s / 48756.9489 s
env0_first_0:                 episode reward: -0.6500,                 loss: -0.1023
env0_second_0:                 episode reward: 0.6500,                 loss: -0.0926
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 1449.25,                last time consumption/overall running time: 192.0837s / 48949.0326 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.0965
env0_second_0:                 episode reward: -0.7500,                 loss: -0.0975
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 1393.05,                last time consumption/overall running time: 190.3076s / 49139.3402 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0924
env0_second_0:                 episode reward: 0.0000,                 loss: -0.0858
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 1415.35,                last time consumption/overall running time: 191.3676s / 49330.7078 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.0919
env0_second_0:                 episode reward: 0.5000,                 loss: -0.0992
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 1506.8,                last time consumption/overall running time: 202.8214s / 49533.5292 s
env0_first_0:                 episode reward: 1.0000,                 loss: -0.0985
env0_second_0:                 episode reward: -1.0000,                 loss: -0.0862
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 1435.25,                last time consumption/overall running time: 194.8246s / 49728.3537 s
env0_first_0:                 episode reward: -0.8000,                 loss: -0.0812
env0_second_0:                 episode reward: 0.8000,                 loss: -0.0764
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 1430.5,                last time consumption/overall running time: 192.4495s / 49920.8032 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0711
env0_second_0:                 episode reward: -0.0500,                 loss: -0.0778
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 1429.65,                last time consumption/overall running time: 195.7481s / 50116.5513 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.0859
env0_second_0:                 episode reward: -0.6500,                 loss: -0.0857
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 1435.95,                last time consumption/overall running time: 191.2105s / 50307.7618 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.0846
env0_second_0:                 episode reward: 0.7000,                 loss: -0.0841
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 1407.95,                last time consumption/overall running time: 191.7063s / 50499.4681 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.0875
env0_second_0:                 episode reward: -0.4000,                 loss: -0.0791
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 1377.2,                last time consumption/overall running time: 184.0295s / 50683.4976 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.0676
env0_second_0:                 episode reward: 0.7500,                 loss: -0.0685
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 1401.15,                last time consumption/overall running time: 187.5755s / 50871.0731 s
env0_first_0:                 episode reward: -1.4000,                 loss: -0.0811
env0_second_0:                 episode reward: 1.4000,                 loss: -0.0608
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 1394.3,                last time consumption/overall running time: 190.3378s / 51061.4109 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.0817
env0_second_0:                 episode reward: 0.4000,                 loss: -0.0569
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 1418.95,                last time consumption/overall running time: 192.3177s / 51253.7286 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.0879
env0_second_0:                 episode reward: -0.9500,                 loss: -0.0701
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 1511.35,                last time consumption/overall running time: 205.5860s / 51459.3146 s
env0_first_0:                 episode reward: -1.3000,                 loss: -0.0820
env0_second_0:                 episode reward: 1.3000,                 loss: -0.0710
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 1430.8,                last time consumption/overall running time: 197.2777s / 51656.5923 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.0655
env0_second_0:                 episode reward: 0.1500,                 loss: -0.0700
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 1472.6,                last time consumption/overall running time: 195.8630s / 51852.4554 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.1031
env0_second_0:                 episode reward: -0.1500,                 loss: -0.0978
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 1423.3,                last time consumption/overall running time: 193.1339s / 52045.5893 s
env0_first_0:                 episode reward: -1.5000,                 loss: -0.1038
env0_second_0:                 episode reward: 1.5000,                 loss: -0.0977
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 1376.45,                last time consumption/overall running time: 186.4059s / 52231.9953 s
env0_first_0:                 episode reward: -1.7500,                 loss: -0.0958
env0_second_0:                 episode reward: 1.7500,                 loss: -0.0849
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 1455.25,                last time consumption/overall running time: 200.1842s / 52432.1795 s
env0_first_0:                 episode reward: -1.8500,                 loss: -0.0671
env0_second_0:                 episode reward: 1.8500,                 loss: -0.0641
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 1447.5,                last time consumption/overall running time: 197.5852s / 52629.7647 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.0826
env0_second_0:                 episode reward: 0.2500,                 loss: -0.0957
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 1427.15,                last time consumption/overall running time: 196.9601s / 52826.7248 s
env0_first_0:                 episode reward: -1.1000,                 loss: -0.0869
env0_second_0:                 episode reward: 1.1000,                 loss: -0.1038
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 1443.75,                last time consumption/overall running time: 195.7852s / 53022.5100 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0994
env0_second_0:                 episode reward: 0.0000,                 loss: -0.0981
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 1411.95,                last time consumption/overall running time: 189.5669s / 53212.0769 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.0713
env0_second_0:                 episode reward: 0.4000,                 loss: -0.0936
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 1419.0,                last time consumption/overall running time: 193.9967s / 53406.0736 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.0782
env0_second_0:                 episode reward: -0.1500,                 loss: -0.0808
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 1447.9,                last time consumption/overall running time: 192.7964s / 53598.8700 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.0827
env0_second_0:                 episode reward: -0.9500,                 loss: -0.0935
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 1472.35,                last time consumption/overall running time: 198.1134s / 53796.9834 s
env0_first_0:                 episode reward: -1.2500,                 loss: -0.0780
env0_second_0:                 episode reward: 1.2500,                 loss: -0.0929
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 1472.85,                last time consumption/overall running time: 197.8146s / 53994.7981 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.0782
env0_second_0:                 episode reward: 0.7500,                 loss: -0.0872
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 1419.5,                last time consumption/overall running time: 190.5292s / 54185.3273 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.0693
env0_second_0:                 episode reward: -0.2500,                 loss: -0.0855
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 1508.9,                last time consumption/overall running time: 202.7671s / 54388.0944 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.0686
env0_second_0:                 episode reward: -0.7000,                 loss: -0.0880
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 1497.2,                last time consumption/overall running time: 199.7758s / 54587.8702 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.0740
env0_second_0:                 episode reward: 0.5500,                 loss: -0.0965
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 1448.75,                last time consumption/overall running time: 194.3139s / 54782.1841 s
env0_first_0:                 episode reward: -0.8500,                 loss: -0.0858
env0_second_0:                 episode reward: 0.8500,                 loss: -0.0898
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 1487.05,                last time consumption/overall running time: 199.0484s / 54981.2325 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0743
env0_second_0:                 episode reward: -0.2000,                 loss: -0.0900
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 1477.25,                last time consumption/overall running time: 197.8114s / 55179.0439 s
env0_first_0:                 episode reward: -1.2000,                 loss: -0.0805
env0_second_0:                 episode reward: 1.2000,                 loss: -0.0942
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 1372.35,                last time consumption/overall running time: 190.2024s / 55369.2463 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.0790
env0_second_0:                 episode reward: 0.7000,                 loss: -0.0899
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 1391.65,                last time consumption/overall running time: 185.0398s / 55554.2861 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.0957
env0_second_0:                 episode reward: -0.1500,                 loss: -0.0980
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 1421.75,                last time consumption/overall running time: 191.7764s / 55746.0625 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.0876
env0_second_0:                 episode reward: 0.6000,                 loss: -0.0765
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 1446.8,                last time consumption/overall running time: 194.2489s / 55940.3114 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.0876
env0_second_0:                 episode reward: 0.3000,                 loss: -0.0843
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 1421.75,                last time consumption/overall running time: 191.3229s / 56131.6343 s
env0_first_0:                 episode reward: -0.6500,                 loss: -0.0901
env0_second_0:                 episode reward: 0.6500,                 loss: -0.0768
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 1429.8,                last time consumption/overall running time: 194.8931s / 56326.5274 s
env0_first_0:                 episode reward: -0.8500,                 loss: -0.0899
env0_second_0:                 episode reward: 0.8500,                 loss: -0.0870
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 1442.4,                last time consumption/overall running time: 191.2873s / 56517.8147 s
env0_first_0:                 episode reward: 1.9000,                 loss: -0.0777
env0_second_0:                 episode reward: -1.9000,                 loss: -0.0907
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 1398.7,                last time consumption/overall running time: 187.4637s / 56705.2784 s
env0_first_0:                 episode reward: -0.6500,                 loss: -0.0744
env0_second_0:                 episode reward: 0.6500,                 loss: -0.0776
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 1390.9,                last time consumption/overall running time: 187.1745s / 56892.4529 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0710
env0_second_0:                 episode reward: -0.1000,                 loss: -0.0871
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 1496.3,                last time consumption/overall running time: 201.2703s / 57093.7232 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.0668
env0_second_0:                 episode reward: 0.6000,                 loss: -0.0751
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 1425.9,                last time consumption/overall running time: 189.4556s / 57283.1788 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.0791
env0_second_0:                 episode reward: 0.6000,                 loss: -0.0902
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 1400.05,                last time consumption/overall running time: 191.5570s / 57474.7358 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.0611
env0_second_0:                 episode reward: 0.0500,                 loss: -0.0797
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 1448.45,                last time consumption/overall running time: 196.5475s / 57671.2833 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.0645
env0_second_0:                 episode reward: -0.4000,                 loss: -0.0888
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 1450.85,                last time consumption/overall running time: 196.5547s / 57867.8380 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0814
env0_second_0:                 episode reward: 0.0000,                 loss: -0.0728
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 1339.35,                last time consumption/overall running time: 179.2102s / 58047.0482 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.0775
env0_second_0:                 episode reward: -0.9500,                 loss: -0.0766
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 1473.2,                last time consumption/overall running time: 199.2394s / 58246.2876 s
env0_first_0:                 episode reward: 1.6500,                 loss: -0.0856
env0_second_0:                 episode reward: -1.6500,                 loss: -0.0977
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 1404.05,                last time consumption/overall running time: 188.2371s / 58434.5247 s
env0_first_0:                 episode reward: -0.9500,                 loss: -0.0779
env0_second_0:                 episode reward: 0.9500,                 loss: -0.0864
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 1430.25,                last time consumption/overall running time: 194.1312s / 58628.6559 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.0887
env0_second_0:                 episode reward: 0.4000,                 loss: -0.0890
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 1449.15,                last time consumption/overall running time: 193.9545s / 58822.6104 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.0702
env0_second_0:                 episode reward: 0.1000,                 loss: -0.0886
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 1373.7,                last time consumption/overall running time: 185.6453s / 59008.2557 s
env0_first_0:                 episode reward: -1.1500,                 loss: -0.0736
env0_second_0:                 episode reward: 1.1500,                 loss: -0.0800
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 1449.1,                last time consumption/overall running time: 198.5932s / 59206.8489 s
env0_first_0:                 episode reward: -1.5500,                 loss: -0.0846
env0_second_0:                 episode reward: 1.5500,                 loss: -0.0937
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 1507.4,                last time consumption/overall running time: 202.8124s / 59409.6613 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.0824
env0_second_0:                 episode reward: -0.3500,                 loss: -0.0805
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 1438.15,                last time consumption/overall running time: 193.0703s / 59602.7315 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.0725
env0_second_0:                 episode reward: -0.9500,                 loss: -0.0865
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 1463.0,                last time consumption/overall running time: 199.5440s / 59802.2755 s
env0_first_0:                 episode reward: -1.2000,                 loss: -0.0926
env0_second_0:                 episode reward: 1.2000,                 loss: -0.0974
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 1535.5,                last time consumption/overall running time: 205.5266s / 60007.8022 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.0892
env0_second_0:                 episode reward: 0.7500,                 loss: -0.0879
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 1355.3,                last time consumption/overall running time: 184.5166s / 60192.3188 s
env0_first_0:                 episode reward: -1.1500,                 loss: -0.1006
env0_second_0:                 episode reward: 1.1500,                 loss: -0.0855
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 1467.15,                last time consumption/overall running time: 195.6111s / 60387.9299 s
env0_first_0:                 episode reward: 1.4500,                 loss: -0.0900
env0_second_0:                 episode reward: -1.4500,                 loss: -0.0743
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 1390.2,                last time consumption/overall running time: 185.6537s / 60573.5835 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.0845
env0_second_0:                 episode reward: 0.7000,                 loss: -0.0895
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 1451.6,                last time consumption/overall running time: 195.5013s / 60769.0848 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.0704
env0_second_0:                 episode reward: -0.3000,                 loss: -0.0825
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 1380.3,                last time consumption/overall running time: 186.6565s / 60955.7413 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0721
env0_second_0:                 episode reward: -0.2000,                 loss: -0.1005
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 1416.6,                last time consumption/overall running time: 191.5766s / 61147.3179 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0983
env0_second_0:                 episode reward: 0.2000,                 loss: -0.0991
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 1484.85,                last time consumption/overall running time: 192.5768s / 61339.8947 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.0850
env0_second_0:                 episode reward: -1.1500,                 loss: -0.0883
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 1470.15,                last time consumption/overall running time: 194.7294s / 61534.6241 s
env0_first_0:                 episode reward: 1.2000,                 loss: -0.0639
env0_second_0:                 episode reward: -1.2000,                 loss: -0.0959
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 1489.65,                last time consumption/overall running time: 200.3638s / 61734.9879 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.0824
env0_second_0:                 episode reward: 0.5500,                 loss: -0.1045
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 1414.35,                last time consumption/overall running time: 191.0485s / 61926.0365 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.0665
env0_second_0:                 episode reward: -0.2500,                 loss: -0.0870
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 1507.15,                last time consumption/overall running time: 200.3071s / 62126.3436 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0808
env0_second_0:                 episode reward: 0.0000,                 loss: -0.1009
env1_first_0:                 episode reward: -0.1500,                 loss: nan