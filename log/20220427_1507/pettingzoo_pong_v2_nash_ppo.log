pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [776, 547, 298, 777, 421]
<SubprocVectorEnv instance>
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'feature': {'hidden_dim_list': [128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'policy': {'hidden_dim_list': [128, 128], 'hidden_activation': False, 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220427_1507/pettingzoo_pong_v2_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220427_1507/pettingzoo_pong_v2_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 5.6033s / 5.6033 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.6015
env0_second_0:                 episode reward: -2.0000,                 loss: nan
env1_first_0:                 episode reward: 7.0000,                 loss: nan
env1_second_0:                 episode reward: -7.0000,                 loss: nan
env2_first_0:                 episode reward: -7.0000,                 loss: nan
env2_second_0:                 episode reward: 7.0000,                 loss: nan
env3_first_0:                 episode reward: 3.0000,                 loss: nan
env3_second_0:                 episode reward: -3.0000,                 loss: nan
env4_first_0:                 episode reward: -5.0000,                 loss: nan
env4_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 59.2951s / 64.8984 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.5583
env0_second_0:                 episode reward: -2.2000,                 loss: nan
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
env2_first_0:                 episode reward: 3.2500,                 loss: nan
env2_second_0:                 episode reward: -3.2500,                 loss: nan
env3_first_0:                 episode reward: 3.3500,                 loss: nan
env3_second_0:                 episode reward: -3.3500,                 loss: nan
env4_first_0:                 episode reward: 4.3000,                 loss: nan
env4_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 74.7448s / 139.6432 s
env0_first_0:                 episode reward: 2.4000,                 loss: 1.3573
env0_second_0:                 episode reward: -2.4000,                 loss: nan
env1_first_0:                 episode reward: 4.1500,                 loss: nan
env1_second_0:                 episode reward: -4.1500,                 loss: nan
env2_first_0:                 episode reward: 4.1000,                 loss: nan
env2_second_0:                 episode reward: -4.1000,                 loss: nan
env3_first_0:                 episode reward: 3.0000,                 loss: nan
env3_second_0:                 episode reward: -3.0000,                 loss: nan
env4_first_0:                 episode reward: 1.8000,                 loss: nan
env4_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5644s / 216.2076 s
env0_first_0:                 episode reward: 2.3500,                 loss: 1.2936
env0_second_0:                 episode reward: -2.3500,                 loss: nan
env1_first_0:                 episode reward: 4.2500,                 loss: nan
env1_second_0:                 episode reward: -4.2500,                 loss: nan
env2_first_0:                 episode reward: 3.6500,                 loss: nan
env2_second_0:                 episode reward: -3.6500,                 loss: nan
env3_first_0:                 episode reward: 3.5000,                 loss: nan
env3_second_0:                 episode reward: -3.5000,                 loss: nan
env4_first_0:                 episode reward: 4.9000,                 loss: nan
env4_second_0:                 episode reward: -4.9000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.2727s / 291.4802 s
env0_first_0:                 episode reward: 0.9500,                 loss: 1.6335
env0_second_0:                 episode reward: -0.9500,                 loss: nan
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
env2_first_0:                 episode reward: 2.6000,                 loss: nan
env2_second_0:                 episode reward: -2.6000,                 loss: nan
env3_first_0:                 episode reward: 3.2500,                 loss: nan
env3_second_0:                 episode reward: -3.2500,                 loss: nan
env4_first_0:                 episode reward: 4.2000,                 loss: nan
env4_second_0:                 episode reward: -4.2000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 73.9426s / 365.4229 s
env0_first_0:                 episode reward: 3.9000,                 loss: 1.2858
env0_second_0:                 episode reward: -3.9000,                 loss: nan
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
env2_first_0:                 episode reward: 3.4000,                 loss: nan
env2_second_0:                 episode reward: -3.4000,                 loss: nan
env3_first_0:                 episode reward: 1.9500,                 loss: nan
env3_second_0:                 episode reward: -1.9500,                 loss: nan
env4_first_0:                 episode reward: 3.4000,                 loss: nan
env4_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 74.6167s / 440.0395 s
env0_first_0:                 episode reward: 2.7000,                 loss: 1.3806
env0_second_0:                 episode reward: -2.7000,                 loss: nan
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
env2_first_0:                 episode reward: 3.6000,                 loss: nan
env2_second_0:                 episode reward: -3.6000,                 loss: nan
env3_first_0:                 episode reward: 2.4000,                 loss: nan
env3_second_0:                 episode reward: -2.4000,                 loss: nan
env4_first_0:                 episode reward: 3.1000,                 loss: nan
env4_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 72.8905s / 512.9301 s
env0_first_0:                 episode reward: 2.1000,                 loss: 1.4480
env0_second_0:                 episode reward: -2.1000,                 loss: nan
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
env2_first_0:                 episode reward: 2.6500,                 loss: nan
env2_second_0:                 episode reward: -2.6500,                 loss: nan
env3_first_0:                 episode reward: 3.3000,                 loss: nan
env3_second_0:                 episode reward: -3.3000,                 loss: nan
env4_first_0:                 episode reward: 2.7000,                 loss: nan
env4_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 72.4678s / 585.3978 s
env0_first_0:                 episode reward: 1.9000,                 loss: 1.2276
env0_second_0:                 episode reward: -1.9000,                 loss: nan
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 3.4000,                 loss: nan
env2_second_0:                 episode reward: -3.4000,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 2.2000,                 loss: nan
env4_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 73.8344s / 659.2322 s
env0_first_0:                 episode reward: 1.6000,                 loss: 1.5157
env0_second_0:                 episode reward: -1.6000,                 loss: nan
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
env2_first_0:                 episode reward: 2.4500,                 loss: nan
env2_second_0:                 episode reward: -2.4500,                 loss: nan
env3_first_0:                 episode reward: 2.9500,                 loss: nan
env3_second_0:                 episode reward: -2.9500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.7291s / 736.9613 s
env0_first_0:                 episode reward: -1.8500,                 loss: 1.4278
env0_second_0:                 episode reward: 1.8500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: -0.7500,                 loss: nan
env3_second_0:                 episode reward: 0.7500,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.7670s / 815.7283 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.8933
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
env2_first_0:                 episode reward: -2.2500,                 loss: nan
env2_second_0:                 episode reward: 2.2500,                 loss: nan
env3_first_0:                 episode reward: -2.0500,                 loss: nan
env3_second_0:                 episode reward: 2.0500,                 loss: nan
env4_first_0:                 episode reward: -2.6000,                 loss: nan
env4_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.0908s / 893.8191 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.9053
env0_second_0:                 episode reward: 3.6000,                 loss: nan
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -1.8000,                 loss: nan
env2_second_0:                 episode reward: 1.8000,                 loss: nan
env3_first_0:                 episode reward: -1.8500,                 loss: nan
env3_second_0:                 episode reward: 1.8500,                 loss: nan
env4_first_0:                 episode reward: -2.9500,                 loss: nan
env4_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6936s / 971.5128 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.7293
env0_second_0:                 episode reward: 2.7000,                 loss: nan
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
env2_first_0:                 episode reward: -2.7500,                 loss: nan
env2_second_0:                 episode reward: 2.7500,                 loss: nan
env3_first_0:                 episode reward: -2.8500,                 loss: nan
env3_second_0:                 episode reward: 2.8500,                 loss: nan
env4_first_0:                 episode reward: -2.7000,                 loss: nan
env4_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.0388s / 1047.5516 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.4935
env0_second_0:                 episode reward: 3.6500,                 loss: nan
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
env2_first_0:                 episode reward: -3.7500,                 loss: nan
env2_second_0:                 episode reward: 3.7500,                 loss: nan
env3_first_0:                 episode reward: -4.5000,                 loss: nan
env3_second_0:                 episode reward: 4.5000,                 loss: nan
env4_first_0:                 episode reward: -3.9500,                 loss: nan
env4_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.6647s / 1123.2163 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.7245
env0_second_0:                 episode reward: 3.0500,                 loss: nan
env1_first_0:                 episode reward: -4.6500,                 loss: nan
env1_second_0:                 episode reward: 4.6500,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
env3_first_0:                 episode reward: -3.0000,                 loss: nan
env3_second_0:                 episode reward: 3.0000,                 loss: nan
env4_first_0:                 episode reward: -3.5000,                 loss: nan
env4_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1472s / 1200.3634 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.7200
env0_second_0:                 episode reward: 1.8500,                 loss: nan
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
env2_first_0:                 episode reward: -2.9500,                 loss: nan
env2_second_0:                 episode reward: 2.9500,                 loss: nan
env3_first_0:                 episode reward: -2.7500,                 loss: nan
env3_second_0:                 episode reward: 2.7500,                 loss: nan
env4_first_0:                 episode reward: -3.3500,                 loss: nan
env4_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.2450s / 1277.6085 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.7444
env0_second_0:                 episode reward: 2.4500,                 loss: nan
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
env2_first_0:                 episode reward: -4.2000,                 loss: nan
env2_second_0:                 episode reward: 4.2000,                 loss: nan
env3_first_0:                 episode reward: -3.9000,                 loss: nan
env3_second_0:                 episode reward: 3.9000,                 loss: nan
env4_first_0:                 episode reward: -1.7500,                 loss: nan
env4_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.9786s / 1353.5871 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.7910
env0_second_0:                 episode reward: 2.3500,                 loss: nan
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
env2_first_0:                 episode reward: -2.2500,                 loss: nan
env2_second_0:                 episode reward: 2.2500,                 loss: nan
env3_first_0:                 episode reward: -2.4000,                 loss: nan
env3_second_0:                 episode reward: 2.4000,                 loss: nan
env4_first_0:                 episode reward: -2.2500,                 loss: nan
env4_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.7204s / 1430.3074 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.9256
env0_second_0:                 episode reward: 1.4000,                 loss: nan
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -2.2000,                 loss: nan
env2_second_0:                 episode reward: 2.2000,                 loss: nan
env3_first_0:                 episode reward: -2.2500,                 loss: nan
env3_second_0:                 episode reward: 2.2500,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.7140s / 1508.0214 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.8439
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.8000,                 loss: nan
env2_second_0:                 episode reward: 0.8000,                 loss: nan
env3_first_0:                 episode reward: -0.7000,                 loss: nan
env3_second_0:                 episode reward: 0.7000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8749s / 1585.8963 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.7121
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: -1.1000,                 loss: nan
env4_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.0106s / 1662.9069 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.7626
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.2538s / 1738.1607 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.7109
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.9437s / 1814.1044 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.6014
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.2135s / 1890.3179 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.5397
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.0848s / 1967.4026 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.6514
env0_second_0:                 episode reward: -0.6500,                 loss: nan
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 1.3000,                 loss: nan
env4_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4185s / 2043.8211 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.6184
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.5500,                 loss: nan
env4_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4406s / 2121.2617 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.8274
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
env3_first_0:                 episode reward: -0.7000,                 loss: nan
env3_second_0:                 episode reward: 0.7000,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4436s / 2198.7053 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.6278
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.7500,                 loss: nan
env3_second_0:                 episode reward: 0.7500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.3411s / 2278.0464 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.6223
env0_second_0:                 episode reward: 1.4000,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -1.0000,                 loss: nan
env4_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.6572s / 2356.7036 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.6490
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.9486s / 2433.6522 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.5158
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.5907s / 2512.2429 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.4934
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.9974s / 2591.2403 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.4757
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.6000,                 loss: nan
env4_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.8364s / 2668.0768 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.4620
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
env3_first_0:                 episode reward: -0.8500,                 loss: nan
env3_second_0:                 episode reward: 0.8500,                 loss: nan
env4_first_0:                 episode reward: -1.0000,                 loss: nan
env4_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.0241s / 2746.1009 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.5976
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: -1.2000,                 loss: nan
env4_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.7171s / 2823.8179 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.5346
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.8500,                 loss: nan
env3_second_0:                 episode reward: -0.8500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.1595s / 2902.9775 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.5832
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: -1.0500,                 loss: nan
env3_second_0:                 episode reward: 1.0500,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.6319s / 2981.6093 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.7132
env0_second_0:                 episode reward: 1.2000,                 loss: nan
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
env3_first_0:                 episode reward: -1.0000,                 loss: nan
env3_second_0:                 episode reward: 1.0000,                 loss: nan
env4_first_0:                 episode reward: -0.5000,                 loss: nan
env4_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.8975s / 3060.5068 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.4738
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.8355s / 3139.3423 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.5450
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.7000,                 loss: nan
env3_second_0:                 episode reward: 0.7000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.3675s / 3217.7098 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.5661
env0_second_0:                 episode reward: 1.8500,                 loss: nan
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
env2_first_0:                 episode reward: -1.3500,                 loss: nan
env2_second_0:                 episode reward: 1.3500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -1.2000,                 loss: nan
env4_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4302s / 3294.1400 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.6471
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.9096s / 3371.0496 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.4866
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -1.4500,                 loss: nan
env3_second_0:                 episode reward: 1.4500,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5086s / 3447.5582 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.5857
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.8500,                 loss: nan
env4_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.0227s / 3524.5808 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.4474
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.6000,                 loss: nan
env4_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.5349s / 3602.1158 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.4652
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.5770s / 3679.6928 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.5683
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.9607s / 3755.6535 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.5664
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -1.3500,                 loss: nan
env4_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.2633s / 3830.9169 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.5762
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
env2_first_0:                 episode reward: -1.3500,                 loss: nan
env2_second_0:                 episode reward: 1.3500,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: -1.6500,                 loss: nan
env4_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.3281s / 3907.2450 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.5334
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.8000,                 loss: nan
env3_second_0:                 episode reward: 0.8000,                 loss: nan
env4_first_0:                 episode reward: -0.6500,                 loss: nan
env4_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.1881s / 3983.4331 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.5417
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
env2_first_0:                 episode reward: -2.0500,                 loss: nan
env2_second_0:                 episode reward: 2.0500,                 loss: nan
env3_first_0:                 episode reward: -0.7000,                 loss: nan
env3_second_0:                 episode reward: 0.7000,                 loss: nan
env4_first_0:                 episode reward: -1.2500,                 loss: nan
env4_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.7969s / 4059.2299 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.4747
env0_second_0:                 episode reward: 1.0000,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
env3_first_0:                 episode reward: -0.7000,                 loss: nan
env3_second_0:                 episode reward: 0.7000,                 loss: nan
env4_first_0:                 episode reward: -0.6000,                 loss: nan
env4_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.5220s / 4134.7520 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.5615
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.8000,                 loss: nan
env4_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6265s / 4212.3785 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.6743
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: -1.6500,                 loss: nan
env3_second_0:                 episode reward: 1.6500,                 loss: nan
env4_first_0:                 episode reward: -2.5000,                 loss: nan
env4_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.3545s / 4287.7330 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.6810
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -1.2500,                 loss: nan
env3_second_0:                 episode reward: 1.2500,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.8824s / 4364.6154 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.9021
env0_second_0:                 episode reward: -0.9500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -1.4000,                 loss: nan
env3_second_0:                 episode reward: 1.4000,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.2748s / 4439.8902 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.7203
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: -1.3000,                 loss: nan
env4_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.1891s / 4516.0792 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.9018
env0_second_0:                 episode reward: 1.1000,                 loss: nan
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
env2_first_0:                 episode reward: -1.7500,                 loss: nan
env2_second_0:                 episode reward: 1.7500,                 loss: nan
env3_first_0:                 episode reward: -1.0000,                 loss: nan
env3_second_0:                 episode reward: 1.0000,                 loss: nan
env4_first_0:                 episode reward: -1.5500,                 loss: nan
env4_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.8199s / 4592.8992 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.9283
env0_second_0:                 episode reward: 2.6500,                 loss: nan
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
env2_first_0:                 episode reward: -2.6000,                 loss: nan
env2_second_0:                 episode reward: 2.6000,                 loss: nan
env3_first_0:                 episode reward: -1.6500,                 loss: nan
env3_second_0:                 episode reward: 1.6500,                 loss: nan
env4_first_0:                 episode reward: -1.9000,                 loss: nan
env4_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.5788s / 4670.4780 s
env0_first_0:                 episode reward: -0.9000,                 loss: 1.0464
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.5500,                 loss: nan
env3_second_0:                 episode reward: -0.5500,                 loss: nan
env4_first_0:                 episode reward: 0.7500,                 loss: nan
env4_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.7842s / 4747.2622 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.9790
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.8000,                 loss: nan
env4_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.0262s / 4822.2884 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.7991
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 1.4500,                 loss: nan
env2_second_0:                 episode reward: -1.4500,                 loss: nan
env3_first_0:                 episode reward: 0.6000,                 loss: nan
env3_second_0:                 episode reward: -0.6000,                 loss: nan
env4_first_0:                 episode reward: 0.7500,                 loss: nan
env4_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.8017s / 4899.0901 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.8463
env0_second_0:                 episode reward: -1.6500,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: 1.1000,                 loss: nan
env3_second_0:                 episode reward: -1.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.3364s / 4975.4265 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.7914
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
env3_first_0:                 episode reward: 1.3000,                 loss: nan
env3_second_0:                 episode reward: -1.3000,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.2218s / 5051.6483 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.7869
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 1.1000,                 loss: nan
env3_second_0:                 episode reward: -1.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4896s / 5128.1379 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.5905
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 1.1500,                 loss: nan
env3_second_0:                 episode reward: -1.1500,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.3269s / 5204.4648 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.9019
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.7845s / 5280.2493 s
env0_first_0:                 episode reward: 2.9500,                 loss: 1.1357
env0_second_0:                 episode reward: -2.9500,                 loss: nan
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
env2_first_0:                 episode reward: 3.6500,                 loss: nan
env2_second_0:                 episode reward: -3.6500,                 loss: nan
env3_first_0:                 episode reward: 2.5500,                 loss: nan
env3_second_0:                 episode reward: -2.5500,                 loss: nan
env4_first_0:                 episode reward: 3.4000,                 loss: nan
env4_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6718s / 5357.9211 s
env0_first_0:                 episode reward: 2.2000,                 loss: 1.3589
env0_second_0:                 episode reward: -2.2000,                 loss: nan
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
env2_first_0:                 episode reward: 2.3000,                 loss: nan
env2_second_0:                 episode reward: -2.3000,                 loss: nan
env3_first_0:                 episode reward: 3.5500,                 loss: nan
env3_second_0:                 episode reward: -3.5500,                 loss: nan
env4_first_0:                 episode reward: 2.8000,                 loss: nan
env4_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.6386s / 5434.5597 s
env0_first_0:                 episode reward: -2.9000,                 loss: 1.6017
env0_second_0:                 episode reward: 2.9000,                 loss: nan
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -2.1000,                 loss: nan
env2_second_0:                 episode reward: 2.1000,                 loss: nan
env3_first_0:                 episode reward: -2.1500,                 loss: nan
env3_second_0:                 episode reward: 2.1500,                 loss: nan
env4_first_0:                 episode reward: -3.5500,                 loss: nan
env4_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.2729s / 5510.8326 s
env0_first_0:                 episode reward: -3.1000,                 loss: 1.1757
env0_second_0:                 episode reward: 3.1000,                 loss: nan
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
env2_first_0:                 episode reward: -3.6000,                 loss: nan
env2_second_0:                 episode reward: 3.6000,                 loss: nan
env3_first_0:                 episode reward: -3.5500,                 loss: nan
env3_second_0:                 episode reward: 3.5500,                 loss: nan
env4_first_0:                 episode reward: -2.0500,                 loss: nan
env4_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.2127s / 5587.0454 s
env0_first_0:                 episode reward: 5.1000,                 loss: 1.3126
env0_second_0:                 episode reward: -5.1000,                 loss: nan
env1_first_0:                 episode reward: 5.3000,                 loss: nan
env1_second_0:                 episode reward: -5.3000,                 loss: nan
env2_first_0:                 episode reward: 5.6500,                 loss: nan
env2_second_0:                 episode reward: -5.6500,                 loss: nan
env3_first_0:                 episode reward: 6.0000,                 loss: nan
env3_second_0:                 episode reward: -6.0000,                 loss: nan
env4_first_0:                 episode reward: 5.7000,                 loss: nan
env4_second_0:                 episode reward: -5.7000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1934s / 5664.2387 s
env0_first_0:                 episode reward: 8.0000,                 loss: 0.4428
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 7.2000,                 loss: nan
env1_second_0:                 episode reward: -7.2000,                 loss: nan
env2_first_0:                 episode reward: 7.1000,                 loss: nan
env2_second_0:                 episode reward: -7.1000,                 loss: nan
env3_first_0:                 episode reward: 7.4500,                 loss: nan
env3_second_0:                 episode reward: -7.4500,                 loss: nan
env4_first_0:                 episode reward: 7.0500,                 loss: nan
env4_second_0:                 episode reward: -7.0500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.9678s / 5742.2065 s
env0_first_0:                 episode reward: 7.7500,                 loss: 0.0074
env0_second_0:                 episode reward: -7.7500,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 7.6500,                 loss: nan
env2_second_0:                 episode reward: -7.6500,                 loss: nan
env3_first_0:                 episode reward: 7.3000,                 loss: nan
env3_second_0:                 episode reward: -7.3000,                 loss: nan
env4_first_0:                 episode reward: 7.7500,                 loss: nan
env4_second_0:                 episode reward: -7.7500,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.0924s / 5818.2989 s
env0_first_0:                 episode reward: 4.0000,                 loss: 1.1829
env0_second_0:                 episode reward: -4.0000,                 loss: nan
env1_first_0:                 episode reward: 4.3500,                 loss: nan
env1_second_0:                 episode reward: -4.3500,                 loss: nan
env2_first_0:                 episode reward: 2.4500,                 loss: nan
env2_second_0:                 episode reward: -2.4500,                 loss: nan
env3_first_0:                 episode reward: 4.9000,                 loss: nan
env3_second_0:                 episode reward: -4.9000,                 loss: nan
env4_first_0:                 episode reward: 4.3000,                 loss: nan
env4_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.1874s / 5894.4863 s
env0_first_0:                 episode reward: 1.3000,                 loss: 1.3779
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 1.6500,                 loss: nan
env4_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.7296s / 5970.2160 s
env0_first_0:                 episode reward: -1.0500,                 loss: 1.0324
env0_second_0:                 episode reward: 1.0500,                 loss: nan
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.8000,                 loss: nan
env3_second_0:                 episode reward: -0.8000,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.9671s / 6047.1831 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.8279
env0_second_0:                 episode reward: -1.3500,                 loss: nan
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: 1.4500,                 loss: nan
env2_second_0:                 episode reward: -1.4500,                 loss: nan
env3_first_0:                 episode reward: 0.8000,                 loss: nan
env3_second_0:                 episode reward: -0.8000,                 loss: nan
env4_first_0:                 episode reward: 0.9500,                 loss: nan
env4_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.9039s / 6123.0870 s
env0_first_0:                 episode reward: 4.5500,                 loss: 0.7704
env0_second_0:                 episode reward: -4.5500,                 loss: nan
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
env2_first_0:                 episode reward: 3.7500,                 loss: nan
env2_second_0:                 episode reward: -3.7500,                 loss: nan
env3_first_0:                 episode reward: 3.4000,                 loss: nan
env3_second_0:                 episode reward: -3.4000,                 loss: nan
env4_first_0:                 episode reward: 3.3500,                 loss: nan
env4_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3254s / 6200.4124 s
env0_first_0:                 episode reward: 5.7500,                 loss: 0.7030
env0_second_0:                 episode reward: -5.7500,                 loss: nan
env1_first_0:                 episode reward: 3.7000,                 loss: nan
env1_second_0:                 episode reward: -3.7000,                 loss: nan
env2_first_0:                 episode reward: 6.0000,                 loss: nan
env2_second_0:                 episode reward: -6.0000,                 loss: nan
env3_first_0:                 episode reward: 4.7500,                 loss: nan
env3_second_0:                 episode reward: -4.7500,                 loss: nan
env4_first_0:                 episode reward: 4.0000,                 loss: nan
env4_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.8320s / 6277.2443 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.8179
env0_second_0:                 episode reward: -2.9500,                 loss: nan
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 3.1500,                 loss: nan
env2_second_0:                 episode reward: -3.1500,                 loss: nan
env3_first_0:                 episode reward: 3.0500,                 loss: nan
env3_second_0:                 episode reward: -3.0500,                 loss: nan
env4_first_0:                 episode reward: 4.1000,                 loss: nan
env4_second_0:                 episode reward: -4.1000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.8938s / 6354.1381 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.9930
env0_second_0:                 episode reward: -2.7500,                 loss: nan
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
env3_first_0:                 episode reward: 1.2000,                 loss: nan
env3_second_0:                 episode reward: -1.2000,                 loss: nan
env4_first_0:                 episode reward: 1.6000,                 loss: nan
env4_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.9538s / 6431.0919 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.9186
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
env2_first_0:                 episode reward: 1.0500,                 loss: nan
env2_second_0:                 episode reward: -1.0500,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 1.6000,                 loss: nan
env4_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3403s / 6508.4322 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.8887
env0_second_0:                 episode reward: -1.6500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 1.2000,                 loss: nan
env3_second_0:                 episode reward: -1.2000,                 loss: nan
env4_first_0:                 episode reward: 1.6000,                 loss: nan
env4_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1486s / 6585.5808 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.6477
env0_second_0:                 episode reward: -0.6000,                 loss: nan
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6872s / 6663.2679 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.7288
env0_second_0:                 episode reward: -0.6500,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.0496s / 6740.3175 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.7389
env0_second_0:                 episode reward: -1.7500,                 loss: nan
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: 1.1000,                 loss: nan
env2_second_0:                 episode reward: -1.1000,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4470s / 6816.7645 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.5866
env0_second_0:                 episode reward: -1.8000,                 loss: nan
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
env3_first_0:                 episode reward: 2.0000,                 loss: nan
env3_second_0:                 episode reward: -2.0000,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.7271s / 6892.4916 s
env0_first_0:                 episode reward: -2.3000,                 loss: 1.0067
env0_second_0:                 episode reward: 2.3000,                 loss: nan
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -1.4000,                 loss: nan
env2_second_0:                 episode reward: 1.4000,                 loss: nan
env3_first_0:                 episode reward: -2.4000,                 loss: nan
env3_second_0:                 episode reward: 2.4000,                 loss: nan
env4_first_0:                 episode reward: -0.9500,                 loss: nan
env4_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1914s / 6969.6830 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.5670
env0_second_0:                 episode reward: -3.0000,                 loss: nan
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
env3_first_0:                 episode reward: 2.5000,                 loss: nan
env3_second_0:                 episode reward: -2.5000,                 loss: nan
env4_first_0:                 episode reward: 0.9000,                 loss: nan
env4_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.9263s / 7046.6094 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.5377
env0_second_0:                 episode reward: -1.6500,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.0000,                 loss: nan
env3_second_0:                 episode reward: -1.0000,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.8845s / 7123.4938 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.4450
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 0.9500,                 loss: nan
env2_second_0:                 episode reward: -0.9500,                 loss: nan
env3_first_0:                 episode reward: 1.1500,                 loss: nan
env3_second_0:                 episode reward: -1.1500,                 loss: nan
env4_first_0:                 episode reward: 1.9000,                 loss: nan
env4_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.0813s / 7200.5751 s
env0_first_0:                 episode reward: 3.1000,                 loss: 0.4980
env0_second_0:                 episode reward: -3.1000,                 loss: nan
env1_first_0:                 episode reward: 4.1500,                 loss: nan
env1_second_0:                 episode reward: -4.1500,                 loss: nan
env2_first_0:                 episode reward: 3.8000,                 loss: nan
env2_second_0:                 episode reward: -3.8000,                 loss: nan
env3_first_0:                 episode reward: 3.8000,                 loss: nan
env3_second_0:                 episode reward: -3.8000,                 loss: nan
env4_first_0:                 episode reward: 2.5500,                 loss: nan
env4_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4807s / 7277.0558 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.4809
env0_second_0:                 episode reward: -0.9000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
env3_first_0:                 episode reward: 0.9500,                 loss: nan
env3_second_0:                 episode reward: -0.9500,                 loss: nan
env4_first_0:                 episode reward: 1.3000,                 loss: nan
env4_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4016s / 7353.4574 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.4192
env0_second_0:                 episode reward: -1.6000,                 loss: nan
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 1.3500,                 loss: nan
env3_second_0:                 episode reward: -1.3500,                 loss: nan
env4_first_0:                 episode reward: 2.1000,                 loss: nan
env4_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3837s / 7430.8410 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.6845
env0_second_0:                 episode reward: -2.1000,                 loss: nan
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
env2_first_0:                 episode reward: 1.3500,                 loss: nan
env2_second_0:                 episode reward: -1.3500,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 2.2500,                 loss: nan
env4_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.7048s / 7507.5459 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.6869
env0_second_0:                 episode reward: -0.9500,                 loss: nan
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
env2_first_0:                 episode reward: 1.2000,                 loss: nan
env2_second_0:                 episode reward: -1.2000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: 1.4000,                 loss: nan
env4_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1866s / 7584.7324 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.7783
env0_second_0:                 episode reward: -0.8500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 1.2000,                 loss: nan
env3_second_0:                 episode reward: -1.2000,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.9131s / 7660.6455 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.5346
env0_second_0:                 episode reward: -0.7500,                 loss: nan
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 1.1500,                 loss: nan
env2_second_0:                 episode reward: -1.1500,                 loss: nan
env3_first_0:                 episode reward: 1.1500,                 loss: nan
env3_second_0:                 episode reward: -1.1500,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.0319s / 7735.6774 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.4085
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 2.3000,                 loss: nan
env2_second_0:                 episode reward: -2.3000,                 loss: nan
env3_first_0:                 episode reward: 1.1000,                 loss: nan
env3_second_0:                 episode reward: -1.1000,                 loss: nan
env4_first_0:                 episode reward: 1.8500,                 loss: nan
env4_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3438s / 7813.0212 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.5600
env0_second_0:                 episode reward: -0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
env2_first_0:                 episode reward: 0.8000,                 loss: nan
env2_second_0:                 episode reward: -0.8000,                 loss: nan
env3_first_0:                 episode reward: 1.1000,                 loss: nan
env3_second_0:                 episode reward: -1.1000,                 loss: nan
env4_first_0:                 episode reward: 0.9500,                 loss: nan
env4_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1733s / 7890.1945 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.5060
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5990s / 7966.7936 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.5884
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.7993s / 8043.5929 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3298
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.9000,                 loss: nan
env3_second_0:                 episode reward: -0.9000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.7941s / 8121.3869 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.6431
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4815s / 8197.8684 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.5533
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
env3_first_0:                 episode reward: -1.0000,                 loss: nan
env3_second_0:                 episode reward: 1.0000,                 loss: nan
env4_first_0:                 episode reward: 0.5500,                 loss: nan
env4_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.9711s / 8274.8395 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.4565
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.3880s / 8350.2276 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.8351
env0_second_0:                 episode reward: -2.8500,                 loss: nan
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
env2_first_0:                 episode reward: 2.7500,                 loss: nan
env2_second_0:                 episode reward: -2.7500,                 loss: nan
env3_first_0:                 episode reward: 2.5500,                 loss: nan
env3_second_0:                 episode reward: -2.5500,                 loss: nan
env4_first_0:                 episode reward: 2.1500,                 loss: nan
env4_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1913s / 8427.4189 s
env0_first_0:                 episode reward: 4.5000,                 loss: 0.7932
env0_second_0:                 episode reward: -4.5000,                 loss: nan
env1_first_0:                 episode reward: 4.0500,                 loss: nan
env1_second_0:                 episode reward: -4.0500,                 loss: nan
env2_first_0:                 episode reward: 4.7000,                 loss: nan
env2_second_0:                 episode reward: -4.7000,                 loss: nan
env3_first_0:                 episode reward: 5.5000,                 loss: nan
env3_second_0:                 episode reward: -5.5000,                 loss: nan
env4_first_0:                 episode reward: 5.0500,                 loss: nan
env4_second_0:                 episode reward: -5.0500,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3726s / 8504.7914 s
env0_first_0:                 episode reward: 7.1000,                 loss: 0.1017
env0_second_0:                 episode reward: -7.1000,                 loss: nan
env1_first_0:                 episode reward: 7.1500,                 loss: nan
env1_second_0:                 episode reward: -7.1500,                 loss: nan
env2_first_0:                 episode reward: 7.4500,                 loss: nan
env2_second_0:                 episode reward: -7.4500,                 loss: nan
env3_first_0:                 episode reward: 6.8500,                 loss: nan
env3_second_0:                 episode reward: -6.8500,                 loss: nan
env4_first_0:                 episode reward: 6.6500,                 loss: nan
env4_second_0:                 episode reward: -6.6500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.7901s / 8581.5815 s
env0_first_0:                 episode reward: 3.2500,                 loss: 0.6820
env0_second_0:                 episode reward: -3.2500,                 loss: nan
env1_first_0:                 episode reward: 4.1000,                 loss: nan
env1_second_0:                 episode reward: -4.1000,                 loss: nan
env2_first_0:                 episode reward: 3.7500,                 loss: nan
env2_second_0:                 episode reward: -3.7500,                 loss: nan
env3_first_0:                 episode reward: 5.0000,                 loss: nan
env3_second_0:                 episode reward: -5.0000,                 loss: nan
env4_first_0:                 episode reward: 4.7500,                 loss: nan
env4_second_0:                 episode reward: -4.7500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.7999s / 8657.3815 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.8473
env0_second_0:                 episode reward: -3.3000,                 loss: nan
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
env2_first_0:                 episode reward: 2.8000,                 loss: nan
env2_second_0:                 episode reward: -2.8000,                 loss: nan
env3_first_0:                 episode reward: 4.0500,                 loss: nan
env3_second_0:                 episode reward: -4.0500,                 loss: nan
env4_first_0:                 episode reward: 4.0500,                 loss: nan
env4_second_0:                 episode reward: -4.0500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.2484s / 8733.6298 s
env0_first_0:                 episode reward: 3.4000,                 loss: 0.9228
env0_second_0:                 episode reward: -3.4000,                 loss: nan
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
env2_first_0:                 episode reward: 2.6000,                 loss: nan
env2_second_0:                 episode reward: -2.6000,                 loss: nan
env3_first_0:                 episode reward: 2.4000,                 loss: nan
env3_second_0:                 episode reward: -2.4000,                 loss: nan
env4_first_0:                 episode reward: 2.8000,                 loss: nan
env4_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5307s / 8810.1605 s
env0_first_0:                 episode reward: 2.6000,                 loss: 1.0414
env0_second_0:                 episode reward: -2.6000,                 loss: nan
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
env2_first_0:                 episode reward: 2.1500,                 loss: nan
env2_second_0:                 episode reward: -2.1500,                 loss: nan
env3_first_0:                 episode reward: 3.7500,                 loss: nan
env3_second_0:                 episode reward: -3.7500,                 loss: nan
env4_first_0:                 episode reward: 2.5500,                 loss: nan
env4_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.0599s / 8887.2204 s
env0_first_0:                 episode reward: 3.1000,                 loss: 1.1793
env0_second_0:                 episode reward: -3.1000,                 loss: nan
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
env2_first_0:                 episode reward: 4.6500,                 loss: nan
env2_second_0:                 episode reward: -4.6500,                 loss: nan
env3_first_0:                 episode reward: 3.3500,                 loss: nan
env3_second_0:                 episode reward: -3.3500,                 loss: nan
env4_first_0:                 episode reward: 3.7500,                 loss: nan
env4_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.9506s / 8965.1710 s
env0_first_0:                 episode reward: 1.9500,                 loss: 1.3759
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
env2_first_0:                 episode reward: 3.0500,                 loss: nan
env2_second_0:                 episode reward: -3.0500,                 loss: nan
env3_first_0:                 episode reward: 2.8500,                 loss: nan
env3_second_0:                 episode reward: -2.8500,                 loss: nan
env4_first_0:                 episode reward: 3.7000,                 loss: nan
env4_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.8827s / 9041.0537 s
env0_first_0:                 episode reward: 3.6500,                 loss: 1.2725
env0_second_0:                 episode reward: -3.6500,                 loss: nan
env1_first_0:                 episode reward: 4.4000,                 loss: nan
env1_second_0:                 episode reward: -4.4000,                 loss: nan
env2_first_0:                 episode reward: 3.1500,                 loss: nan
env2_second_0:                 episode reward: -3.1500,                 loss: nan
env3_first_0:                 episode reward: 4.4500,                 loss: nan
env3_second_0:                 episode reward: -4.4500,                 loss: nan
env4_first_0:                 episode reward: 5.1000,                 loss: nan
env4_second_0:                 episode reward: -5.1000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.2271s / 9118.2808 s
env0_first_0:                 episode reward: 2.0500,                 loss: 1.1816
env0_second_0:                 episode reward: -2.0500,                 loss: nan
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
env2_first_0:                 episode reward: 2.2500,                 loss: nan
env2_second_0:                 episode reward: -2.2500,                 loss: nan
env3_first_0:                 episode reward: 3.7500,                 loss: nan
env3_second_0:                 episode reward: -3.7500,                 loss: nan
env4_first_0:                 episode reward: 2.8500,                 loss: nan
env4_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3329s / 9195.6136 s
env0_first_0:                 episode reward: 2.0500,                 loss: 1.3462
env0_second_0:                 episode reward: -2.0500,                 loss: nan
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.8955s / 9271.5091 s
env0_first_0:                 episode reward: 4.0000,                 loss: 1.2657
env0_second_0:                 episode reward: -4.0000,                 loss: nan
env1_first_0:                 episode reward: 4.9500,                 loss: nan
env1_second_0:                 episode reward: -4.9500,                 loss: nan
env2_first_0:                 episode reward: 3.2000,                 loss: nan
env2_second_0:                 episode reward: -3.2000,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 3.3500,                 loss: nan
env4_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.0463s / 9348.5554 s
env0_first_0:                 episode reward: 3.4500,                 loss: 1.4523
env0_second_0:                 episode reward: -3.4500,                 loss: nan
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
env2_first_0:                 episode reward: 3.2500,                 loss: nan
env2_second_0:                 episode reward: -3.2500,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 1.9000,                 loss: nan
env4_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.2568s / 9425.8121 s
env0_first_0:                 episode reward: 2.2000,                 loss: 1.2186
env0_second_0:                 episode reward: -2.2000,                 loss: nan
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
env2_first_0:                 episode reward: 2.8500,                 loss: nan
env2_second_0:                 episode reward: -2.8500,                 loss: nan
env3_first_0:                 episode reward: 2.2500,                 loss: nan
env3_second_0:                 episode reward: -2.2500,                 loss: nan
env4_first_0:                 episode reward: 2.5000,                 loss: nan
env4_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5307s / 9502.3429 s
env0_first_0:                 episode reward: 5.6000,                 loss: 0.8465
env0_second_0:                 episode reward: -5.6000,                 loss: nan
env1_first_0:                 episode reward: 4.8500,                 loss: nan
env1_second_0:                 episode reward: -4.8500,                 loss: nan
env2_first_0:                 episode reward: 6.2000,                 loss: nan
env2_second_0:                 episode reward: -6.2000,                 loss: nan
env3_first_0:                 episode reward: 4.9500,                 loss: nan
env3_second_0:                 episode reward: -4.9500,                 loss: nan
env4_first_0:                 episode reward: 5.5500,                 loss: nan
env4_second_0:                 episode reward: -5.5500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.5492s / 9579.8921 s
env0_first_0:                 episode reward: 3.6500,                 loss: 1.1213
env0_second_0:                 episode reward: -3.6500,                 loss: nan
env1_first_0:                 episode reward: 4.4000,                 loss: nan
env1_second_0:                 episode reward: -4.4000,                 loss: nan
env2_first_0:                 episode reward: 3.7500,                 loss: nan
env2_second_0:                 episode reward: -3.7500,                 loss: nan
env3_first_0:                 episode reward: 3.1000,                 loss: nan
env3_second_0:                 episode reward: -3.1000,                 loss: nan
env4_first_0:                 episode reward: 2.1000,                 loss: nan
env4_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6211s / 9657.5132 s
env0_first_0:                 episode reward: 3.2500,                 loss: 1.2904
env0_second_0:                 episode reward: -3.2500,                 loss: nan
env1_first_0:                 episode reward: 3.9500,                 loss: nan
env1_second_0:                 episode reward: -3.9500,                 loss: nan
env2_first_0:                 episode reward: 3.0500,                 loss: nan
env2_second_0:                 episode reward: -3.0500,                 loss: nan
env3_first_0:                 episode reward: 1.9000,                 loss: nan
env3_second_0:                 episode reward: -1.9000,                 loss: nan
env4_first_0:                 episode reward: 3.9000,                 loss: nan
env4_second_0:                 episode reward: -3.9000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.0409s / 9734.5542 s
env0_first_0:                 episode reward: 3.2500,                 loss: 1.1723
env0_second_0:                 episode reward: -3.2500,                 loss: nan
env1_first_0:                 episode reward: 3.6500,                 loss: nan
env1_second_0:                 episode reward: -3.6500,                 loss: nan
env2_first_0:                 episode reward: 2.8000,                 loss: nan
env2_second_0:                 episode reward: -2.8000,                 loss: nan
env3_first_0:                 episode reward: 3.0500,                 loss: nan
env3_second_0:                 episode reward: -3.0500,                 loss: nan
env4_first_0:                 episode reward: 2.9000,                 loss: nan
env4_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1628s / 9811.7170 s
env0_first_0:                 episode reward: 6.8500,                 loss: 0.2511
env0_second_0:                 episode reward: -6.8500,                 loss: nan
env1_first_0:                 episode reward: 7.1500,                 loss: nan
env1_second_0:                 episode reward: -7.1500,                 loss: nan
env2_first_0:                 episode reward: 6.9500,                 loss: nan
env2_second_0:                 episode reward: -6.9500,                 loss: nan
env3_first_0:                 episode reward: 7.1000,                 loss: nan
env3_second_0:                 episode reward: -7.1000,                 loss: nan
env4_first_0:                 episode reward: 6.3000,                 loss: nan
env4_second_0:                 episode reward: -6.3000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1570s / 9888.8740 s
env0_first_0:                 episode reward: 3.3000,                 loss: 1.3364
env0_second_0:                 episode reward: -3.3000,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.7620s / 9966.6359 s
env0_first_0:                 episode reward: -2.6500,                 loss: 1.6539
env0_second_0:                 episode reward: 2.6500,                 loss: nan
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
env2_first_0:                 episode reward: -1.7000,                 loss: nan
env2_second_0:                 episode reward: 1.7000,                 loss: nan
env3_first_0:                 episode reward: -1.3000,                 loss: nan
env3_second_0:                 episode reward: 1.3000,                 loss: nan
env4_first_0:                 episode reward: -1.0500,                 loss: nan
env4_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8015s / 10044.4374 s
env0_first_0:                 episode reward: -1.7500,                 loss: 1.8184
env0_second_0:                 episode reward: 1.7500,                 loss: nan
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
env3_first_0:                 episode reward: -1.8000,                 loss: nan
env3_second_0:                 episode reward: 1.8000,                 loss: nan
env4_first_0:                 episode reward: -3.6000,                 loss: nan
env4_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4269s / 10120.8643 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.9942
env0_second_0:                 episode reward: 4.8000,                 loss: nan
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
env2_first_0:                 episode reward: -4.9000,                 loss: nan
env2_second_0:                 episode reward: 4.9000,                 loss: nan
env3_first_0:                 episode reward: -6.7000,                 loss: nan
env3_second_0:                 episode reward: 6.7000,                 loss: nan
env4_first_0:                 episode reward: -4.3000,                 loss: nan
env4_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.6910s / 10196.5553 s
env0_first_0:                 episode reward: -5.9500,                 loss: 0.7362
env0_second_0:                 episode reward: 5.9500,                 loss: nan
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
env2_first_0:                 episode reward: -5.5000,                 loss: nan
env2_second_0:                 episode reward: 5.5000,                 loss: nan
env3_first_0:                 episode reward: -5.3000,                 loss: nan
env3_second_0:                 episode reward: 5.3000,                 loss: nan
env4_first_0:                 episode reward: -4.4000,                 loss: nan
env4_second_0:                 episode reward: 4.4000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4968s / 10274.0521 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.4179
env0_second_0:                 episode reward: 4.1500,                 loss: nan
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
env2_first_0:                 episode reward: -5.6000,                 loss: nan
env2_second_0:                 episode reward: 5.6000,                 loss: nan
env3_first_0:                 episode reward: -6.3000,                 loss: nan
env3_second_0:                 episode reward: 6.3000,                 loss: nan
env4_first_0:                 episode reward: -6.5500,                 loss: nan
env4_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4017s / 10351.4538 s
env0_first_0:                 episode reward: -5.6500,                 loss: 0.6200
env0_second_0:                 episode reward: 5.6500,                 loss: nan
env1_first_0:                 episode reward: -5.5500,                 loss: nan
env1_second_0:                 episode reward: 5.5500,                 loss: nan
env2_first_0:                 episode reward: -5.2000,                 loss: nan
env2_second_0:                 episode reward: 5.2000,                 loss: nan
env3_first_0:                 episode reward: -5.6500,                 loss: nan
env3_second_0:                 episode reward: 5.6500,                 loss: nan
env4_first_0:                 episode reward: -6.0000,                 loss: nan
env4_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.9556s / 10429.4094 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.9147
env0_second_0:                 episode reward: 2.9000,                 loss: nan
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
env2_first_0:                 episode reward: -2.5500,                 loss: nan
env2_second_0:                 episode reward: 2.5500,                 loss: nan
env3_first_0:                 episode reward: -3.0000,                 loss: nan
env3_second_0:                 episode reward: 3.0000,                 loss: nan
env4_first_0:                 episode reward: -2.5500,                 loss: nan
env4_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.0048s / 10504.4143 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.7648
env0_second_0:                 episode reward: 2.0500,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
env3_first_0:                 episode reward: -2.1500,                 loss: nan
env3_second_0:                 episode reward: 2.1500,                 loss: nan
env4_first_0:                 episode reward: -2.0500,                 loss: nan
env4_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.2863s / 10582.7006 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.9627
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: -1.5500,                 loss: nan
env2_second_0:                 episode reward: 1.5500,                 loss: nan
env3_first_0:                 episode reward: -1.4000,                 loss: nan
env3_second_0:                 episode reward: 1.4000,                 loss: nan
env4_first_0:                 episode reward: -1.1000,                 loss: nan
env4_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.5729s / 10660.2735 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.8029
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8244s / 10738.0979 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.8827
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4440s / 10815.5419 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.8821
env0_second_0:                 episode reward: -1.0000,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.9432s / 10892.4851 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.6728
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 1.0500,                 loss: nan
env2_second_0:                 episode reward: -1.0500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 1.3000,                 loss: nan
env4_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.5683s / 10970.0534 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.5319
env0_second_0:                 episode reward: -1.5500,                 loss: nan
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.3700s / 11048.4234 s
env0_first_0:                 episode reward: -1.9000,                 loss: 1.0036
env0_second_0:                 episode reward: 1.9000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.5500,                 loss: nan
env2_second_0:                 episode reward: -0.5500,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.5302s / 11125.9536 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.6630
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.8302s / 11204.7839 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.7175
env0_second_0:                 episode reward: 0.6500,                 loss: nan
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: -0.8000,                 loss: nan
env2_second_0:                 episode reward: 0.8000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6317s / 11282.4155 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.5190
env0_second_0:                 episode reward: -2.0000,                 loss: nan
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.9500,                 loss: nan
env3_second_0:                 episode reward: -0.9500,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1270s / 11359.5425 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.5867
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4974s / 11437.0399 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.9272
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
env3_first_0:                 episode reward: -1.0000,                 loss: nan
env3_second_0:                 episode reward: 1.0000,                 loss: nan
env4_first_0:                 episode reward: -1.0500,                 loss: nan
env4_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.3940s / 11513.4338 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.8709
env0_second_0:                 episode reward: 3.3000,                 loss: nan
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
env2_first_0:                 episode reward: -2.7000,                 loss: nan
env2_second_0:                 episode reward: 2.7000,                 loss: nan
env3_first_0:                 episode reward: -2.8500,                 loss: nan
env3_second_0:                 episode reward: 2.8500,                 loss: nan
env4_first_0:                 episode reward: -1.4500,                 loss: nan
env4_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5811s / 11590.0149 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.8854
env0_second_0:                 episode reward: 1.4000,                 loss: nan
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: -2.0000,                 loss: nan
env4_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.0397s / 11667.0546 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.7487
env0_second_0:                 episode reward: -0.7000,                 loss: nan
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.3589s / 11743.4135 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.6094
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.9000,                 loss: nan
env4_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.7533s / 11820.1669 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.6374
env0_second_0:                 episode reward: 1.6000,                 loss: nan
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
env3_first_0:                 episode reward: -1.4000,                 loss: nan
env3_second_0:                 episode reward: 1.4000,                 loss: nan
env4_first_0:                 episode reward: -1.4500,                 loss: nan
env4_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1180s / 11897.2849 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.4981
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3658s / 11974.6507 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3670
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8758s / 12052.5265 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.3129
env0_second_0:                 episode reward: -2.0000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8063s / 12130.3328 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3666
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
env2_first_0:                 episode reward: 0.8000,                 loss: nan
env2_second_0:                 episode reward: -0.8000,                 loss: nan
env3_first_0:                 episode reward: 1.0000,                 loss: nan
env3_second_0:                 episode reward: -1.0000,                 loss: nan
env4_first_0:                 episode reward: 0.7000,                 loss: nan
env4_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.8272s / 12206.1600 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.3847
env0_second_0:                 episode reward: 0.6500,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3164s / 12283.4764 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3842
env0_second_0:                 episode reward: -0.8000,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: 1.5000,                 loss: nan
env4_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.1197s / 12359.5961 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.3162
env0_second_0:                 episode reward: -0.9500,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 1.1500,                 loss: nan
env3_second_0:                 episode reward: -1.1500,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4292s / 12437.0254 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2749
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
env2_first_0:                 episode reward: 1.1500,                 loss: nan
env2_second_0:                 episode reward: -1.1500,                 loss: nan
env3_first_0:                 episode reward: 0.9500,                 loss: nan
env3_second_0:                 episode reward: -0.9500,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.1071s / 12515.1325 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.4024
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.9000,                 loss: nan
env3_second_0:                 episode reward: -0.9000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.2727s / 12592.4052 s
env0_first_0:                 episode reward: -4.9000,                 loss: 0.5088
env0_second_0:                 episode reward: 4.9000,                 loss: nan
env1_first_0:                 episode reward: -5.6500,                 loss: nan
env1_second_0:                 episode reward: 5.6500,                 loss: nan
env2_first_0:                 episode reward: -4.9000,                 loss: nan
env2_second_0:                 episode reward: 4.9000,                 loss: nan
env3_first_0:                 episode reward: -5.5500,                 loss: nan
env3_second_0:                 episode reward: 5.5500,                 loss: nan
env4_first_0:                 episode reward: -5.0000,                 loss: nan
env4_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5400s / 12668.9453 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.1097
env0_second_0:                 episode reward: 6.7500,                 loss: nan
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
env2_first_0:                 episode reward: -6.0000,                 loss: nan
env2_second_0:                 episode reward: 6.0000,                 loss: nan
env3_first_0:                 episode reward: -6.3500,                 loss: nan
env3_second_0:                 episode reward: 6.3500,                 loss: nan
env4_first_0:                 episode reward: -5.3500,                 loss: nan
env4_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.2838s / 12745.2291 s
env0_first_0:                 episode reward: -6.4500,                 loss: -0.0366
env0_second_0:                 episode reward: 6.4500,                 loss: nan
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
env2_first_0:                 episode reward: -7.0000,                 loss: nan
env2_second_0:                 episode reward: 7.0000,                 loss: nan
env3_first_0:                 episode reward: -6.6000,                 loss: nan
env3_second_0:                 episode reward: 6.6000,                 loss: nan
env4_first_0:                 episode reward: -6.3500,                 loss: nan
env4_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.0608s / 12823.2899 s
env0_first_0:                 episode reward: -5.4000,                 loss: 0.2290
env0_second_0:                 episode reward: 5.4000,                 loss: nan
env1_first_0:                 episode reward: -6.6500,                 loss: nan
env1_second_0:                 episode reward: 6.6500,                 loss: nan
env2_first_0:                 episode reward: -6.0000,                 loss: nan
env2_second_0:                 episode reward: 6.0000,                 loss: nan
env3_first_0:                 episode reward: -6.1000,                 loss: nan
env3_second_0:                 episode reward: 6.1000,                 loss: nan
env4_first_0:                 episode reward: -6.1000,                 loss: nan
env4_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1407s / 12900.4305 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.2180
env0_second_0:                 episode reward: 6.0500,                 loss: nan
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
env2_first_0:                 episode reward: -5.9500,                 loss: nan
env2_second_0:                 episode reward: 5.9500,                 loss: nan
env3_first_0:                 episode reward: -5.6500,                 loss: nan
env3_second_0:                 episode reward: 5.6500,                 loss: nan
env4_first_0:                 episode reward: -6.6500,                 loss: nan
env4_second_0:                 episode reward: 6.6500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.9372s / 12977.3677 s
env0_first_0:                 episode reward: -5.0000,                 loss: 0.3307
env0_second_0:                 episode reward: 5.0000,                 loss: nan
env1_first_0:                 episode reward: -5.2000,                 loss: nan
env1_second_0:                 episode reward: 5.2000,                 loss: nan
env2_first_0:                 episode reward: -5.4500,                 loss: nan
env2_second_0:                 episode reward: 5.4500,                 loss: nan
env3_first_0:                 episode reward: -3.9000,                 loss: nan
env3_second_0:                 episode reward: 3.9000,                 loss: nan
env4_first_0:                 episode reward: -5.3000,                 loss: nan
env4_second_0:                 episode reward: 5.3000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.7990s / 13055.1668 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.3076
env0_second_0:                 episode reward: 3.9000,                 loss: nan
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
env2_first_0:                 episode reward: -4.6000,                 loss: nan
env2_second_0:                 episode reward: 4.6000,                 loss: nan
env3_first_0:                 episode reward: -4.4500,                 loss: nan
env3_second_0:                 episode reward: 4.4500,                 loss: nan
env4_first_0:                 episode reward: -4.5000,                 loss: nan
env4_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3265s / 13132.4932 s
env0_first_0:                 episode reward: -6.6000,                 loss: 0.0517
env0_second_0:                 episode reward: 6.6000,                 loss: nan
env1_first_0:                 episode reward: -5.8500,                 loss: nan
env1_second_0:                 episode reward: 5.8500,                 loss: nan
env2_first_0:                 episode reward: -5.9500,                 loss: nan
env2_second_0:                 episode reward: 5.9500,                 loss: nan
env3_first_0:                 episode reward: -6.2500,                 loss: nan
env3_second_0:                 episode reward: 6.2500,                 loss: nan
env4_first_0:                 episode reward: -6.2500,                 loss: nan
env4_second_0:                 episode reward: 6.2500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.9146s / 13209.4079 s
env0_first_0:                 episode reward: -6.1000,                 loss: 0.4293
env0_second_0:                 episode reward: 6.1000,                 loss: nan
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
env2_first_0:                 episode reward: -5.0500,                 loss: nan
env2_second_0:                 episode reward: 5.0500,                 loss: nan
env3_first_0:                 episode reward: -5.5500,                 loss: nan
env3_second_0:                 episode reward: 5.5500,                 loss: nan
env4_first_0:                 episode reward: -4.9500,                 loss: nan
env4_second_0:                 episode reward: 4.9500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4385s / 13286.8464 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.2951
env0_second_0:                 episode reward: 6.0500,                 loss: nan
env1_first_0:                 episode reward: -6.5000,                 loss: nan
env1_second_0:                 episode reward: 6.5000,                 loss: nan
env2_first_0:                 episode reward: -6.1500,                 loss: nan
env2_second_0:                 episode reward: 6.1500,                 loss: nan
env3_first_0:                 episode reward: -5.7000,                 loss: nan
env3_second_0:                 episode reward: 5.7000,                 loss: nan
env4_first_0:                 episode reward: -5.5500,                 loss: nan
env4_second_0:                 episode reward: 5.5500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.0142s / 13363.8606 s
env0_first_0:                 episode reward: -7.0000,                 loss: -0.1297
env0_second_0:                 episode reward: 7.0000,                 loss: nan
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
env2_first_0:                 episode reward: -6.8500,                 loss: nan
env2_second_0:                 episode reward: 6.8500,                 loss: nan
env3_first_0:                 episode reward: -6.8000,                 loss: nan
env3_second_0:                 episode reward: 6.8000,                 loss: nan
env4_first_0:                 episode reward: -6.9000,                 loss: nan
env4_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.6600s / 13440.5205 s
env0_first_0:                 episode reward: -6.6000,                 loss: -0.1541
env0_second_0:                 episode reward: 6.6000,                 loss: nan
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
env2_first_0:                 episode reward: -6.9500,                 loss: nan
env2_second_0:                 episode reward: 6.9500,                 loss: nan
env3_first_0:                 episode reward: -6.5500,                 loss: nan
env3_second_0:                 episode reward: 6.5500,                 loss: nan
env4_first_0:                 episode reward: -6.5500,                 loss: nan
env4_second_0:                 episode reward: 6.5500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8973s / 13518.4178 s
env0_first_0:                 episode reward: -5.5000,                 loss: 0.1104
env0_second_0:                 episode reward: 5.5000,                 loss: nan
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
env2_first_0:                 episode reward: -4.2500,                 loss: nan
env2_second_0:                 episode reward: 4.2500,                 loss: nan
env3_first_0:                 episode reward: -5.2000,                 loss: nan
env3_second_0:                 episode reward: 5.2000,                 loss: nan
env4_first_0:                 episode reward: -5.7000,                 loss: nan
env4_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4604s / 13594.8783 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.3089
env0_second_0:                 episode reward: 3.6000,                 loss: nan
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
env2_first_0:                 episode reward: -4.0500,                 loss: nan
env2_second_0:                 episode reward: 4.0500,                 loss: nan
env3_first_0:                 episode reward: -3.5000,                 loss: nan
env3_second_0:                 episode reward: 3.5000,                 loss: nan
env4_first_0:                 episode reward: -3.8000,                 loss: nan
env4_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4754s / 13672.3536 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.2396
env0_second_0:                 episode reward: 4.0000,                 loss: nan
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
env2_first_0:                 episode reward: -4.1500,                 loss: nan
env2_second_0:                 episode reward: 4.1500,                 loss: nan
env3_first_0:                 episode reward: -2.8000,                 loss: nan
env3_second_0:                 episode reward: 2.8000,                 loss: nan
env4_first_0:                 episode reward: -3.7000,                 loss: nan
env4_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3106s / 13749.6643 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.3470
env0_second_0:                 episode reward: 3.5500,                 loss: nan
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
env3_first_0:                 episode reward: -2.8000,                 loss: nan
env3_second_0:                 episode reward: 2.8000,                 loss: nan
env4_first_0:                 episode reward: -2.8500,                 loss: nan
env4_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.3980s / 13826.0623 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.7865
env0_second_0:                 episode reward: -2.9000,                 loss: nan
env1_first_0:                 episode reward: 5.5000,                 loss: nan
env1_second_0:                 episode reward: -5.5000,                 loss: nan
env2_first_0:                 episode reward: 4.9000,                 loss: nan
env2_second_0:                 episode reward: -4.9000,                 loss: nan
env3_first_0:                 episode reward: 5.3000,                 loss: nan
env3_second_0:                 episode reward: -5.3000,                 loss: nan
env4_first_0:                 episode reward: 4.5500,                 loss: nan
env4_second_0:                 episode reward: -4.5500,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4587s / 13902.5210 s
env0_first_0:                 episode reward: 7.6500,                 loss: 0.2238
env0_second_0:                 episode reward: -7.6500,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 7.6000,                 loss: nan
env2_second_0:                 episode reward: -7.6000,                 loss: nan
env3_first_0:                 episode reward: 7.2000,                 loss: nan
env3_second_0:                 episode reward: -7.2000,                 loss: nan
env4_first_0:                 episode reward: 7.5500,                 loss: nan
env4_second_0:                 episode reward: -7.5500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.9298s / 13979.4508 s
env0_first_0:                 episode reward: 6.2000,                 loss: 0.4549
env0_second_0:                 episode reward: -6.2000,                 loss: nan
env1_first_0:                 episode reward: 6.8000,                 loss: nan
env1_second_0:                 episode reward: -6.8000,                 loss: nan
env2_first_0:                 episode reward: 7.5500,                 loss: nan
env2_second_0:                 episode reward: -7.5500,                 loss: nan
env3_first_0:                 episode reward: 7.4000,                 loss: nan
env3_second_0:                 episode reward: -7.4000,                 loss: nan
env4_first_0:                 episode reward: 7.2000,                 loss: nan
env4_second_0:                 episode reward: -7.2000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.0428s / 14058.4936 s
env0_first_0:                 episode reward: 4.4500,                 loss: 0.7538
env0_second_0:                 episode reward: -4.4500,                 loss: nan
env1_first_0:                 episode reward: 5.8500,                 loss: nan
env1_second_0:                 episode reward: -5.8500,                 loss: nan
env2_first_0:                 episode reward: 5.7000,                 loss: nan
env2_second_0:                 episode reward: -5.7000,                 loss: nan
env3_first_0:                 episode reward: 5.7000,                 loss: nan
env3_second_0:                 episode reward: -5.7000,                 loss: nan
env4_first_0:                 episode reward: 6.6500,                 loss: nan
env4_second_0:                 episode reward: -6.6500,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.0474s / 14136.5410 s
env0_first_0:                 episode reward: 1.5000,                 loss: 1.5251
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 5.1500,                 loss: nan
env1_second_0:                 episode reward: -5.1500,                 loss: nan
env2_first_0:                 episode reward: 4.6500,                 loss: nan
env2_second_0:                 episode reward: -4.6500,                 loss: nan
env3_first_0:                 episode reward: 2.9500,                 loss: nan
env3_second_0:                 episode reward: -2.9500,                 loss: nan
env4_first_0:                 episode reward: 1.8000,                 loss: nan
env4_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.7462s / 14213.2872 s
env0_first_0:                 episode reward: 1.6500,                 loss: 1.8437
env0_second_0:                 episode reward: -1.6500,                 loss: nan
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
env2_first_0:                 episode reward: 5.0500,                 loss: nan
env2_second_0:                 episode reward: -5.0500,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.0500,                 loss: nan
env4_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.2936s / 14291.5808 s
env0_first_0:                 episode reward: 2.8000,                 loss: 1.4818
env0_second_0:                 episode reward: -2.8000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.9500,                 loss: nan
env3_second_0:                 episode reward: -1.9500,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3929s / 14368.9737 s
env0_first_0:                 episode reward: 4.4000,                 loss: 1.5417
env0_second_0:                 episode reward: -4.4000,                 loss: nan
env1_first_0:                 episode reward: 5.1500,                 loss: nan
env1_second_0:                 episode reward: -5.1500,                 loss: nan
env2_first_0:                 episode reward: 3.2000,                 loss: nan
env2_second_0:                 episode reward: -3.2000,                 loss: nan
env3_first_0:                 episode reward: 2.2500,                 loss: nan
env3_second_0:                 episode reward: -2.2500,                 loss: nan
env4_first_0:                 episode reward: 2.9500,                 loss: nan
env4_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.3902s / 14447.3639 s
env0_first_0:                 episode reward: -0.3500,                 loss: 2.0359
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 1.6500,                 loss: nan
env4_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4581s / 14524.8220 s
env0_first_0:                 episode reward: -1.5500,                 loss: 1.3359
env0_second_0:                 episode reward: 1.5500,                 loss: nan
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: -3.6000,                 loss: nan
env2_second_0:                 episode reward: 3.6000,                 loss: nan
env3_first_0:                 episode reward: -3.8000,                 loss: nan
env3_second_0:                 episode reward: 3.8000,                 loss: nan
env4_first_0:                 episode reward: -2.0000,                 loss: nan
env4_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.6186s / 14601.4406 s
env0_first_0:                 episode reward: -2.5000,                 loss: 1.5298
env0_second_0:                 episode reward: 2.5000,                 loss: nan
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
env2_first_0:                 episode reward: -2.5500,                 loss: nan
env2_second_0:                 episode reward: 2.5500,                 loss: nan
env3_first_0:                 episode reward: -3.4000,                 loss: nan
env3_second_0:                 episode reward: 3.4000,                 loss: nan
env4_first_0:                 episode reward: -2.3500,                 loss: nan
env4_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.2021s / 14678.6427 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.4053
env0_second_0:                 episode reward: 6.3000,                 loss: nan
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
env2_first_0:                 episode reward: -5.4000,                 loss: nan
env2_second_0:                 episode reward: 5.4000,                 loss: nan
env3_first_0:                 episode reward: -5.8000,                 loss: nan
env3_second_0:                 episode reward: 5.8000,                 loss: nan
env4_first_0:                 episode reward: -5.6000,                 loss: nan
env4_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4829s / 14756.1256 s
env0_first_0:                 episode reward: -5.8000,                 loss: 0.3164
env0_second_0:                 episode reward: 5.8000,                 loss: nan
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
env2_first_0:                 episode reward: -6.5000,                 loss: nan
env2_second_0:                 episode reward: 6.5000,                 loss: nan
env3_first_0:                 episode reward: -5.8500,                 loss: nan
env3_second_0:                 episode reward: 5.8500,                 loss: nan
env4_first_0:                 episode reward: -5.9000,                 loss: nan
env4_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.8545s / 14832.9801 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.0203
env0_second_0:                 episode reward: 6.8000,                 loss: nan
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
env2_first_0:                 episode reward: -6.0000,                 loss: nan
env2_second_0:                 episode reward: 6.0000,                 loss: nan
env3_first_0:                 episode reward: -6.8000,                 loss: nan
env3_second_0:                 episode reward: 6.8000,                 loss: nan
env4_first_0:                 episode reward: -6.0500,                 loss: nan
env4_second_0:                 episode reward: 6.0500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.4438s / 14911.4240 s
env0_first_0:                 episode reward: -6.9000,                 loss: -0.2501
env0_second_0:                 episode reward: 6.9000,                 loss: nan
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
env2_first_0:                 episode reward: -7.0000,                 loss: nan
env2_second_0:                 episode reward: 7.0000,                 loss: nan
env3_first_0:                 episode reward: -6.7500,                 loss: nan
env3_second_0:                 episode reward: 6.7500,                 loss: nan
env4_first_0:                 episode reward: -6.8000,                 loss: nan
env4_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.0466s / 14988.4705 s
env0_first_0:                 episode reward: -2.4500,                 loss: 1.0414
env0_second_0:                 episode reward: 2.4500,                 loss: nan
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
env2_first_0:                 episode reward: -2.3500,                 loss: nan
env2_second_0:                 episode reward: 2.3500,                 loss: nan
env3_first_0:                 episode reward: -1.7000,                 loss: nan
env3_second_0:                 episode reward: 1.7000,                 loss: nan
env4_first_0:                 episode reward: -2.3500,                 loss: nan
env4_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.8078s / 15064.2783 s
env0_first_0:                 episode reward: -1.4500,                 loss: 1.5216
env0_second_0:                 episode reward: 1.4500,                 loss: nan
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
env2_first_0:                 episode reward: -3.2500,                 loss: nan
env2_second_0:                 episode reward: 3.2500,                 loss: nan
env3_first_0:                 episode reward: -2.0000,                 loss: nan
env3_second_0:                 episode reward: 2.0000,                 loss: nan
env4_first_0:                 episode reward: -4.2000,                 loss: nan
env4_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8562s / 15142.1345 s
env0_first_0:                 episode reward: -2.6500,                 loss: 1.3424
env0_second_0:                 episode reward: 2.6500,                 loss: nan
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -2.6000,                 loss: nan
env3_second_0:                 episode reward: 2.6000,                 loss: nan
env4_first_0:                 episode reward: -3.6000,                 loss: nan
env4_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.2421s / 15218.3766 s
env0_first_0:                 episode reward: 1.7000,                 loss: 1.5725
env0_second_0:                 episode reward: -1.7000,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
env3_first_0:                 episode reward: 0.6500,                 loss: nan
env3_second_0:                 episode reward: -0.6500,                 loss: nan
env4_first_0:                 episode reward: 0.8500,                 loss: nan
env4_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8541s / 15296.2307 s
env0_first_0:                 episode reward: -1.3500,                 loss: 1.7188
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 1.2000,                 loss: nan
env3_second_0:                 episode reward: -1.2000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.7524s / 15372.9831 s
env0_first_0:                 episode reward: 0.3000,                 loss: 1.7235
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
env3_first_0:                 episode reward: 4.3500,                 loss: nan
env3_second_0:                 episode reward: -4.3500,                 loss: nan
env4_first_0:                 episode reward: 3.8000,                 loss: nan
env4_second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1582s / 15450.1413 s
env0_first_0:                 episode reward: 1.6000,                 loss: 1.8878
env0_second_0:                 episode reward: -1.6000,                 loss: nan
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 2.7500,                 loss: nan
env3_second_0:                 episode reward: -2.7500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.2231s / 15526.3644 s
env0_first_0:                 episode reward: -1.3500,                 loss: 1.8566
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
env2_first_0:                 episode reward: 2.6000,                 loss: nan
env2_second_0:                 episode reward: -2.6000,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3339s / 15603.6983 s
env0_first_0:                 episode reward: 0.6500,                 loss: 1.2264
env0_second_0:                 episode reward: -0.6500,                 loss: nan
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
env2_first_0:                 episode reward: 4.5500,                 loss: nan
env2_second_0:                 episode reward: -4.5500,                 loss: nan
env3_first_0:                 episode reward: 2.7500,                 loss: nan
env3_second_0:                 episode reward: -2.7500,                 loss: nan
env4_first_0:                 episode reward: 2.2500,                 loss: nan
env4_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.9014s / 15681.5997 s
env0_first_0:                 episode reward: 1.4000,                 loss: 1.7535
env0_second_0:                 episode reward: -1.4000,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.1305s / 15757.7303 s
env0_first_0:                 episode reward: -4.0000,                 loss: 1.5702
env0_second_0:                 episode reward: 4.0000,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
env2_first_0:                 episode reward: -4.4500,                 loss: nan
env2_second_0:                 episode reward: 4.4500,                 loss: nan
env3_first_0:                 episode reward: -1.9000,                 loss: nan
env3_second_0:                 episode reward: 1.9000,                 loss: nan
env4_first_0:                 episode reward: -3.8500,                 loss: nan
env4_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.6604s / 15834.3907 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.7879
env0_second_0:                 episode reward: 4.3500,                 loss: nan
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
env2_first_0:                 episode reward: -5.8500,                 loss: nan
env2_second_0:                 episode reward: 5.8500,                 loss: nan
env3_first_0:                 episode reward: -4.7500,                 loss: nan
env3_second_0:                 episode reward: 4.7500,                 loss: nan
env4_first_0:                 episode reward: -4.2500,                 loss: nan
env4_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3266s / 15911.7172 s
env0_first_0:                 episode reward: 4.5500,                 loss: 0.4000
env0_second_0:                 episode reward: -4.5500,                 loss: nan
env1_first_0:                 episode reward: 4.1000,                 loss: nan
env1_second_0:                 episode reward: -4.1000,                 loss: nan
env2_first_0:                 episode reward: 4.8000,                 loss: nan
env2_second_0:                 episode reward: -4.8000,                 loss: nan
env3_first_0:                 episode reward: 5.4000,                 loss: nan
env3_second_0:                 episode reward: -5.4000,                 loss: nan
env4_first_0:                 episode reward: 3.6000,                 loss: nan
env4_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.8190s / 15988.5362 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.0852
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 7.7000,                 loss: nan
env1_second_0:                 episode reward: -7.7000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.5753s / 16066.1116 s
env0_first_0:                 episode reward: 5.9000,                 loss: 0.7644
env0_second_0:                 episode reward: -5.9000,                 loss: nan
env1_first_0:                 episode reward: 6.5000,                 loss: nan
env1_second_0:                 episode reward: -6.5000,                 loss: nan
env2_first_0:                 episode reward: 6.1500,                 loss: nan
env2_second_0:                 episode reward: -6.1500,                 loss: nan
env3_first_0:                 episode reward: 5.9500,                 loss: nan
env3_second_0:                 episode reward: -5.9500,                 loss: nan
env4_first_0:                 episode reward: 6.8000,                 loss: nan
env4_second_0:                 episode reward: -6.8000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.5276s / 16143.6392 s
env0_first_0:                 episode reward: 1.3000,                 loss: 1.4467
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -1.9500,                 loss: nan
env2_second_0:                 episode reward: 1.9500,                 loss: nan
env3_first_0:                 episode reward: -1.7000,                 loss: nan
env3_second_0:                 episode reward: 1.7000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.5804s / 16222.2196 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.7302
env0_second_0:                 episode reward: 2.7000,                 loss: nan
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
env3_first_0:                 episode reward: -2.9500,                 loss: nan
env3_second_0:                 episode reward: 2.9500,                 loss: nan
env4_first_0:                 episode reward: -2.4000,                 loss: nan
env4_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.6985s / 16298.9180 s
env0_first_0:                 episode reward: -1.6500,                 loss: 1.0173
env0_second_0:                 episode reward: 1.6500,                 loss: nan
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
env2_first_0:                 episode reward: -2.2500,                 loss: nan
env2_second_0:                 episode reward: 2.2500,                 loss: nan
env3_first_0:                 episode reward: -1.6500,                 loss: nan
env3_second_0:                 episode reward: 1.6500,                 loss: nan
env4_first_0:                 episode reward: -2.2500,                 loss: nan
env4_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8518s / 16376.7698 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.5672
env0_second_0:                 episode reward: 3.8000,                 loss: nan
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
env3_first_0:                 episode reward: -2.5500,                 loss: nan
env3_second_0:                 episode reward: 2.5500,                 loss: nan
env4_first_0:                 episode reward: -3.0000,                 loss: nan
env4_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6121s / 16454.3819 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.3978
env0_second_0:                 episode reward: 3.1000,                 loss: nan
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
env2_first_0:                 episode reward: -2.5500,                 loss: nan
env2_second_0:                 episode reward: 2.5500,                 loss: nan
env3_first_0:                 episode reward: -3.7000,                 loss: nan
env3_second_0:                 episode reward: 3.7000,                 loss: nan
env4_first_0:                 episode reward: -3.5000,                 loss: nan
env4_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8049s / 16532.1869 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.7648
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -2.4500,                 loss: nan
env2_second_0:                 episode reward: 2.4500,                 loss: nan
env3_first_0:                 episode reward: -3.2000,                 loss: nan
env3_second_0:                 episode reward: 3.2000,                 loss: nan
env4_first_0:                 episode reward: -2.8500,                 loss: nan
env4_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4211s / 16609.6079 s
env0_first_0:                 episode reward: 6.5000,                 loss: 0.4467
env0_second_0:                 episode reward: -6.5000,                 loss: nan
env1_first_0:                 episode reward: 6.1500,                 loss: nan
env1_second_0:                 episode reward: -6.1500,                 loss: nan
env2_first_0:                 episode reward: 6.0500,                 loss: nan
env2_second_0:                 episode reward: -6.0500,                 loss: nan
env3_first_0:                 episode reward: 6.5000,                 loss: nan
env3_second_0:                 episode reward: -6.5000,                 loss: nan
env4_first_0:                 episode reward: 5.9500,                 loss: nan
env4_second_0:                 episode reward: -5.9500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.2550s / 16688.8629 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.2333
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 7.9000,                 loss: nan
env3_second_0:                 episode reward: -7.9000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8100s / 16766.6729 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.2515
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.7267s / 16844.3995 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.2608
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.9993s / 16921.3988 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.1160
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 7.2500,                 loss: nan
env4_second_0:                 episode reward: -7.2500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.5210s / 16998.9198 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.1431
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 7.9500,                 loss: nan
env2_second_0:                 episode reward: -7.9500,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 7.9000,                 loss: nan
env4_second_0:                 episode reward: -7.9000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.4747s / 17077.3944 s
env0_first_0:                 episode reward: 4.7500,                 loss: 0.9099
env0_second_0:                 episode reward: -4.7500,                 loss: nan
env1_first_0:                 episode reward: 5.5000,                 loss: nan
env1_second_0:                 episode reward: -5.5000,                 loss: nan
env2_first_0:                 episode reward: 4.0500,                 loss: nan
env2_second_0:                 episode reward: -4.0500,                 loss: nan
env3_first_0:                 episode reward: 6.0500,                 loss: nan
env3_second_0:                 episode reward: -6.0500,                 loss: nan
env4_first_0:                 episode reward: 5.8000,                 loss: nan
env4_second_0:                 episode reward: -5.8000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.3784s / 17153.7728 s
env0_first_0:                 episode reward: 6.9000,                 loss: 0.7001
env0_second_0:                 episode reward: -6.9000,                 loss: nan
env1_first_0:                 episode reward: 5.7000,                 loss: nan
env1_second_0:                 episode reward: -5.7000,                 loss: nan
env2_first_0:                 episode reward: 3.5500,                 loss: nan
env2_second_0:                 episode reward: -3.5500,                 loss: nan
env3_first_0:                 episode reward: 5.0500,                 loss: nan
env3_second_0:                 episode reward: -5.0500,                 loss: nan
env4_first_0:                 episode reward: 4.3500,                 loss: nan
env4_second_0:                 episode reward: -4.3500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.2525s / 17231.0253 s
env0_first_0:                 episode reward: 4.9000,                 loss: 1.2495
env0_second_0:                 episode reward: -4.9000,                 loss: nan
env1_first_0:                 episode reward: 5.0000,                 loss: nan
env1_second_0:                 episode reward: -5.0000,                 loss: nan
env2_first_0:                 episode reward: 3.1500,                 loss: nan
env2_second_0:                 episode reward: -3.1500,                 loss: nan
env3_first_0:                 episode reward: 3.9500,                 loss: nan
env3_second_0:                 episode reward: -3.9500,                 loss: nan
env4_first_0:                 episode reward: 0.9000,                 loss: nan
env4_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1896s / 17308.2149 s
env0_first_0:                 episode reward: 3.4000,                 loss: 0.7698
env0_second_0:                 episode reward: -3.4000,                 loss: nan
env1_first_0:                 episode reward: 5.2000,                 loss: nan
env1_second_0:                 episode reward: -5.2000,                 loss: nan
env2_first_0:                 episode reward: 4.7500,                 loss: nan
env2_second_0:                 episode reward: -4.7500,                 loss: nan
env3_first_0:                 episode reward: 5.6500,                 loss: nan
env3_second_0:                 episode reward: -5.6500,                 loss: nan
env4_first_0:                 episode reward: 7.2500,                 loss: nan
env4_second_0:                 episode reward: -7.2500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4447s / 17385.6596 s
env0_first_0:                 episode reward: 8.0000,                 loss: 0.0322
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 7.7500,                 loss: nan
env1_second_0:                 episode reward: -7.7500,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 7.8000,                 loss: nan
env3_second_0:                 episode reward: -7.8000,                 loss: nan
env4_first_0:                 episode reward: 7.0000,                 loss: nan
env4_second_0:                 episode reward: -7.0000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.0267s / 17461.6862 s
env0_first_0:                 episode reward: 8.0000,                 loss: 0.0064
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 7.2500,                 loss: nan
env1_second_0:                 episode reward: -7.2500,                 loss: nan
env2_first_0:                 episode reward: 7.2500,                 loss: nan
env2_second_0:                 episode reward: -7.2500,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 7.2500,                 loss: nan
env4_second_0:                 episode reward: -7.2500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4822s / 17538.1685 s
env0_first_0:                 episode reward: 4.5000,                 loss: 1.3643
env0_second_0:                 episode reward: -4.5000,                 loss: nan
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 2.8000,                 loss: nan
env2_second_0:                 episode reward: -2.8000,                 loss: nan
env3_first_0:                 episode reward: 3.7500,                 loss: nan
env3_second_0:                 episode reward: -3.7500,                 loss: nan
env4_first_0:                 episode reward: 5.3500,                 loss: nan
env4_second_0:                 episode reward: -5.3500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.8035s / 17613.9719 s
env0_first_0:                 episode reward: 2.8500,                 loss: 1.5450
env0_second_0:                 episode reward: -2.8500,                 loss: nan
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: 2.4000,                 loss: nan
env2_second_0:                 episode reward: -2.4000,                 loss: nan
env3_first_0:                 episode reward: 3.0000,                 loss: nan
env3_second_0:                 episode reward: -3.0000,                 loss: nan
env4_first_0:                 episode reward: 4.0500,                 loss: nan
env4_second_0:                 episode reward: -4.0500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.8752s / 17689.8471 s
env0_first_0:                 episode reward: 3.1500,                 loss: 1.6067
env0_second_0:                 episode reward: -3.1500,                 loss: nan
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
env2_first_0:                 episode reward: 1.8000,                 loss: nan
env2_second_0:                 episode reward: -1.8000,                 loss: nan
env3_first_0:                 episode reward: 4.6000,                 loss: nan
env3_second_0:                 episode reward: -4.6000,                 loss: nan
env4_first_0:                 episode reward: 0.8000,                 loss: nan
env4_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.0632s / 17767.9103 s
env0_first_0:                 episode reward: 3.8000,                 loss: 1.5096
env0_second_0:                 episode reward: -3.8000,                 loss: nan
env1_first_0:                 episode reward: 3.8500,                 loss: nan
env1_second_0:                 episode reward: -3.8500,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
env3_first_0:                 episode reward: 4.8000,                 loss: nan
env3_second_0:                 episode reward: -4.8000,                 loss: nan
env4_first_0:                 episode reward: 3.6000,                 loss: nan
env4_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.4971s / 17846.4074 s
env0_first_0:                 episode reward: 4.2000,                 loss: 1.2575
env0_second_0:                 episode reward: -4.2000,                 loss: nan
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
env2_first_0:                 episode reward: 3.5000,                 loss: nan
env2_second_0:                 episode reward: -3.5000,                 loss: nan
env3_first_0:                 episode reward: 7.4000,                 loss: nan
env3_second_0:                 episode reward: -7.4000,                 loss: nan
env4_first_0:                 episode reward: 5.2000,                 loss: nan
env4_second_0:                 episode reward: -5.2000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.2545s / 17923.6620 s
env0_first_0:                 episode reward: 2.8500,                 loss: 1.3234
env0_second_0:                 episode reward: -2.8500,                 loss: nan
env1_first_0:                 episode reward: 4.2500,                 loss: nan
env1_second_0:                 episode reward: -4.2500,                 loss: nan
env2_first_0:                 episode reward: 3.5000,                 loss: nan
env2_second_0:                 episode reward: -3.5000,                 loss: nan
env3_first_0:                 episode reward: 3.0500,                 loss: nan
env3_second_0:                 episode reward: -3.0500,                 loss: nan
env4_first_0:                 episode reward: 2.7500,                 loss: nan
env4_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.6176s / 18002.2796 s
env0_first_0:                 episode reward: 1.2000,                 loss: 1.1975
env0_second_0:                 episode reward: -1.2000,                 loss: nan
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
env2_first_0:                 episode reward: 4.6000,                 loss: nan
env2_second_0:                 episode reward: -4.6000,                 loss: nan
env3_first_0:                 episode reward: 2.8500,                 loss: nan
env3_second_0:                 episode reward: -2.8500,                 loss: nan
env4_first_0:                 episode reward: 5.7500,                 loss: nan
env4_second_0:                 episode reward: -5.7500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.7829s / 18079.0625 s
env0_first_0:                 episode reward: 3.6500,                 loss: 1.1612
env0_second_0:                 episode reward: -3.6500,                 loss: nan
env1_first_0:                 episode reward: 5.0000,                 loss: nan
env1_second_0:                 episode reward: -5.0000,                 loss: nan
env2_first_0:                 episode reward: 3.9000,                 loss: nan
env2_second_0:                 episode reward: -3.9000,                 loss: nan
env3_first_0:                 episode reward: 4.3000,                 loss: nan
env3_second_0:                 episode reward: -4.3000,                 loss: nan
env4_first_0:                 episode reward: 2.7500,                 loss: nan
env4_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3832s / 18156.4458 s
env0_first_0:                 episode reward: 1.9500,                 loss: 1.0731
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
env2_first_0:                 episode reward: 5.1000,                 loss: nan
env2_second_0:                 episode reward: -5.1000,                 loss: nan
env3_first_0:                 episode reward: 5.0000,                 loss: nan
env3_second_0:                 episode reward: -5.0000,                 loss: nan
env4_first_0:                 episode reward: 5.6500,                 loss: nan
env4_second_0:                 episode reward: -5.6500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.0045s / 18233.4503 s
env0_first_0:                 episode reward: 2.6000,                 loss: 1.2300
env0_second_0:                 episode reward: -2.6000,                 loss: nan
env1_first_0:                 episode reward: 5.0000,                 loss: nan
env1_second_0:                 episode reward: -5.0000,                 loss: nan
env2_first_0:                 episode reward: 6.2500,                 loss: nan
env2_second_0:                 episode reward: -6.2500,                 loss: nan
env3_first_0:                 episode reward: 3.4000,                 loss: nan
env3_second_0:                 episode reward: -3.4000,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.1061s / 18312.5564 s
env0_first_0:                 episode reward: 1.9500,                 loss: 1.2697
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 4.7500,                 loss: nan
env3_second_0:                 episode reward: -4.7500,                 loss: nan
env4_first_0:                 episode reward: 2.2500,                 loss: nan
env4_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8798s / 18390.4362 s
env0_first_0:                 episode reward: 3.9000,                 loss: 1.3005
env0_second_0:                 episode reward: -3.9000,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 4.9500,                 loss: nan
env2_second_0:                 episode reward: -4.9500,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 4.2000,                 loss: nan
env4_second_0:                 episode reward: -4.2000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.8421s / 18469.2783 s
env0_first_0:                 episode reward: 4.6000,                 loss: 1.3609
env0_second_0:                 episode reward: -4.6000,                 loss: nan
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 2.7000,                 loss: nan
env3_second_0:                 episode reward: -2.7000,                 loss: nan
env4_first_0:                 episode reward: 0.5500,                 loss: nan
env4_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.2615s / 18546.5398 s
env0_first_0:                 episode reward: 3.8500,                 loss: 1.4321
env0_second_0:                 episode reward: -3.8500,                 loss: nan
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
env2_first_0:                 episode reward: 3.7000,                 loss: nan
env2_second_0:                 episode reward: -3.7000,                 loss: nan
env3_first_0:                 episode reward: 4.5000,                 loss: nan
env3_second_0:                 episode reward: -4.5000,                 loss: nan
env4_first_0:                 episode reward: 2.7000,                 loss: nan
env4_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8122s / 18624.3520 s
env0_first_0:                 episode reward: 2.9500,                 loss: 1.6627
env0_second_0:                 episode reward: -2.9500,                 loss: nan
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: 1.9000,                 loss: nan
env3_second_0:                 episode reward: -1.9000,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.2245s / 18702.5765 s
env0_first_0:                 episode reward: 1.2000,                 loss: 1.5103
env0_second_0:                 episode reward: -1.2000,                 loss: nan
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
env2_first_0:                 episode reward: -2.4500,                 loss: nan
env2_second_0:                 episode reward: 2.4500,                 loss: nan
env3_first_0:                 episode reward: -0.8000,                 loss: nan
env3_second_0:                 episode reward: 0.8000,                 loss: nan
env4_first_0:                 episode reward: -2.8000,                 loss: nan
env4_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.7501s / 18780.3266 s
env0_first_0:                 episode reward: -1.5500,                 loss: 1.6943
env0_second_0:                 episode reward: 1.5500,                 loss: nan
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: -2.9000,                 loss: nan
env2_second_0:                 episode reward: 2.9000,                 loss: nan
env3_first_0:                 episode reward: -3.2500,                 loss: nan
env3_second_0:                 episode reward: 3.2500,                 loss: nan
env4_first_0:                 episode reward: -2.1000,                 loss: nan
env4_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.7791s / 18857.1056 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.4929
env0_second_0:                 episode reward: 4.3000,                 loss: nan
env1_first_0:                 episode reward: -6.5000,                 loss: nan
env1_second_0:                 episode reward: 6.5000,                 loss: nan
env2_first_0:                 episode reward: -5.9000,                 loss: nan
env2_second_0:                 episode reward: 5.9000,                 loss: nan
env3_first_0:                 episode reward: -4.1500,                 loss: nan
env3_second_0:                 episode reward: 4.1500,                 loss: nan
env4_first_0:                 episode reward: -6.3000,                 loss: nan
env4_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3700s / 18934.4756 s
env0_first_0:                 episode reward: -4.6500,                 loss: 0.5667
env0_second_0:                 episode reward: 4.6500,                 loss: nan
env1_first_0:                 episode reward: -4.6000,                 loss: nan
env1_second_0:                 episode reward: 4.6000,                 loss: nan
env2_first_0:                 episode reward: -4.7500,                 loss: nan
env2_second_0:                 episode reward: 4.7500,                 loss: nan
env3_first_0:                 episode reward: -5.5500,                 loss: nan
env3_second_0:                 episode reward: 5.5500,                 loss: nan
env4_first_0:                 episode reward: -4.9500,                 loss: nan
env4_second_0:                 episode reward: 4.9500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.6052s / 19013.0808 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.6089
env0_second_0:                 episode reward: 4.8000,                 loss: nan
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
env2_first_0:                 episode reward: -6.8000,                 loss: nan
env2_second_0:                 episode reward: 6.8000,                 loss: nan
env3_first_0:                 episode reward: -5.1000,                 loss: nan
env3_second_0:                 episode reward: 5.1000,                 loss: nan
env4_first_0:                 episode reward: -4.9500,                 loss: nan
env4_second_0:                 episode reward: 4.9500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6078s / 19090.6887 s
env0_first_0:                 episode reward: -5.5000,                 loss: 1.5156
env0_second_0:                 episode reward: 5.5000,                 loss: nan
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
env2_first_0:                 episode reward: -4.0500,                 loss: nan
env2_second_0:                 episode reward: 4.0500,                 loss: nan
env3_first_0:                 episode reward: -3.2500,                 loss: nan
env3_second_0:                 episode reward: 3.2500,                 loss: nan
env4_first_0:                 episode reward: -3.7000,                 loss: nan
env4_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4327s / 19167.1214 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.8752
env0_second_0:                 episode reward: 4.4500,                 loss: nan
env1_first_0:                 episode reward: -5.4000,                 loss: nan
env1_second_0:                 episode reward: 5.4000,                 loss: nan
env2_first_0:                 episode reward: -5.8500,                 loss: nan
env2_second_0:                 episode reward: 5.8500,                 loss: nan
env3_first_0:                 episode reward: -4.4500,                 loss: nan
env3_second_0:                 episode reward: 4.4500,                 loss: nan
env4_first_0:                 episode reward: -4.7500,                 loss: nan
env4_second_0:                 episode reward: 4.7500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.6603s / 19243.7817 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.8528
env0_second_0:                 episode reward: 3.7000,                 loss: nan
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
env2_first_0:                 episode reward: -4.7000,                 loss: nan
env2_second_0:                 episode reward: 4.7000,                 loss: nan
env3_first_0:                 episode reward: -5.1500,                 loss: nan
env3_second_0:                 episode reward: 5.1500,                 loss: nan
env4_first_0:                 episode reward: -4.0000,                 loss: nan
env4_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.0114s / 19319.7931 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.7790
env0_second_0:                 episode reward: 3.7500,                 loss: nan
env1_first_0:                 episode reward: -4.7500,                 loss: nan
env1_second_0:                 episode reward: 4.7500,                 loss: nan
env2_first_0:                 episode reward: -5.4500,                 loss: nan
env2_second_0:                 episode reward: 5.4500,                 loss: nan
env3_first_0:                 episode reward: -4.0500,                 loss: nan
env3_second_0:                 episode reward: 4.0500,                 loss: nan
env4_first_0:                 episode reward: -4.1000,                 loss: nan
env4_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.7104s / 19395.5035 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.3301
env0_second_0:                 episode reward: 4.4500,                 loss: nan
env1_first_0:                 episode reward: -5.5500,                 loss: nan
env1_second_0:                 episode reward: 5.5500,                 loss: nan
env2_first_0:                 episode reward: -6.1500,                 loss: nan
env2_second_0:                 episode reward: 6.1500,                 loss: nan
env3_first_0:                 episode reward: -5.9500,                 loss: nan
env3_second_0:                 episode reward: 5.9500,                 loss: nan
env4_first_0:                 episode reward: -5.1000,                 loss: nan
env4_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.2619s / 19473.7654 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.4481
env0_second_0:                 episode reward: 4.3000,                 loss: nan
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
env2_first_0:                 episode reward: -6.3000,                 loss: nan
env2_second_0:                 episode reward: 6.3000,                 loss: nan
env3_first_0:                 episode reward: -5.9000,                 loss: nan
env3_second_0:                 episode reward: 5.9000,                 loss: nan
env4_first_0:                 episode reward: -4.8500,                 loss: nan
env4_second_0:                 episode reward: 4.8500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.5436s / 19552.3089 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.7712
env0_second_0:                 episode reward: 5.7000,                 loss: nan
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
env2_first_0:                 episode reward: -3.8000,                 loss: nan
env2_second_0:                 episode reward: 3.8000,                 loss: nan
env3_first_0:                 episode reward: -4.9000,                 loss: nan
env3_second_0:                 episode reward: 4.9000,                 loss: nan
env4_first_0:                 episode reward: -6.1000,                 loss: nan
env4_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.7156s / 19630.0246 s
env0_first_0:                 episode reward: -6.7000,                 loss: -0.1296
env0_second_0:                 episode reward: 6.7000,                 loss: nan
env1_first_0:                 episode reward: -6.6000,                 loss: nan
env1_second_0:                 episode reward: 6.6000,                 loss: nan
env2_first_0:                 episode reward: -6.9000,                 loss: nan
env2_second_0:                 episode reward: 6.9000,                 loss: nan
env3_first_0:                 episode reward: -6.6500,                 loss: nan
env3_second_0:                 episode reward: 6.6500,                 loss: nan
env4_first_0:                 episode reward: -6.8500,                 loss: nan
env4_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6122s / 19707.6368 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.9126
env0_second_0:                 episode reward: 1.5500,                 loss: nan
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
env3_first_0:                 episode reward: -2.2000,                 loss: nan
env3_second_0:                 episode reward: 2.2000,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1292s / 19784.7660 s
env0_first_0:                 episode reward: -3.5500,                 loss: 1.8651
env0_second_0:                 episode reward: 3.5500,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -4.4500,                 loss: nan
env2_second_0:                 episode reward: 4.4500,                 loss: nan
env3_first_0:                 episode reward: -1.3500,                 loss: nan
env3_second_0:                 episode reward: 1.3500,                 loss: nan
env4_first_0:                 episode reward: -1.7500,                 loss: nan
env4_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.9329s / 19862.6989 s
env0_first_0:                 episode reward: 0.0000,                 loss: 1.9685
env0_second_0:                 episode reward: 0.0000,                 loss: nan
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: -2.6000,                 loss: nan
env2_second_0:                 episode reward: 2.6000,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: -1.7500,                 loss: nan
env4_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.0067s / 19940.7056 s
env0_first_0:                 episode reward: 1.4500,                 loss: 2.0307
env0_second_0:                 episode reward: -1.4500,                 loss: nan
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: -1.4500,                 loss: nan
env3_second_0:                 episode reward: 1.4500,                 loss: nan
env4_first_0:                 episode reward: -1.1500,                 loss: nan
env4_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3737s / 20018.0793 s
env0_first_0:                 episode reward: -1.7500,                 loss: 1.6870
env0_second_0:                 episode reward: 1.7500,                 loss: nan
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: -3.4500,                 loss: nan
env2_second_0:                 episode reward: 3.4500,                 loss: nan
env3_first_0:                 episode reward: -2.0000,                 loss: nan
env3_second_0:                 episode reward: 2.0000,                 loss: nan
env4_first_0:                 episode reward: -2.2500,                 loss: nan
env4_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.1410s / 20094.2203 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.7903
env0_second_0:                 episode reward: 4.5000,                 loss: nan
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
env2_first_0:                 episode reward: -4.7500,                 loss: nan
env2_second_0:                 episode reward: 4.7500,                 loss: nan
env3_first_0:                 episode reward: -5.6000,                 loss: nan
env3_second_0:                 episode reward: 5.6000,                 loss: nan
env4_first_0:                 episode reward: -5.5500,                 loss: nan
env4_second_0:                 episode reward: 5.5500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8950s / 20172.1153 s
env0_first_0:                 episode reward: -1.2000,                 loss: 1.2683
env0_second_0:                 episode reward: 1.2000,                 loss: nan
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
env3_first_0:                 episode reward: -2.4000,                 loss: nan
env3_second_0:                 episode reward: 2.4000,                 loss: nan
env4_first_0:                 episode reward: -1.9000,                 loss: nan
env4_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.1710s / 20250.2863 s
env0_first_0:                 episode reward: -3.9000,                 loss: 1.6543
env0_second_0:                 episode reward: 3.9000,                 loss: nan
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
env2_first_0:                 episode reward: -2.8000,                 loss: nan
env2_second_0:                 episode reward: 2.8000,                 loss: nan
env3_first_0:                 episode reward: -1.2000,                 loss: nan
env3_second_0:                 episode reward: 1.2000,                 loss: nan
env4_first_0:                 episode reward: -2.5000,                 loss: nan
env4_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.9467s / 20329.2330 s
env0_first_0:                 episode reward: 1.0000,                 loss: 1.0967
env0_second_0:                 episode reward: -1.0000,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 2.0000,                 loss: nan
env3_second_0:                 episode reward: -2.0000,                 loss: nan
env4_first_0:                 episode reward: 2.7500,                 loss: nan
env4_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.5102s / 20406.7432 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.3112
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.2699s / 20484.0132 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.2807
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.8598s / 20562.8729 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.2659
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.5817s / 20641.4546 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.2381
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.2796s / 20718.7342 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.1873
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3767s / 20796.1109 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.1425
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5259s / 20872.6368 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.1360
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3102s / 20949.9470 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.1468
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.7387s / 21027.6857 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.1258
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.0766s / 21105.7622 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.1454
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4041s / 21183.1664 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.1207
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.7432s / 21260.9095 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.1406
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1827s / 21338.0922 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.1334
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.9407s / 21416.0328 s
env0_first_0:                 episode reward: 7.9500,                 loss: 0.0009
env0_second_0:                 episode reward: -7.9500,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6709s / 21493.7038 s
env0_first_0:                 episode reward: 1.9500,                 loss: 1.7738
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
env3_first_0:                 episode reward: 0.8500,                 loss: nan
env3_second_0:                 episode reward: -0.8500,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4589s / 21571.1627 s
env0_first_0:                 episode reward: 2.6000,                 loss: 1.4978
env0_second_0:                 episode reward: -2.6000,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 3.5500,                 loss: nan
env2_second_0:                 episode reward: -3.5500,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 3.7500,                 loss: nan
env4_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.1933s / 21649.3560 s
env0_first_0:                 episode reward: -0.1500,                 loss: 1.2298
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
env3_first_0:                 episode reward: -1.7000,                 loss: nan
env3_second_0:                 episode reward: 1.7000,                 loss: nan
env4_first_0:                 episode reward: -2.0500,                 loss: nan
env4_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6148s / 21726.9708 s
env0_first_0:                 episode reward: 4.8000,                 loss: 0.4697
env0_second_0:                 episode reward: -4.8000,                 loss: nan
env1_first_0:                 episode reward: 3.8500,                 loss: nan
env1_second_0:                 episode reward: -3.8500,                 loss: nan
env2_first_0:                 episode reward: 4.4500,                 loss: nan
env2_second_0:                 episode reward: -4.4500,                 loss: nan
env3_first_0:                 episode reward: 5.2000,                 loss: nan
env3_second_0:                 episode reward: -5.2000,                 loss: nan
env4_first_0:                 episode reward: 4.7500,                 loss: nan
env4_second_0:                 episode reward: -4.7500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4380s / 21804.4088 s
env0_first_0:                 episode reward: 1.1500,                 loss: 1.3649
env0_second_0:                 episode reward: -1.1500,                 loss: nan
env1_first_0:                 episode reward: 5.0500,                 loss: nan
env1_second_0:                 episode reward: -5.0500,                 loss: nan
env2_first_0:                 episode reward: 3.0000,                 loss: nan
env2_second_0:                 episode reward: -3.0000,                 loss: nan
env3_first_0:                 episode reward: 1.2000,                 loss: nan
env3_second_0:                 episode reward: -1.2000,                 loss: nan
env4_first_0:                 episode reward: 3.8000,                 loss: nan
env4_second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.7710s / 21882.1799 s
env0_first_0:                 episode reward: 5.8500,                 loss: 0.3655
env0_second_0:                 episode reward: -5.8500,                 loss: nan
env1_first_0:                 episode reward: 6.2500,                 loss: nan
env1_second_0:                 episode reward: -6.2500,                 loss: nan
env2_first_0:                 episode reward: 6.5500,                 loss: nan
env2_second_0:                 episode reward: -6.5500,                 loss: nan
env3_first_0:                 episode reward: 5.1500,                 loss: nan
env3_second_0:                 episode reward: -5.1500,                 loss: nan
env4_first_0:                 episode reward: 5.9500,                 loss: nan
env4_second_0:                 episode reward: -5.9500,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4023s / 21959.5821 s
env0_first_0:                 episode reward: 0.4500,                 loss: 1.0231
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: 1.3000,                 loss: nan
env3_second_0:                 episode reward: -1.3000,                 loss: nan
env4_first_0:                 episode reward: 1.0500,                 loss: nan
env4_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.0578s / 22036.6399 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.2958
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 7.4500,                 loss: nan
env3_second_0:                 episode reward: -7.4500,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.4489s / 22115.0888 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.3493
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.4585s / 22193.5473 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.2118
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 7.6500,                 loss: nan
env4_second_0:                 episode reward: -7.6500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.2196s / 22271.7669 s
env0_first_0:                 episode reward: 7.4000,                 loss: -0.1243
env0_second_0:                 episode reward: -7.4000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.6799s / 22350.4467 s
env0_first_0:                 episode reward: 2.7500,                 loss: 1.4507
env0_second_0:                 episode reward: -2.7500,                 loss: nan
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
env3_first_0:                 episode reward: 2.2500,                 loss: nan
env3_second_0:                 episode reward: -2.2500,                 loss: nan
env4_first_0:                 episode reward: 3.7000,                 loss: nan
env4_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.0879s / 22427.5346 s
env0_first_0:                 episode reward: 1.0000,                 loss: 1.7773
env0_second_0:                 episode reward: -1.0000,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 2.5500,                 loss: nan
env2_second_0:                 episode reward: -2.5500,                 loss: nan
env3_first_0:                 episode reward: 3.1500,                 loss: nan
env3_second_0:                 episode reward: -3.1500,                 loss: nan
env4_first_0:                 episode reward: 4.2000,                 loss: nan
env4_second_0:                 episode reward: -4.2000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.5464s / 22506.0811 s
env0_first_0:                 episode reward: 1.0000,                 loss: 1.2645
env0_second_0:                 episode reward: -1.0000,                 loss: nan
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: 0.9000,                 loss: nan
env2_second_0:                 episode reward: -0.9000,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.5511s / 22584.6321 s
env0_first_0:                 episode reward: 0.2000,                 loss: 1.0898
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
env3_first_0:                 episode reward: 1.4500,                 loss: nan
env3_second_0:                 episode reward: -1.4500,                 loss: nan
env4_first_0:                 episode reward: 2.3500,                 loss: nan
env4_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4215s / 22662.0536 s
env0_first_0:                 episode reward: 0.3000,                 loss: 1.0410
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.8000,                 loss: nan
env4_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.2464s / 22740.3001 s
env0_first_0:                 episode reward: -0.2000,                 loss: 1.0176
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: 2.4000,                 loss: nan
env3_second_0:                 episode reward: -2.4000,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.0006s / 22817.3007 s
env0_first_0:                 episode reward: 2.6500,                 loss: 1.0091
env0_second_0:                 episode reward: -2.6500,                 loss: nan
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.6455s / 22895.9461 s
env0_first_0:                 episode reward: 2.0500,                 loss: 1.1065
env0_second_0:                 episode reward: -2.0500,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 1.7500,                 loss: nan
env4_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.1650s / 22974.1111 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.8202
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
env3_first_0:                 episode reward: 1.2000,                 loss: nan
env3_second_0:                 episode reward: -1.2000,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.7828s / 23051.8939 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.6632
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.9554s / 23129.8493 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.7828
env0_second_0:                 episode reward: -1.4500,                 loss: nan
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
env2_first_0:                 episode reward: 0.5500,                 loss: nan
env2_second_0:                 episode reward: -0.5500,                 loss: nan
env3_first_0:                 episode reward: 2.0000,                 loss: nan
env3_second_0:                 episode reward: -2.0000,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4050s / 23207.2543 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.8117
env0_second_0:                 episode reward: -1.8500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.6112s / 23283.8655 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.8371
env0_second_0:                 episode reward: -1.2000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.4400s / 23362.3055 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.5893
env0_second_0:                 episode reward: -1.1500,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.1837s / 23440.4892 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.7200
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.6615s / 23517.1506 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.9146
env0_second_0:                 episode reward: -3.1500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 0.8500,                 loss: nan
env4_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.9140s / 23596.0646 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.6537
env0_second_0:                 episode reward: -0.6500,                 loss: nan
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: 0.7000,                 loss: nan
env3_second_0:                 episode reward: -0.7000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8669s / 23673.9315 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.7489
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 1.0000,                 loss: nan
env4_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.3899s / 23750.3214 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.7573
env0_second_0:                 episode reward: -1.3500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.6500,                 loss: nan
env3_second_0:                 episode reward: -0.6500,                 loss: nan
env4_first_0:                 episode reward: 1.0500,                 loss: nan
env4_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.3573s / 23826.6787 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.9414
env0_second_0:                 episode reward: -0.6500,                 loss: nan
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
env3_first_0:                 episode reward: 1.3000,                 loss: nan
env3_second_0:                 episode reward: -1.3000,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6375s / 23904.3162 s
env0_first_0:                 episode reward: 5.4500,                 loss: 0.3095
env0_second_0:                 episode reward: -5.4500,                 loss: nan
env1_first_0:                 episode reward: 5.9000,                 loss: nan
env1_second_0:                 episode reward: -5.9000,                 loss: nan
env2_first_0:                 episode reward: 5.6500,                 loss: nan
env2_second_0:                 episode reward: -5.6500,                 loss: nan
env3_first_0:                 episode reward: 5.2500,                 loss: nan
env3_second_0:                 episode reward: -5.2500,                 loss: nan
env4_first_0:                 episode reward: 5.0000,                 loss: nan
env4_second_0:                 episode reward: -5.0000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.1346s / 23983.4509 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.3010
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.6609s / 24060.1117 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.2584
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5336s / 24136.6453 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.2639
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.6250s / 24213.2703 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.2581
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6347s / 24290.9050 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.1992
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.2086s / 24369.1136 s
env0_first_0:                 episode reward: 6.0500,                 loss: 0.4423
env0_second_0:                 episode reward: -6.0500,                 loss: nan
env1_first_0:                 episode reward: 5.6000,                 loss: nan
env1_second_0:                 episode reward: -5.6000,                 loss: nan
env2_first_0:                 episode reward: 5.6500,                 loss: nan
env2_second_0:                 episode reward: -5.6500,                 loss: nan
env3_first_0:                 episode reward: 5.6000,                 loss: nan
env3_second_0:                 episode reward: -5.6000,                 loss: nan
env4_first_0:                 episode reward: 5.6500,                 loss: nan
env4_second_0:                 episode reward: -5.6500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3446s / 24446.4582 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.9934
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.9500,                 loss: nan
env4_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6840s / 24524.1421 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.9989
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 1.4000,                 loss: nan
env2_second_0:                 episode reward: -1.4000,                 loss: nan
env3_first_0:                 episode reward: 0.8500,                 loss: nan
env3_second_0:                 episode reward: -0.8500,                 loss: nan
env4_first_0:                 episode reward: 1.4000,                 loss: nan
env4_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8221s / 24601.9642 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.9467
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 2.0500,                 loss: nan
env3_second_0:                 episode reward: -2.0500,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8421s / 24679.8063 s
env0_first_0:                 episode reward: 1.5000,                 loss: 1.1026
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
env2_first_0:                 episode reward: 1.3500,                 loss: nan
env2_second_0:                 episode reward: -1.3500,                 loss: nan
env3_first_0:                 episode reward: 2.1000,                 loss: nan
env3_second_0:                 episode reward: -2.1000,                 loss: nan
env4_first_0:                 episode reward: 1.9500,                 loss: nan
env4_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.7547s / 24756.5610 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.6528
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3228s / 24833.8838 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.5541
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.9002s / 24909.7841 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.5700
env0_second_0:                 episode reward: -1.0500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.6000,                 loss: nan
env4_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4101s / 24986.1942 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.9147
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6382s / 25063.8324 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.7546
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 1.4500,                 loss: nan
env3_second_0:                 episode reward: -1.4500,                 loss: nan
env4_first_0:                 episode reward: 1.3000,                 loss: nan
env4_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6374s / 25141.4698 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.5587
env0_second_0:                 episode reward: -0.9000,                 loss: nan
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
env2_first_0:                 episode reward: 1.1500,                 loss: nan
env2_second_0:                 episode reward: -1.1500,                 loss: nan
env3_first_0:                 episode reward: 0.9000,                 loss: nan
env3_second_0:                 episode reward: -0.9000,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.6415s / 25218.1113 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.7134
env0_second_0:                 episode reward: -0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: 1.1000,                 loss: nan
env2_second_0:                 episode reward: -1.1000,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.1766s / 25294.2879 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.7440
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.0902s / 25372.3781 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.7654
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: 0.5500,                 loss: nan
env3_second_0:                 episode reward: -0.5500,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4546s / 25449.8327 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.7255
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 0.6500,                 loss: nan
env3_second_0:                 episode reward: -0.6500,                 loss: nan
env4_first_0:                 episode reward: 1.2000,                 loss: nan
env4_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.5386s / 25528.3712 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.7178
env0_second_0:                 episode reward: -2.1500,                 loss: nan
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
env2_first_0:                 episode reward: 2.6500,                 loss: nan
env2_second_0:                 episode reward: -2.6500,                 loss: nan
env3_first_0:                 episode reward: 1.3000,                 loss: nan
env3_second_0:                 episode reward: -1.3000,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.9215s / 25604.2927 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.6770
env0_second_0:                 episode reward: -3.5500,                 loss: nan
env1_first_0:                 episode reward: 4.4000,                 loss: nan
env1_second_0:                 episode reward: -4.4000,                 loss: nan
env2_first_0:                 episode reward: 4.6500,                 loss: nan
env2_second_0:                 episode reward: -4.6500,                 loss: nan
env3_first_0:                 episode reward: 4.1000,                 loss: nan
env3_second_0:                 episode reward: -4.1000,                 loss: nan
env4_first_0:                 episode reward: 4.4500,                 loss: nan
env4_second_0:                 episode reward: -4.4500,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.7825s / 25681.0752 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.6886
env0_second_0:                 episode reward: -0.9500,                 loss: nan
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 1.8000,                 loss: nan
env4_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.6153s / 25757.6905 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.6505
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.9605s / 25834.6510 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.7113
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 1.4000,                 loss: nan
env4_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.3492s / 25913.0002 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.5046
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -1.2500,                 loss: nan
env3_second_0:                 episode reward: 1.2500,                 loss: nan
env4_first_0:                 episode reward: -1.5500,                 loss: nan
env4_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.6285s / 25989.6287 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.5035
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6409s / 26067.2696 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.4168
env0_second_0:                 episode reward: 1.1500,                 loss: nan
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -1.4000,                 loss: nan
env4_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3429s / 26144.6125 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.4346
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
env3_first_0:                 episode reward: -0.7500,                 loss: nan
env3_second_0:                 episode reward: 0.7500,                 loss: nan
env4_first_0:                 episode reward: -1.0500,                 loss: nan
env4_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5180s / 26221.1305 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.5745
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 1.2000,                 loss: nan
env2_second_0:                 episode reward: -1.2000,                 loss: nan
env3_first_0:                 episode reward: 0.8000,                 loss: nan
env3_second_0:                 episode reward: -0.8000,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.2640s / 26300.3945 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.5401
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.9000,                 loss: nan
env3_second_0:                 episode reward: 0.9000,                 loss: nan
env4_first_0:                 episode reward: -1.4500,                 loss: nan
env4_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.0138s / 26378.4083 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.5766
env0_second_0:                 episode reward: 2.2000,                 loss: nan
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
env2_first_0:                 episode reward: -0.8000,                 loss: nan
env2_second_0:                 episode reward: 0.8000,                 loss: nan
env3_first_0:                 episode reward: -1.8000,                 loss: nan
env3_second_0:                 episode reward: 1.8000,                 loss: nan
env4_first_0:                 episode reward: -1.3500,                 loss: nan
env4_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.7233s / 26455.1316 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.3645
env0_second_0:                 episode reward: 1.4500,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
env3_first_0:                 episode reward: -0.8000,                 loss: nan
env3_second_0:                 episode reward: 0.8000,                 loss: nan
env4_first_0:                 episode reward: -1.0500,                 loss: nan
env4_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.1780s / 26531.3096 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2216
env0_second_0:                 episode reward: 1.1000,                 loss: nan
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
env3_first_0:                 episode reward: -0.7000,                 loss: nan
env3_second_0:                 episode reward: 0.7000,                 loss: nan
env4_first_0:                 episode reward: -1.4500,                 loss: nan
env4_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5659s / 26607.8755 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.2746
env0_second_0:                 episode reward: 1.5000,                 loss: nan
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
env3_first_0:                 episode reward: -1.6000,                 loss: nan
env3_second_0:                 episode reward: 1.6000,                 loss: nan
env4_first_0:                 episode reward: -2.0000,                 loss: nan
env4_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8107s / 26685.6862 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.3519
env0_second_0:                 episode reward: 1.6000,                 loss: nan
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.8000,                 loss: nan
env4_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.0385s / 26763.7247 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.4305
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3714s / 26841.0961 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.5469
env0_second_0:                 episode reward: 2.2500,                 loss: nan
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
env3_first_0:                 episode reward: -1.0500,                 loss: nan
env3_second_0:                 episode reward: 1.0500,                 loss: nan
env4_first_0:                 episode reward: -1.2500,                 loss: nan
env4_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3411s / 26918.4371 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.6606
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -1.8000,                 loss: nan
env4_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.5419s / 26996.9791 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.7224
env0_second_0:                 episode reward: 1.6500,                 loss: nan
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: -1.9500,                 loss: nan
env2_second_0:                 episode reward: 1.9500,                 loss: nan
env3_first_0:                 episode reward: -1.7500,                 loss: nan
env3_second_0:                 episode reward: 1.7500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.1143s / 27075.0933 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.6590
env0_second_0:                 episode reward: 2.5500,                 loss: nan
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
env2_first_0:                 episode reward: -2.7500,                 loss: nan
env2_second_0:                 episode reward: 2.7500,                 loss: nan
env3_first_0:                 episode reward: -2.2000,                 loss: nan
env3_second_0:                 episode reward: 2.2000,                 loss: nan
env4_first_0:                 episode reward: -0.8000,                 loss: nan
env4_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.9884s / 27153.0818 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.6632
env0_second_0:                 episode reward: 2.6500,                 loss: nan
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
env2_first_0:                 episode reward: -2.0500,                 loss: nan
env2_second_0:                 episode reward: 2.0500,                 loss: nan
env3_first_0:                 episode reward: -1.4500,                 loss: nan
env3_second_0:                 episode reward: 1.4500,                 loss: nan
env4_first_0:                 episode reward: -2.1500,                 loss: nan
env4_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.9936s / 27231.0754 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.6281
env0_second_0:                 episode reward: 1.2000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -2.8000,                 loss: nan
env2_second_0:                 episode reward: 2.8000,                 loss: nan
env3_first_0:                 episode reward: -2.6500,                 loss: nan
env3_second_0:                 episode reward: 2.6500,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.2817s / 27308.3571 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.7914
env0_second_0:                 episode reward: 1.1500,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -1.2000,                 loss: nan
env4_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.0249s / 27385.3820 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.7733
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.7785s / 27463.1605 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.5003
env0_second_0:                 episode reward: 2.6000,                 loss: nan
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
env2_first_0:                 episode reward: -1.8000,                 loss: nan
env2_second_0:                 episode reward: 1.8000,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: -1.4500,                 loss: nan
env4_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3166s / 27540.4771 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.4266
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
env2_first_0:                 episode reward: -2.0500,                 loss: nan
env2_second_0:                 episode reward: 2.0500,                 loss: nan
env3_first_0:                 episode reward: -2.0500,                 loss: nan
env3_second_0:                 episode reward: 2.0500,                 loss: nan
env4_first_0:                 episode reward: -1.8500,                 loss: nan
env4_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.7728s / 27616.2499 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.3096
env0_second_0:                 episode reward: 2.3500,                 loss: nan
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -1.9500,                 loss: nan
env2_second_0:                 episode reward: 1.9500,                 loss: nan
env3_first_0:                 episode reward: -2.3000,                 loss: nan
env3_second_0:                 episode reward: 2.3000,                 loss: nan
env4_first_0:                 episode reward: -1.8000,                 loss: nan
env4_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6061s / 27693.8560 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.3689
env0_second_0:                 episode reward: 2.0500,                 loss: nan
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
env2_first_0:                 episode reward: -1.7000,                 loss: nan
env2_second_0:                 episode reward: 1.7000,                 loss: nan
env3_first_0:                 episode reward: -2.4500,                 loss: nan
env3_second_0:                 episode reward: 2.4500,                 loss: nan
env4_first_0:                 episode reward: -1.6000,                 loss: nan
env4_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.9190s / 27771.7750 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.4745
env0_second_0:                 episode reward: 1.1000,                 loss: nan
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
env2_first_0:                 episode reward: -2.3000,                 loss: nan
env2_second_0:                 episode reward: 2.3000,                 loss: nan
env3_first_0:                 episode reward: -1.6000,                 loss: nan
env3_second_0:                 episode reward: 1.6000,                 loss: nan
env4_first_0:                 episode reward: -1.4000,                 loss: nan
env4_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.3824s / 27850.1574 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.3475
env0_second_0:                 episode reward: 1.1000,                 loss: nan
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
env2_first_0:                 episode reward: -1.8000,                 loss: nan
env2_second_0:                 episode reward: 1.8000,                 loss: nan
env3_first_0:                 episode reward: -1.7500,                 loss: nan
env3_second_0:                 episode reward: 1.7500,                 loss: nan
env4_first_0:                 episode reward: -2.2000,                 loss: nan
env4_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.6078s / 27926.7652 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.4331
env0_second_0:                 episode reward: 2.1500,                 loss: nan
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
env2_first_0:                 episode reward: -2.3500,                 loss: nan
env2_second_0:                 episode reward: 2.3500,                 loss: nan
env3_first_0:                 episode reward: -2.7500,                 loss: nan
env3_second_0:                 episode reward: 2.7500,                 loss: nan
env4_first_0:                 episode reward: -2.7500,                 loss: nan
env4_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.0728s / 28003.8380 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.5491
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
env3_first_0:                 episode reward: -1.7500,                 loss: nan
env3_second_0:                 episode reward: 1.7500,                 loss: nan
env4_first_0:                 episode reward: -1.1000,                 loss: nan
env4_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.7003s / 28080.5383 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.4338
env0_second_0:                 episode reward: 1.9000,                 loss: nan
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
env3_first_0:                 episode reward: -2.4500,                 loss: nan
env3_second_0:                 episode reward: 2.4500,                 loss: nan
env4_first_0:                 episode reward: -2.5500,                 loss: nan
env4_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.5922s / 28156.1305 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.4904
env0_second_0:                 episode reward: 1.8000,                 loss: nan
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
env2_first_0:                 episode reward: -1.7500,                 loss: nan
env2_second_0:                 episode reward: 1.7500,                 loss: nan
env3_first_0:                 episode reward: -2.3000,                 loss: nan
env3_second_0:                 episode reward: 2.3000,                 loss: nan
env4_first_0:                 episode reward: -1.2500,                 loss: nan
env4_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4315s / 28232.5620 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.6187
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
env3_first_0:                 episode reward: -2.8000,                 loss: nan
env3_second_0:                 episode reward: 2.8000,                 loss: nan
env4_first_0:                 episode reward: -2.3000,                 loss: nan
env4_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.9105s / 28309.4726 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.5782
env0_second_0:                 episode reward: 1.5500,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
env3_first_0:                 episode reward: -1.8500,                 loss: nan
env3_second_0:                 episode reward: 1.8500,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4645s / 28385.9371 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.4425
env0_second_0:                 episode reward: 1.0000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -1.1500,                 loss: nan
env4_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.2838s / 28462.2209 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.5458
env0_second_0:                 episode reward: -1.4500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.5821s / 28541.8030 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.5217
env0_second_0:                 episode reward: -0.6500,                 loss: nan
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.7000,                 loss: nan
env3_second_0:                 episode reward: -0.7000,                 loss: nan
env4_first_0:                 episode reward: -0.7500,                 loss: nan
env4_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.2533s / 28617.0562 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.4475
env0_second_0:                 episode reward: 1.1000,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -1.7000,                 loss: nan
env3_second_0:                 episode reward: 1.7000,                 loss: nan
env4_first_0:                 episode reward: -1.1500,                 loss: nan
env4_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5951s / 28693.6513 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.5154
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
env3_first_0:                 episode reward: -1.6000,                 loss: nan
env3_second_0:                 episode reward: 1.6000,                 loss: nan
env4_first_0:                 episode reward: -1.5000,                 loss: nan
env4_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.1703s / 28769.8216 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.2887
env0_second_0:                 episode reward: 1.9000,                 loss: nan
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -2.1500,                 loss: nan
env2_second_0:                 episode reward: 2.1500,                 loss: nan
env3_first_0:                 episode reward: -2.3000,                 loss: nan
env3_second_0:                 episode reward: 2.3000,                 loss: nan
env4_first_0:                 episode reward: -2.4000,                 loss: nan
env4_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.2768s / 28846.0984 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.5612
env0_second_0:                 episode reward: 1.1000,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
env3_first_0:                 episode reward: -0.9500,                 loss: nan
env3_second_0:                 episode reward: 0.9500,                 loss: nan
env4_first_0:                 episode reward: -0.9500,                 loss: nan
env4_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.3708s / 28922.4691 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.5101
env0_second_0:                 episode reward: 2.2000,                 loss: nan
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -2.1000,                 loss: nan
env4_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4471s / 28998.9162 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.3721
env0_second_0:                 episode reward: 2.4000,                 loss: nan
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
env2_first_0:                 episode reward: -1.5500,                 loss: nan
env2_second_0:                 episode reward: 1.5500,                 loss: nan
env3_first_0:                 episode reward: -1.8500,                 loss: nan
env3_second_0:                 episode reward: 1.8500,                 loss: nan
env4_first_0:                 episode reward: -1.7000,                 loss: nan
env4_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.2834s / 29076.1995 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.4933
env0_second_0:                 episode reward: 1.4000,                 loss: nan
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: -1.7500,                 loss: nan
env2_second_0:                 episode reward: 1.7500,                 loss: nan
env3_first_0:                 episode reward: -1.4000,                 loss: nan
env3_second_0:                 episode reward: 1.4000,                 loss: nan
env4_first_0:                 episode reward: -1.2000,                 loss: nan
env4_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.9823s / 29152.1818 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.4261
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
env3_first_0:                 episode reward: -1.4500,                 loss: nan
env3_second_0:                 episode reward: 1.4500,                 loss: nan
env4_first_0:                 episode reward: -1.1000,                 loss: nan
env4_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.0916s / 29229.2735 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.4653
env0_second_0:                 episode reward: 2.0500,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
env2_first_0:                 episode reward: -2.2500,                 loss: nan
env2_second_0:                 episode reward: 2.2500,                 loss: nan
env3_first_0:                 episode reward: -2.3500,                 loss: nan
env3_second_0:                 episode reward: 2.3500,                 loss: nan
env4_first_0:                 episode reward: -2.4500,                 loss: nan
env4_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.7862s / 29306.0597 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.3719
env0_second_0:                 episode reward: 1.4500,                 loss: nan
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
env3_first_0:                 episode reward: -2.4000,                 loss: nan
env3_second_0:                 episode reward: 2.4000,                 loss: nan
env4_first_0:                 episode reward: -1.6000,                 loss: nan
env4_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.9892s / 29383.0489 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.3059
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
env2_first_0:                 episode reward: -1.5500,                 loss: nan
env2_second_0:                 episode reward: 1.5500,                 loss: nan
env3_first_0:                 episode reward: -2.0500,                 loss: nan
env3_second_0:                 episode reward: 2.0500,                 loss: nan
env4_first_0:                 episode reward: -2.0500,                 loss: nan
env4_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.5821s / 29458.6310 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.3586
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -2.0500,                 loss: nan
env2_second_0:                 episode reward: 2.0500,                 loss: nan
env3_first_0:                 episode reward: -1.6000,                 loss: nan
env3_second_0:                 episode reward: 1.6000,                 loss: nan
env4_first_0:                 episode reward: -2.0000,                 loss: nan
env4_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1021s / 29535.7330 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.5534
env0_second_0:                 episode reward: 1.7500,                 loss: nan
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
env3_first_0:                 episode reward: -1.6500,                 loss: nan
env3_second_0:                 episode reward: 1.6500,                 loss: nan
env4_first_0:                 episode reward: -2.1000,                 loss: nan
env4_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4009s / 29612.1339 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.3212
env0_second_0:                 episode reward: 2.2000,                 loss: nan
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
env2_first_0:                 episode reward: -2.0000,                 loss: nan
env2_second_0:                 episode reward: 2.0000,                 loss: nan
env3_first_0:                 episode reward: -1.6500,                 loss: nan
env3_second_0:                 episode reward: 1.6500,                 loss: nan
env4_first_0:                 episode reward: -2.1500,                 loss: nan
env4_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5265s / 29688.6604 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.3399
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
env2_first_0:                 episode reward: -1.2000,                 loss: nan
env2_second_0:                 episode reward: 1.2000,                 loss: nan
env3_first_0:                 episode reward: -1.4000,                 loss: nan
env3_second_0:                 episode reward: 1.4000,                 loss: nan
env4_first_0:                 episode reward: -1.1000,                 loss: nan
env4_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.5463s / 29766.2068 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.3615
env0_second_0:                 episode reward: 1.8000,                 loss: nan
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
env3_first_0:                 episode reward: -1.4500,                 loss: nan
env3_second_0:                 episode reward: 1.4500,                 loss: nan
env4_first_0:                 episode reward: -2.0500,                 loss: nan
env4_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.6826s / 29841.8894 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.4836
env0_second_0:                 episode reward: 1.2500,                 loss: nan
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
env3_first_0:                 episode reward: -1.9500,                 loss: nan
env3_second_0:                 episode reward: 1.9500,                 loss: nan
env4_first_0:                 episode reward: -2.2000,                 loss: nan
env4_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.9848s / 29918.8742 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.5122
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
env3_first_0:                 episode reward: -1.6500,                 loss: nan
env3_second_0:                 episode reward: 1.6500,                 loss: nan
env4_first_0:                 episode reward: -0.6500,                 loss: nan
env4_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.5145s / 29994.3886 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.5326
env0_second_0:                 episode reward: 1.9000,                 loss: nan
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
env3_first_0:                 episode reward: -2.0500,                 loss: nan
env3_second_0:                 episode reward: 2.0500,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.1071s / 30070.4957 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.3994
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -1.4500,                 loss: nan
env3_second_0:                 episode reward: 1.4500,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4936s / 30147.9893 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.5252
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
env3_first_0:                 episode reward: -0.6000,                 loss: nan
env3_second_0:                 episode reward: 0.6000,                 loss: nan
env4_first_0:                 episode reward: -1.2500,                 loss: nan
env4_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4856s / 30224.4749 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.5962
env0_second_0:                 episode reward: 1.0000,                 loss: nan
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 74.8482s / 30299.3231 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.5683
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -1.2000,                 loss: nan
env4_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.6906s / 30375.0137 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.4469
env0_second_0:                 episode reward: 1.0500,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: -0.9500,                 loss: nan
env4_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5371s / 30451.5508 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.4483
env0_second_0:                 episode reward: 1.0000,                 loss: nan
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -1.2000,                 loss: nan
env3_second_0:                 episode reward: 1.2000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3010s / 30528.8518 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.6169
env0_second_0:                 episode reward: 1.5000,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: -1.6000,                 loss: nan
env4_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.8550s / 30605.7068 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.6763
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.6142s / 30682.3209 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.4910
env0_second_0:                 episode reward: 1.0000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -1.2500,                 loss: nan
env2_second_0:                 episode reward: 1.2500,                 loss: nan
env3_first_0:                 episode reward: -1.0000,                 loss: nan
env3_second_0:                 episode reward: 1.0000,                 loss: nan
env4_first_0:                 episode reward: -0.5000,                 loss: nan
env4_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.2272s / 30759.5482 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.4584
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -1.5500,                 loss: nan
env3_second_0:                 episode reward: 1.5500,                 loss: nan
env4_first_0:                 episode reward: -0.8000,                 loss: nan
env4_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.4106s / 30834.9587 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.5901
env0_second_0:                 episode reward: 1.0500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -1.7500,                 loss: nan
env3_second_0:                 episode reward: 1.7500,                 loss: nan
env4_first_0:                 episode reward: -1.9500,                 loss: nan
env4_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.9066s / 30910.8654 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.4673
env0_second_0:                 episode reward: 1.7500,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -1.2500,                 loss: nan
env2_second_0:                 episode reward: 1.2500,                 loss: nan
env3_first_0:                 episode reward: -1.5000,                 loss: nan
env3_second_0:                 episode reward: 1.5000,                 loss: nan
env4_first_0:                 episode reward: -1.0000,                 loss: nan
env4_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.1589s / 30987.0242 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.5458
env0_second_0:                 episode reward: 1.2000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.6000,                 loss: nan
env4_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.0409s / 31064.0651 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.4220
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -1.4000,                 loss: nan
env2_second_0:                 episode reward: 1.4000,                 loss: nan
env3_first_0:                 episode reward: -0.8500,                 loss: nan
env3_second_0:                 episode reward: 0.8500,                 loss: nan
env4_first_0:                 episode reward: -1.1000,                 loss: nan
env4_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.6494s / 31139.7145 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2924
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
env3_first_0:                 episode reward: -2.1000,                 loss: nan
env3_second_0:                 episode reward: 2.1000,                 loss: nan
env4_first_0:                 episode reward: -0.7500,                 loss: nan
env4_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3469s / 31217.0614 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.4062
env0_second_0:                 episode reward: 1.4000,                 loss: nan
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
env2_first_0:                 episode reward: -1.4000,                 loss: nan
env2_second_0:                 episode reward: 1.4000,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -1.6000,                 loss: nan
env4_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.1406s / 31293.2020 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.5480
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -1.4000,                 loss: nan
env2_second_0:                 episode reward: 1.4000,                 loss: nan
env3_first_0:                 episode reward: -0.8000,                 loss: nan
env3_second_0:                 episode reward: 0.8000,                 loss: nan
env4_first_0:                 episode reward: -1.1500,                 loss: nan
env4_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.1054s / 31369.3075 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.6582
env0_second_0:                 episode reward: 2.5500,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -1.6500,                 loss: nan
env3_second_0:                 episode reward: 1.6500,                 loss: nan
env4_first_0:                 episode reward: -2.4000,                 loss: nan
env4_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.0025s / 31447.3100 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.4595
env0_second_0:                 episode reward: 1.6000,                 loss: nan
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
env2_first_0:                 episode reward: -2.2000,                 loss: nan
env2_second_0:                 episode reward: 2.2000,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -1.6000,                 loss: nan
env4_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.8431s / 31524.1530 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.3836
env0_second_0:                 episode reward: 1.0000,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
env3_first_0:                 episode reward: -1.8000,                 loss: nan
env3_second_0:                 episode reward: 1.8000,                 loss: nan
env4_first_0:                 episode reward: -1.3000,                 loss: nan
env4_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.0118s / 31600.1648 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.4010
env0_second_0:                 episode reward: 1.8000,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
env3_first_0:                 episode reward: -1.3000,                 loss: nan
env3_second_0:                 episode reward: 1.3000,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.9453s / 31677.1101 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.4484
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.7500,                 loss: nan
env3_second_0:                 episode reward: 0.7500,                 loss: nan
env4_first_0:                 episode reward: -0.6500,                 loss: nan
env4_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.2873s / 31753.3974 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.4229
env0_second_0:                 episode reward: 1.1500,                 loss: nan
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
env3_first_0:                 episode reward: -0.7500,                 loss: nan
env3_second_0:                 episode reward: 0.7500,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.6568s / 31830.0542 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.5442
env0_second_0:                 episode reward: 1.2000,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -1.4000,                 loss: nan
env2_second_0:                 episode reward: 1.4000,                 loss: nan
env3_first_0:                 episode reward: -1.4000,                 loss: nan
env3_second_0:                 episode reward: 1.4000,                 loss: nan
env4_first_0:                 episode reward: -1.2000,                 loss: nan
env4_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.0888s / 31908.1430 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.3264
env0_second_0:                 episode reward: 2.4500,                 loss: nan
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -2.0000,                 loss: nan
env2_second_0:                 episode reward: 2.0000,                 loss: nan
env3_first_0:                 episode reward: -1.7000,                 loss: nan
env3_second_0:                 episode reward: 1.7000,                 loss: nan
env4_first_0:                 episode reward: -1.7500,                 loss: nan
env4_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6120s / 31985.7550 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3655
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: -1.2000,                 loss: nan
env4_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.8620s / 32062.6170 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.4099
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -1.3500,                 loss: nan
env2_second_0:                 episode reward: 1.3500,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 79.3580s / 32141.9750 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.3480
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.8000,                 loss: nan
env4_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.4071s / 32220.3820 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.5164
env0_second_0:                 episode reward: 0.6500,                 loss: nan
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -1.2500,                 loss: nan
env3_second_0:                 episode reward: 1.2500,                 loss: nan
env4_first_0:                 episode reward: -1.0500,                 loss: nan
env4_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1405s / 32297.5226 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.3361
env0_second_0:                 episode reward: 1.0000,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.8000,                 loss: nan
env4_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.1871s / 32373.7097 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.4553
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -1.1500,                 loss: nan
env4_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6305s / 32451.3402 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2694
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -1.2500,                 loss: nan
env3_second_0:                 episode reward: 1.2500,                 loss: nan
env4_first_0:                 episode reward: -0.7500,                 loss: nan
env4_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8596s / 32529.1998 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2431
env0_second_0:                 episode reward: 1.0500,                 loss: nan
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.9500,                 loss: nan
env3_second_0:                 episode reward: 0.9500,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.9333s / 32607.1331 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.2457
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
env3_first_0:                 episode reward: -0.8000,                 loss: nan
env3_second_0:                 episode reward: 0.8000,                 loss: nan
env4_first_0:                 episode reward: -1.2000,                 loss: nan
env4_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.7920s / 32685.9251 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3330
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -1.3500,                 loss: nan
env2_second_0:                 episode reward: 1.3500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -1.8500,                 loss: nan
env4_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.3675s / 32762.2926 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.2788
env0_second_0:                 episode reward: 1.5500,                 loss: nan
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -1.3500,                 loss: nan
env2_second_0:                 episode reward: 1.3500,                 loss: nan
env3_first_0:                 episode reward: -1.6000,                 loss: nan
env3_second_0:                 episode reward: 1.6000,                 loss: nan
env4_first_0:                 episode reward: -1.6000,                 loss: nan
env4_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.2986s / 32838.5912 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2455
env0_second_0:                 episode reward: 1.0000,                 loss: nan
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -1.4000,                 loss: nan
env2_second_0:                 episode reward: 1.4000,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: -1.7500,                 loss: nan
env4_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1142s / 32915.7054 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3740
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.7000,                 loss: nan
env3_second_0:                 episode reward: 0.7000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.0353s / 32993.7406 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2615
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.6000,                 loss: nan
env4_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.7814s / 33070.5221 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2471
env0_second_0:                 episode reward: 0.6500,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.9000,                 loss: nan
env3_second_0:                 episode reward: -0.9000,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4186s / 33146.9407 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.1485
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.1213s / 33223.0620 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.1647
env0_second_0:                 episode reward: 0.8500,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
env3_first_0:                 episode reward: -1.8000,                 loss: nan
env3_second_0:                 episode reward: 1.8000,                 loss: nan
env4_first_0:                 episode reward: -0.5000,                 loss: nan
env4_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.6647s / 33299.7267 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0987
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
env2_first_0:                 episode reward: -1.7500,                 loss: nan
env2_second_0:                 episode reward: 1.7500,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.2730s / 33376.9997 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2229
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -1.3000,                 loss: nan
env3_second_0:                 episode reward: 1.3000,                 loss: nan
env4_first_0:                 episode reward: -1.5500,                 loss: nan
env4_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1376s / 33454.1373 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3471
env0_second_0:                 episode reward: -0.7000,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 1.4500,                 loss: nan
env2_second_0:                 episode reward: -1.4500,                 loss: nan
env3_first_0:                 episode reward: 1.0000,                 loss: nan
env3_second_0:                 episode reward: -1.0000,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.7352s / 33530.8726 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2731
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5515s / 33607.4240 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.4799
env0_second_0:                 episode reward: -0.9500,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.7000,                 loss: nan
env3_second_0:                 episode reward: -0.7000,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6159s / 33685.0399 s
env0_first_0:                 episode reward: 4.7500,                 loss: 0.4488
env0_second_0:                 episode reward: -4.7500,                 loss: nan
env1_first_0:                 episode reward: 3.8000,                 loss: nan
env1_second_0:                 episode reward: -3.8000,                 loss: nan
env2_first_0:                 episode reward: 4.4500,                 loss: nan
env2_second_0:                 episode reward: -4.4500,                 loss: nan
env3_first_0:                 episode reward: 4.4500,                 loss: nan
env3_second_0:                 episode reward: -4.4500,                 loss: nan
env4_first_0:                 episode reward: 5.1500,                 loss: nan
env4_second_0:                 episode reward: -5.1500,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.7261s / 33762.7660 s
env0_first_0:                 episode reward: 6.0000,                 loss: 0.4031
env0_second_0:                 episode reward: -6.0000,                 loss: nan
env1_first_0:                 episode reward: 6.8000,                 loss: nan
env1_second_0:                 episode reward: -6.8000,                 loss: nan
env2_first_0:                 episode reward: 6.5500,                 loss: nan
env2_second_0:                 episode reward: -6.5500,                 loss: nan
env3_first_0:                 episode reward: 6.3000,                 loss: nan
env3_second_0:                 episode reward: -6.3000,                 loss: nan
env4_first_0:                 episode reward: 5.9000,                 loss: nan
env4_second_0:                 episode reward: -5.9000,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.0886s / 33838.8545 s
env0_first_0:                 episode reward: 4.5500,                 loss: 0.9043
env0_second_0:                 episode reward: -4.5500,                 loss: nan
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
env2_first_0:                 episode reward: 2.8000,                 loss: nan
env2_second_0:                 episode reward: -2.8000,                 loss: nan
env3_first_0:                 episode reward: 3.0500,                 loss: nan
env3_second_0:                 episode reward: -3.0500,                 loss: nan
env4_first_0:                 episode reward: 3.9000,                 loss: nan
env4_second_0:                 episode reward: -3.9000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3839s / 33916.2385 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.7144
env0_second_0:                 episode reward: -3.5000,                 loss: nan
env1_first_0:                 episode reward: 4.1500,                 loss: nan
env1_second_0:                 episode reward: -4.1500,                 loss: nan
env2_first_0:                 episode reward: 2.9000,                 loss: nan
env2_second_0:                 episode reward: -2.9000,                 loss: nan
env3_first_0:                 episode reward: 3.3500,                 loss: nan
env3_second_0:                 episode reward: -3.3500,                 loss: nan
env4_first_0:                 episode reward: 3.2500,                 loss: nan
env4_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.0038s / 33994.2423 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.8509
env0_second_0:                 episode reward: -1.8500,                 loss: nan
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
env2_first_0:                 episode reward: 3.4500,                 loss: nan
env2_second_0:                 episode reward: -3.4500,                 loss: nan
env3_first_0:                 episode reward: 3.1500,                 loss: nan
env3_second_0:                 episode reward: -3.1500,                 loss: nan
env4_first_0:                 episode reward: 2.4000,                 loss: nan
env4_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4914s / 34070.7337 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.6839
env0_second_0:                 episode reward: -1.9500,                 loss: nan
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
env2_first_0:                 episode reward: 1.8000,                 loss: nan
env2_second_0:                 episode reward: -1.8000,                 loss: nan
env3_first_0:                 episode reward: 1.0000,                 loss: nan
env3_second_0:                 episode reward: -1.0000,                 loss: nan
env4_first_0:                 episode reward: 3.0500,                 loss: nan
env4_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.9961s / 34146.7297 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.4756
env0_second_0:                 episode reward: -2.3500,                 loss: nan
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
env2_first_0:                 episode reward: 2.3000,                 loss: nan
env2_second_0:                 episode reward: -2.3000,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 2.4500,                 loss: nan
env4_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6818s / 34224.4115 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.6073
env0_second_0:                 episode reward: -2.4500,                 loss: nan
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 3.6500,                 loss: nan
env3_second_0:                 episode reward: -3.6500,                 loss: nan
env4_first_0:                 episode reward: 3.7000,                 loss: nan
env4_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5575s / 34300.9690 s
env0_first_0:                 episode reward: 4.6500,                 loss: 0.7271
env0_second_0:                 episode reward: -4.6500,                 loss: nan
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
env2_first_0:                 episode reward: 3.6000,                 loss: nan
env2_second_0:                 episode reward: -3.6000,                 loss: nan
env3_first_0:                 episode reward: 3.2500,                 loss: nan
env3_second_0:                 episode reward: -3.2500,                 loss: nan
env4_first_0:                 episode reward: 3.0000,                 loss: nan
env4_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.9554s / 34377.9244 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.5670
env0_second_0:                 episode reward: -2.4000,                 loss: nan
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
env2_first_0:                 episode reward: 2.8000,                 loss: nan
env2_second_0:                 episode reward: -2.8000,                 loss: nan
env3_first_0:                 episode reward: 2.2500,                 loss: nan
env3_second_0:                 episode reward: -2.2500,                 loss: nan
env4_first_0:                 episode reward: 2.7500,                 loss: nan
env4_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.8632s / 34456.7876 s
env0_first_0:                 episode reward: 3.1000,                 loss: 0.6070
env0_second_0:                 episode reward: -3.1000,                 loss: nan
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 1.6000,                 loss: nan
env4_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.3985s / 34533.1860 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.5877
env0_second_0:                 episode reward: -1.2500,                 loss: nan
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 1.4000,                 loss: nan
env4_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1920s / 34610.3780 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.3344
env0_second_0:                 episode reward: -2.1500,                 loss: nan
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
env2_first_0:                 episode reward: 0.9500,                 loss: nan
env2_second_0:                 episode reward: -0.9500,                 loss: nan
env3_first_0:                 episode reward: 0.8500,                 loss: nan
env3_second_0:                 episode reward: -0.8500,                 loss: nan
env4_first_0:                 episode reward: 1.6500,                 loss: nan
env4_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1047s / 34687.4827 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.5510
env0_second_0:                 episode reward: -2.3500,                 loss: nan
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
env2_first_0:                 episode reward: 2.1500,                 loss: nan
env2_second_0:                 episode reward: -2.1500,                 loss: nan
env3_first_0:                 episode reward: 3.0000,                 loss: nan
env3_second_0:                 episode reward: -3.0000,                 loss: nan
env4_first_0:                 episode reward: 1.9000,                 loss: nan
env4_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4332s / 34763.9159 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.4571
env0_second_0:                 episode reward: -2.7000,                 loss: nan
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 2.6000,                 loss: nan
env3_second_0:                 episode reward: -2.6000,                 loss: nan
env4_first_0:                 episode reward: 2.8000,                 loss: nan
env4_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.9167s / 34841.8327 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.5126
env0_second_0:                 episode reward: -2.5500,                 loss: nan
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
env2_first_0:                 episode reward: 2.4500,                 loss: nan
env2_second_0:                 episode reward: -2.4500,                 loss: nan
env3_first_0:                 episode reward: 2.8000,                 loss: nan
env3_second_0:                 episode reward: -2.8000,                 loss: nan
env4_first_0:                 episode reward: 2.2500,                 loss: nan
env4_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.3215s / 34920.1542 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.4855
env0_second_0:                 episode reward: -2.3000,                 loss: nan
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 3.1000,                 loss: nan
env2_second_0:                 episode reward: -3.1000,                 loss: nan
env3_first_0:                 episode reward: 1.1500,                 loss: nan
env3_second_0:                 episode reward: -1.1500,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.5653s / 34998.7195 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.5256
env0_second_0:                 episode reward: -2.1500,                 loss: nan
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
env2_first_0:                 episode reward: 3.0500,                 loss: nan
env2_second_0:                 episode reward: -3.0500,                 loss: nan
env3_first_0:                 episode reward: 2.0500,                 loss: nan
env3_second_0:                 episode reward: -2.0500,                 loss: nan
env4_first_0:                 episode reward: 1.3500,                 loss: nan
env4_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.9084s / 35077.6279 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.5376
env0_second_0:                 episode reward: -1.5000,                 loss: nan
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 2.0500,                 loss: nan
env3_second_0:                 episode reward: -2.0500,                 loss: nan
env4_first_0:                 episode reward: 1.6500,                 loss: nan
env4_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.5954s / 35155.2233 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.4297
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 1.0000,                 loss: nan
env4_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.6423s / 35233.8656 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.3456
env0_second_0:                 episode reward: -1.0500,                 loss: nan
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
env2_first_0:                 episode reward: 0.9500,                 loss: nan
env2_second_0:                 episode reward: -0.9500,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.9000,                 loss: nan
env4_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.8697s / 35311.7353 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.3873
env0_second_0:                 episode reward: 1.4500,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
env3_first_0:                 episode reward: -0.9000,                 loss: nan
env3_second_0:                 episode reward: 0.9000,                 loss: nan
env4_first_0:                 episode reward: -0.9500,                 loss: nan
env4_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.3529s / 35390.0882 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.3733
env0_second_0:                 episode reward: -0.8500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 1.0500,                 loss: nan
env4_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.3391s / 35465.4273 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.3491
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 0.8500,                 loss: nan
env3_second_0:                 episode reward: -0.8500,                 loss: nan
env4_first_0:                 episode reward: 0.9500,                 loss: nan
env4_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.8205s / 35542.2477 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2905
env0_second_0:                 episode reward: -0.6500,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.9500,                 loss: nan
env2_second_0:                 episode reward: -0.9500,                 loss: nan
env3_first_0:                 episode reward: 0.5500,                 loss: nan
env3_second_0:                 episode reward: -0.5500,                 loss: nan
env4_first_0:                 episode reward: -0.0500,                 loss: nan
env4_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5257s / 35618.7734 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.3247
env0_second_0:                 episode reward: -0.6500,                 loss: nan
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
env2_first_0:                 episode reward: 1.4500,                 loss: nan
env2_second_0:                 episode reward: -1.4500,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.5798s / 35696.3533 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.4994
env0_second_0:                 episode reward: -0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3183s / 35773.6715 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.1827
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.2572s / 35850.9287 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.1659
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.8000,                 loss: nan
env3_second_0:                 episode reward: 0.8000,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.4978s / 35929.4265 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2701
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: -0.9500,                 loss: nan
env3_second_0:                 episode reward: 0.9500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5701s / 36005.9966 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2531
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
env3_first_0:                 episode reward: -0.6000,                 loss: nan
env3_second_0:                 episode reward: 0.6000,                 loss: nan
env4_first_0:                 episode reward: -0.9500,                 loss: nan
env4_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.7445s / 36083.7411 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3751
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3372s / 36161.0783 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2850
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.5827s / 36239.6610 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3888
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1500,                 loss: nan
env4_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6729s / 36317.3339 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2486
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
env3_first_0:                 episode reward: -0.9000,                 loss: nan
env3_second_0:                 episode reward: 0.9000,                 loss: nan
env4_first_0:                 episode reward: -1.0500,                 loss: nan
env4_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.9913s / 36395.3252 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.1533
env0_second_0:                 episode reward: 1.0500,                 loss: nan
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
env3_first_0:                 episode reward: -1.3000,                 loss: nan
env3_second_0:                 episode reward: 1.3000,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.9276s / 36473.2528 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.1926
env0_second_0:                 episode reward: 1.2500,                 loss: nan
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.7000,                 loss: nan
env3_second_0:                 episode reward: 0.7000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3272s / 36550.5800 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.1849
env0_second_0:                 episode reward: 1.2000,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -1.2500,                 loss: nan
env4_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.0178s / 36628.5977 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2239
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.8573s / 36705.4550 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.3416
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.2000,                 loss: nan
env3_second_0:                 episode reward: 0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.0111s / 36781.4661 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.3842
env0_second_0:                 episode reward: 0.2000,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.7500,                 loss: nan
env4_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.5989s / 36857.0649 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.3501
env0_second_0:                 episode reward: 0.6000,                 loss: nan
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: -0.7500,                 loss: nan
env2_second_0:                 episode reward: 0.7500,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.8816s / 36932.9465 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.5537
env0_second_0:                 episode reward: 0.0500,                 loss: nan
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.2500,                 loss: nan
env3_second_0:                 episode reward: -0.2500,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.3180s / 37009.2645 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.5336
env0_second_0:                 episode reward: -0.6000,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 1.2000,                 loss: nan
env2_second_0:                 episode reward: -1.2000,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.5120s / 37085.7764 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.3537
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4430s / 37162.2194 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.4242
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -1.2000,                 loss: nan
env3_second_0:                 episode reward: 1.2000,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.4948s / 37239.7142 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2683
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.4805s / 37316.1947 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.3139
env0_second_0:                 episode reward: -0.3500,                 loss: nan
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.1927s / 37392.3874 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.7046
env0_second_0:                 episode reward: -2.3000,                 loss: nan
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
env2_first_0:                 episode reward: 2.8000,                 loss: nan
env2_second_0:                 episode reward: -2.8000,                 loss: nan
env3_first_0:                 episode reward: 2.1000,                 loss: nan
env3_second_0:                 episode reward: -2.1000,                 loss: nan
env4_first_0:                 episode reward: 2.3500,                 loss: nan
env4_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.5843s / 37467.9717 s
env0_first_0:                 episode reward: 7.8500,                 loss: 0.0251
env0_second_0:                 episode reward: -7.8500,                 loss: nan
env1_first_0:                 episode reward: 7.9500,                 loss: nan
env1_second_0:                 episode reward: -7.9500,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 7.9500,                 loss: nan
env3_second_0:                 episode reward: -7.9500,                 loss: nan
env4_first_0:                 episode reward: 7.8500,                 loss: nan
env4_second_0:                 episode reward: -7.8500,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.3230s / 37545.2947 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.1191
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.6691s / 37621.9638 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.0797
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.1624s / 37698.1262 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.0649
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.6673s / 37775.7935 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.0647
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.9717s / 37851.7652 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.1125
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.8486s / 37928.6137 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.2152
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.2511s / 38005.8649 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.2564
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.7935s / 38084.6584 sLoad pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: 8.0000,                 loss: -0.2897
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 76.2844s / 38160.9428 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.3085
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.2777s / 38236.2205 s
env0_first_0:                 episode reward: 8.0000,                 loss: -0.2405
env0_second_0:                 episode reward: -8.0000,                 loss: nan
env1_first_0:                 episode reward: 7.8000,                 loss: nan
env1_second_0:                 episode reward: -7.8000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 78.0228s / 38314.2433 s
env0_first_0:                 episode reward: 7.3500,                 loss: -0.1305
env0_second_0:                 episode reward: -7.3500,                 loss: nan
env1_first_0:                 episode reward: 7.7000,                 loss: nan
env1_second_0:                 episode reward: -7.7000,                 loss: nan
env2_first_0:                 episode reward: 7.5500,                 loss: nan
env2_second_0:                 episode reward: -7.5500,                 loss: nan
env3_first_0:                 episode reward: 8.0000,                 loss: nan
env3_second_0:                 episode reward: -8.0000,                 loss: nan
env4_first_0:                 episode reward: 8.0000,                 loss: nan
env4_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 77.1427s / 38391.3860 s
env0_first_0:                 episode reward: 6.1000,                 loss: 0.1856
env0_second_0:                 episode reward: -6.1000,                 loss: nan
env1_first_0:                 episode reward: 6.4500,                 loss: nan
env1_second_0:                 episode reward: -6.4500,                 loss: nan
env2_first_0:                 episode reward: 6.2000,                 loss: nan
env2_second_0:                 episode reward: -6.2000,                 loss: nan
env3_first_0:                 episode reward: 7.1000,                 loss: nan
env3_second_0:                 episode reward: -7.1000,                 loss: nan
env4_first_0:                 episode reward: 6.7000,                 loss: nan
env4_second_0:                 episode reward: -6.7000,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 75.7305s / 38467.1165 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.3846
env0_second_0:                 episode reward: 4.3000,                 loss: nan
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
env2_first_0:                 episode reward: -4.6500,                 loss: nan
env2_second_0:                 episode reward: 4.6500,                 loss: nan
env3_first_0:                 episode reward: -4.4000,                 loss: nan
env3_second_0:                 episode reward: 4.4000,                 loss: nan
env4_first_0:                 episode reward: -3.7500,                 loss: nan
env4_second_0:                 episode reward: 3.7500,                 loss: nan
