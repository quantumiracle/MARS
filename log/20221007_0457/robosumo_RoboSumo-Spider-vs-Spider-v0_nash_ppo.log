wandb: Currently logged in as: quantumiracle. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.13.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.0
wandb: Run data is saved locally in /data/zihan/research/MARS/wandb/run-20221007_045732-270upuy9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robosumo_RoboSumo-Spider-vs-Spider-v0_nash_ppo_202210070457
wandb: ‚≠êÔ∏è View project at https://wandb.ai/quantumiracle/Pettingzoo_MARS
wandb: üöÄ View run at https://wandb.ai/quantumiracle/Pettingzoo_MARS/runs/270upuy9
robosumo_RoboSumo-Spider-vs-Spider-v0
default:  {'env_name': 'RoboSumo-Spider-vs-Spider-v0', 'env_type': 'robosumo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'record_video': False, 'against_baseline': False, 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True, 'max_grad_norm': 0.5, 'entropy_coeff': 0.01, 'vf_coeff': 0.5, 'policy_loss_coeff': 0.08}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'feature': {'hidden_dim_list': [128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'policy': {'hidden_dim_list': [128], 'hidden_activation': False, 'output_activation': 'Tanh'}, 'value': {'hidden_dim_list': [128], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
{'env_name': 'RoboSumo-Spider-vs-Spider-v0', 'env_type': 'robosumo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'record_video': True, 'against_baseline': False, 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True, 'max_grad_norm': 0.5, 'entropy_coeff': 0.01, 'vf_coeff': 0.5, 'policy_loss_coeff': 0.08}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202210070457, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': True, 'wandb_entity': 'quantumiracle', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'feature': {'hidden_dim_list': [128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'policy': {'hidden_dim_list': [128], 'hidden_activation': False, 'output_activation': 'Tanh'}, 'value': {'hidden_dim_list': [128], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}, 'record_video_interval': 1000}
args:  {'env_name': 'RoboSumo-Spider-vs-Spider-v0', 'env_type': 'robosumo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'record_video': True, 'against_baseline': False, 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True, 'max_grad_norm': 0.5, 'entropy_coeff': 0.01, 'vf_coeff': 0.5, 'policy_loss_coeff': 0.08}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202210070457, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': True, 'wandb_entity': 'quantumiracle', 'wandb_project': 'Pettingzoo_MARS', 'wandb_group': '202210070457', 'wandb_name': 'robosumo_RoboSumo-Spider-vs-Spider-v0_nash_ppo_202210070457', 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'feature': {'hidden_dim_list': [128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'policy': {'hidden_dim_list': [128], 'hidden_activation': False, 'output_activation': 'Tanh'}, 'value': {'hidden_dim_list': [128], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}, 'record_video_interval': 1000}
RoboSumo-Spider-vs-Spider-v0 robosumo
record video: interval 1000, length 300
Load RoboSumo-Spider-vs-Spider-v0 environment in type robosumo.
Env observation space: Box(-inf, inf, (208,), float32) action space: Box(-1.0, 1.0, (16,), float32)
random seed: 159
<RecordVideo<mars.env.wrappers.mars_wrappers.RoboSumoWrapper object at 0x7f874cb5d438>>
gaussian_policy 16 Box(-1.0, 1.0, (16,), float32)
[MLP(
  (body): Sequential(
    (0): Linear(in_features=208, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=208, bias=True)
  )
), MLP(
  (body): Sequential(
    (0): Linear(in_features=208, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=208, bias=True)
  )
)] [MLP(
  (body): Sequential(
    (0): Linear(in_features=208, out_features=128, bias=True)
    (1): Linear(in_features=128, out_features=32, bias=True)
    (2): Tanh()
  )
), MLP(
  (body): Sequential(
    (0): Linear(in_features=208, out_features=128, bias=True)
    (1): Linear(in_features=128, out_features=32, bias=True)
    (2): Tanh()
  )
)] [MLP(
  (body): Sequential(
    (0): Linear(in_features=208, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
), MLP(
  (body): Sequential(
    (0): Linear(in_features=208, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
)] MLP(
  (body): Sequential(
    (0): Linear(in_features=416, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
)
gaussian_policy 16 Box(-1.0, 1.0, (16,), float32)
[MLP(
  (body): Sequential(
    (0): Linear(in_features=208, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=208, bias=True)
  )
), MLP(
  (body): Sequential(
    (0): Linear(in_features=208, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=208, bias=True)
  )
)] [MLP(
  (body): Sequential(
    (0): Linear(in_features=208, out_features=128, bias=True)
    (1): Linear(in_features=128, out_features=32, bias=True)
    (2): Tanh()
  )
), MLP(
  (body): Sequential(
    (0): Linear(in_features=208, out_features=128, bias=True)
    (1): Linear(in_features=128, out_features=32, bias=True)
    (2): Tanh()
  )
)] [MLP(
  (body): Sequential(
    (0): Linear(in_features=208, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
), MLP(
  (body): Sequential(
    (0): Linear(in_features=208, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
)] MLP(
  (body): Sequential(
    (0): Linear(in_features=416, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
)