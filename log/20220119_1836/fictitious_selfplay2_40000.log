pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fe3c1ec3e48>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.018 0.018 0.018 ... 0.018 0.018 0.018]
 [0.018 0.018 0.018 ... 0.018 0.018 0.018]]
Load checkpoints (policy family):  [['50' '5253' '7615' ... '37270' '38685' '39143']
 ['193' '5289' '7712' ... '37326' '38773' '39204']]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 1, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220117153310/epi_40000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/quantumiracle/research/MARS/data/model/20220117153310_exploit_40000/mdp_arbitrary_mdp_fictitious_selfplay2. 
 Save logs to: /home/quantumiracle/research/MARS/data/log/20220117153310_exploit_40000/mdp_arbitrary_mdp_fictitious_selfplay2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0292s / 0.0292 s
agent0:                 episode reward: -0.8113,                 loss: nan
agent1:                 episode reward: 0.8113,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0604s / 0.0896 s
agent0:                 episode reward: 0.3691,                 loss: nan
agent1:                 episode reward: -0.3691,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0547s / 0.1443 s
agent0:                 episode reward: 0.3408,                 loss: nan
agent1:                 episode reward: -0.3408,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0477s / 0.1920 s
agent0:                 episode reward: 0.2924,                 loss: nan
agent1:                 episode reward: -0.2924,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0559s / 0.2479 s
agent0:                 episode reward: -0.2276,                 loss: nan
agent1:                 episode reward: 0.2276,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0475s / 0.2953 s
agent0:                 episode reward: -0.0119,                 loss: nan
agent1:                 episode reward: 0.0119,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0491s / 0.3445 s
agent0:                 episode reward: -0.1219,                 loss: nan
agent1:                 episode reward: 0.1219,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0444s / 0.3889 s
agent0:                 episode reward: -0.0104,                 loss: nan
agent1:                 episode reward: 0.0104,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0428s / 0.4317 s
agent0:                 episode reward: -0.0711,                 loss: nan
agent1:                 episode reward: 0.0711,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0429s / 0.4746 s
agent0:                 episode reward: 0.1457,                 loss: nan
agent1:                 episode reward: -0.1457,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0428s / 0.5173 s
agent0:                 episode reward: 0.3106,                 loss: nan
agent1:                 episode reward: -0.3106,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1057s / 0.6231 s
agent0:                 episode reward: -0.2227,                 loss: nan
agent1:                 episode reward: 0.2227,                 loss: 0.2862
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1522s / 0.7753 s
agent0:                 episode reward: 0.0255,                 loss: nan
agent1:                 episode reward: -0.0255,                 loss: 0.2455
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1530s / 0.9283 s
agent0:                 episode reward: 0.0565,                 loss: nan
agent1:                 episode reward: -0.0565,                 loss: 0.2118
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1543s / 1.0826 s
agent0:                 episode reward: 0.3824,                 loss: nan
agent1:                 episode reward: -0.3824,                 loss: 0.1892
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1547s / 1.2373 s
agent0:                 episode reward: 0.1443,                 loss: nan
agent1:                 episode reward: -0.1443,                 loss: 0.1805
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1588s / 1.3961 s
agent0:                 episode reward: 0.1952,                 loss: nan
agent1:                 episode reward: -0.1952,                 loss: 0.1761
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1557s / 1.5517 s
agent0:                 episode reward: -0.0632,                 loss: nan
agent1:                 episode reward: 0.0632,                 loss: 0.1731
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1544s / 1.7062 s
agent0:                 episode reward: 0.2161,                 loss: nan
agent1:                 episode reward: -0.2161,                 loss: 0.1690
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1566s / 1.8628 s
agent0:                 episode reward: 0.1654,                 loss: nan
agent1:                 episode reward: -0.1654,                 loss: 0.1648
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1850s / 2.0478 s
agent0:                 episode reward: 0.1193,                 loss: nan
agent1:                 episode reward: -0.1193,                 loss: 0.1634
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1568s / 2.2046 s
agent0:                 episode reward: 0.1345,                 loss: nan
agent1:                 episode reward: -0.1345,                 loss: 0.1582
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1550s / 2.3596 s
agent0:                 episode reward: 0.1890,                 loss: nan
agent1:                 episode reward: -0.1890,                 loss: 0.1559
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1548s / 2.5144 s
agent0:                 episode reward: -0.1501,                 loss: nan
agent1:                 episode reward: 0.1501,                 loss: 0.1542
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1550s / 2.6693 s
agent0:                 episode reward: 0.1279,                 loss: nan
agent1:                 episode reward: -0.1279,                 loss: 0.1522
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1555s / 2.8248 s
agent0:                 episode reward: 0.0465,                 loss: nan
agent1:                 episode reward: -0.0465,                 loss: 0.1515
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1552s / 2.9800 s
agent0:                 episode reward: -0.0270,                 loss: nan
agent1:                 episode reward: 0.0270,                 loss: 0.1514
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1602s / 3.1402 s
agent0:                 episode reward: -0.2986,                 loss: nan
agent1:                 episode reward: 0.2986,                 loss: 0.1476
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1695s / 3.3097 s
agent0:                 episode reward: 0.4693,                 loss: nan
agent1:                 episode reward: -0.4693,                 loss: 0.1587
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1814s / 3.4911 s
agent0:                 episode reward: -0.1523,                 loss: nan
agent1:                 episode reward: 0.1523,                 loss: 0.1457
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1616s / 3.6526 s
agent0:                 episode reward: 0.2331,                 loss: nan
agent1:                 episode reward: -0.2331,                 loss: 0.1442
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1588s / 3.8114 s
agent0:                 episode reward: 0.0579,                 loss: nan
agent1:                 episode reward: -0.0579,                 loss: 0.1430
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1548s / 3.9662 s
agent0:                 episode reward: -0.4263,                 loss: nan
agent1:                 episode reward: 0.4263,                 loss: 0.1417
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1550s / 4.1212 s
agent0:                 episode reward: 0.0047,                 loss: nan
agent1:                 episode reward: -0.0047,                 loss: 0.1425
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1558s / 4.2771 s
agent0:                 episode reward: 0.4405,                 loss: nan
agent1:                 episode reward: -0.4405,                 loss: 0.1398
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1589s / 4.4360 s
agent0:                 episode reward: 0.0547,                 loss: nan
agent1:                 episode reward: -0.0547,                 loss: 0.1397
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1646s / 4.6006 s
agent0:                 episode reward: 0.1464,                 loss: nan
agent1:                 episode reward: -0.1464,                 loss: 0.1408
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1664s / 4.7670 s
agent0:                 episode reward: -0.1177,                 loss: nan
agent1:                 episode reward: 0.1177,                 loss: 0.1392
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1641s / 4.9311 s
agent0:                 episode reward: 0.0759,                 loss: nan
agent1:                 episode reward: -0.0759,                 loss: 0.1382
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1582s / 5.0892 s
agent0:                 episode reward: 0.1016,                 loss: nan
agent1:                 episode reward: -0.1016,                 loss: 0.1377
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1607s / 5.2499 s
agent0:                 episode reward: 0.3403,                 loss: nan
agent1:                 episode reward: -0.3403,                 loss: 0.1387
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1583s / 5.4082 s
agent0:                 episode reward: -0.2700,                 loss: nan
agent1:                 episode reward: 0.2700,                 loss: 0.1386
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1609s / 5.5691 s
agent0:                 episode reward: -0.3332,                 loss: nan
agent1:                 episode reward: 0.3332,                 loss: 0.1389
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1648s / 5.7339 s
agent0:                 episode reward: 0.0971,                 loss: nan
agent1:                 episode reward: -0.0971,                 loss: 0.1382
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1645s / 5.8984 s
agent0:                 episode reward: -0.1756,                 loss: nan
agent1:                 episode reward: 0.1756,                 loss: 0.1401
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1632s / 6.0616 s
agent0:                 episode reward: 0.0134,                 loss: nan
agent1:                 episode reward: -0.0134,                 loss: 0.1345
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1708s / 6.2324 s
agent0:                 episode reward: 0.0253,                 loss: nan
agent1:                 episode reward: -0.0253,                 loss: 0.1319
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1836s / 6.4160 s
agent0:                 episode reward: 0.0303,                 loss: nan
agent1:                 episode reward: -0.0303,                 loss: 0.1310
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1735s / 6.5894 s
agent0:                 episode reward: 0.0380,                 loss: nan
agent1:                 episode reward: -0.0380,                 loss: 0.1319
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1637s / 6.7531 s
agent0:                 episode reward: -0.1940,                 loss: nan
agent1:                 episode reward: 0.1940,                 loss: 0.1306
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1652s / 6.9183 s
agent0:                 episode reward: -0.2088,                 loss: nan
agent1:                 episode reward: 0.2088,                 loss: 0.1310
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1611s / 7.0794 s
agent0:                 episode reward: 0.1704,                 loss: nan
agent1:                 episode reward: -0.1704,                 loss: 0.1304
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1634s / 7.2428 s
agent0:                 episode reward: -0.0555,                 loss: nan
agent1:                 episode reward: 0.0555,                 loss: 0.1302
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1658s / 7.4087 s
agent0:                 episode reward: 0.0682,                 loss: nan
agent1:                 episode reward: -0.0682,                 loss: 0.1288
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1659s / 7.5746 s
agent0:                 episode reward: 0.5241,                 loss: nan
agent1:                 episode reward: -0.5241,                 loss: 0.1278
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1621s / 7.7367 s
agent0:                 episode reward: 0.2109,                 loss: nan
agent1:                 episode reward: -0.2109,                 loss: 0.1266
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1616s / 7.8983 s
agent0:                 episode reward: 0.0959,                 loss: nan
agent1:                 episode reward: -0.0959,                 loss: 0.1263
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1640s / 8.0623 s
agent0:                 episode reward: -0.0786,                 loss: nan
agent1:                 episode reward: 0.0786,                 loss: 0.1266
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1685s / 8.2308 s
agent0:                 episode reward: -0.0156,                 loss: nan
agent1:                 episode reward: 0.0156,                 loss: 0.1275
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1619s / 8.3927 s
agent0:                 episode reward: -0.3209,                 loss: nan
agent1:                 episode reward: 0.3209,                 loss: 0.1267
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1672s / 8.5598 s
agent0:                 episode reward: -0.1373,                 loss: nan
agent1:                 episode reward: 0.1373,                 loss: 0.1263
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1674s / 8.7273 s
agent0:                 episode reward: -0.0355,                 loss: nan
agent1:                 episode reward: 0.0355,                 loss: 0.1263
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1675s / 8.8948 s
agent0:                 episode reward: 0.0868,                 loss: nan
agent1:                 episode reward: -0.0868,                 loss: 0.1283
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1612s / 9.0560 s
agent0:                 episode reward: -0.2936,                 loss: nan
agent1:                 episode reward: 0.2936,                 loss: 0.1287
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1658s / 9.2218 s
agent0:                 episode reward: 0.3215,                 loss: nan
agent1:                 episode reward: -0.3215,                 loss: 0.1295
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1805s / 9.4023 s
agent0:                 episode reward: 0.0244,                 loss: nan
agent1:                 episode reward: -0.0244,                 loss: 0.1285
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1793s / 9.5817 s
agent0:                 episode reward: 0.1152,                 loss: nan
agent1:                 episode reward: -0.1152,                 loss: 0.1271
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1666s / 9.7483 s
agent0:                 episode reward: 0.4670,                 loss: nan
agent1:                 episode reward: -0.4670,                 loss: 0.1265
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1622s / 9.9104 s
agent0:                 episode reward: -0.0117,                 loss: nan
agent1:                 episode reward: 0.0117,                 loss: 0.1238
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1641s / 10.0745 s
agent0:                 episode reward: 0.2647,                 loss: nan
agent1:                 episode reward: -0.2647,                 loss: 0.1253
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1656s / 10.2402 s
agent0:                 episode reward: 0.5958,                 loss: nan
agent1:                 episode reward: -0.5958,                 loss: 0.1262
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1668s / 10.4070 s
agent0:                 episode reward: 0.1950,                 loss: nan
agent1:                 episode reward: -0.1950,                 loss: 0.1264
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1680s / 10.5750 s
agent0:                 episode reward: -0.1641,                 loss: nan
agent1:                 episode reward: 0.1641,                 loss: 0.1266
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1716s / 10.7466 s
agent0:                 episode reward: -0.2483,                 loss: nan
agent1:                 episode reward: 0.2483,                 loss: 0.1268
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1667s / 10.9133 s
agent0:                 episode reward: 0.0154,                 loss: nan
agent1:                 episode reward: -0.0154,                 loss: 0.1258
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1679s / 11.0812 s
agent0:                 episode reward: 0.0645,                 loss: nan
agent1:                 episode reward: -0.0645,                 loss: 0.1238
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1671s / 11.2483 s
agent0:                 episode reward: 0.0510,                 loss: nan
agent1:                 episode reward: -0.0510,                 loss: 0.1253
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1662s / 11.4145 s
agent0:                 episode reward: 0.0543,                 loss: nan
agent1:                 episode reward: -0.0543,                 loss: 0.1239
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1654s / 11.5799 s
agent0:                 episode reward: -0.2212,                 loss: nan
agent1:                 episode reward: 0.2212,                 loss: 0.1255
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1811s / 11.7611 s
agent0:                 episode reward: 0.1127,                 loss: nan
agent1:                 episode reward: -0.1127,                 loss: 0.1253
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1943s / 11.9553 s
agent0:                 episode reward: -0.0533,                 loss: nan
agent1:                 episode reward: 0.0533,                 loss: 0.1244
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1708s / 12.1261 s
agent0:                 episode reward: -0.1575,                 loss: nan
agent1:                 episode reward: 0.1575,                 loss: 0.1249
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1684s / 12.2945 s
agent0:                 episode reward: -0.0530,                 loss: nan
agent1:                 episode reward: 0.0530,                 loss: 0.1239
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2139s / 12.5084 s
agent0:                 episode reward: -0.0219,                 loss: nan
agent1:                 episode reward: 0.0219,                 loss: 0.1252
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1876s / 12.6960 s
agent0:                 episode reward: 0.0010,                 loss: nan
agent1:                 episode reward: -0.0010,                 loss: 0.1248
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1749s / 12.8709 s
agent0:                 episode reward: 0.2835,                 loss: nan
agent1:                 episode reward: -0.2835,                 loss: 0.1242
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1707s / 13.0416 s
agent0:                 episode reward: -0.2046,                 loss: nan
agent1:                 episode reward: 0.2046,                 loss: 0.1248
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1677s / 13.2093 s
agent0:                 episode reward: -0.0851,                 loss: nan
agent1:                 episode reward: 0.0851,                 loss: 0.1232
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1705s / 13.3798 s
agent0:                 episode reward: -0.3303,                 loss: nan
agent1:                 episode reward: 0.3303,                 loss: 0.1246
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1632s / 13.5431 s
agent0:                 episode reward: 0.0261,                 loss: nan
agent1:                 episode reward: -0.0261,                 loss: 0.1225
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1677s / 13.7107 s
agent0:                 episode reward: -0.2484,                 loss: nan
agent1:                 episode reward: 0.2484,                 loss: 0.1244
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1685s / 13.8792 s
agent0:                 episode reward: -0.2859,                 loss: nan
agent1:                 episode reward: 0.2859,                 loss: 0.1226
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1601s / 14.0393 s
agent0:                 episode reward: -0.1111,                 loss: nan
agent1:                 episode reward: 0.1111,                 loss: 0.1235
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1663s / 14.2056 s
agent0:                 episode reward: 0.2034,                 loss: nan
agent1:                 episode reward: -0.2034,                 loss: 0.1219
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1691s / 14.3746 s
agent0:                 episode reward: -0.3003,                 loss: nan
agent1:                 episode reward: 0.3003,                 loss: 0.1231
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1717s / 14.5464 s
agent0:                 episode reward: 0.1205,                 loss: nan
agent1:                 episode reward: -0.1205,                 loss: 0.1232
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1620s / 14.7083 s
agent0:                 episode reward: -0.1277,                 loss: nan
agent1:                 episode reward: 0.1277,                 loss: 0.1212
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1655s / 14.8738 s
agent0:                 episode reward: -0.3414,                 loss: nan
agent1:                 episode reward: 0.3414,                 loss: 0.1218
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1710s / 15.0448 s
agent0:                 episode reward: -0.1072,                 loss: nan
agent1:                 episode reward: 0.1072,                 loss: 0.1218
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1734s / 15.2182 s
agent0:                 episode reward: 0.3252,                 loss: nan
agent1:                 episode reward: -0.3252,                 loss: 0.1228
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1827s / 15.4009 s
agent0:                 episode reward: -0.0094,                 loss: nan
agent1:                 episode reward: 0.0094,                 loss: 0.1224
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1919s / 15.5928 s
agent0:                 episode reward: -0.2976,                 loss: nan
agent1:                 episode reward: 0.2976,                 loss: 0.1217
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1805s / 15.7734 s
agent0:                 episode reward: -0.1158,                 loss: nan
agent1:                 episode reward: 0.1158,                 loss: 0.1219
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1730s / 15.9464 s
agent0:                 episode reward: 0.3442,                 loss: nan
agent1:                 episode reward: -0.3442,                 loss: 0.1229
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1672s / 16.1136 s
agent0:                 episode reward: 0.4316,                 loss: nan
agent1:                 episode reward: -0.4316,                 loss: 0.1210
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1702s / 16.2838 s
agent0:                 episode reward: 0.0731,                 loss: nan
agent1:                 episode reward: -0.0731,                 loss: 0.1217
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1700s / 16.4538 s
agent0:                 episode reward: 0.3806,                 loss: nan
agent1:                 episode reward: -0.3806,                 loss: 0.1224
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1697s / 16.6234 s
agent0:                 episode reward: -0.1068,                 loss: nan
agent1:                 episode reward: 0.1068,                 loss: 0.1195
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1757s / 16.7992 s
agent0:                 episode reward: -0.1036,                 loss: nan
agent1:                 episode reward: 0.1036,                 loss: 0.1209
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1741s / 16.9733 s
agent0:                 episode reward: 0.0448,                 loss: nan
agent1:                 episode reward: -0.0448,                 loss: 0.1208
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1712s / 17.1444 s
agent0:                 episode reward: -0.1396,                 loss: nan
agent1:                 episode reward: 0.1396,                 loss: 0.1203
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1699s / 17.3144 s
agent0:                 episode reward: 0.1473,                 loss: nan
agent1:                 episode reward: -0.1473,                 loss: 0.1203
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1714s / 17.4857 s
agent0:                 episode reward: -0.4580,                 loss: nan
agent1:                 episode reward: 0.4580,                 loss: 0.1182
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1673s / 17.6530 s
agent0:                 episode reward: 0.0434,                 loss: nan
agent1:                 episode reward: -0.0434,                 loss: 0.1195
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1731s / 17.8261 s
agent0:                 episode reward: -0.4261,                 loss: nan
agent1:                 episode reward: 0.4261,                 loss: 0.1214
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1751s / 18.0013 s
agent0:                 episode reward: -0.0613,                 loss: nan
agent1:                 episode reward: 0.0613,                 loss: 0.1214
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1687s / 18.1700 s
agent0:                 episode reward: 0.0021,                 loss: nan
agent1:                 episode reward: -0.0021,                 loss: 0.1187
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1709s / 18.3409 s
agent0:                 episode reward: 0.2202,                 loss: nan
agent1:                 episode reward: -0.2202,                 loss: 0.1208
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2084s / 18.5493 s
agent0:                 episode reward: -0.0752,                 loss: nan
agent1:                 episode reward: 0.0752,                 loss: 0.1232
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1909s / 18.7402 s
agent0:                 episode reward: -0.1784,                 loss: nan
agent1:                 episode reward: 0.1784,                 loss: 0.1215
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1714s / 18.9116 s
agent0:                 episode reward: -0.1791,                 loss: nan
agent1:                 episode reward: 0.1791,                 loss: 0.1196
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1897s / 19.1012 s
agent0:                 episode reward: -0.0759,                 loss: nan
agent1:                 episode reward: 0.0759,                 loss: 0.1195
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1726s / 19.2739 s
agent0:                 episode reward: -0.1220,                 loss: nan
agent1:                 episode reward: 0.1220,                 loss: 0.1195
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1726s / 19.4465 s
agent0:                 episode reward: 0.1066,                 loss: nan
agent1:                 episode reward: -0.1066,                 loss: 0.1191
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1768s / 19.6233 s
agent0:                 episode reward: 0.1071,                 loss: nan
agent1:                 episode reward: -0.1071,                 loss: 0.1199
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1733s / 19.7966 s
agent0:                 episode reward: -0.2001,                 loss: nan
agent1:                 episode reward: 0.2001,                 loss: 0.1180
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1729s / 19.9694 s
agent0:                 episode reward: -0.1913,                 loss: nan
agent1:                 episode reward: 0.1913,                 loss: 0.1185
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1885s / 20.1580 s
agent0:                 episode reward: 0.1220,                 loss: nan
agent1:                 episode reward: -0.1220,                 loss: 0.1190
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1708s / 20.3288 s
agent0:                 episode reward: -0.4816,                 loss: nan
agent1:                 episode reward: 0.4816,                 loss: 0.1168
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1719s / 20.5007 s
agent0:                 episode reward: -0.4273,                 loss: nan
agent1:                 episode reward: 0.4273,                 loss: 0.1154
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1673s / 20.6680 s
agent0:                 episode reward: -0.1454,                 loss: nan
agent1:                 episode reward: 0.1454,                 loss: 0.1160
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1711s / 20.8391 s
agent0:                 episode reward: 0.1947,                 loss: nan
agent1:                 episode reward: -0.1947,                 loss: 0.1153
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1703s / 21.0094 s
agent0:                 episode reward: -0.1677,                 loss: nan
agent1:                 episode reward: 0.1677,                 loss: 0.1165
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1712s / 21.1806 s
agent0:                 episode reward: 0.1419,                 loss: nan
agent1:                 episode reward: -0.1419,                 loss: 0.1156
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1802s / 21.3608 s
agent0:                 episode reward: 0.2046,                 loss: nan
agent1:                 episode reward: -0.2046,                 loss: 0.1156
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1834s / 21.5442 s
agent0:                 episode reward: -0.0283,                 loss: nan
agent1:                 episode reward: 0.0283,                 loss: 0.1152
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 21.7463 s
agent0:                 episode reward: -0.4523,                 loss: nan
agent1:                 episode reward: 0.4523,                 loss: 0.1165
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 21.9405 s
agent0:                 episode reward: -0.3807,                 loss: nan
agent1:                 episode reward: 0.3807,                 loss: 0.1169
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1890s / 22.1295 s
agent0:                 episode reward: -0.1142,                 loss: nan
agent1:                 episode reward: 0.1142,                 loss: 0.1156
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1836s / 22.3131 s
agent0:                 episode reward: -0.2069,                 loss: nan
agent1:                 episode reward: 0.2069,                 loss: 0.1178
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2080s / 22.5212 s
agent0:                 episode reward: -0.0510,                 loss: nan
agent1:                 episode reward: 0.0510,                 loss: 0.1155
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1823s / 22.7035 s
agent0:                 episode reward: 0.0802,                 loss: nan
agent1:                 episode reward: -0.0802,                 loss: 0.1168
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1805s / 22.8840 s
agent0:                 episode reward: 0.1369,                 loss: nan
agent1:                 episode reward: -0.1369,                 loss: 0.1166
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1794s / 23.0634 s
agent0:                 episode reward: -0.1855,                 loss: nan
agent1:                 episode reward: 0.1855,                 loss: 0.1153
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1812s / 23.2446 s
agent0:                 episode reward: -0.0280,                 loss: nan
agent1:                 episode reward: 0.0280,                 loss: 0.1169
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1846s / 23.4292 s
agent0:                 episode reward: -0.0687,                 loss: nan
agent1:                 episode reward: 0.0687,                 loss: 0.1208
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1821s / 23.6113 s
agent0:                 episode reward: -0.3502,                 loss: nan
agent1:                 episode reward: 0.3502,                 loss: 0.1183
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1832s / 23.7945 s
agent0:                 episode reward: -0.1927,                 loss: nan
agent1:                 episode reward: 0.1927,                 loss: 0.1187
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1825s / 23.9770 s
agent0:                 episode reward: -0.0497,                 loss: nan
agent1:                 episode reward: 0.0497,                 loss: 0.1196
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1808s / 24.1578 s
agent0:                 episode reward: -0.3057,                 loss: nan
agent1:                 episode reward: 0.3057,                 loss: 0.1176
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1836s / 24.3414 s
agent0:                 episode reward: -0.1550,                 loss: nan
agent1:                 episode reward: 0.1550,                 loss: 0.1191
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1872s / 24.5286 s
agent0:                 episode reward: -0.2878,                 loss: nan
agent1:                 episode reward: 0.2878,                 loss: 0.1191
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2084s / 24.7370 s
agent0:                 episode reward: -0.4820,                 loss: nan
agent1:                 episode reward: 0.4820,                 loss: 0.1176
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 24.9356 s
agent0:                 episode reward: -0.1397,                 loss: nan
agent1:                 episode reward: 0.1397,                 loss: 0.1179
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1796s / 25.1152 s
agent0:                 episode reward: -0.1261,                 loss: nan
agent1:                 episode reward: 0.1261,                 loss: 0.1180
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1733s / 25.2885 s
agent0:                 episode reward: 0.0545,                 loss: nan
agent1:                 episode reward: -0.0545,                 loss: 0.1190
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1765s / 25.4650 s
agent0:                 episode reward: -0.3881,                 loss: nan
agent1:                 episode reward: 0.3881,                 loss: 0.1190
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1740s / 25.6390 s
agent0:                 episode reward: -0.1794,                 loss: nan
agent1:                 episode reward: 0.1794,                 loss: 0.1187
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1736s / 25.8126 s
agent0:                 episode reward: 0.0209,                 loss: nan
agent1:                 episode reward: -0.0209,                 loss: 0.1194
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1769s / 25.9894 s
agent0:                 episode reward: 0.3453,                 loss: nan
agent1:                 episode reward: -0.3453,                 loss: 0.1186
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1761s / 26.1655 s
agent0:                 episode reward: 0.0808,                 loss: nan
agent1:                 episode reward: -0.0808,                 loss: 0.1192
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1808s / 26.3462 s
agent0:                 episode reward: -0.2247,                 loss: nan
agent1:                 episode reward: 0.2247,                 loss: 0.1206
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1761s / 26.5224 s
agent0:                 episode reward: -0.2364,                 loss: nan
agent1:                 episode reward: 0.2364,                 loss: 0.1215
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1732s / 26.6956 s
agent0:                 episode reward: -0.4787,                 loss: nan
agent1:                 episode reward: 0.4787,                 loss: 0.1199
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1716s / 26.8673 s
agent0:                 episode reward: -0.4818,                 loss: nan
agent1:                 episode reward: 0.4818,                 loss: 0.1210
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1732s / 27.0405 s
agent0:                 episode reward: -0.4163,                 loss: nan
agent1:                 episode reward: 0.4163,                 loss: 0.1227
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1722s / 27.2127 s
agent0:                 episode reward: 0.1728,                 loss: nan
agent1:                 episode reward: -0.1728,                 loss: 0.1208
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1758s / 27.3885 s
agent0:                 episode reward: -0.3280,                 loss: nan
agent1:                 episode reward: 0.3280,                 loss: 0.1203
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1725s / 27.5610 s
agent0:                 episode reward: -0.4404,                 loss: nan
agent1:                 episode reward: 0.4404,                 loss: 0.1218
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1936s / 27.7546 s
agent0:                 episode reward: -0.2073,                 loss: nan
agent1:                 episode reward: 0.2073,                 loss: 0.1212
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1938s / 27.9484 s
agent0:                 episode reward: -0.1401,                 loss: nan
agent1:                 episode reward: 0.1401,                 loss: 0.1206
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1737s / 28.1221 s
agent0:                 episode reward: -0.2489,                 loss: nan
agent1:                 episode reward: 0.2489,                 loss: 0.1196
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1751s / 28.2972 s
agent0:                 episode reward: 0.0887,                 loss: nan
agent1:                 episode reward: -0.0887,                 loss: 0.1206
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1925s / 28.4897 s
agent0:                 episode reward: -0.1641,                 loss: nan
agent1:                 episode reward: 0.1641,                 loss: 0.1214
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1803s / 28.6699 s
agent0:                 episode reward: -0.1327,                 loss: nan
agent1:                 episode reward: 0.1327,                 loss: 0.1193
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1789s / 28.8489 s
agent0:                 episode reward: -0.2503,                 loss: nan
agent1:                 episode reward: 0.2503,                 loss: 0.1203
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1797s / 29.0285 s
agent0:                 episode reward: 0.2827,                 loss: nan
agent1:                 episode reward: -0.2827,                 loss: 0.1189
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1824s / 29.2109 s
agent0:                 episode reward: -0.2891,                 loss: nan
agent1:                 episode reward: 0.2891,                 loss: 0.1199
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1850s / 29.3958 s
agent0:                 episode reward: -0.2980,                 loss: nan
agent1:                 episode reward: 0.2980,                 loss: 0.1194
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1830s / 29.5788 s
agent0:                 episode reward: 0.0963,                 loss: nan
agent1:                 episode reward: -0.0963,                 loss: 0.1179
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1842s / 29.7631 s
agent0:                 episode reward: -0.1733,                 loss: nan
agent1:                 episode reward: 0.1733,                 loss: 0.1204
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1832s / 29.9463 s
agent0:                 episode reward: -0.0763,                 loss: nan
agent1:                 episode reward: 0.0763,                 loss: 0.1180
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1802s / 30.1265 s
agent0:                 episode reward: -0.0101,                 loss: nan
agent1:                 episode reward: 0.0101,                 loss: 0.1184
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1817s / 30.3083 s
agent0:                 episode reward: -0.0014,                 loss: nan
agent1:                 episode reward: 0.0014,                 loss: 0.1182
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1824s / 30.4907 s
agent0:                 episode reward: 0.0570,                 loss: nan
agent1:                 episode reward: -0.0570,                 loss: 0.1195
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1912s / 30.6818 s
agent0:                 episode reward: -0.3758,                 loss: nan
agent1:                 episode reward: 0.3758,                 loss: 0.1189
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2290s / 30.9108 s
agent0:                 episode reward: -0.1505,                 loss: nan
agent1:                 episode reward: 0.1505,                 loss: 0.1180
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 31.1114 s
agent0:                 episode reward: -0.4302,                 loss: nan
agent1:                 episode reward: 0.4302,                 loss: 0.1185
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1841s / 31.2954 s
agent0:                 episode reward: 0.1036,                 loss: nan
agent1:                 episode reward: -0.1036,                 loss: 0.1192
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1828s / 31.4782 s
agent0:                 episode reward: -0.0450,                 loss: nan
agent1:                 episode reward: 0.0450,                 loss: 0.1186
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1791s / 31.6573 s
agent0:                 episode reward: 0.0574,                 loss: nan
agent1:                 episode reward: -0.0574,                 loss: 0.1194
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1785s / 31.8358 s
agent0:                 episode reward: -0.3917,                 loss: nan
agent1:                 episode reward: 0.3917,                 loss: 0.1191
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1777s / 32.0135 s
agent0:                 episode reward: 0.0584,                 loss: nan
agent1:                 episode reward: -0.0584,                 loss: 0.1194
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1774s / 32.1909 s
agent0:                 episode reward: -0.0880,                 loss: nan
agent1:                 episode reward: 0.0880,                 loss: 0.1180
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1794s / 32.3703 s
agent0:                 episode reward: -0.1939,                 loss: nan
agent1:                 episode reward: 0.1939,                 loss: 0.1179
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1771s / 32.5474 s
agent0:                 episode reward: -0.2095,                 loss: nan
agent1:                 episode reward: 0.2095,                 loss: 0.1167
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1809s / 32.7283 s
agent0:                 episode reward: 0.0060,                 loss: nan
agent1:                 episode reward: -0.0060,                 loss: 0.1169
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1775s / 32.9058 s
agent0:                 episode reward: -0.1378,                 loss: nan
agent1:                 episode reward: 0.1378,                 loss: 0.1155
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1811s / 33.0870 s
agent0:                 episode reward: -0.4810,                 loss: nan
agent1:                 episode reward: 0.4810,                 loss: 0.1167
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1813s / 33.2683 s
agent0:                 episode reward: 0.0371,                 loss: nan
agent1:                 episode reward: -0.0371,                 loss: 0.1166
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1852s / 33.4534 s
agent0:                 episode reward: -0.0289,                 loss: nan
agent1:                 episode reward: 0.0289,                 loss: 0.1176
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1858s / 33.6392 s
agent0:                 episode reward: -0.2293,                 loss: nan
agent1:                 episode reward: 0.2293,                 loss: 0.1180
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1808s / 33.8200 s
agent0:                 episode reward: -0.4359,                 loss: nan
agent1:                 episode reward: 0.4359,                 loss: 0.1169
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1763s / 33.9963 s
agent0:                 episode reward: -0.4798,                 loss: nan
agent1:                 episode reward: 0.4798,                 loss: 0.1178
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1808s / 34.1771 s
agent0:                 episode reward: 0.1623,                 loss: nan
agent1:                 episode reward: -0.1623,                 loss: 0.1179
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1825s / 34.3596 s
agent0:                 episode reward: -0.4175,                 loss: nan
agent1:                 episode reward: 0.4175,                 loss: 0.1181
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1872s / 34.5468 s
agent0:                 episode reward: -0.7002,                 loss: nan
agent1:                 episode reward: 0.7002,                 loss: 0.1181
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1931s / 34.7399 s
agent0:                 episode reward: -0.1611,                 loss: nan
agent1:                 episode reward: 0.1611,                 loss: 0.1170
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1841s / 34.9240 s
agent0:                 episode reward: -0.3504,                 loss: nan
agent1:                 episode reward: 0.3504,                 loss: 0.1166
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1815s / 35.1056 s
agent0:                 episode reward: -0.4723,                 loss: nan
agent1:                 episode reward: 0.4723,                 loss: 0.1173
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1827s / 35.2882 s
agent0:                 episode reward: -0.3435,                 loss: nan
agent1:                 episode reward: 0.3435,                 loss: 0.1177
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1799s / 35.4681 s
agent0:                 episode reward: 0.1650,                 loss: nan
agent1:                 episode reward: -0.1650,                 loss: 0.1199
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1806s / 35.6487 s
agent0:                 episode reward: -0.1249,                 loss: nan
agent1:                 episode reward: 0.1249,                 loss: 0.1204
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1822s / 35.8309 s
agent0:                 episode reward: -0.2367,                 loss: nan
agent1:                 episode reward: 0.2367,                 loss: 0.1204
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1858s / 36.0167 s
agent0:                 episode reward: -0.1318,                 loss: nan
agent1:                 episode reward: 0.1318,                 loss: 0.1197
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1855s / 36.2022 s
agent0:                 episode reward: 0.2173,                 loss: nan
agent1:                 episode reward: -0.2173,                 loss: 0.1191
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2044s / 36.4066 s
agent0:                 episode reward: -0.2274,                 loss: nan
agent1:                 episode reward: 0.2274,                 loss: 0.1207
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2062s / 36.6128 s
agent0:                 episode reward: -0.4449,                 loss: nan
agent1:                 episode reward: 0.4449,                 loss: 0.1209
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2074s / 36.8202 s
agent0:                 episode reward: -0.2345,                 loss: nan
agent1:                 episode reward: 0.2345,                 loss: 0.1204
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1888s / 37.0090 s
agent0:                 episode reward: -0.4156,                 loss: nan
agent1:                 episode reward: 0.4156,                 loss: 0.1201
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1864s / 37.1954 s
agent0:                 episode reward: -0.0494,                 loss: nan
agent1:                 episode reward: 0.0494,                 loss: 0.1205
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 37.3895 s
agent0:                 episode reward: -0.1492,                 loss: nan
agent1:                 episode reward: 0.1492,                 loss: 0.1202
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1880s / 37.5775 s
agent0:                 episode reward: -0.3175,                 loss: nan
agent1:                 episode reward: 0.3175,                 loss: 0.1196
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1824s / 37.7599 s
agent0:                 episode reward: -0.0446,                 loss: nan
agent1:                 episode reward: 0.0446,                 loss: 0.1208
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1797s / 37.9396 s
agent0:                 episode reward: -0.4763,                 loss: nan
agent1:                 episode reward: 0.4763,                 loss: 0.1209
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1790s / 38.1185 s
agent0:                 episode reward: 0.1808,                 loss: nan
agent1:                 episode reward: -0.1808,                 loss: 0.1211
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1809s / 38.2995 s
agent0:                 episode reward: -0.0950,                 loss: nan
agent1:                 episode reward: 0.0950,                 loss: 0.1202
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1832s / 38.4827 s
agent0:                 episode reward: 0.1224,                 loss: nan
agent1:                 episode reward: -0.1224,                 loss: 0.1207
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1821s / 38.6648 s
agent0:                 episode reward: 0.1058,                 loss: nan
agent1:                 episode reward: -0.1058,                 loss: 0.1187
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1822s / 38.8470 s
agent0:                 episode reward: -0.2189,                 loss: nan
agent1:                 episode reward: 0.2189,                 loss: 0.1172
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1861s / 39.0331 s
agent0:                 episode reward: -0.3088,                 loss: nan
agent1:                 episode reward: 0.3088,                 loss: 0.1186
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1855s / 39.2186 s
agent0:                 episode reward: -0.3219,                 loss: nan
agent1:                 episode reward: 0.3219,                 loss: 0.1181
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1877s / 39.4063 s
agent0:                 episode reward: -0.2943,                 loss: nan
agent1:                 episode reward: 0.2943,                 loss: 0.1178
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2097s / 39.6160 s
agent0:                 episode reward: -0.4804,                 loss: nan
agent1:                 episode reward: 0.4804,                 loss: 0.1173
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2042s / 39.8202 s
agent0:                 episode reward: -0.3916,                 loss: nan
agent1:                 episode reward: 0.3916,                 loss: 0.1168
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1922s / 40.0124 s
agent0:                 episode reward: -0.3306,                 loss: nan
agent1:                 episode reward: 0.3306,                 loss: 0.1167
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1897s / 40.2021 s
agent0:                 episode reward: -0.0478,                 loss: nan
agent1:                 episode reward: 0.0478,                 loss: 0.1187
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1894s / 40.3914 s
agent0:                 episode reward: -0.2703,                 loss: nan
agent1:                 episode reward: 0.2703,                 loss: 0.1183
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1890s / 40.5804 s
agent0:                 episode reward: -0.2258,                 loss: nan
agent1:                 episode reward: 0.2258,                 loss: 0.1173
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1913s / 40.7717 s
agent0:                 episode reward: -0.1105,                 loss: nan
agent1:                 episode reward: 0.1105,                 loss: 0.1176
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1921s / 40.9638 s
agent0:                 episode reward: 0.0956,                 loss: nan
agent1:                 episode reward: -0.0956,                 loss: 0.1175
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1904s / 41.1542 s
agent0:                 episode reward: -0.4032,                 loss: nan
agent1:                 episode reward: 0.4032,                 loss: 0.1186
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1898s / 41.3440 s
agent0:                 episode reward: 0.2373,                 loss: nan
agent1:                 episode reward: -0.2373,                 loss: 0.1169
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 41.5416 s
agent0:                 episode reward: -0.2289,                 loss: nan
agent1:                 episode reward: 0.2289,                 loss: 0.1171
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1904s / 41.7320 s
agent0:                 episode reward: -0.1511,                 loss: nan
agent1:                 episode reward: 0.1511,                 loss: 0.1179
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1928s / 41.9248 s
agent0:                 episode reward: -0.1133,                 loss: nan
agent1:                 episode reward: 0.1133,                 loss: 0.1193
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1916s / 42.1164 s
agent0:                 episode reward: -0.4047,                 loss: nan
agent1:                 episode reward: 0.4047,                 loss: 0.1199
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1916s / 42.3080 s
agent0:                 episode reward: -0.4893,                 loss: nan
agent1:                 episode reward: 0.4893,                 loss: 0.1194
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 42.5064 s
agent0:                 episode reward: -0.2832,                 loss: nan
agent1:                 episode reward: 0.2832,                 loss: 0.1206
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2094s / 42.7158 s
agent0:                 episode reward: -0.0475,                 loss: nan
agent1:                 episode reward: 0.0475,                 loss: 0.1199
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1906s / 42.9064 s
agent0:                 episode reward: -0.0994,                 loss: nan
agent1:                 episode reward: 0.0994,                 loss: 0.1204
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1902s / 43.0966 s
agent0:                 episode reward: -0.2551,                 loss: nan
agent1:                 episode reward: 0.2551,                 loss: 0.1195
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1900s / 43.2866 s
agent0:                 episode reward: -0.5382,                 loss: nan
agent1:                 episode reward: 0.5382,                 loss: 0.1202
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 43.4855 s
agent0:                 episode reward: 0.0765,                 loss: nan
agent1:                 episode reward: -0.0765,                 loss: 0.1199
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2003s / 43.6858 s
agent0:                 episode reward: -0.1500,                 loss: nan
agent1:                 episode reward: 0.1500,                 loss: 0.1201
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 43.8821 s
agent0:                 episode reward: -0.5249,                 loss: nan
agent1:                 episode reward: 0.5249,                 loss: 0.1194
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1931s / 44.0752 s
agent0:                 episode reward: -0.1853,                 loss: nan
agent1:                 episode reward: 0.1853,                 loss: 0.1191
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 44.2748 s
agent0:                 episode reward: 0.2046,                 loss: nan
agent1:                 episode reward: -0.2046,                 loss: 0.1194
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 44.4740 s
agent0:                 episode reward: -0.1370,                 loss: nan
agent1:                 episode reward: 0.1370,                 loss: 0.1205
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 44.6695 s
agent0:                 episode reward: -0.3026,                 loss: nan
agent1:                 episode reward: 0.3026,                 loss: 0.1204
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1911s / 44.8606 s
agent0:                 episode reward: -0.4587,                 loss: nan
agent1:                 episode reward: 0.4587,                 loss: 0.1188
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1946s / 45.0552 s
agent0:                 episode reward: 0.2605,                 loss: nan
agent1:                 episode reward: -0.2605,                 loss: 0.1192
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2069s / 45.2621 s
agent0:                 episode reward: 0.1440,                 loss: nan
agent1:                 episode reward: -0.1440,                 loss: 0.1166
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1903s / 45.4524 s
agent0:                 episode reward: -0.1228,                 loss: nan
agent1:                 episode reward: 0.1228,                 loss: 0.1168
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2137s / 45.6661 s
agent0:                 episode reward: 0.0315,                 loss: nan
agent1:                 episode reward: -0.0315,                 loss: 0.1167
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2112s / 45.8773 s
agent0:                 episode reward: -0.1634,                 loss: nan
agent1:                 episode reward: 0.1634,                 loss: 0.1164
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 46.0732 s
agent0:                 episode reward: -0.5834,                 loss: nan
agent1:                 episode reward: 0.5834,                 loss: 0.1160
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1945s / 46.2677 s
agent0:                 episode reward: -0.2905,                 loss: nan
agent1:                 episode reward: 0.2905,                 loss: 0.1153
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 46.4637 s
agent0:                 episode reward: -0.3675,                 loss: nan
agent1:                 episode reward: 0.3675,                 loss: 0.1161
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 46.6592 s
agent0:                 episode reward: -0.6395,                 loss: nan
agent1:                 episode reward: 0.6395,                 loss: 0.1166
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1855s / 46.8447 s
agent0:                 episode reward: -0.7243,                 loss: nan
agent1:                 episode reward: 0.7243,                 loss: 0.1161
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1889s / 47.0336 s
agent0:                 episode reward: -0.5278,                 loss: nan
agent1:                 episode reward: 0.5278,                 loss: 0.1168
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1906s / 47.2242 s
agent0:                 episode reward: -0.6447,                 loss: nan
agent1:                 episode reward: 0.6447,                 loss: 0.1166
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1911s / 47.4153 s
agent0:                 episode reward: -0.0992,                 loss: nan
agent1:                 episode reward: 0.0992,                 loss: 0.1159
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1920s / 47.6073 s
agent0:                 episode reward: -0.0611,                 loss: nan
agent1:                 episode reward: 0.0611,                 loss: 0.1156
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1913s / 47.7986 s
agent0:                 episode reward: -0.0675,                 loss: nan
agent1:                 episode reward: 0.0675,                 loss: 0.1155
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2283s / 48.0268 s
agent0:                 episode reward: 0.0290,                 loss: nan
agent1:                 episode reward: -0.0290,                 loss: 0.1164
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 48.2222 s
agent0:                 episode reward: 0.1316,                 loss: nan
agent1:                 episode reward: -0.1316,                 loss: 0.1164
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1951s / 48.4173 s
agent0:                 episode reward: -0.1058,                 loss: nan
agent1:                 episode reward: 0.1058,                 loss: 0.1143
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 48.6135 s
agent0:                 episode reward: -0.2359,                 loss: nan
agent1:                 episode reward: 0.2359,                 loss: 0.1149
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2219s / 48.8354 s
agent0:                 episode reward: 0.0326,                 loss: nan
agent1:                 episode reward: -0.0326,                 loss: 0.1142
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 49.0380 s
agent0:                 episode reward: -0.2144,                 loss: nan
agent1:                 episode reward: 0.2144,                 loss: 0.1153
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 49.2371 s
agent0:                 episode reward: -0.2361,                 loss: nan
agent1:                 episode reward: 0.2361,                 loss: 0.1151
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 49.4349 s
agent0:                 episode reward: -0.4140,                 loss: nan
agent1:                 episode reward: 0.4140,                 loss: 0.1152
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 49.6301 s
agent0:                 episode reward: -0.3326,                 loss: nan
agent1:                 episode reward: 0.3326,                 loss: 0.1136
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1936s / 49.8237 s
agent0:                 episode reward: -0.4776,                 loss: nan
agent1:                 episode reward: 0.4776,                 loss: 0.1150
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1920s / 50.0158 s
agent0:                 episode reward: -0.1540,                 loss: nan
agent1:                 episode reward: 0.1540,                 loss: 0.1157
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 50.2110 s
agent0:                 episode reward: -0.5158,                 loss: nan
agent1:                 episode reward: 0.5158,                 loss: 0.1158
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 50.4066 s
agent0:                 episode reward: -0.2590,                 loss: nan
agent1:                 episode reward: 0.2590,                 loss: 0.1152
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1944s / 50.6010 s
agent0:                 episode reward: -0.2236,                 loss: nan
agent1:                 episode reward: 0.2236,                 loss: 0.1152
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 50.7956 s
agent0:                 episode reward: -0.2517,                 loss: nan
agent1:                 episode reward: 0.2517,                 loss: 0.1154
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 50.9944 s
agent0:                 episode reward: -0.2414,                 loss: nan
agent1:                 episode reward: 0.2414,                 loss: 0.1146
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 51.1901 s
agent0:                 episode reward: -0.0272,                 loss: nan
agent1:                 episode reward: 0.0272,                 loss: 0.1156
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1951s / 51.3852 s
agent0:                 episode reward: -0.4466,                 loss: nan
agent1:                 episode reward: 0.4466,                 loss: 0.1145
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1934s / 51.5786 s
agent0:                 episode reward: -0.1001,                 loss: nan
agent1:                 episode reward: 0.1001,                 loss: 0.1151
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2259s / 51.8045 s
agent0:                 episode reward: -0.7542,                 loss: nan
agent1:                 episode reward: 0.7542,                 loss: 0.1174
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2169s / 52.0214 s
agent0:                 episode reward: -0.3916,                 loss: nan
agent1:                 episode reward: 0.3916,                 loss: 0.1154
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 52.2221 s
agent0:                 episode reward: -0.2825,                 loss: nan
agent1:                 episode reward: 0.2825,                 loss: 0.1154
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1937s / 52.4157 s
agent0:                 episode reward: -0.3761,                 loss: nan
agent1:                 episode reward: 0.3761,                 loss: 0.1154
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2032s / 52.6190 s
agent0:                 episode reward: -0.4342,                 loss: nan
agent1:                 episode reward: 0.4342,                 loss: 0.1162
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2050s / 52.8240 s
agent0:                 episode reward: -0.2960,                 loss: nan
agent1:                 episode reward: 0.2960,                 loss: 0.1141
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2032s / 53.0271 s
agent0:                 episode reward: -0.3427,                 loss: nan
agent1:                 episode reward: 0.3427,                 loss: 0.1143
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2053s / 53.2324 s
agent0:                 episode reward: -0.1449,                 loss: nan
agent1:                 episode reward: 0.1449,                 loss: 0.1141
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2228s / 53.4552 s
agent0:                 episode reward: -0.3891,                 loss: nan
agent1:                 episode reward: 0.3891,                 loss: 0.1154
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 53.6567 s
agent0:                 episode reward: -0.3831,                 loss: nan
agent1:                 episode reward: 0.3831,                 loss: 0.1167
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2061s / 53.8627 s
agent0:                 episode reward: -0.2203,                 loss: nan
agent1:                 episode reward: 0.2203,                 loss: 0.1156
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2086s / 54.0713 s
agent0:                 episode reward: -0.5355,                 loss: nan
agent1:                 episode reward: 0.5355,                 loss: 0.1144
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2048s / 54.2762 s
agent0:                 episode reward: -0.4220,                 loss: nan
agent1:                 episode reward: 0.4220,                 loss: 0.1150
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 54.4743 s
agent0:                 episode reward: -0.3278,                 loss: nan
agent1:                 episode reward: 0.3278,                 loss: 0.1156
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 54.6738 s
agent0:                 episode reward: -0.2535,                 loss: nan
agent1:                 episode reward: 0.2535,                 loss: 0.1153
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2181s / 54.8919 s
agent0:                 episode reward: -0.1771,                 loss: nan
agent1:                 episode reward: 0.1771,                 loss: 0.1158
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2081s / 55.1000 s
agent0:                 episode reward: -0.5342,                 loss: nan
agent1:                 episode reward: 0.5342,                 loss: 0.1158
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 55.3015 s
agent0:                 episode reward: -0.0586,                 loss: nan
agent1:                 episode reward: 0.0586,                 loss: 0.1155
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2168s / 55.5183 s
agent0:                 episode reward: -0.3430,                 loss: nan
agent1:                 episode reward: 0.3430,                 loss: 0.1149
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2185s / 55.7368 s
agent0:                 episode reward: -0.1739,                 loss: nan
agent1:                 episode reward: 0.1739,                 loss: 0.1134
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2156s / 55.9523 s
agent0:                 episode reward: -0.0601,                 loss: nan
agent1:                 episode reward: 0.0601,                 loss: 0.1140
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2108s / 56.1632 s
agent0:                 episode reward: -0.5956,                 loss: nan
agent1:                 episode reward: 0.5956,                 loss: 0.1127
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 56.3643 s
agent0:                 episode reward: -0.1487,                 loss: nan
agent1:                 episode reward: 0.1487,                 loss: 0.1140
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 56.5640 s
agent0:                 episode reward: -0.3250,                 loss: nan
agent1:                 episode reward: 0.3250,                 loss: 0.1144
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 56.7651 s
agent0:                 episode reward: -0.2198,                 loss: nan
agent1:                 episode reward: 0.2198,                 loss: 0.1125
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 56.9661 s
agent0:                 episode reward: -0.8201,                 loss: nan
agent1:                 episode reward: 0.8201,                 loss: 0.1138
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 57.1654 s
agent0:                 episode reward: -0.2282,                 loss: nan
agent1:                 episode reward: 0.2282,                 loss: 0.1139
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 57.3652 s
agent0:                 episode reward: -0.4503,                 loss: nan
agent1:                 episode reward: 0.4503,                 loss: 0.1139
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 57.5654 s
agent0:                 episode reward: -0.3094,                 loss: nan
agent1:                 episode reward: 0.3094,                 loss: 0.1140
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 57.7681 s
agent0:                 episode reward: -0.0196,                 loss: nan
agent1:                 episode reward: 0.0196,                 loss: 0.1152
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2222s / 57.9904 s
agent0:                 episode reward: -0.3477,                 loss: nan
agent1:                 episode reward: 0.3477,                 loss: 0.1146
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2052s / 58.1956 s
agent0:                 episode reward: -0.4934,                 loss: nan
agent1:                 episode reward: 0.4934,                 loss: 0.1134
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2201s / 58.4156 s
agent0:                 episode reward: -0.0644,                 loss: nan
agent1:                 episode reward: 0.0644,                 loss: 0.1145
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 58.6114 s
agent0:                 episode reward: -0.5916,                 loss: nan
agent1:                 episode reward: 0.5916,                 loss: 0.1130
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 58.8061 s
agent0:                 episode reward: -0.2684,                 loss: nan
agent1:                 episode reward: 0.2684,                 loss: 0.1139
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 59.0026 s
agent0:                 episode reward: -0.5438,                 loss: nan
agent1:                 episode reward: 0.5438,                 loss: 0.1142
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 59.2048 s
agent0:                 episode reward: -0.3249,                 loss: nan
agent1:                 episode reward: 0.3249,                 loss: 0.1116
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2028s / 59.4076 s
agent0:                 episode reward: -0.4284,                 loss: nan
agent1:                 episode reward: 0.4284,                 loss: 0.1127
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 59.6093 s
agent0:                 episode reward: -0.1908,                 loss: nan
agent1:                 episode reward: 0.1908,                 loss: 0.1121
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2114s / 59.8207 s
agent0:                 episode reward: -0.0790,                 loss: nan
agent1:                 episode reward: 0.0790,                 loss: 0.1116
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2138s / 60.0345 s
agent0:                 episode reward: -0.4734,                 loss: nan
agent1:                 episode reward: 0.4734,                 loss: 0.1128
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2128s / 60.2473 s
agent0:                 episode reward: -0.5447,                 loss: nan
agent1:                 episode reward: 0.5447,                 loss: 0.1119
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 60.4481 s
agent0:                 episode reward: -0.0784,                 loss: nan
agent1:                 episode reward: 0.0784,                 loss: 0.1128
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 60.6497 s
agent0:                 episode reward: -0.1197,                 loss: nan
agent1:                 episode reward: 0.1197,                 loss: 0.1133
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2079s / 60.8576 s
agent0:                 episode reward: -0.4677,                 loss: nan
agent1:                 episode reward: 0.4677,                 loss: 0.1128
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2280s / 61.0855 s
agent0:                 episode reward: 0.0870,                 loss: nan
agent1:                 episode reward: -0.0870,                 loss: 0.1125
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2051s / 61.2907 s
agent0:                 episode reward: -0.2474,                 loss: nan
agent1:                 episode reward: 0.2474,                 loss: 0.1125
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 61.4876 s
agent0:                 episode reward: -0.1399,                 loss: nan
agent1:                 episode reward: 0.1399,                 loss: 0.1125
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2049s / 61.6925 s
agent0:                 episode reward: -0.5753,                 loss: nan
agent1:                 episode reward: 0.5753,                 loss: 0.1132
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2151s / 61.9076 s
agent0:                 episode reward: -0.1126,                 loss: nan
agent1:                 episode reward: 0.1126,                 loss: 0.1137
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 62.1069 s
agent0:                 episode reward: -0.2917,                 loss: nan
agent1:                 episode reward: 0.2917,                 loss: 0.1119
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2116s / 62.3185 s
agent0:                 episode reward: -0.5400,                 loss: nan
agent1:                 episode reward: 0.5400,                 loss: 0.1131
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2085s / 62.5270 s
agent0:                 episode reward: -0.0562,                 loss: nan
agent1:                 episode reward: 0.0562,                 loss: 0.1130
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2100s / 62.7370 s
agent0:                 episode reward: -0.4754,                 loss: nan
agent1:                 episode reward: 0.4754,                 loss: 0.1120
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2120s / 62.9490 s
agent0:                 episode reward: -0.5590,                 loss: nan
agent1:                 episode reward: 0.5590,                 loss: 0.1124
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2024s / 63.1514 s
agent0:                 episode reward: 0.2162,                 loss: nan
agent1:                 episode reward: -0.2162,                 loss: 0.1129
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2068s / 63.3582 s
agent0:                 episode reward: -0.3446,                 loss: nan
agent1:                 episode reward: 0.3446,                 loss: 0.1134
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2106s / 63.5688 s
agent0:                 episode reward: -0.1854,                 loss: nan
agent1:                 episode reward: 0.1854,                 loss: 0.1127
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2116s / 63.7804 s
agent0:                 episode reward: -0.5471,                 loss: nan
agent1:                 episode reward: 0.5471,                 loss: 0.1134
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2273s / 64.0076 s
agent0:                 episode reward: -0.4806,                 loss: nan
agent1:                 episode reward: 0.4806,                 loss: 0.1129
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2310s / 64.2387 s
agent0:                 episode reward: -0.1878,                 loss: nan
agent1:                 episode reward: 0.1878,                 loss: 0.1129
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2168s / 64.4555 s
agent0:                 episode reward: -0.1405,                 loss: nan
agent1:                 episode reward: 0.1405,                 loss: 0.1143
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2185s / 64.6740 s
agent0:                 episode reward: -0.4497,                 loss: nan
agent1:                 episode reward: 0.4497,                 loss: 0.1126
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2147s / 64.8888 s
agent0:                 episode reward: -0.3097,                 loss: nan
agent1:                 episode reward: 0.3097,                 loss: 0.1124
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2136s / 65.1023 s
agent0:                 episode reward: -0.3730,                 loss: nan
agent1:                 episode reward: 0.3730,                 loss: 0.1132
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2159s / 65.3182 s
agent0:                 episode reward: -0.2190,                 loss: nan
agent1:                 episode reward: 0.2190,                 loss: 0.1129
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2234s / 65.5416 s
agent0:                 episode reward: -0.5422,                 loss: nan
agent1:                 episode reward: 0.5422,                 loss: 0.1142
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2124s / 65.7541 s
agent0:                 episode reward: -0.2827,                 loss: nan
agent1:                 episode reward: 0.2827,                 loss: 0.1144
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2134s / 65.9675 s
agent0:                 episode reward: -0.2883,                 loss: nan
agent1:                 episode reward: 0.2883,                 loss: 0.1144
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2141s / 66.1816 s
agent0:                 episode reward: -0.5268,                 loss: nan
agent1:                 episode reward: 0.5268,                 loss: 0.1142
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2089s / 66.3905 s
agent0:                 episode reward: -0.3496,                 loss: nan
agent1:                 episode reward: 0.3496,                 loss: 0.1130
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2093s / 66.5998 s
agent0:                 episode reward: -0.2370,                 loss: nan
agent1:                 episode reward: 0.2370,                 loss: 0.1147
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2079s / 66.8077 s
agent0:                 episode reward: -0.2158,                 loss: nan
agent1:                 episode reward: 0.2158,                 loss: 0.1134
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2138s / 67.0215 s
agent0:                 episode reward: -0.3896,                 loss: nan
agent1:                 episode reward: 0.3896,                 loss: 0.1136
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2299s / 67.2513 s
agent0:                 episode reward: -0.5118,                 loss: nan
agent1:                 episode reward: 0.5118,                 loss: 0.1141
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2147s / 67.4661 s
agent0:                 episode reward: -0.4605,                 loss: nan
agent1:                 episode reward: 0.4605,                 loss: 0.1135
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2091s / 67.6752 s
agent0:                 episode reward: -0.4384,                 loss: nan
agent1:                 episode reward: 0.4384,                 loss: 0.1137
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2107s / 67.8858 s
agent0:                 episode reward: -0.7630,                 loss: nan
agent1:                 episode reward: 0.7630,                 loss: 0.1140
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2070s / 68.0928 s
agent0:                 episode reward: -0.6905,                 loss: nan
agent1:                 episode reward: 0.6905,                 loss: 0.1140
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2071s / 68.2999 s
agent0:                 episode reward: -0.2162,                 loss: nan
agent1:                 episode reward: 0.2162,                 loss: 0.1128
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2121s / 68.5120 s
agent0:                 episode reward: -0.3150,                 loss: nan
agent1:                 episode reward: 0.3150,                 loss: 0.1139
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2082s / 68.7202 s
agent0:                 episode reward: -0.2281,                 loss: nan
agent1:                 episode reward: 0.2281,                 loss: 0.1131
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2097s / 68.9299 s
agent0:                 episode reward: -0.1735,                 loss: nan
agent1:                 episode reward: 0.1735,                 loss: 0.1136
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2081s / 69.1380 s
agent0:                 episode reward: -0.3480,                 loss: nan
agent1:                 episode reward: 0.3480,                 loss: 0.1159
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2131s / 69.3511 s
agent0:                 episode reward: -0.5654,                 loss: nan
agent1:                 episode reward: 0.5654,                 loss: 0.1143
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2088s / 69.5600 s
agent0:                 episode reward: -0.2698,                 loss: nan
agent1:                 episode reward: 0.2698,                 loss: 0.1122
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2082s / 69.7681 s
agent0:                 episode reward: -0.6538,                 loss: nan
agent1:                 episode reward: 0.6538,                 loss: 0.1143
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2068s / 69.9749 s
agent0:                 episode reward: -0.1267,                 loss: nan
agent1:                 episode reward: 0.1267,                 loss: 0.1133
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2545s / 70.2294 s
agent0:                 episode reward: -0.4475,                 loss: nan
agent1:                 episode reward: 0.4475,                 loss: 0.1145
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2360s / 70.4655 s
agent0:                 episode reward: -0.5890,                 loss: nan
agent1:                 episode reward: 0.5890,                 loss: 0.1148
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2146s / 70.6801 s
agent0:                 episode reward: -0.2062,                 loss: nan
agent1:                 episode reward: 0.2062,                 loss: 0.1146
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2094s / 70.8894 s
agent0:                 episode reward: -0.4084,                 loss: nan
agent1:                 episode reward: 0.4084,                 loss: 0.1149
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2134s / 71.1028 s
agent0:                 episode reward: -0.7380,                 loss: nan
agent1:                 episode reward: 0.7380,                 loss: 0.1133
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2108s / 71.3136 s
agent0:                 episode reward: -0.8691,                 loss: nan
agent1:                 episode reward: 0.8691,                 loss: 0.1132
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2107s / 71.5244 s
agent0:                 episode reward: -0.3704,                 loss: nan
agent1:                 episode reward: 0.3704,                 loss: 0.1141
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2050s / 71.7294 s
agent0:                 episode reward: -0.3259,                 loss: nan
agent1:                 episode reward: 0.3259,                 loss: 0.1137
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2146s / 71.9440 s
agent0:                 episode reward: -0.3810,                 loss: nan
agent1:                 episode reward: 0.3810,                 loss: 0.1151
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2111s / 72.1551 s
agent0:                 episode reward: -0.4099,                 loss: nan
agent1:                 episode reward: 0.4099,                 loss: 0.1145
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2073s / 72.3624 s
agent0:                 episode reward: -0.1942,                 loss: nan
agent1:                 episode reward: 0.1942,                 loss: 0.1148
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2078s / 72.5702 s
agent0:                 episode reward: -0.3656,                 loss: nan
agent1:                 episode reward: 0.3656,                 loss: 0.1125
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2055s / 72.7758 s
agent0:                 episode reward: -0.7405,                 loss: nan
agent1:                 episode reward: 0.7405,                 loss: 0.1143
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2045s / 72.9802 s
agent0:                 episode reward: -0.8580,                 loss: nan
agent1:                 episode reward: 0.8580,                 loss: 0.1122
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2299s / 73.2101 s
agent0:                 episode reward: -0.5473,                 loss: nan
agent1:                 episode reward: 0.5473,                 loss: 0.1121
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2212s / 73.4313 s
agent0:                 episode reward: -0.3148,                 loss: nan
agent1:                 episode reward: 0.3148,                 loss: 0.1125
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2150s / 73.6463 s
agent0:                 episode reward: -0.0538,                 loss: nan
agent1:                 episode reward: 0.0538,                 loss: 0.1121
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2156s / 73.8619 s
agent0:                 episode reward: -0.2313,                 loss: nan
agent1:                 episode reward: 0.2313,                 loss: 0.1122
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2048s / 74.0667 s
agent0:                 episode reward: -0.2924,                 loss: nan
agent1:                 episode reward: 0.2924,                 loss: 0.1114
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2118s / 74.2785 s
agent0:                 episode reward: 0.2122,                 loss: nan
agent1:                 episode reward: -0.2122,                 loss: 0.1129
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2192s / 74.4977 s
agent0:                 episode reward: -0.2896,                 loss: nan
agent1:                 episode reward: 0.2896,                 loss: 0.1128
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2051s / 74.7028 s
agent0:                 episode reward: -0.1935,                 loss: nan
agent1:                 episode reward: 0.1935,                 loss: 0.1114
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2117s / 74.9145 s
agent0:                 episode reward: -0.3360,                 loss: nan
agent1:                 episode reward: 0.3360,                 loss: 0.1119
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2140s / 75.1285 s
agent0:                 episode reward: -0.6808,                 loss: nan
agent1:                 episode reward: 0.6808,                 loss: 0.1124
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2146s / 75.3431 s
agent0:                 episode reward: -0.0200,                 loss: nan
agent1:                 episode reward: 0.0200,                 loss: 0.1112
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2123s / 75.5554 s
agent0:                 episode reward: -0.1853,                 loss: nan
agent1:                 episode reward: 0.1853,                 loss: 0.1122
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2056s / 75.7610 s
agent0:                 episode reward: -0.2628,                 loss: nan
agent1:                 episode reward: 0.2628,                 loss: 0.1141
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2070s / 75.9680 s
agent0:                 episode reward: -0.3608,                 loss: nan
agent1:                 episode reward: 0.3608,                 loss: 0.1123
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2038s / 76.1718 s
agent0:                 episode reward: -0.4464,                 loss: nan
agent1:                 episode reward: 0.4464,                 loss: 0.1111
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 76.3723 s
agent0:                 episode reward: -0.3966,                 loss: nan
agent1:                 episode reward: 0.3966,                 loss: 0.1132
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 76.5746 s
agent0:                 episode reward: -0.6663,                 loss: nan
agent1:                 episode reward: 0.6663,                 loss: 0.1118
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 76.7762 s
agent0:                 episode reward: -0.5272,                 loss: nan
agent1:                 episode reward: 0.5272,                 loss: 0.1115
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2038s / 76.9800 s
agent0:                 episode reward: -0.1632,                 loss: nan
agent1:                 episode reward: 0.1632,                 loss: 0.1127
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 77.1782 s
agent0:                 episode reward: -0.1980,                 loss: nan
agent1:                 episode reward: 0.1980,                 loss: 0.1125
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2113s / 77.3895 s
agent0:                 episode reward: -0.4993,                 loss: nan
agent1:                 episode reward: 0.4993,                 loss: 0.1122
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2131s / 77.6026 s
agent0:                 episode reward: -0.3785,                 loss: nan
agent1:                 episode reward: 0.3785,                 loss: 0.1114
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2170s / 77.8196 s
agent0:                 episode reward: -0.2039,                 loss: nan
agent1:                 episode reward: 0.2039,                 loss: 0.1138
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2193s / 78.0390 s
agent0:                 episode reward: -0.7088,                 loss: nan
agent1:                 episode reward: 0.7088,                 loss: 0.1114
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2146s / 78.2536 s
agent0:                 episode reward: -0.2783,                 loss: nan
agent1:                 episode reward: 0.2783,                 loss: 0.1116
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2342s / 78.4877 s
agent0:                 episode reward: -0.3715,                 loss: nan
agent1:                 episode reward: 0.3715,                 loss: 0.1130
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2063s / 78.6940 s
agent0:                 episode reward: -0.6927,                 loss: nan
agent1:                 episode reward: 0.6927,                 loss: 0.1122
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2535s / 78.9475 s
agent0:                 episode reward: -0.1197,                 loss: nan
agent1:                 episode reward: 0.1197,                 loss: 0.1135
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2319s / 79.1794 s
agent0:                 episode reward: -0.3959,                 loss: nan
agent1:                 episode reward: 0.3959,                 loss: 0.1116
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2122s / 79.3916 s
agent0:                 episode reward: -0.3192,                 loss: nan
agent1:                 episode reward: 0.3192,                 loss: 0.1136
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2100s / 79.6016 s
agent0:                 episode reward: -0.3773,                 loss: nan
agent1:                 episode reward: 0.3773,                 loss: 0.1126
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2111s / 79.8127 s
agent0:                 episode reward: -0.7381,                 loss: nan
agent1:                 episode reward: 0.7381,                 loss: 0.1112
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2061s / 80.0189 s
agent0:                 episode reward: -0.4999,                 loss: nan
agent1:                 episode reward: 0.4999,                 loss: 0.1107
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2077s / 80.2266 s
agent0:                 episode reward: -0.5198,                 loss: nan
agent1:                 episode reward: 0.5198,                 loss: 0.1105
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2108s / 80.4374 s
agent0:                 episode reward: -0.2982,                 loss: nan
agent1:                 episode reward: 0.2982,                 loss: 0.1092
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2076s / 80.6451 s
agent0:                 episode reward: -0.3620,                 loss: nan
agent1:                 episode reward: 0.3620,                 loss: 0.1105
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2072s / 80.8523 s
agent0:                 episode reward: -0.3972,                 loss: nan
agent1:                 episode reward: 0.3972,                 loss: 0.1100
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2152s / 81.0675 s
agent0:                 episode reward: -0.6706,                 loss: nan
agent1:                 episode reward: 0.6706,                 loss: 0.1086
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2100s / 81.2775 s
agent0:                 episode reward: -0.2664,                 loss: nan
agent1:                 episode reward: 0.2664,                 loss: 0.1105
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2071s / 81.4846 s
agent0:                 episode reward: -0.5720,                 loss: nan
agent1:                 episode reward: 0.5720,                 loss: 0.1099
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2054s / 81.6900 s
agent0:                 episode reward: -0.7777,                 loss: nan
agent1:                 episode reward: 0.7777,                 loss: 0.1091
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2121s / 81.9021 s
agent0:                 episode reward: -0.4561,                 loss: nan
agent1:                 episode reward: 0.4561,                 loss: 0.1099
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2326s / 82.1347 s
agent0:                 episode reward: -0.7227,                 loss: nan
agent1:                 episode reward: 0.7227,                 loss: 0.1094
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2333s / 82.3680 s
agent0:                 episode reward: -0.2179,                 loss: nan
agent1:                 episode reward: 0.2179,                 loss: 0.1108
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2078s / 82.5758 s
agent0:                 episode reward: 0.0211,                 loss: nan
agent1:                 episode reward: -0.0211,                 loss: 0.1102
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2355s / 82.8112 s
agent0:                 episode reward: -0.5487,                 loss: nan
agent1:                 episode reward: 0.5487,                 loss: 0.1102
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2197s / 83.0309 s
agent0:                 episode reward: -0.5439,                 loss: nan
agent1:                 episode reward: 0.5439,                 loss: 0.1098
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2193s / 83.2502 s
agent0:                 episode reward: -0.3060,                 loss: nan
agent1:                 episode reward: 0.3060,                 loss: 0.1098
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2200s / 83.4702 s
agent0:                 episode reward: -0.4891,                 loss: nan
agent1:                 episode reward: 0.4891,                 loss: 0.1116
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2144s / 83.6847 s
agent0:                 episode reward: -0.2689,                 loss: nan
agent1:                 episode reward: 0.2689,                 loss: 0.1106
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2241s / 83.9088 s
agent0:                 episode reward: -0.2420,                 loss: nan
agent1:                 episode reward: 0.2420,                 loss: 0.1129
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2263s / 84.1351 s
agent0:                 episode reward: -0.2694,                 loss: nan
agent1:                 episode reward: 0.2694,                 loss: 0.1117
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2272s / 84.3623 s
agent0:                 episode reward: -0.3216,                 loss: nan
agent1:                 episode reward: 0.3216,                 loss: 0.1106
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2228s / 84.5851 s
agent0:                 episode reward: -0.2525,                 loss: nan
agent1:                 episode reward: 0.2525,                 loss: 0.1121
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2215s / 84.8067 s
agent0:                 episode reward: -0.7883,                 loss: nan
agent1:                 episode reward: 0.7883,                 loss: 0.1113
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2204s / 85.0271 s
agent0:                 episode reward: -0.3166,                 loss: nan
agent1:                 episode reward: 0.3166,                 loss: 0.1115
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2441s / 85.2712 s
agent0:                 episode reward: -0.5679,                 loss: nan
agent1:                 episode reward: 0.5679,                 loss: 0.1111
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2291s / 85.5003 s
agent0:                 episode reward: -0.5581,                 loss: nan
agent1:                 episode reward: 0.5581,                 loss: 0.1111
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2194s / 85.7197 s
agent0:                 episode reward: -0.8013,                 loss: nan
agent1:                 episode reward: 0.8013,                 loss: 0.1107
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2223s / 85.9420 s
agent0:                 episode reward: -0.4558,                 loss: nan
agent1:                 episode reward: 0.4558,                 loss: 0.1095
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2076s / 86.1496 s
agent0:                 episode reward: -0.0996,                 loss: nan
agent1:                 episode reward: 0.0996,                 loss: 0.1098
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2157s / 86.3653 s
agent0:                 episode reward: -0.5628,                 loss: nan
agent1:                 episode reward: 0.5628,                 loss: 0.1125
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2133s / 86.5786 s
agent0:                 episode reward: -0.6622,                 loss: nan
agent1:                 episode reward: 0.6622,                 loss: 0.1102
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2269s / 86.8055 s
agent0:                 episode reward: -0.3135,                 loss: nan
agent1:                 episode reward: 0.3135,                 loss: 0.1115
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2215s / 87.0270 s
agent0:                 episode reward: -0.5276,                 loss: nan
agent1:                 episode reward: 0.5276,                 loss: 0.1100
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2195s / 87.2465 s
agent0:                 episode reward: -0.5731,                 loss: nan
agent1:                 episode reward: 0.5731,                 loss: 0.1103
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2136s / 87.4601 s
agent0:                 episode reward: -0.5789,                 loss: nan
agent1:                 episode reward: 0.5789,                 loss: 0.1094
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2138s / 87.6738 s
agent0:                 episode reward: -0.1393,                 loss: nan
agent1:                 episode reward: 0.1393,                 loss: 0.1107
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2232s / 87.8970 s
agent0:                 episode reward: -0.2379,                 loss: nan
agent1:                 episode reward: 0.2379,                 loss: 0.1106
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2202s / 88.1172 s
agent0:                 episode reward: -0.1796,                 loss: nan
agent1:                 episode reward: 0.1796,                 loss: 0.1103
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2226s / 88.3398 s
agent0:                 episode reward: -0.4365,                 loss: nan
agent1:                 episode reward: 0.4365,                 loss: 0.1119
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2211s / 88.5609 s
agent0:                 episode reward: -0.1179,                 loss: nan
agent1:                 episode reward: 0.1179,                 loss: 0.1093
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2180s / 88.7789 s
agent0:                 episode reward: -0.0308,                 loss: nan
agent1:                 episode reward: 0.0308,                 loss: 0.1099
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2163s / 88.9953 s
agent0:                 episode reward: -0.5346,                 loss: nan
agent1:                 episode reward: 0.5346,                 loss: 0.1102
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2170s / 89.2122 s
agent0:                 episode reward: -0.6527,                 loss: nan
agent1:                 episode reward: 0.6527,                 loss: 0.1094
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2200s / 89.4322 s
agent0:                 episode reward: -0.4012,                 loss: nan
agent1:                 episode reward: 0.4012,                 loss: 0.1098
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2207s / 89.6529 s
agent0:                 episode reward: -0.5796,                 loss: nan
agent1:                 episode reward: 0.5796,                 loss: 0.1107
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2200s / 89.8729 s
agent0:                 episode reward: -0.6216,                 loss: nan
agent1:                 episode reward: 0.6216,                 loss: 0.1083
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2198s / 90.0927 s
agent0:                 episode reward: -0.3974,                 loss: nan
agent1:                 episode reward: 0.3974,                 loss: 0.1109
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2326s / 90.3253 s
agent0:                 episode reward: -0.1603,                 loss: nan
agent1:                 episode reward: 0.1603,                 loss: 0.1105
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2232s / 90.5486 s
agent0:                 episode reward: -0.0183,                 loss: nan
agent1:                 episode reward: 0.0183,                 loss: 0.1088
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2222s / 90.7708 s
agent0:                 episode reward: -0.0997,                 loss: nan
agent1:                 episode reward: 0.0997,                 loss: 0.1095
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2278s / 90.9985 s
agent0:                 episode reward: -0.6796,                 loss: nan
agent1:                 episode reward: 0.6796,                 loss: 0.1121
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2312s / 91.2297 s
agent0:                 episode reward: -0.4918,                 loss: nan
agent1:                 episode reward: 0.4918,                 loss: 0.1098
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2127s / 91.4424 s
agent0:                 episode reward: -0.4115,                 loss: nan
agent1:                 episode reward: 0.4115,                 loss: 0.1114
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2182s / 91.6607 s
agent0:                 episode reward: -0.1716,                 loss: nan
agent1:                 episode reward: 0.1716,                 loss: 0.1106
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2243s / 91.8850 s
agent0:                 episode reward: -0.3324,                 loss: nan
agent1:                 episode reward: 0.3324,                 loss: 0.1113
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2240s / 92.1089 s
agent0:                 episode reward: -0.3488,                 loss: nan
agent1:                 episode reward: 0.3488,                 loss: 0.1113
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2262s / 92.3352 s
agent0:                 episode reward: -0.4864,                 loss: nan
agent1:                 episode reward: 0.4864,                 loss: 0.1107
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2216s / 92.5567 s
agent0:                 episode reward: -0.0705,                 loss: nan
agent1:                 episode reward: 0.0705,                 loss: 0.1109
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2304s / 92.7871 s
agent0:                 episode reward: -0.5449,                 loss: nan
agent1:                 episode reward: 0.5449,                 loss: 0.1106
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2523s / 93.0394 s
agent0:                 episode reward: -0.0938,                 loss: nan
agent1:                 episode reward: 0.0938,                 loss: 0.1118
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2202s / 93.2596 s
agent0:                 episode reward: -0.3207,                 loss: nan
agent1:                 episode reward: 0.3207,                 loss: 0.1104
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2259s / 93.4855 s
agent0:                 episode reward: -0.1730,                 loss: nan
agent1:                 episode reward: 0.1730,                 loss: 0.1111
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2419s / 93.7274 s
agent0:                 episode reward: -0.5812,                 loss: nan
agent1:                 episode reward: 0.5812,                 loss: 0.1110
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2425s / 93.9699 s
agent0:                 episode reward: -0.4199,                 loss: nan
agent1:                 episode reward: 0.4199,                 loss: 0.1119
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2728s / 94.2427 s
agent0:                 episode reward: -0.4052,                 loss: nan
agent1:                 episode reward: 0.4052,                 loss: 0.1105
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2278s / 94.4705 s
agent0:                 episode reward: -0.0589,                 loss: nan
agent1:                 episode reward: 0.0589,                 loss: 0.1104
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2159s / 94.6864 s
agent0:                 episode reward: -0.3433,                 loss: nan
agent1:                 episode reward: 0.3433,                 loss: 0.1123
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2185s / 94.9049 s
agent0:                 episode reward: -0.3557,                 loss: nan
agent1:                 episode reward: 0.3557,                 loss: 0.1118
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2444s / 95.1493 s
agent0:                 episode reward: -0.5248,                 loss: nan
agent1:                 episode reward: 0.5248,                 loss: 0.1108
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2223s / 95.3716 s
agent0:                 episode reward: -0.8155,                 loss: nan
agent1:                 episode reward: 0.8155,                 loss: 0.1105
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2171s / 95.5887 s
agent0:                 episode reward: -0.0665,                 loss: nan
agent1:                 episode reward: 0.0665,                 loss: 0.1109
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2127s / 95.8014 s
agent0:                 episode reward: -0.2254,                 loss: nan
agent1:                 episode reward: 0.2254,                 loss: 0.1108
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2264s / 96.0278 s
agent0:                 episode reward: 0.0701,                 loss: nan
agent1:                 episode reward: -0.0701,                 loss: 0.1109
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2162s / 96.2440 s
agent0:                 episode reward: -0.2521,                 loss: nan
agent1:                 episode reward: 0.2521,                 loss: 0.1109
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2139s / 96.4580 s
agent0:                 episode reward: -0.0394,                 loss: nan
agent1:                 episode reward: 0.0394,                 loss: 0.1108
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2229s / 96.6809 s
agent0:                 episode reward: -0.3204,                 loss: nan
agent1:                 episode reward: 0.3204,                 loss: 0.1116
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2217s / 96.9025 s
agent0:                 episode reward: -0.2173,                 loss: nan
agent1:                 episode reward: 0.2173,                 loss: 0.1096
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2392s / 97.1417 s
agent0:                 episode reward: -0.5744,                 loss: nan
agent1:                 episode reward: 0.5744,                 loss: 0.1104
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2358s / 97.3776 s
agent0:                 episode reward: -0.7517,                 loss: nan
agent1:                 episode reward: 0.7517,                 loss: 0.1112
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2143s / 97.5919 s
agent0:                 episode reward: -0.6657,                 loss: nan
agent1:                 episode reward: 0.6657,                 loss: 0.1128
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2167s / 97.8086 s
agent0:                 episode reward: -0.3431,                 loss: nan
agent1:                 episode reward: 0.3431,                 loss: 0.1107
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2220s / 98.0306 s
agent0:                 episode reward: -0.4229,                 loss: nan
agent1:                 episode reward: 0.4229,                 loss: 0.1092
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2170s / 98.2476 s
agent0:                 episode reward: -0.3905,                 loss: nan
agent1:                 episode reward: 0.3905,                 loss: 0.1113
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2160s / 98.4636 s
agent0:                 episode reward: -0.3635,                 loss: nan
agent1:                 episode reward: 0.3635,                 loss: 0.1091
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2195s / 98.6830 s
agent0:                 episode reward: -0.1931,                 loss: nan
agent1:                 episode reward: 0.1931,                 loss: 0.1083
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2192s / 98.9022 s
agent0:                 episode reward: -0.7071,                 loss: nan
agent1:                 episode reward: 0.7071,                 loss: 0.1086
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2171s / 99.1193 s
agent0:                 episode reward: -0.2170,                 loss: nan
agent1:                 episode reward: 0.2170,                 loss: 0.1092
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2172s / 99.3366 s
agent0:                 episode reward: -0.7244,                 loss: nan
agent1:                 episode reward: 0.7244,                 loss: 0.1095
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2211s / 99.5576 s
agent0:                 episode reward: -0.5775,                 loss: nan
agent1:                 episode reward: 0.5775,                 loss: 0.1093
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2187s / 99.7763 s
agent0:                 episode reward: -0.4585,                 loss: nan
agent1:                 episode reward: 0.4585,                 loss: 0.1088
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2207s / 99.9970 s
agent0:                 episode reward: -0.5441,                 loss: nan
agent1:                 episode reward: 0.5441,                 loss: 0.1075
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2453s / 100.2423 s
agent0:                 episode reward: -0.6082,                 loss: nan
agent1:                 episode reward: 0.6082,                 loss: 0.1088
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2329s / 100.4752 s
agent0:                 episode reward: -0.2354,                 loss: nan
agent1:                 episode reward: 0.2354,                 loss: 0.1078
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2300s / 100.7051 s
agent0:                 episode reward: -0.3219,                 loss: nan
agent1:                 episode reward: 0.3219,                 loss: 0.1077
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2305s / 100.9356 s
agent0:                 episode reward: -0.4075,                 loss: nan
agent1:                 episode reward: 0.4075,                 loss: 0.1093
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2303s / 101.1659 s
agent0:                 episode reward: -0.5119,                 loss: nan
agent1:                 episode reward: 0.5119,                 loss: 0.1079
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2300s / 101.3959 s
agent0:                 episode reward: -0.3927,                 loss: nan
agent1:                 episode reward: 0.3927,                 loss: 0.1087
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2258s / 101.6217 s
agent0:                 episode reward: -0.3848,                 loss: nan
agent1:                 episode reward: 0.3848,                 loss: 0.1079
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2202s / 101.8419 s
agent0:                 episode reward: -0.5996,                 loss: nan
agent1:                 episode reward: 0.5996,                 loss: 0.1080
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2196s / 102.0615 s
agent0:                 episode reward: -0.2205,                 loss: nan
agent1:                 episode reward: 0.2205,                 loss: 0.1097
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2216s / 102.2831 s
agent0:                 episode reward: -0.2356,                 loss: nan
agent1:                 episode reward: 0.2356,                 loss: 0.1105
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2246s / 102.5077 s
agent0:                 episode reward: -0.8892,                 loss: nan
agent1:                 episode reward: 0.8892,                 loss: 0.1095
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2321s / 102.7398 s
agent0:                 episode reward: -0.4788,                 loss: nan
agent1:                 episode reward: 0.4788,                 loss: 0.1105
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2253s / 102.9651 s
agent0:                 episode reward: -0.2066,                 loss: nan
agent1:                 episode reward: 0.2066,                 loss: 0.1102
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2452s / 103.2103 s
agent0:                 episode reward: -0.3735,                 loss: nan
agent1:                 episode reward: 0.3735,                 loss: 0.1112
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2679s / 103.4782 s
agent0:                 episode reward: -0.5230,                 loss: nan
agent1:                 episode reward: 0.5230,                 loss: 0.1097
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2220s / 103.7002 s
agent0:                 episode reward: -0.4302,                 loss: nan
agent1:                 episode reward: 0.4302,                 loss: 0.1100
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2211s / 103.9213 s
agent0:                 episode reward: -0.5223,                 loss: nan
agent1:                 episode reward: 0.5223,                 loss: 0.1098
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2188s / 104.1401 s
agent0:                 episode reward: -0.3453,                 loss: nan
agent1:                 episode reward: 0.3453,                 loss: 0.1098
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2263s / 104.3664 s
agent0:                 episode reward: -0.6377,                 loss: nan
agent1:                 episode reward: 0.6377,                 loss: 0.1098
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2159s / 104.5823 s
agent0:                 episode reward: -0.4945,                 loss: nan
agent1:                 episode reward: 0.4945,                 loss: 0.1103
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2159s / 104.7982 s
agent0:                 episode reward: -0.5015,                 loss: nan
agent1:                 episode reward: 0.5015,                 loss: 0.1094
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2177s / 105.0160 s
agent0:                 episode reward: -0.7795,                 loss: nan
agent1:                 episode reward: 0.7795,                 loss: 0.1095
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2232s / 105.2391 s
agent0:                 episode reward: -0.3653,                 loss: nan
agent1:                 episode reward: 0.3653,                 loss: 0.1095
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2148s / 105.4539 s
agent0:                 episode reward: -0.3967,                 loss: nan
agent1:                 episode reward: 0.3967,                 loss: 0.1094
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2143s / 105.6682 s
agent0:                 episode reward: -0.5738,                 loss: nan
agent1:                 episode reward: 0.5738,                 loss: 0.1087
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2164s / 105.8846 s
agent0:                 episode reward: -0.1649,                 loss: nan
agent1:                 episode reward: 0.1649,                 loss: 0.1078
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2212s / 106.1058 s
agent0:                 episode reward: -0.5841,                 loss: nan
agent1:                 episode reward: 0.5841,                 loss: 0.1069
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2447s / 106.3504 s
agent0:                 episode reward: -0.3832,                 loss: nan
agent1:                 episode reward: 0.3832,                 loss: 0.1075
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2421s / 106.5926 s
agent0:                 episode reward: -0.6396,                 loss: nan
agent1:                 episode reward: 0.6396,                 loss: 0.1079
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2200s / 106.8125 s
agent0:                 episode reward: -0.5533,                 loss: nan
agent1:                 episode reward: 0.5533,                 loss: 0.1077
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2231s / 107.0357 s
agent0:                 episode reward: -0.6553,                 loss: nan
agent1:                 episode reward: 0.6553,                 loss: 0.1073
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2386s / 107.2743 s
agent0:                 episode reward: -0.6605,                 loss: nan
agent1:                 episode reward: 0.6605,                 loss: 0.1063
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2427s / 107.5170 s
agent0:                 episode reward: -0.4326,                 loss: nan
agent1:                 episode reward: 0.4326,                 loss: 0.1085
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2345s / 107.7515 s
agent0:                 episode reward: -0.2627,                 loss: nan
agent1:                 episode reward: 0.2627,                 loss: 0.1090
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2274s / 107.9789 s
agent0:                 episode reward: -0.4879,                 loss: nan
agent1:                 episode reward: 0.4879,                 loss: 0.1079
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2269s / 108.2058 s
agent0:                 episode reward: -0.1520,                 loss: nan
agent1:                 episode reward: 0.1520,                 loss: 0.1080
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2325s / 108.4383 s
agent0:                 episode reward: -0.6041,                 loss: nan
agent1:                 episode reward: 0.6041,                 loss: 0.1078
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2370s / 108.6753 s
agent0:                 episode reward: -0.7200,                 loss: nan
agent1:                 episode reward: 0.7200,                 loss: 0.1083
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2331s / 108.9084 s
agent0:                 episode reward: -0.2986,                 loss: nan
agent1:                 episode reward: 0.2986,                 loss: 0.1074
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2327s / 109.1411 s
agent0:                 episode reward: -0.5258,                 loss: nan
agent1:                 episode reward: 0.5258,                 loss: 0.1067
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2548s / 109.3960 s
agent0:                 episode reward: -0.6791,                 loss: nan
agent1:                 episode reward: 0.6791,                 loss: 0.1080
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2546s / 109.6506 s
agent0:                 episode reward: -0.8651,                 loss: nan
agent1:                 episode reward: 0.8651,                 loss: 0.1096
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2351s / 109.8858 s
agent0:                 episode reward: -0.5650,                 loss: nan
agent1:                 episode reward: 0.5650,                 loss: 0.1101
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2343s / 110.1201 s
agent0:                 episode reward: -0.1738,                 loss: nan
agent1:                 episode reward: 0.1738,                 loss: 0.1081
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2295s / 110.3496 s
agent0:                 episode reward: -0.2307,                 loss: nan
agent1:                 episode reward: 0.2307,                 loss: 0.1102
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2310s / 110.5806 s
agent0:                 episode reward: -0.5316,                 loss: nan
agent1:                 episode reward: 0.5316,                 loss: 0.1114
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2293s / 110.8100 s
agent0:                 episode reward: -0.3482,                 loss: nan
agent1:                 episode reward: 0.3482,                 loss: 0.1094
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2348s / 111.0447 s
agent0:                 episode reward: -1.0753,                 loss: nan
agent1:                 episode reward: 1.0753,                 loss: 0.1097
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2318s / 111.2766 s
agent0:                 episode reward: -0.6798,                 loss: nan
agent1:                 episode reward: 0.6798,                 loss: 0.1100
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2308s / 111.5074 s
agent0:                 episode reward: -0.6663,                 loss: nan
agent1:                 episode reward: 0.6663,                 loss: 0.1100
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2425s / 111.7499 s
agent0:                 episode reward: -0.5967,                 loss: nan
agent1:                 episode reward: 0.5967,                 loss: 0.1092
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2569s / 112.0067 s
agent0:                 episode reward: -0.3725,                 loss: nan
agent1:                 episode reward: 0.3725,                 loss: 0.1102
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2359s / 112.2426 s
agent0:                 episode reward: -0.4642,                 loss: nan
agent1:                 episode reward: 0.4642,                 loss: 0.1092
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2629s / 112.5056 s
agent0:                 episode reward: -0.0303,                 loss: nan
agent1:                 episode reward: 0.0303,                 loss: 0.1085
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2625s / 112.7681 s
agent0:                 episode reward: -0.4380,                 loss: nan
agent1:                 episode reward: 0.4380,                 loss: 0.1092
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2375s / 113.0055 s
agent0:                 episode reward: 0.0259,                 loss: nan
agent1:                 episode reward: -0.0259,                 loss: 0.1093
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2354s / 113.2409 s
agent0:                 episode reward: -0.5517,                 loss: nan
agent1:                 episode reward: 0.5517,                 loss: 0.1085
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2344s / 113.4754 s
agent0:                 episode reward: -0.0467,                 loss: nan
agent1:                 episode reward: 0.0467,                 loss: 0.1098
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2354s / 113.7107 s
agent0:                 episode reward: -0.3622,                 loss: nan
agent1:                 episode reward: 0.3622,                 loss: 0.1091
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2327s / 113.9434 s
agent0:                 episode reward: -0.3246,                 loss: nan
agent1:                 episode reward: 0.3246,                 loss: 0.1086
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2329s / 114.1763 s
agent0:                 episode reward: -0.3701,                 loss: nan
agent1:                 episode reward: 0.3701,                 loss: 0.1079
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2425s / 114.4189 s
agent0:                 episode reward: -0.4457,                 loss: nan
agent1:                 episode reward: 0.4457,                 loss: 0.1093
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2332s / 114.6520 s
agent0:                 episode reward: -0.6619,                 loss: nan
agent1:                 episode reward: 0.6619,                 loss: 0.1085
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2321s / 114.8842 s
agent0:                 episode reward: -0.5561,                 loss: nan
agent1:                 episode reward: 0.5561,                 loss: 0.1075
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2335s / 115.1177 s
agent0:                 episode reward: -0.4550,                 loss: nan
agent1:                 episode reward: 0.4550,                 loss: 0.1071
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2406s / 115.3583 s
agent0:                 episode reward: -0.5915,                 loss: nan
agent1:                 episode reward: 0.5915,                 loss: 0.1085
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2541s / 115.6124 s
agent0:                 episode reward: -0.7171,                 loss: nan
agent1:                 episode reward: 0.7171,                 loss: 0.1075
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2434s / 115.8558 s
agent0:                 episode reward: -0.3276,                 loss: nan
agent1:                 episode reward: 0.3276,                 loss: 0.1073
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2378s / 116.0936 s
agent0:                 episode reward: -0.5959,                 loss: nan
agent1:                 episode reward: 0.5959,                 loss: 0.1084
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2403s / 116.3339 s
agent0:                 episode reward: -0.0346,                 loss: nan
agent1:                 episode reward: 0.0346,                 loss: 0.1090
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2388s / 116.5727 s
agent0:                 episode reward: -0.6228,                 loss: nan
agent1:                 episode reward: 0.6228,                 loss: 0.1071
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2416s / 116.8143 s
agent0:                 episode reward: -0.4731,                 loss: nan
agent1:                 episode reward: 0.4731,                 loss: 0.1082
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2703s / 117.0845 s
agent0:                 episode reward: -0.2097,                 loss: nan
agent1:                 episode reward: 0.2097,                 loss: 0.1057
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2379s / 117.3225 s
agent0:                 episode reward: -0.6994,                 loss: nan
agent1:                 episode reward: 0.6994,                 loss: 0.1085
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2351s / 117.5576 s
agent0:                 episode reward: -0.9341,                 loss: nan
agent1:                 episode reward: 0.9341,                 loss: 0.1085
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2324s / 117.7900 s
agent0:                 episode reward: -0.6187,                 loss: nan
agent1:                 episode reward: 0.6187,                 loss: 0.1075
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2352s / 118.0253 s
agent0:                 episode reward: -0.2549,                 loss: nan
agent1:                 episode reward: 0.2549,                 loss: 0.1053
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2311s / 118.2564 s
agent0:                 episode reward: -0.6154,                 loss: nan
agent1:                 episode reward: 0.6154,                 loss: 0.1065
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2426s / 118.4990 s
agent0:                 episode reward: -0.5968,                 loss: nan
agent1:                 episode reward: 0.5968,                 loss: 0.1085
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2582s / 118.7571 s
agent0:                 episode reward: -0.3573,                 loss: nan
agent1:                 episode reward: 0.3573,                 loss: 0.1066
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2335s / 118.9906 s
agent0:                 episode reward: -0.3766,                 loss: nan
agent1:                 episode reward: 0.3766,                 loss: 0.1075
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2369s / 119.2275 s
agent0:                 episode reward: -0.3999,                 loss: nan
agent1:                 episode reward: 0.3999,                 loss: 0.1075
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2403s / 119.4678 s
agent0:                 episode reward: -0.6206,                 loss: nan
agent1:                 episode reward: 0.6206,                 loss: 0.1070
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2359s / 119.7037 s
agent0:                 episode reward: -0.6445,                 loss: nan
agent1:                 episode reward: 0.6445,                 loss: 0.1080
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2439s / 119.9476 s
agent0:                 episode reward: -0.4417,                 loss: nan
agent1:                 episode reward: 0.4417,                 loss: 0.1075
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2513s / 120.1988 s
agent0:                 episode reward: -0.1989,                 loss: nan
agent1:                 episode reward: 0.1989,                 loss: 0.1071
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2350s / 120.4338 s
agent0:                 episode reward: -0.6018,                 loss: nan
agent1:                 episode reward: 0.6018,                 loss: 0.1062
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2222s / 120.6560 s
agent0:                 episode reward: -0.5664,                 loss: nan
agent1:                 episode reward: 0.5664,                 loss: 0.1063
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2264s / 120.8824 s
agent0:                 episode reward: -0.1808,                 loss: nan
agent1:                 episode reward: 0.1808,                 loss: 0.1067
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2271s / 121.1095 s
agent0:                 episode reward: -0.6099,                 loss: nan
agent1:                 episode reward: 0.6099,                 loss: 0.1075
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2310s / 121.3405 s
agent0:                 episode reward: -0.1885,                 loss: nan
agent1:                 episode reward: 0.1885,                 loss: 0.1070
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2439s / 121.5843 s
agent0:                 episode reward: -0.1856,                 loss: nan
agent1:                 episode reward: 0.1856,                 loss: 0.1076
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2565s / 121.8408 s
agent0:                 episode reward: -0.7963,                 loss: nan
agent1:                 episode reward: 0.7963,                 loss: 0.1067
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2379s / 122.0787 s
agent0:                 episode reward: -0.2780,                 loss: nan
agent1:                 episode reward: 0.2780,                 loss: 0.1068
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2379s / 122.3166 s
agent0:                 episode reward: -0.2768,                 loss: nan
agent1:                 episode reward: 0.2768,                 loss: 0.1074
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2392s / 122.5558 s
agent0:                 episode reward: 0.0650,                 loss: nan
agent1:                 episode reward: -0.0650,                 loss: 0.1083
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2384s / 122.7942 s
agent0:                 episode reward: -0.2753,                 loss: nan
agent1:                 episode reward: 0.2753,                 loss: 0.1071
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2418s / 123.0360 s
agent0:                 episode reward: -0.1371,                 loss: nan
agent1:                 episode reward: 0.1371,                 loss: 0.1070
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2396s / 123.2756 s
agent0:                 episode reward: -0.7656,                 loss: nan
agent1:                 episode reward: 0.7656,                 loss: 0.1071
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2355s / 123.5110 s
agent0:                 episode reward: -0.6475,                 loss: nan
agent1:                 episode reward: 0.6475,                 loss: 0.1075
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2420s / 123.7530 s
agent0:                 episode reward: -0.4406,                 loss: nan
agent1:                 episode reward: 0.4406,                 loss: 0.1073
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2374s / 123.9904 s
agent0:                 episode reward: -0.5452,                 loss: nan
agent1:                 episode reward: 0.5452,                 loss: 0.1064
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2402s / 124.2306 s
agent0:                 episode reward: -0.1235,                 loss: nan
agent1:                 episode reward: 0.1235,                 loss: 0.1064
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2455s / 124.4761 s
agent0:                 episode reward: -0.5646,                 loss: nan
agent1:                 episode reward: 0.5646,                 loss: 0.1079
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2567s / 124.7329 s
agent0:                 episode reward: -0.2958,                 loss: nan
agent1:                 episode reward: 0.2958,                 loss: 0.1063
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2607s / 124.9936 s
agent0:                 episode reward: -0.4927,                 loss: nan
agent1:                 episode reward: 0.4927,                 loss: 0.1066
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2353s / 125.2289 s
agent0:                 episode reward: -0.8021,                 loss: nan
agent1:                 episode reward: 0.8021,                 loss: 0.1072
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2425s / 125.4714 s
agent0:                 episode reward: 0.0268,                 loss: nan
agent1:                 episode reward: -0.0268,                 loss: 0.1083
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2530s / 125.7244 s
agent0:                 episode reward: -0.5729,                 loss: nan
agent1:                 episode reward: 0.5729,                 loss: 0.1086
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2557s / 125.9801 s
agent0:                 episode reward: -0.4130,                 loss: nan
agent1:                 episode reward: 0.4130,                 loss: 0.1077
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2603s / 126.2404 s
agent0:                 episode reward: -0.4985,                 loss: nan
agent1:                 episode reward: 0.4985,                 loss: 0.1072
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2761s / 126.5165 s
agent0:                 episode reward: -0.4640,                 loss: nan
agent1:                 episode reward: 0.4640,                 loss: 0.1088
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2522s / 126.7687 s
agent0:                 episode reward: -0.3678,                 loss: nan
agent1:                 episode reward: 0.3678,                 loss: 0.1063
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2468s / 127.0156 s
agent0:                 episode reward: -0.5135,                 loss: nan
agent1:                 episode reward: 0.5135,                 loss: 0.1077
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2433s / 127.2588 s
agent0:                 episode reward: -0.6996,                 loss: nan
agent1:                 episode reward: 0.6996,                 loss: 0.1084
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2444s / 127.5032 s
agent0:                 episode reward: -0.4333,                 loss: nan
agent1:                 episode reward: 0.4333,                 loss: 0.1081
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2607s / 127.7639 s
agent0:                 episode reward: -0.6168,                 loss: nan
agent1:                 episode reward: 0.6168,                 loss: 0.1069
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2654s / 128.0292 s
agent0:                 episode reward: -0.2669,                 loss: nan
agent1:                 episode reward: 0.2669,                 loss: 0.1064
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2449s / 128.2741 s
agent0:                 episode reward: -0.6633,                 loss: nan
agent1:                 episode reward: 0.6633,                 loss: 0.1073
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2659s / 128.5400 s
agent0:                 episode reward: -0.3821,                 loss: nan
agent1:                 episode reward: 0.3821,                 loss: 0.1069
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2457s / 128.7857 s
agent0:                 episode reward: -0.4394,                 loss: nan
agent1:                 episode reward: 0.4394,                 loss: 0.1080
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2468s / 129.0325 s
agent0:                 episode reward: -0.1919,                 loss: nan
agent1:                 episode reward: 0.1919,                 loss: 0.1066
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2453s / 129.2777 s
agent0:                 episode reward: -0.7428,                 loss: nan
agent1:                 episode reward: 0.7428,                 loss: 0.1073
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2474s / 129.5252 s
agent0:                 episode reward: -0.3207,                 loss: nan
agent1:                 episode reward: 0.3207,                 loss: 0.1077
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2471s / 129.7723 s
agent0:                 episode reward: -0.4062,                 loss: nan
agent1:                 episode reward: 0.4062,                 loss: 0.1078
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2459s / 130.0182 s
agent0:                 episode reward: -0.2511,                 loss: nan
agent1:                 episode reward: 0.2511,                 loss: 0.1096
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2569s / 130.2750 s
agent0:                 episode reward: -0.5129,                 loss: nan
agent1:                 episode reward: 0.5129,                 loss: 0.1075
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2453s / 130.5203 s
agent0:                 episode reward: -0.3462,                 loss: nan
agent1:                 episode reward: 0.3462,                 loss: 0.1086
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2544s / 130.7747 s
agent0:                 episode reward: -0.5418,                 loss: nan
agent1:                 episode reward: 0.5418,                 loss: 0.1084
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2823s / 131.0570 s
agent0:                 episode reward: -0.4354,                 loss: nan
agent1:                 episode reward: 0.4354,                 loss: 0.1091
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2598s / 131.3168 s
agent0:                 episode reward: -0.5063,                 loss: nan
agent1:                 episode reward: 0.5063,                 loss: 0.1076
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2561s / 131.5728 s
agent0:                 episode reward: -0.3373,                 loss: nan
agent1:                 episode reward: 0.3373,                 loss: 0.1080
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2487s / 131.8215 s
agent0:                 episode reward: 0.0933,                 loss: nan
agent1:                 episode reward: -0.0933,                 loss: 0.1074
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2529s / 132.0744 s
agent0:                 episode reward: -0.5420,                 loss: nan
agent1:                 episode reward: 0.5420,                 loss: 0.1081
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2474s / 132.3218 s
agent0:                 episode reward: -0.5832,                 loss: nan
agent1:                 episode reward: 0.5832,                 loss: 0.1076
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2430s / 132.5648 s
agent0:                 episode reward: -0.1127,                 loss: nan
agent1:                 episode reward: 0.1127,                 loss: 0.1067
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2325s / 132.7973 s
agent0:                 episode reward: -0.4145,                 loss: nan
agent1:                 episode reward: 0.4145,                 loss: 0.1070
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2358s / 133.0331 s
agent0:                 episode reward: -0.6011,                 loss: nan
agent1:                 episode reward: 0.6011,                 loss: 0.1083
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2356s / 133.2687 s
agent0:                 episode reward: -0.2418,                 loss: nan
agent1:                 episode reward: 0.2418,                 loss: 0.1090
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2473s / 133.5160 s
agent0:                 episode reward: -0.4260,                 loss: nan
agent1:                 episode reward: 0.4260,                 loss: 0.1072
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2552s / 133.7713 s
agent0:                 episode reward: -0.8058,                 loss: nan
agent1:                 episode reward: 0.8058,                 loss: 0.1072
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2666s / 134.0378 s
agent0:                 episode reward: -0.6020,                 loss: nan
agent1:                 episode reward: 0.6020,                 loss: 0.1067
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2380s / 134.2758 s
agent0:                 episode reward: -0.3624,                 loss: nan
agent1:                 episode reward: 0.3624,                 loss: 0.1075
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2380s / 134.5139 s
agent0:                 episode reward: -0.9984,                 loss: nan
agent1:                 episode reward: 0.9984,                 loss: 0.1062
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2462s / 134.7600 s
agent0:                 episode reward: -0.2933,                 loss: nan
agent1:                 episode reward: 0.2933,                 loss: 0.1074
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2382s / 134.9983 s
agent0:                 episode reward: -0.4414,                 loss: nan
agent1:                 episode reward: 0.4414,                 loss: 0.1057
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2409s / 135.2392 s
agent0:                 episode reward: -0.3358,                 loss: nan
agent1:                 episode reward: 0.3358,                 loss: 0.1067
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2352s / 135.4744 s
agent0:                 episode reward: -0.3399,                 loss: nan
agent1:                 episode reward: 0.3399,                 loss: 0.1065
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2374s / 135.7118 s
agent0:                 episode reward: -0.7461,                 loss: nan
agent1:                 episode reward: 0.7461,                 loss: 0.1052
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2382s / 135.9500 s
agent0:                 episode reward: -0.7711,                 loss: nan
agent1:                 episode reward: 0.7711,                 loss: 0.1058
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2399s / 136.1899 s
agent0:                 episode reward: -0.6865,                 loss: nan
agent1:                 episode reward: 0.6865,                 loss: 0.1060
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2367s / 136.4266 s
agent0:                 episode reward: -0.4186,                 loss: nan
agent1:                 episode reward: 0.4186,                 loss: 0.1045
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2387s / 136.6653 s
agent0:                 episode reward: -0.4814,                 loss: nan
agent1:                 episode reward: 0.4814,                 loss: 0.1044
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2776s / 136.9429 s
agent0:                 episode reward: -0.4228,                 loss: nan
agent1:                 episode reward: 0.4228,                 loss: 0.1051
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2564s / 137.1994 s
agent0:                 episode reward: -0.6657,                 loss: nan
agent1:                 episode reward: 0.6657,                 loss: 0.1064
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2409s / 137.4402 s
agent0:                 episode reward: -0.6354,                 loss: nan
agent1:                 episode reward: 0.6354,                 loss: 0.1058
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2397s / 137.6799 s
agent0:                 episode reward: -0.8160,                 loss: nan
agent1:                 episode reward: 0.8160,                 loss: 0.1059
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2357s / 137.9156 s
agent0:                 episode reward: -0.6648,                 loss: nan
agent1:                 episode reward: 0.6648,                 loss: 0.1063
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2337s / 138.1492 s
agent0:                 episode reward: -0.5898,                 loss: nan
agent1:                 episode reward: 0.5898,                 loss: 0.1057
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2353s / 138.3845 s
agent0:                 episode reward: -0.5579,                 loss: nan
agent1:                 episode reward: 0.5579,                 loss: 0.1064
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2422s / 138.6267 s
agent0:                 episode reward: -0.4826,                 loss: nan
agent1:                 episode reward: 0.4826,                 loss: 0.1073
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2452s / 138.8719 s
agent0:                 episode reward: -0.5383,                 loss: nan
agent1:                 episode reward: 0.5383,                 loss: 0.1065
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2363s / 139.1082 s
agent0:                 episode reward: -0.3663,                 loss: nan
agent1:                 episode reward: 0.3663,                 loss: 0.1068
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2388s / 139.3470 s
agent0:                 episode reward: -0.4474,                 loss: nan
agent1:                 episode reward: 0.4474,                 loss: 0.1064
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2417s / 139.5888 s
agent0:                 episode reward: -0.5804,                 loss: nan
agent1:                 episode reward: 0.5804,                 loss: 0.1070
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2443s / 139.8331 s
agent0:                 episode reward: -0.4870,                 loss: nan
agent1:                 episode reward: 0.4870,                 loss: 0.1066
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2626s / 140.0957 s
agent0:                 episode reward: -0.5095,                 loss: nan
agent1:                 episode reward: 0.5095,                 loss: 0.1053
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2483s / 140.3440 s
agent0:                 episode reward: -0.6589,                 loss: nan
agent1:                 episode reward: 0.6589,                 loss: 0.1076
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2397s / 140.5837 s
agent0:                 episode reward: -0.9615,                 loss: nan
agent1:                 episode reward: 0.9615,                 loss: 0.1067
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2385s / 140.8222 s
agent0:                 episode reward: -0.4158,                 loss: nan
agent1:                 episode reward: 0.4158,                 loss: 0.1065
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2425s / 141.0647 s
agent0:                 episode reward: -0.4584,                 loss: nan
agent1:                 episode reward: 0.4584,                 loss: 0.1065
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2373s / 141.3020 s
agent0:                 episode reward: -0.8886,                 loss: nan
agent1:                 episode reward: 0.8886,                 loss: 0.1059
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2368s / 141.5388 s
agent0:                 episode reward: -0.8181,                 loss: nan
agent1:                 episode reward: 0.8181,                 loss: 0.1074
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2430s / 141.7819 s
agent0:                 episode reward: -0.3221,                 loss: nan
agent1:                 episode reward: 0.3221,                 loss: 0.1069
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2510s / 142.0329 s
agent0:                 episode reward: -0.6399,                 loss: nan
agent1:                 episode reward: 0.6399,                 loss: 0.1065
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2543s / 142.2873 s
agent0:                 episode reward: -0.2594,                 loss: nan
agent1:                 episode reward: 0.2594,                 loss: 0.1060
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2546s / 142.5419 s
agent0:                 episode reward: -0.2998,                 loss: nan
agent1:                 episode reward: 0.2998,                 loss: 0.1050
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2516s / 142.7934 s
agent0:                 episode reward: -0.1901,                 loss: nan
agent1:                 episode reward: 0.1901,                 loss: 0.1059
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2786s / 143.0721 s
agent0:                 episode reward: -0.3491,                 loss: nan
agent1:                 episode reward: 0.3491,                 loss: 0.1054
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2734s / 143.3455 s
agent0:                 episode reward: -0.4422,                 loss: nan
agent1:                 episode reward: 0.4422,                 loss: 0.1051
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2530s / 143.5985 s
agent0:                 episode reward: -0.5380,                 loss: nan
agent1:                 episode reward: 0.5380,                 loss: 0.1044
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2511s / 143.8496 s
agent0:                 episode reward: -0.6989,                 loss: nan
agent1:                 episode reward: 0.6989,                 loss: 0.1048
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2492s / 144.0988 s
agent0:                 episode reward: -0.1745,                 loss: nan
agent1:                 episode reward: 0.1745,                 loss: 0.1054
Episode: 14061/30000 (46.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2552s / 144.3540 s
agent0:                 episode reward: -0.5515,                 loss: nan
agent1:                 episode reward: 0.5515,                 loss: 0.1065
Episode: 14081/30000 (46.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2468s / 144.6008 s
agent0:                 episode reward: -0.5732,                 loss: nan
agent1:                 episode reward: 0.5732,                 loss: 0.1056
Episode: 14101/30000 (47.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2475s / 144.8483 s
agent0:                 episode reward: -0.4066,                 loss: nan
agent1:                 episode reward: 0.4066,                 loss: 0.1041
Episode: 14121/30000 (47.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2672s / 145.1154 s
agent0:                 episode reward: -0.2826,                 loss: nan
agent1:                 episode reward: 0.2826,                 loss: 0.1059
Episode: 14141/30000 (47.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2397s / 145.3551 s
agent0:                 episode reward: -0.6622,                 loss: nan
agent1:                 episode reward: 0.6622,                 loss: 0.1054
Episode: 14161/30000 (47.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2382s / 145.5933 s
agent0:                 episode reward: -0.4926,                 loss: nan
agent1:                 episode reward: 0.4926,                 loss: 0.1058
Episode: 14181/30000 (47.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2401s / 145.8334 s
agent0:                 episode reward: -0.9543,                 loss: nan
agent1:                 episode reward: 0.9543,                 loss: 0.1057
Episode: 14201/30000 (47.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2726s / 146.1060 s
agent0:                 episode reward: -0.7681,                 loss: nan
agent1:                 episode reward: 0.7681,                 loss: 0.1050
Episode: 14221/30000 (47.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2609s / 146.3670 s
agent0:                 episode reward: -0.6530,                 loss: nan
agent1:                 episode reward: 0.6530,                 loss: 0.1057
Episode: 14241/30000 (47.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2416s / 146.6086 s
agent0:                 episode reward: -0.3720,                 loss: nan
agent1:                 episode reward: 0.3720,                 loss: 0.1053
Episode: 14261/30000 (47.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2413s / 146.8499 s
agent0:                 episode reward: -0.5438,                 loss: nan
agent1:                 episode reward: 0.5438,                 loss: 0.1056
Episode: 14281/30000 (47.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2394s / 147.0892 s
agent0:                 episode reward: -0.4073,                 loss: nan
agent1:                 episode reward: 0.4073,                 loss: 0.1066
Episode: 14301/30000 (47.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2612s / 147.3504 s
agent0:                 episode reward: -0.6079,                 loss: nan
agent1:                 episode reward: 0.6079,                 loss: 0.1053
Episode: 14321/30000 (47.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2386s / 147.5890 s
agent0:                 episode reward: -0.5599,                 loss: nan
agent1:                 episode reward: 0.5599,                 loss: 0.1053
Episode: 14341/30000 (47.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2394s / 147.8284 s
agent0:                 episode reward: -0.4558,                 loss: nan
agent1:                 episode reward: 0.4558,                 loss: 0.1058
Episode: 14361/30000 (47.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2414s / 148.0697 s
agent0:                 episode reward: -0.3952,                 loss: nan
agent1:                 episode reward: 0.3952,                 loss: 0.1047
Episode: 14381/30000 (47.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2378s / 148.3076 s
agent0:                 episode reward: -0.4091,                 loss: nan
agent1:                 episode reward: 0.4091,                 loss: 0.1049
Episode: 14401/30000 (48.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2430s / 148.5505 s
agent0:                 episode reward: -0.5561,                 loss: nan
agent1:                 episode reward: 0.5561,                 loss: 0.1049
Episode: 14421/30000 (48.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2442s / 148.7947 s
agent0:                 episode reward: -0.2828,                 loss: nan
agent1:                 episode reward: 0.2828,                 loss: 0.1055
Episode: 14441/30000 (48.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2395s / 149.0342 s
agent0:                 episode reward: -0.6095,                 loss: nan
agent1:                 episode reward: 0.6095,                 loss: 0.1057
Episode: 14461/30000 (48.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2745s / 149.3088 s
agent0:                 episode reward: -0.5217,                 loss: nan
agent1:                 episode reward: 0.5217,                 loss: 0.1053
Episode: 14481/30000 (48.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2559s / 149.5647 s
agent0:                 episode reward: -0.3732,                 loss: nan
agent1:                 episode reward: 0.3732,                 loss: 0.1063
Episode: 14501/30000 (48.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2430s / 149.8077 s
agent0:                 episode reward: -0.8512,                 loss: nan
agent1:                 episode reward: 0.8512,                 loss: 0.1051
Episode: 14521/30000 (48.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2459s / 150.0535 s
agent0:                 episode reward: -0.4881,                 loss: nan
agent1:                 episode reward: 0.4881,                 loss: 0.1065
Episode: 14541/30000 (48.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2452s / 150.2987 s
agent0:                 episode reward: -0.4302,                 loss: nan
agent1:                 episode reward: 0.4302,                 loss: 0.1062
Episode: 14561/30000 (48.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2458s / 150.5445 s
agent0:                 episode reward: -0.3670,                 loss: nan
agent1:                 episode reward: 0.3670,                 loss: 0.1057
Episode: 14581/30000 (48.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2418s / 150.7863 s
agent0:                 episode reward: -0.5967,                 loss: nan
agent1:                 episode reward: 0.5967,                 loss: 0.1052
Episode: 14601/30000 (48.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2462s / 151.0325 s
agent0:                 episode reward: -0.5559,                 loss: nan
agent1:                 episode reward: 0.5559,                 loss: 0.1045
Episode: 14621/30000 (48.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2546s / 151.2871 s
agent0:                 episode reward: -0.4742,                 loss: nan
agent1:                 episode reward: 0.4742,                 loss: 0.1066
Episode: 14641/30000 (48.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2563s / 151.5434 s
agent0:                 episode reward: -0.5468,                 loss: nan
agent1:                 episode reward: 0.5468,                 loss: 0.1062
Episode: 14661/30000 (48.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2536s / 151.7970 s
agent0:                 episode reward: -0.7588,                 loss: nan
agent1:                 episode reward: 0.7588,                 loss: 0.1049
Episode: 14681/30000 (48.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2575s / 152.0545 s
agent0:                 episode reward: -0.2408,                 loss: nan
agent1:                 episode reward: 0.2408,                 loss: 0.1048
Episode: 14701/30000 (49.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2702s / 152.3247 s
agent0:                 episode reward: -0.5672,                 loss: nan
agent1:                 episode reward: 0.5672,                 loss: 0.1051
Episode: 14721/30000 (49.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2520s / 152.5767 s
agent0:                 episode reward: -0.8912,                 loss: nan
agent1:                 episode reward: 0.8912,                 loss: 0.1060
Episode: 14741/30000 (49.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2539s / 152.8306 s
agent0:                 episode reward: -0.5396,                 loss: nan
agent1:                 episode reward: 0.5396,                 loss: 0.1040
Episode: 14761/30000 (49.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2719s / 153.1025 s
agent0:                 episode reward: -0.5044,                 loss: nan
agent1:                 episode reward: 0.5044,                 loss: 0.1043
Episode: 14781/30000 (49.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2815s / 153.3840 s
agent0:                 episode reward: -0.3747,                 loss: nan
agent1:                 episode reward: 0.3747,                 loss: 0.1043
Episode: 14801/30000 (49.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2562s / 153.6402 s
agent0:                 episode reward: -0.6750,                 loss: nan
agent1:                 episode reward: 0.6750,                 loss: 0.1057
Episode: 14821/30000 (49.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2551s / 153.8953 s
agent0:                 episode reward: -1.0322,                 loss: nan
agent1:                 episode reward: 1.0322,                 loss: 0.1056
Episode: 14841/30000 (49.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2520s / 154.1473 s
agent0:                 episode reward: -0.5311,                 loss: nan
agent1:                 episode reward: 0.5311,                 loss: 0.1035
Episode: 14861/30000 (49.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2653s / 154.4126 s
agent0:                 episode reward: -0.0937,                 loss: nan
agent1:                 episode reward: 0.0937,                 loss: 0.1050
Episode: 14881/30000 (49.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2563s / 154.6689 s
agent0:                 episode reward: -0.6194,                 loss: nan
agent1:                 episode reward: 0.6194,                 loss: 0.1055
Episode: 14901/30000 (49.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2617s / 154.9306 s
agent0:                 episode reward: -0.2847,                 loss: nan
agent1:                 episode reward: 0.2847,                 loss: 0.1057
Episode: 14921/30000 (49.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2552s / 155.1858 s
agent0:                 episode reward: -0.6049,                 loss: nan
agent1:                 episode reward: 0.6049,                 loss: 0.1043
Episode: 14941/30000 (49.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2749s / 155.4607 s
agent0:                 episode reward: -0.3653,                 loss: nan
agent1:                 episode reward: 0.3653,                 loss: 0.1048
Episode: 14961/30000 (49.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2525s / 155.7132 s
agent0:                 episode reward: -0.1701,                 loss: nan
agent1:                 episode reward: 0.1701,                 loss: 0.1049
Episode: 14981/30000 (49.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2556s / 155.9688 s
agent0:                 episode reward: -0.5085,                 loss: nan
agent1:                 episode reward: 0.5085,                 loss: 0.1053
Episode: 15001/30000 (50.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2520s / 156.2208 s
agent0:                 episode reward: -0.8220,                 loss: nan
agent1:                 episode reward: 0.8220,                 loss: 0.1056
Episode: 15021/30000 (50.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2522s / 156.4730 s
agent0:                 episode reward: -0.4918,                 loss: nan
agent1:                 episode reward: 0.4918,                 loss: 0.1043
Episode: 15041/30000 (50.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2582s / 156.7311 s
agent0:                 episode reward: -0.6645,                 loss: nan
agent1:                 episode reward: 0.6645,                 loss: 0.1060
Episode: 15061/30000 (50.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2599s / 156.9910 s
agent0:                 episode reward: -0.1722,                 loss: nan
agent1:                 episode reward: 0.1722,                 loss: 0.1044
Episode: 15081/30000 (50.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2547s / 157.2457 s
agent0:                 episode reward: -0.5218,                 loss: nan
agent1:                 episode reward: 0.5218,                 loss: 0.1038
Episode: 15101/30000 (50.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2558s / 157.5016 s
agent0:                 episode reward: -0.5041,                 loss: nan
agent1:                 episode reward: 0.5041,                 loss: 0.1074
Episode: 15121/30000 (50.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2530s / 157.7545 s
agent0:                 episode reward: -0.7993,                 loss: nan
agent1:                 episode reward: 0.7993,                 loss: 0.1064
Episode: 15141/30000 (50.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2531s / 158.0076 s
agent0:                 episode reward: -0.5352,                 loss: nan
agent1:                 episode reward: 0.5352,                 loss: 0.1056
Episode: 15161/30000 (50.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2561s / 158.2637 s
agent0:                 episode reward: -0.4581,                 loss: nan
agent1:                 episode reward: 0.4581,                 loss: 0.1056
Episode: 15181/30000 (50.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2820s / 158.5457 s
agent0:                 episode reward: -0.4186,                 loss: nan
agent1:                 episode reward: 0.4186,                 loss: 0.1035
Episode: 15201/30000 (50.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2569s / 158.8026 s
agent0:                 episode reward: -0.7634,                 loss: nan
agent1:                 episode reward: 0.7634,                 loss: 0.1061
Episode: 15221/30000 (50.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2525s / 159.0551 s
agent0:                 episode reward: -0.5156,                 loss: nan
agent1:                 episode reward: 0.5156,                 loss: 0.1055
Episode: 15241/30000 (50.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2507s / 159.3058 s
agent0:                 episode reward: -0.6165,                 loss: nan
agent1:                 episode reward: 0.6165,                 loss: 0.1054
Episode: 15261/30000 (50.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2611s / 159.5668 s
agent0:                 episode reward: -0.5011,                 loss: nan
agent1:                 episode reward: 0.5011,                 loss: 0.1052
Episode: 15281/30000 (50.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2574s / 159.8242 s
agent0:                 episode reward: -0.6462,                 loss: nan
agent1:                 episode reward: 0.6462,                 loss: 0.1050
Episode: 15301/30000 (51.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2496s / 160.0738 s
agent0:                 episode reward: -0.6676,                 loss: nan
agent1:                 episode reward: 0.6676,                 loss: 0.1045
Episode: 15321/30000 (51.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2431s / 160.3169 s
agent0:                 episode reward: -0.5229,                 loss: nan
agent1:                 episode reward: 0.5229,                 loss: 0.1049
Episode: 15341/30000 (51.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2466s / 160.5634 s
agent0:                 episode reward: -0.7539,                 loss: nan
agent1:                 episode reward: 0.7539,                 loss: 0.1039
Episode: 15361/30000 (51.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2487s / 160.8121 s
agent0:                 episode reward: -0.6426,                 loss: nan
agent1:                 episode reward: 0.6426,                 loss: 0.1037
Episode: 15381/30000 (51.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2504s / 161.0626 s
agent0:                 episode reward: -0.5850,                 loss: nan
agent1:                 episode reward: 0.5850,                 loss: 0.1050
Episode: 15401/30000 (51.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2513s / 161.3139 s
agent0:                 episode reward: -0.4719,                 loss: nan
agent1:                 episode reward: 0.4719,                 loss: 0.1038
Episode: 15421/30000 (51.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2730s / 161.5869 s
agent0:                 episode reward: -0.6222,                 loss: nan
agent1:                 episode reward: 0.6222,                 loss: 0.1044
Episode: 15441/30000 (51.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2942s / 161.8810 s
agent0:                 episode reward: -0.7596,                 loss: nan
agent1:                 episode reward: 0.7596,                 loss: 0.1049
Episode: 15461/30000 (51.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2786s / 162.1596 s
agent0:                 episode reward: -0.6126,                 loss: nan
agent1:                 episode reward: 0.6126,                 loss: 0.1039
Episode: 15481/30000 (51.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2680s / 162.4276 s
agent0:                 episode reward: -0.5269,                 loss: nan
agent1:                 episode reward: 0.5269,                 loss: 0.1052
Episode: 15501/30000 (51.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2633s / 162.6909 s
agent0:                 episode reward: -0.7827,                 loss: nan
agent1:                 episode reward: 0.7827,                 loss: 0.1043
Episode: 15521/30000 (51.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2653s / 162.9562 s
agent0:                 episode reward: -0.5674,                 loss: nan
agent1:                 episode reward: 0.5674,                 loss: 0.1046
Episode: 15541/30000 (51.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2621s / 163.2183 s
agent0:                 episode reward: -0.9216,                 loss: nan
agent1:                 episode reward: 0.9216,                 loss: 0.1047
Episode: 15561/30000 (51.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2680s / 163.4863 s
agent0:                 episode reward: -1.0780,                 loss: nan
agent1:                 episode reward: 1.0780,                 loss: 0.1053
Episode: 15581/30000 (51.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2666s / 163.7529 s
agent0:                 episode reward: -0.3543,                 loss: nan
agent1:                 episode reward: 0.3543,                 loss: 0.1057
Episode: 15601/30000 (52.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3120s / 164.0649 s
agent0:                 episode reward: -0.6047,                 loss: nan
agent1:                 episode reward: 0.6047,                 loss: 0.1081
Episode: 15621/30000 (52.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2617s / 164.3266 s
agent0:                 episode reward: -0.3957,                 loss: nan
agent1:                 episode reward: 0.3957,                 loss: 0.1069
Episode: 15641/30000 (52.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2862s / 164.6127 s
agent0:                 episode reward: -0.6656,                 loss: nan
agent1:                 episode reward: 0.6656,                 loss: 0.1066
Episode: 15661/30000 (52.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2649s / 164.8776 s
agent0:                 episode reward: -0.9031,                 loss: nan
agent1:                 episode reward: 0.9031,                 loss: 0.1069
Episode: 15681/30000 (52.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2606s / 165.1382 s
agent0:                 episode reward: -0.4026,                 loss: nan
agent1:                 episode reward: 0.4026,                 loss: 0.1064
Episode: 15701/30000 (52.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2619s / 165.4001 s
agent0:                 episode reward: -0.8170,                 loss: nan
agent1:                 episode reward: 0.8170,                 loss: 0.1064
Episode: 15721/30000 (52.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2599s / 165.6599 s
agent0:                 episode reward: -0.2923,                 loss: nan
agent1:                 episode reward: 0.2923,                 loss: 0.1064
Episode: 15741/30000 (52.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2613s / 165.9213 s
agent0:                 episode reward: -0.5449,                 loss: nan
agent1:                 episode reward: 0.5449,                 loss: 0.1056
Episode: 15761/30000 (52.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2643s / 166.1855 s
agent0:                 episode reward: -0.5454,                 loss: nan
agent1:                 episode reward: 0.5454,                 loss: 0.1061
Episode: 15781/30000 (52.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2602s / 166.4457 s
agent0:                 episode reward: -0.4118,                 loss: nan
agent1:                 episode reward: 0.4118,                 loss: 0.1064
Episode: 15801/30000 (52.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2671s / 166.7128 s
agent0:                 episode reward: -0.4552,                 loss: nan
agent1:                 episode reward: 0.4552,                 loss: 0.1062
Episode: 15821/30000 (52.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2633s / 166.9760 s
agent0:                 episode reward: -0.5848,                 loss: nan
agent1:                 episode reward: 0.5848,                 loss: 0.1054
Episode: 15841/30000 (52.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2575s / 167.2335 s
agent0:                 episode reward: -0.6393,                 loss: nan
agent1:                 episode reward: 0.6393,                 loss: 0.1047
Episode: 15861/30000 (52.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2765s / 167.5100 s
agent0:                 episode reward: -0.2492,                 loss: nan
agent1:                 episode reward: 0.2492,                 loss: 0.1057
Episode: 15881/30000 (52.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2902s / 167.8002 s
agent0:                 episode reward: -0.3774,                 loss: nan
agent1:                 episode reward: 0.3774,                 loss: 0.1066
Episode: 15901/30000 (53.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2647s / 168.0649 s
agent0:                 episode reward: -1.0551,                 loss: nan
agent1:                 episode reward: 1.0551,                 loss: 0.1053
Episode: 15921/30000 (53.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2599s / 168.3248 s
agent0:                 episode reward: -0.6585,                 loss: nan
agent1:                 episode reward: 0.6585,                 loss: 0.1056
Episode: 15941/30000 (53.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2596s / 168.5844 s
agent0:                 episode reward: -0.5311,                 loss: nan
agent1:                 episode reward: 0.5311,                 loss: 0.1057
Episode: 15961/30000 (53.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2619s / 168.8462 s
agent0:                 episode reward: -0.5562,                 loss: nan
agent1:                 episode reward: 0.5562,                 loss: 0.1058
Episode: 15981/30000 (53.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2597s / 169.1060 s
agent0:                 episode reward: -0.4096,                 loss: nan
agent1:                 episode reward: 0.4096,                 loss: 0.1056
Episode: 16001/30000 (53.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2637s / 169.3697 s
agent0:                 episode reward: -0.3929,                 loss: nan
agent1:                 episode reward: 0.3929,                 loss: 0.1050
Episode: 16021/30000 (53.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2664s / 169.6361 s
agent0:                 episode reward: -0.3734,                 loss: nan
agent1:                 episode reward: 0.3734,                 loss: 0.1053
Episode: 16041/30000 (53.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2667s / 169.9028 s
agent0:                 episode reward: -0.9305,                 loss: nan
agent1:                 episode reward: 0.9305,                 loss: 0.1052
Episode: 16061/30000 (53.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2772s / 170.1800 s
agent0:                 episode reward: -0.4706,                 loss: nan
agent1:                 episode reward: 0.4706,                 loss: 0.1049
Episode: 16081/30000 (53.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2608s / 170.4408 s
agent0:                 episode reward: -0.8578,                 loss: nan
agent1:                 episode reward: 0.8578,                 loss: 0.1051
Episode: 16101/30000 (53.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2959s / 170.7367 s
agent0:                 episode reward: -0.9220,                 loss: nan
agent1:                 episode reward: 0.9220,                 loss: 0.1069
Episode: 16121/30000 (53.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2671s / 171.0038 s
agent0:                 episode reward: -0.7057,                 loss: nan
agent1:                 episode reward: 0.7057,                 loss: 0.1041
Episode: 16141/30000 (53.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2580s / 171.2617 s
agent0:                 episode reward: -0.7586,                 loss: nan
agent1:                 episode reward: 0.7586,                 loss: 0.1053
Episode: 16161/30000 (53.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2618s / 171.5235 s
agent0:                 episode reward: -0.9409,                 loss: nan
agent1:                 episode reward: 0.9409,                 loss: 0.1056
Episode: 16181/30000 (53.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2624s / 171.7860 s
agent0:                 episode reward: -0.7800,                 loss: nan
agent1:                 episode reward: 0.7800,                 loss: 0.1047
Episode: 16201/30000 (54.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2650s / 172.0510 s
agent0:                 episode reward: -0.4811,                 loss: nan
agent1:                 episode reward: 0.4811,                 loss: 0.1041
Episode: 16221/30000 (54.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2632s / 172.3142 s
agent0:                 episode reward: -0.3665,                 loss: nan
agent1:                 episode reward: 0.3665,                 loss: 0.1054
Episode: 16241/30000 (54.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2644s / 172.5785 s
agent0:                 episode reward: -0.4359,                 loss: nan
agent1:                 episode reward: 0.4359,                 loss: 0.1059
Episode: 16261/30000 (54.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2632s / 172.8418 s
agent0:                 episode reward: -0.7180,                 loss: nan
agent1:                 episode reward: 0.7180,                 loss: 0.1056
Episode: 16281/30000 (54.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2622s / 173.1039 s
agent0:                 episode reward: -0.7016,                 loss: nan
agent1:                 episode reward: 0.7016,                 loss: 0.1057
Episode: 16301/30000 (54.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2654s / 173.3694 s
agent0:                 episode reward: -0.3591,                 loss: nan
agent1:                 episode reward: 0.3591,                 loss: 0.1045
Episode: 16321/30000 (54.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2639s / 173.6332 s
agent0:                 episode reward: -0.5583,                 loss: nan
agent1:                 episode reward: 0.5583,                 loss: 0.1052
Episode: 16341/30000 (54.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2656s / 173.8988 s
agent0:                 episode reward: -0.4187,                 loss: nan
agent1:                 episode reward: 0.4187,                 loss: 0.1059
Episode: 16361/30000 (54.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2663s / 174.1651 s
agent0:                 episode reward: -0.6069,                 loss: nan
agent1:                 episode reward: 0.6069,                 loss: 0.1029
Episode: 16381/30000 (54.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2696s / 174.4347 s
agent0:                 episode reward: -0.6619,                 loss: nan
agent1:                 episode reward: 0.6619,                 loss: 0.1063
Episode: 16401/30000 (54.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2612s / 174.6959 s
agent0:                 episode reward: -0.4083,                 loss: nan
agent1:                 episode reward: 0.4083,                 loss: 0.1038
Episode: 16421/30000 (54.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2577s / 174.9536 s
agent0:                 episode reward: -0.3432,                 loss: nan
agent1:                 episode reward: 0.3432,                 loss: 0.1049
Episode: 16441/30000 (54.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2574s / 175.2110 s
agent0:                 episode reward: -0.1934,                 loss: nan
agent1:                 episode reward: 0.1934,                 loss: 0.1041
Episode: 16461/30000 (54.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2714s / 175.4824 s
agent0:                 episode reward: -0.4781,                 loss: nan
agent1:                 episode reward: 0.4781,                 loss: 0.1043
Episode: 16481/30000 (54.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2496s / 175.7320 s
agent0:                 episode reward: -0.1961,                 loss: nan
agent1:                 episode reward: 0.1961,                 loss: 0.1051
Episode: 16501/30000 (55.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2509s / 175.9829 s
agent0:                 episode reward: -0.4675,                 loss: nan
agent1:                 episode reward: 0.4675,                 loss: 0.1034
Episode: 16521/30000 (55.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2533s / 176.2361 s
agent0:                 episode reward: -0.5020,                 loss: nan
agent1:                 episode reward: 0.5020,                 loss: 0.1059
Episode: 16541/30000 (55.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2724s / 176.5085 s
agent0:                 episode reward: -0.9586,                 loss: nan
agent1:                 episode reward: 0.9586,                 loss: 0.1062
Episode: 16561/30000 (55.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2638s / 176.7723 s
agent0:                 episode reward: -0.4610,                 loss: nan
agent1:                 episode reward: 0.4610,                 loss: 0.1048
Episode: 16581/30000 (55.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2617s / 177.0340 s
agent0:                 episode reward: -0.5380,                 loss: nan
agent1:                 episode reward: 0.5380,                 loss: 0.1047
Episode: 16601/30000 (55.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2743s / 177.3083 s
agent0:                 episode reward: -0.2521,                 loss: nan
agent1:                 episode reward: 0.2521,                 loss: 0.1037
Episode: 16621/30000 (55.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2603s / 177.5687 s
agent0:                 episode reward: -0.2611,                 loss: nan
agent1:                 episode reward: 0.2611,                 loss: 0.1057
Episode: 16641/30000 (55.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2631s / 177.8317 s
agent0:                 episode reward: -0.3243,                 loss: nan
agent1:                 episode reward: 0.3243,                 loss: 0.1043
Episode: 16661/30000 (55.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2619s / 178.0937 s
agent0:                 episode reward: -0.7662,                 loss: nan
agent1:                 episode reward: 0.7662,                 loss: 0.1046
Episode: 16681/30000 (55.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2760s / 178.3697 s
agent0:                 episode reward: -0.5835,                 loss: nan
agent1:                 episode reward: 0.5835,                 loss: 0.1050
Episode: 16701/30000 (55.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2667s / 178.6364 s
agent0:                 episode reward: -0.5832,                 loss: nan
agent1:                 episode reward: 0.5832,                 loss: 0.1046
Episode: 16721/30000 (55.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2716s / 178.9080 s
agent0:                 episode reward: -0.3756,                 loss: nan
agent1:                 episode reward: 0.3756,                 loss: 0.1044
Episode: 16741/30000 (55.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2712s / 179.1792 s
agent0:                 episode reward: -0.6151,                 loss: nan
agent1:                 episode reward: 0.6151,                 loss: 0.1037
Episode: 16761/30000 (55.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2807s / 179.4599 s
agent0:                 episode reward: -0.4706,                 loss: nan
agent1:                 episode reward: 0.4706,                 loss: 0.1051
Episode: 16781/30000 (55.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2966s / 179.7565 s
agent0:                 episode reward: -0.5295,                 loss: nan
agent1:                 episode reward: 0.5295,                 loss: 0.1022
Episode: 16801/30000 (56.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2691s / 180.0256 s
agent0:                 episode reward: -0.5766,                 loss: nan
agent1:                 episode reward: 0.5766,                 loss: 0.1031
Episode: 16821/30000 (56.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2701s / 180.2957 s
agent0:                 episode reward: -0.8488,                 loss: nan
agent1:                 episode reward: 0.8488,                 loss: 0.1032
Episode: 16841/30000 (56.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2732s / 180.5689 s
agent0:                 episode reward: -0.5441,                 loss: nan
agent1:                 episode reward: 0.5441,                 loss: 0.1043
Episode: 16861/30000 (56.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2677s / 180.8367 s
agent0:                 episode reward: -0.5154,                 loss: nan
agent1:                 episode reward: 0.5154,                 loss: 0.1058
Episode: 16881/30000 (56.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2595s / 181.0961 s
agent0:                 episode reward: -0.6862,                 loss: nan
agent1:                 episode reward: 0.6862,                 loss: 0.1046
Episode: 16901/30000 (56.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2584s / 181.3545 s
agent0:                 episode reward: -0.7906,                 loss: nan
agent1:                 episode reward: 0.7906,                 loss: 0.1055
Episode: 16921/30000 (56.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2575s / 181.6120 s
agent0:                 episode reward: -0.5260,                 loss: nan
agent1:                 episode reward: 0.5260,                 loss: 0.1051
Episode: 16941/30000 (56.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2555s / 181.8675 s
agent0:                 episode reward: -0.7289,                 loss: nan
agent1:                 episode reward: 0.7289,                 loss: 0.1037
Episode: 16961/30000 (56.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2555s / 182.1230 s
agent0:                 episode reward: -0.3412,                 loss: nan
agent1:                 episode reward: 0.3412,                 loss: 0.1051
Episode: 16981/30000 (56.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2606s / 182.3836 s
agent0:                 episode reward: -0.4473,                 loss: nan
agent1:                 episode reward: 0.4473,                 loss: 0.1035
Episode: 17001/30000 (56.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2893s / 182.6730 s
agent0:                 episode reward: -0.5960,                 loss: nan
agent1:                 episode reward: 0.5960,                 loss: 0.1031
Episode: 17021/30000 (56.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2707s / 182.9436 s
agent0:                 episode reward: -0.3973,                 loss: nan
agent1:                 episode reward: 0.3973,                 loss: 0.1034
Episode: 17041/30000 (56.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2652s / 183.2088 s
agent0:                 episode reward: -0.5831,                 loss: nan
agent1:                 episode reward: 0.5831,                 loss: 0.1035
Episode: 17061/30000 (56.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2675s / 183.4763 s
agent0:                 episode reward: -0.4698,                 loss: nan
agent1:                 episode reward: 0.4698,                 loss: 0.1049
Episode: 17081/30000 (56.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2645s / 183.7409 s
agent0:                 episode reward: -0.3051,                 loss: nan
agent1:                 episode reward: 0.3051,                 loss: 0.1026
Episode: 17101/30000 (57.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2697s / 184.0105 s
agent0:                 episode reward: -0.6774,                 loss: nan
agent1:                 episode reward: 0.6774,                 loss: 0.1038
Episode: 17121/30000 (57.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2739s / 184.2845 s
agent0:                 episode reward: -0.7377,                 loss: nan
agent1:                 episode reward: 0.7377,                 loss: 0.1042
Episode: 17141/30000 (57.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2775s / 184.5619 s
agent0:                 episode reward: -0.6692,                 loss: nan
agent1:                 episode reward: 0.6692,                 loss: 0.1049
Episode: 17161/30000 (57.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2720s / 184.8339 s
agent0:                 episode reward: -0.8661,                 loss: nan
agent1:                 episode reward: 0.8661,                 loss: 0.1052
Episode: 17181/30000 (57.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2708s / 185.1047 s
agent0:                 episode reward: -0.7972,                 loss: nan
agent1:                 episode reward: 0.7972,                 loss: 0.1041
Episode: 17201/30000 (57.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2659s / 185.3707 s
agent0:                 episode reward: -0.7811,                 loss: nan
agent1:                 episode reward: 0.7811,                 loss: 0.1044
Episode: 17221/30000 (57.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2626s / 185.6333 s
agent0:                 episode reward: -0.3495,                 loss: nan
agent1:                 episode reward: 0.3495,                 loss: 0.1041
Episode: 17241/30000 (57.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2686s / 185.9019 s
agent0:                 episode reward: -0.4866,                 loss: nan
agent1:                 episode reward: 0.4866,                 loss: 0.1036
Episode: 17261/30000 (57.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2697s / 186.1716 s
agent0:                 episode reward: -0.5242,                 loss: nan
agent1:                 episode reward: 0.5242,                 loss: 0.1034
Episode: 17281/30000 (57.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2661s / 186.4378 s
agent0:                 episode reward: -0.6085,                 loss: nan
agent1:                 episode reward: 0.6085,                 loss: 0.1032
Episode: 17301/30000 (57.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2907s / 186.7285 s
agent0:                 episode reward: -0.3609,                 loss: nan
agent1:                 episode reward: 0.3609,                 loss: 0.1025
Episode: 17321/30000 (57.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2771s / 187.0056 s
agent0:                 episode reward: -0.4157,                 loss: nan
agent1:                 episode reward: 0.4157,                 loss: 0.1044
Episode: 17341/30000 (57.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2703s / 187.2759 s
agent0:                 episode reward: -0.4214,                 loss: nan
agent1:                 episode reward: 0.4214,                 loss: 0.1026
Episode: 17361/30000 (57.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2720s / 187.5479 s
agent0:                 episode reward: -0.7091,                 loss: nan
agent1:                 episode reward: 0.7091,                 loss: 0.1027
Episode: 17381/30000 (57.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2712s / 187.8191 s
agent0:                 episode reward: -0.6475,                 loss: nan
agent1:                 episode reward: 0.6475,                 loss: 0.1028
Episode: 17401/30000 (58.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2731s / 188.0921 s
agent0:                 episode reward: -0.4578,                 loss: nan
agent1:                 episode reward: 0.4578,                 loss: 0.1042
Episode: 17421/30000 (58.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2896s / 188.3818 s
agent0:                 episode reward: -0.5793,                 loss: nan
agent1:                 episode reward: 0.5793,                 loss: 0.1040
Episode: 17441/30000 (58.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2979s / 188.6797 s
agent0:                 episode reward: -0.9382,                 loss: nan
agent1:                 episode reward: 0.9382,                 loss: 0.1043
Episode: 17461/30000 (58.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2767s / 188.9564 s
agent0:                 episode reward: -0.4468,                 loss: nan
agent1:                 episode reward: 0.4468,                 loss: 0.1038
Episode: 17481/30000 (58.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2805s / 189.2369 s
agent0:                 episode reward: -0.8475,                 loss: nan
agent1:                 episode reward: 0.8475,                 loss: 0.1038
Episode: 17501/30000 (58.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2817s / 189.5186 s
agent0:                 episode reward: -0.4568,                 loss: nan
agent1:                 episode reward: 0.4568,                 loss: 0.1038
Episode: 17521/30000 (58.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2731s / 189.7917 s
agent0:                 episode reward: -0.8903,                 loss: nan
agent1:                 episode reward: 0.8903,                 loss: 0.1037
Episode: 17541/30000 (58.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2685s / 190.0603 s
agent0:                 episode reward: -0.6073,                 loss: nan
agent1:                 episode reward: 0.6073,                 loss: 0.1033
Episode: 17561/30000 (58.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2895s / 190.3497 s
agent0:                 episode reward: -0.7125,                 loss: nan
agent1:                 episode reward: 0.7125,                 loss: 0.1031
Episode: 17581/30000 (58.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2904s / 190.6402 s
agent0:                 episode reward: -0.8281,                 loss: nan
agent1:                 episode reward: 0.8281,                 loss: 0.1040
Episode: 17601/30000 (58.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3086s / 190.9487 s
agent0:                 episode reward: -0.2211,                 loss: nan
agent1:                 episode reward: 0.2211,                 loss: 0.1032
Episode: 17621/30000 (58.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2917s / 191.2404 s
agent0:                 episode reward: -0.7499,                 loss: nan
agent1:                 episode reward: 0.7499,                 loss: 0.1035
Episode: 17641/30000 (58.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3179s / 191.5583 s
agent0:                 episode reward: -0.5278,                 loss: nan
agent1:                 episode reward: 0.5278,                 loss: 0.1034
Episode: 17661/30000 (58.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2822s / 191.8405 s
agent0:                 episode reward: -0.4553,                 loss: nan
agent1:                 episode reward: 0.4553,                 loss: 0.1044
Episode: 17681/30000 (58.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2714s / 192.1119 s
agent0:                 episode reward: -0.7179,                 loss: nan
agent1:                 episode reward: 0.7179,                 loss: 0.1040
Episode: 17701/30000 (59.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2713s / 192.3832 s
agent0:                 episode reward: -0.5828,                 loss: nan
agent1:                 episode reward: 0.5828,                 loss: 0.1041
Episode: 17721/30000 (59.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2855s / 192.6687 s
agent0:                 episode reward: -0.4516,                 loss: nan
agent1:                 episode reward: 0.4516,                 loss: 0.1039
Episode: 17741/30000 (59.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2874s / 192.9561 s
agent0:                 episode reward: -0.7873,                 loss: nan
agent1:                 episode reward: 0.7873,                 loss: 0.1038
Episode: 17761/30000 (59.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2877s / 193.2439 s
agent0:                 episode reward: -0.9286,                 loss: nan
agent1:                 episode reward: 0.9286,                 loss: 0.1032
Episode: 17781/30000 (59.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2862s / 193.5300 s
agent0:                 episode reward: -0.7318,                 loss: nan
agent1:                 episode reward: 0.7318,                 loss: 0.1040
Episode: 17801/30000 (59.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2896s / 193.8196 s
agent0:                 episode reward: -0.3918,                 loss: nan
agent1:                 episode reward: 0.3918,                 loss: 0.1028
Episode: 17821/30000 (59.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2730s / 194.0926 s
agent0:                 episode reward: -0.7788,                 loss: nan
agent1:                 episode reward: 0.7788,                 loss: 0.1036
Episode: 17841/30000 (59.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2802s / 194.3728 s
agent0:                 episode reward: -0.2964,                 loss: nan
agent1:                 episode reward: 0.2964,                 loss: 0.1028
Episode: 17861/30000 (59.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2947s / 194.6675 s
agent0:                 episode reward: -0.5440,                 loss: nan
agent1:                 episode reward: 0.5440,                 loss: 0.1050
Episode: 17881/30000 (59.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3068s / 194.9743 s
agent0:                 episode reward: -0.8347,                 loss: nan
agent1:                 episode reward: 0.8347,                 loss: 0.1024
Episode: 17901/30000 (59.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2577s / 195.2320 s
agent0:                 episode reward: -0.5186,                 loss: nan
agent1:                 episode reward: 0.5186,                 loss: 0.1036
Episode: 17921/30000 (59.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2580s / 195.4900 s
agent0:                 episode reward: -0.7764,                 loss: nan
agent1:                 episode reward: 0.7764,                 loss: 0.1040
Episode: 17941/30000 (59.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2584s / 195.7484 s
agent0:                 episode reward: -0.6611,                 loss: nan
agent1:                 episode reward: 0.6611,                 loss: 0.1039
Episode: 17961/30000 (59.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2606s / 196.0090 s
agent0:                 episode reward: -0.4457,                 loss: nan
agent1:                 episode reward: 0.4457,                 loss: 0.1042
Episode: 17981/30000 (59.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2998s / 196.3087 s
agent0:                 episode reward: -0.3107,                 loss: nan
agent1:                 episode reward: 0.3107,                 loss: 0.1042
Episode: 18001/30000 (60.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2925s / 196.6013 s
agent0:                 episode reward: -0.6667,                 loss: nan
agent1:                 episode reward: 0.6667,                 loss: 0.1037
Episode: 18021/30000 (60.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2842s / 196.8855 s
agent0:                 episode reward: -0.4683,                 loss: nan
agent1:                 episode reward: 0.4683,                 loss: 0.1041
Episode: 18041/30000 (60.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2798s / 197.1653 s
agent0:                 episode reward: -0.7155,                 loss: nan
agent1:                 episode reward: 0.7155,                 loss: 0.1050
Episode: 18061/30000 (60.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2841s / 197.4493 s
agent0:                 episode reward: -0.4935,                 loss: nan
agent1:                 episode reward: 0.4935,                 loss: 0.1033
Episode: 18081/30000 (60.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3017s / 197.7510 s
agent0:                 episode reward: -0.3866,                 loss: nan
agent1:                 episode reward: 0.3866,                 loss: 0.1042
Episode: 18101/30000 (60.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2710s / 198.0220 s
agent0:                 episode reward: -0.7262,                 loss: nan
agent1:                 episode reward: 0.7262,                 loss: 0.1032
Episode: 18121/30000 (60.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2652s / 198.2872 s
agent0:                 episode reward: -0.6787,                 loss: nan
agent1:                 episode reward: 0.6787,                 loss: 0.1041
Episode: 18141/30000 (60.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2702s / 198.5574 s
agent0:                 episode reward: -0.2898,                 loss: nan
agent1:                 episode reward: 0.2898,                 loss: 0.1029
Episode: 18161/30000 (60.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2692s / 198.8267 s
agent0:                 episode reward: -0.4254,                 loss: nan
agent1:                 episode reward: 0.4254,                 loss: 0.1030
Episode: 18181/30000 (60.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2715s / 199.0982 s
agent0:                 episode reward: -0.4284,                 loss: nan
agent1:                 episode reward: 0.4284,                 loss: 0.1038
Episode: 18201/30000 (60.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2631s / 199.3613 s
agent0:                 episode reward: -0.6151,                 loss: nan
agent1:                 episode reward: 0.6151,                 loss: 0.1031
Episode: 18221/30000 (60.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2661s / 199.6274 s
agent0:                 episode reward: -0.7027,                 loss: nan
agent1:                 episode reward: 0.7027,                 loss: 0.1030
Episode: 18241/30000 (60.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2619s / 199.8893 s
agent0:                 episode reward: -0.6491,                 loss: nan
agent1:                 episode reward: 0.6491,                 loss: 0.1034
Episode: 18261/30000 (60.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2618s / 200.1511 s
agent0:                 episode reward: -0.5641,                 loss: nan
agent1:                 episode reward: 0.5641,                 loss: 0.1027
Episode: 18281/30000 (60.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2669s / 200.4180 s
agent0:                 episode reward: -0.7363,                 loss: nan
agent1:                 episode reward: 0.7363,                 loss: 0.1019
Episode: 18301/30000 (61.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2829s / 200.7009 s
agent0:                 episode reward: -0.2653,                 loss: nan
agent1:                 episode reward: 0.2653,                 loss: 0.1023
Episode: 18321/30000 (61.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2851s / 200.9861 s
agent0:                 episode reward: -0.4753,                 loss: nan
agent1:                 episode reward: 0.4753,                 loss: 0.1021
Episode: 18341/30000 (61.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2720s / 201.2581 s
agent0:                 episode reward: -0.4978,                 loss: nan
agent1:                 episode reward: 0.4978,                 loss: 0.1031
Episode: 18361/30000 (61.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2751s / 201.5332 s
agent0:                 episode reward: -0.4799,                 loss: nan
agent1:                 episode reward: 0.4799,                 loss: 0.1024
Episode: 18381/30000 (61.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2731s / 201.8063 s
agent0:                 episode reward: -0.4916,                 loss: nan
agent1:                 episode reward: 0.4916,                 loss: 0.1018
Episode: 18401/30000 (61.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2787s / 202.0849 s
agent0:                 episode reward: -0.6628,                 loss: nan
agent1:                 episode reward: 0.6628,                 loss: 0.1030
Episode: 18421/30000 (61.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3033s / 202.3883 s
agent0:                 episode reward: -0.4683,                 loss: nan
agent1:                 episode reward: 0.4683,                 loss: 0.1012
Episode: 18441/30000 (61.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2812s / 202.6695 s
agent0:                 episode reward: -0.4511,                 loss: nan
agent1:                 episode reward: 0.4511,                 loss: 0.1015
Episode: 18461/30000 (61.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2752s / 202.9447 s
agent0:                 episode reward: -0.7387,                 loss: nan
agent1:                 episode reward: 0.7387,                 loss: 0.1021
Episode: 18481/30000 (61.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2732s / 203.2179 s
agent0:                 episode reward: -0.3369,                 loss: nan
agent1:                 episode reward: 0.3369,                 loss: 0.1016
Episode: 18501/30000 (61.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2967s / 203.5146 s
agent0:                 episode reward: -0.6363,                 loss: nan
agent1:                 episode reward: 0.6363,                 loss: 0.1008
Episode: 18521/30000 (61.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2974s / 203.8120 s
agent0:                 episode reward: -0.3279,                 loss: nan
agent1:                 episode reward: 0.3279,                 loss: 0.1032
Episode: 18541/30000 (61.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2848s / 204.0968 s
agent0:                 episode reward: -0.2580,                 loss: nan
agent1:                 episode reward: 0.2580,                 loss: 0.1022
Episode: 18561/30000 (61.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2863s / 204.3831 s
agent0:                 episode reward: -0.3197,                 loss: nan
agent1:                 episode reward: 0.3197,                 loss: 0.1020
Episode: 18581/30000 (61.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2885s / 204.6716 s
agent0:                 episode reward: -0.5175,                 loss: nan
agent1:                 episode reward: 0.5175,                 loss: 0.1032
Episode: 18601/30000 (62.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2866s / 204.9582 s
agent0:                 episode reward: -0.6105,                 loss: nan
agent1:                 episode reward: 0.6105,                 loss: 0.1027
Episode: 18621/30000 (62.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2849s / 205.2431 s
agent0:                 episode reward: -0.6795,                 loss: nan
agent1:                 episode reward: 0.6795,                 loss: 0.1019
Episode: 18641/30000 (62.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2860s / 205.5291 s
agent0:                 episode reward: -0.5353,                 loss: nan
agent1:                 episode reward: 0.5353,                 loss: 0.1030
Episode: 18661/30000 (62.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2836s / 205.8127 s
agent0:                 episode reward: -0.6697,                 loss: nan
agent1:                 episode reward: 0.6697,                 loss: 0.1028
Episode: 18681/30000 (62.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2873s / 206.1000 s
agent0:                 episode reward: -0.3470,                 loss: nan
agent1:                 episode reward: 0.3470,                 loss: 0.1044
Episode: 18701/30000 (62.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2816s / 206.3816 s
agent0:                 episode reward: -0.3997,                 loss: nan
agent1:                 episode reward: 0.3997,                 loss: 0.1028
Episode: 18721/30000 (62.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2797s / 206.6613 s
agent0:                 episode reward: -0.5230,                 loss: nan
agent1:                 episode reward: 0.5230,                 loss: 0.1040
Episode: 18741/30000 (62.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3076s / 206.9689 s
agent0:                 episode reward: -0.2906,                 loss: nan
agent1:                 episode reward: 0.2906,                 loss: 0.1044
Episode: 18761/30000 (62.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2863s / 207.2553 s
agent0:                 episode reward: -0.8246,                 loss: nan
agent1:                 episode reward: 0.8246,                 loss: 0.1036
Episode: 18781/30000 (62.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2791s / 207.5344 s
agent0:                 episode reward: -0.5294,                 loss: nan
agent1:                 episode reward: 0.5294,                 loss: 0.1024
Episode: 18801/30000 (62.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2808s / 207.8152 s
agent0:                 episode reward: -0.7558,                 loss: nan
agent1:                 episode reward: 0.7558,                 loss: 0.1037
Episode: 18821/30000 (62.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2829s / 208.0982 s
agent0:                 episode reward: -0.7288,                 loss: nan
agent1:                 episode reward: 0.7288,                 loss: 0.1023
Episode: 18841/30000 (62.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2814s / 208.3796 s
agent0:                 episode reward: -0.5466,                 loss: nan
agent1:                 episode reward: 0.5466,                 loss: 0.1030
Episode: 18861/30000 (62.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2798s / 208.6594 s
agent0:                 episode reward: -0.4511,                 loss: nan
agent1:                 episode reward: 0.4511,                 loss: 0.1050
Episode: 18881/30000 (62.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2791s / 208.9385 s
agent0:                 episode reward: -0.6813,                 loss: nan
agent1:                 episode reward: 0.6813,                 loss: 0.1023
Episode: 18901/30000 (63.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2744s / 209.2129 s
agent0:                 episode reward: -0.9501,                 loss: nan
agent1:                 episode reward: 0.9501,                 loss: 0.1023
Episode: 18921/30000 (63.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2850s / 209.4979 s
agent0:                 episode reward: -0.7115,                 loss: nan
agent1:                 episode reward: 0.7115,                 loss: 0.1025
Episode: 18941/30000 (63.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2896s / 209.7875 s
agent0:                 episode reward: -0.5569,                 loss: nan
agent1:                 episode reward: 0.5569,                 loss: 0.1016
Episode: 18961/30000 (63.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3056s / 210.0932 s
agent0:                 episode reward: -0.6735,                 loss: nan
agent1:                 episode reward: 0.6735,                 loss: 0.1007
Episode: 18981/30000 (63.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2839s / 210.3771 s
agent0:                 episode reward: -0.8068,                 loss: nan
agent1:                 episode reward: 0.8068,                 loss: 0.1019
Episode: 19001/30000 (63.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2675s / 210.6446 s
agent0:                 episode reward: -0.6278,                 loss: nan
agent1:                 episode reward: 0.6278,                 loss: 0.1020
Episode: 19021/30000 (63.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2798s / 210.9244 s
agent0:                 episode reward: -0.6863,                 loss: nan
agent1:                 episode reward: 0.6863,                 loss: 0.1029
Episode: 19041/30000 (63.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2849s / 211.2093 s
agent0:                 episode reward: -0.6795,                 loss: nan
agent1:                 episode reward: 0.6795,                 loss: 0.1028
Episode: 19061/30000 (63.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2904s / 211.4996 s
agent0:                 episode reward: -0.5011,                 loss: nan
agent1:                 episode reward: 0.5011,                 loss: 0.1025
Episode: 19081/30000 (63.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3041s / 211.8038 s
agent0:                 episode reward: -0.4968,                 loss: nan
agent1:                 episode reward: 0.4968,                 loss: 0.1023
Episode: 19101/30000 (63.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2848s / 212.0886 s
agent0:                 episode reward: -0.5714,                 loss: nan
agent1:                 episode reward: 0.5714,                 loss: 0.1026
Episode: 19121/30000 (63.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2926s / 212.3812 s
agent0:                 episode reward: -0.5206,                 loss: nan
agent1:                 episode reward: 0.5206,                 loss: 0.1010
Episode: 19141/30000 (63.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2847s / 212.6659 s
agent0:                 episode reward: -0.2195,                 loss: nan
agent1:                 episode reward: 0.2195,                 loss: 0.1019
Episode: 19161/30000 (63.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2990s / 212.9649 s
agent0:                 episode reward: -0.7274,                 loss: nan
agent1:                 episode reward: 0.7274,                 loss: 0.1015
Episode: 19181/30000 (63.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2886s / 213.2536 s
agent0:                 episode reward: -0.8186,                 loss: nan
agent1:                 episode reward: 0.8186,                 loss: 0.1017
Episode: 19201/30000 (64.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2898s / 213.5434 s
agent0:                 episode reward: -0.2834,                 loss: nan
agent1:                 episode reward: 0.2834,                 loss: 0.1016
Episode: 19221/30000 (64.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2882s / 213.8316 s
agent0:                 episode reward: -0.8984,                 loss: nan
agent1:                 episode reward: 0.8984,                 loss: 0.1018
Episode: 19241/30000 (64.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2891s / 214.1206 s
agent0:                 episode reward: -0.4890,                 loss: nan
agent1:                 episode reward: 0.4890,                 loss: 0.1035
Episode: 19261/30000 (64.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3031s / 214.4237 s
agent0:                 episode reward: -0.5866,                 loss: nan
agent1:                 episode reward: 0.5866,                 loss: 0.1024
Episode: 19281/30000 (64.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2886s / 214.7124 s
agent0:                 episode reward: -0.5667,                 loss: nan
agent1:                 episode reward: 0.5667,                 loss: 0.1021
Episode: 19301/30000 (64.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2934s / 215.0058 s
agent0:                 episode reward: -0.5823,                 loss: nan
agent1:                 episode reward: 0.5823,                 loss: 0.1020
Episode: 19321/30000 (64.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2901s / 215.2958 s
agent0:                 episode reward: -0.1878,                 loss: nan
agent1:                 episode reward: 0.1878,                 loss: 0.1020
Episode: 19341/30000 (64.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2866s / 215.5824 s
agent0:                 episode reward: -0.6316,                 loss: nan
agent1:                 episode reward: 0.6316,                 loss: 0.1027
Episode: 19361/30000 (64.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2847s / 215.8672 s
agent0:                 episode reward: -0.3000,                 loss: nan
agent1:                 episode reward: 0.3000,                 loss: 0.1031
Episode: 19381/30000 (64.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2991s / 216.1663 s
agent0:                 episode reward: -0.4873,                 loss: nan
agent1:                 episode reward: 0.4873,                 loss: 0.1030
Episode: 19401/30000 (64.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2694s / 216.4357 s
agent0:                 episode reward: -0.2649,                 loss: nan
agent1:                 episode reward: 0.2649,                 loss: 0.1022
Episode: 19421/30000 (64.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2803s / 216.7161 s
agent0:                 episode reward: -0.6155,                 loss: nan
agent1:                 episode reward: 0.6155,                 loss: 0.1024
Episode: 19441/30000 (64.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2943s / 217.0103 s
agent0:                 episode reward: -0.4714,                 loss: nan
agent1:                 episode reward: 0.4714,                 loss: 0.1033
Episode: 19461/30000 (64.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2819s / 217.2923 s
agent0:                 episode reward: -0.4186,                 loss: nan
agent1:                 episode reward: 0.4186,                 loss: 0.1026
Episode: 19481/30000 (64.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2814s / 217.5736 s
agent0:                 episode reward: -0.4445,                 loss: nan
agent1:                 episode reward: 0.4445,                 loss: 0.1025
Episode: 19501/30000 (65.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2828s / 217.8564 s
agent0:                 episode reward: -0.6513,                 loss: nan
agent1:                 episode reward: 0.6513,                 loss: 0.1018
Episode: 19521/30000 (65.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2824s / 218.1388 s
agent0:                 episode reward: -0.4441,                 loss: nan
agent1:                 episode reward: 0.4441,                 loss: 0.1030
Episode: 19541/30000 (65.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2862s / 218.4250 s
agent0:                 episode reward: -0.8294,                 loss: nan
agent1:                 episode reward: 0.8294,                 loss: 0.1026
Episode: 19561/30000 (65.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2789s / 218.7039 s
agent0:                 episode reward: -0.6614,                 loss: nan
agent1:                 episode reward: 0.6614,                 loss: 0.1027
Episode: 19581/30000 (65.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3068s / 219.0107 s
agent0:                 episode reward: -0.8855,                 loss: nan
agent1:                 episode reward: 0.8855,                 loss: 0.1011
Episode: 19601/30000 (65.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2872s / 219.2979 s
agent0:                 episode reward: -0.2190,                 loss: nan
agent1:                 episode reward: 0.2190,                 loss: 0.1016
Episode: 19621/30000 (65.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2700s / 219.5679 s
agent0:                 episode reward: -0.6083,                 loss: nan
agent1:                 episode reward: 0.6083,                 loss: 0.1014
Episode: 19641/30000 (65.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2773s / 219.8452 s
agent0:                 episode reward: -0.8410,                 loss: nan
agent1:                 episode reward: 0.8410,                 loss: 0.1007
Episode: 19661/30000 (65.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2985s / 220.1437 s
agent0:                 episode reward: -0.4015,                 loss: nan
agent1:                 episode reward: 0.4015,                 loss: 0.1010
Episode: 19681/30000 (65.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2852s / 220.4289 s
agent0:                 episode reward: -0.1935,                 loss: nan
agent1:                 episode reward: 0.1935,                 loss: 0.1013
Episode: 19701/30000 (65.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2898s / 220.7187 s
agent0:                 episode reward: -0.4354,                 loss: nan
agent1:                 episode reward: 0.4354,                 loss: 0.1004
Episode: 19721/30000 (65.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2845s / 221.0033 s
agent0:                 episode reward: -0.7342,                 loss: nan
agent1:                 episode reward: 0.7342,                 loss: 0.1010
Episode: 19741/30000 (65.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2783s / 221.2815 s
agent0:                 episode reward: -0.5318,                 loss: nan
agent1:                 episode reward: 0.5318,                 loss: 0.1014
Episode: 19761/30000 (65.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3133s / 221.5949 s
agent0:                 episode reward: -0.5334,                 loss: nan
agent1:                 episode reward: 0.5334,                 loss: 0.1019
Episode: 19781/30000 (65.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2732s / 221.8681 s
agent0:                 episode reward: -0.5820,                 loss: nan
agent1:                 episode reward: 0.5820,                 loss: 0.1012
Episode: 19801/30000 (66.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2984s / 222.1664 s
agent0:                 episode reward: -0.5525,                 loss: nan
agent1:                 episode reward: 0.5525,                 loss: 0.1025
Episode: 19821/30000 (66.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2856s / 222.4520 s
agent0:                 episode reward: -0.6056,                 loss: nan
agent1:                 episode reward: 0.6056,                 loss: 0.1006
Episode: 19841/30000 (66.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2744s / 222.7264 s
agent0:                 episode reward: -0.6883,                 loss: nan
agent1:                 episode reward: 0.6883,                 loss: 0.1013
Episode: 19861/30000 (66.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2717s / 222.9981 s
agent0:                 episode reward: -0.3750,                 loss: nan
agent1:                 episode reward: 0.3750,                 loss: 0.1011
Episode: 19881/30000 (66.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2739s / 223.2720 s
agent0:                 episode reward: -0.8370,                 loss: nan
agent1:                 episode reward: 0.8370,                 loss: 0.1012
Episode: 19901/30000 (66.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2716s / 223.5437 s
agent0:                 episode reward: -0.6550,                 loss: nan
agent1:                 episode reward: 0.6550,                 loss: 0.1028
Episode: 19921/30000 (66.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2748s / 223.8185 s
agent0:                 episode reward: -0.7687,                 loss: nan
agent1:                 episode reward: 0.7687,                 loss: 0.1004
Episode: 19941/30000 (66.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2660s / 224.0845 s
agent0:                 episode reward: -0.6401,                 loss: nan
agent1:                 episode reward: 0.6401,                 loss: 0.1014
Episode: 19961/30000 (66.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2835s / 224.3680 s
agent0:                 episode reward: -0.6202,                 loss: nan
agent1:                 episode reward: 0.6202,                 loss: 0.1018
Episode: 19981/30000 (66.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2742s / 224.6423 s
agent0:                 episode reward: -0.5859,                 loss: nan
agent1:                 episode reward: 0.5859,                 loss: 0.1012
Episode: 20001/30000 (66.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2782s / 224.9205 s
agent0:                 episode reward: -0.5343,                 loss: nan
agent1:                 episode reward: 0.5343,                 loss: 0.1011
Episode: 20021/30000 (66.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2946s / 225.2151 s
agent0:                 episode reward: -0.9313,                 loss: nan
agent1:                 episode reward: 0.9313,                 loss: 0.1015
Episode: 20041/30000 (66.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2810s / 225.4961 s
agent0:                 episode reward: -0.5385,                 loss: nan
agent1:                 episode reward: 0.5385,                 loss: 0.1026
Episode: 20061/30000 (66.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2735s / 225.7697 s
agent0:                 episode reward: -0.1087,                 loss: nan
agent1:                 episode reward: 0.1087,                 loss: 0.1013
Episode: 20081/30000 (66.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2854s / 226.0551 s
agent0:                 episode reward: -0.6151,                 loss: nan
agent1:                 episode reward: 0.6151,                 loss: 0.1015
Episode: 20101/30000 (67.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2746s / 226.3297 s
agent0:                 episode reward: -0.9586,                 loss: nan
agent1:                 episode reward: 0.9586,                 loss: 0.1015
Episode: 20121/30000 (67.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2827s / 226.6124 s
agent0:                 episode reward: -0.4945,                 loss: nan
agent1:                 episode reward: 0.4945,                 loss: 0.1022
Episode: 20141/30000 (67.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2929s / 226.9053 s
agent0:                 episode reward: -0.5202,                 loss: nan
agent1:                 episode reward: 0.5202,                 loss: 0.1022
Episode: 20161/30000 (67.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2829s / 227.1881 s
agent0:                 episode reward: -0.6842,                 loss: nan
agent1:                 episode reward: 0.6842,                 loss: 0.1019
Episode: 20181/30000 (67.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2847s / 227.4728 s
agent0:                 episode reward: -0.5313,                 loss: nan
agent1:                 episode reward: 0.5313,                 loss: 0.1023
Episode: 20201/30000 (67.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2922s / 227.7650 s
agent0:                 episode reward: -1.0797,                 loss: nan
agent1:                 episode reward: 1.0797,                 loss: 0.1008
Episode: 20221/30000 (67.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2841s / 228.0491 s
agent0:                 episode reward: -0.3553,                 loss: nan
agent1:                 episode reward: 0.3553,                 loss: 0.1010
Episode: 20241/30000 (67.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3008s / 228.3499 s
agent0:                 episode reward: -1.1704,                 loss: nan
agent1:                 episode reward: 1.1704,                 loss: 0.1025
Episode: 20261/30000 (67.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2907s / 228.6406 s
agent0:                 episode reward: -0.4480,                 loss: nan
agent1:                 episode reward: 0.4480,                 loss: 0.1018
Episode: 20281/30000 (67.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2907s / 228.9313 s
agent0:                 episode reward: -0.4767,                 loss: nan
agent1:                 episode reward: 0.4767,                 loss: 0.1020
Episode: 20301/30000 (67.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2854s / 229.2167 s
agent0:                 episode reward: -0.8277,                 loss: nan
agent1:                 episode reward: 0.8277,                 loss: 0.1032
Episode: 20321/30000 (67.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2906s / 229.5072 s
agent0:                 episode reward: -0.7521,                 loss: nan
agent1:                 episode reward: 0.7521,                 loss: 0.1026
Episode: 20341/30000 (67.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2858s / 229.7930 s
agent0:                 episode reward: -0.8098,                 loss: nan
agent1:                 episode reward: 0.8098,                 loss: 0.1016
Episode: 20361/30000 (67.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2908s / 230.0838 s
agent0:                 episode reward: -0.9087,                 loss: nan
agent1:                 episode reward: 0.9087,                 loss: 0.1033
Episode: 20381/30000 (67.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2875s / 230.3713 s
agent0:                 episode reward: -0.7768,                 loss: nan
agent1:                 episode reward: 0.7768,                 loss: 0.1005
Episode: 20401/30000 (68.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2875s / 230.6588 s
agent0:                 episode reward: -0.7128,                 loss: nan
agent1:                 episode reward: 0.7128,                 loss: 0.1017
Episode: 20421/30000 (68.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3107s / 230.9694 s
agent0:                 episode reward: -0.4619,                 loss: nan
agent1:                 episode reward: 0.4619,                 loss: 0.1019
Episode: 20441/30000 (68.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3035s / 231.2730 s
agent0:                 episode reward: -0.6929,                 loss: nan
agent1:                 episode reward: 0.6929,                 loss: 0.1013
Episode: 20461/30000 (68.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2846s / 231.5576 s
agent0:                 episode reward: -0.6491,                 loss: nan
agent1:                 episode reward: 0.6491,                 loss: 0.1024
Episode: 20481/30000 (68.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2917s / 231.8493 s
agent0:                 episode reward: -0.4638,                 loss: nan
agent1:                 episode reward: 0.4638,                 loss: 0.1016
Episode: 20501/30000 (68.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2867s / 232.1360 s
agent0:                 episode reward: -0.5748,                 loss: nan
agent1:                 episode reward: 0.5748,                 loss: 0.1018
Episode: 20521/30000 (68.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2916s / 232.4276 s
agent0:                 episode reward: -0.5064,                 loss: nan
agent1:                 episode reward: 0.5064,                 loss: 0.1004
Episode: 20541/30000 (68.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2928s / 232.7204 s
agent0:                 episode reward: -0.3624,                 loss: nan
agent1:                 episode reward: 0.3624,                 loss: 0.1018
Episode: 20561/30000 (68.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2884s / 233.0088 s
agent0:                 episode reward: -0.4835,                 loss: nan
agent1:                 episode reward: 0.4835,                 loss: 0.1022
Episode: 20581/30000 (68.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2841s / 233.2929 s
agent0:                 episode reward: -0.4521,                 loss: nan
agent1:                 episode reward: 0.4521,                 loss: 0.1015
Episode: 20601/30000 (68.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2861s / 233.5790 s
agent0:                 episode reward: -0.6276,                 loss: nan
agent1:                 episode reward: 0.6276,                 loss: 0.1001
Episode: 20621/30000 (68.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2861s / 233.8651 s
agent0:                 episode reward: -0.7247,                 loss: nan
agent1:                 episode reward: 0.7247,                 loss: 0.1012
Episode: 20641/30000 (68.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3134s / 234.1785 s
agent0:                 episode reward: -0.3900,                 loss: nan
agent1:                 episode reward: 0.3900,                 loss: 0.1014
Episode: 20661/30000 (68.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2888s / 234.4673 s
agent0:                 episode reward: -0.7286,                 loss: nan
agent1:                 episode reward: 0.7286,                 loss: 0.1013
Episode: 20681/30000 (68.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2938s / 234.7611 s
agent0:                 episode reward: -0.6155,                 loss: nan
agent1:                 episode reward: 0.6155,                 loss: 0.1010
Episode: 20701/30000 (69.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2899s / 235.0510 s
agent0:                 episode reward: -0.4455,                 loss: nan
agent1:                 episode reward: 0.4455,                 loss: 0.1034
Episode: 20721/30000 (69.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2897s / 235.3407 s
agent0:                 episode reward: -0.5626,                 loss: nan
agent1:                 episode reward: 0.5626,                 loss: 0.1010
Episode: 20741/30000 (69.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2868s / 235.6276 s
agent0:                 episode reward: -0.5543,                 loss: nan
agent1:                 episode reward: 0.5543,                 loss: 0.1008
Episode: 20761/30000 (69.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2897s / 235.9173 s
agent0:                 episode reward: -0.7700,                 loss: nan
agent1:                 episode reward: 0.7700,                 loss: 0.1002
Episode: 20781/30000 (69.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2903s / 236.2076 s
agent0:                 episode reward: -0.9435,                 loss: nan
agent1:                 episode reward: 0.9435,                 loss: 0.1015
Episode: 20801/30000 (69.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2877s / 236.4953 s
agent0:                 episode reward: -0.4624,                 loss: nan
agent1:                 episode reward: 0.4624,                 loss: 0.1013
Episode: 20821/30000 (69.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3120s / 236.8073 s
agent0:                 episode reward: -0.7984,                 loss: nan
agent1:                 episode reward: 0.7984,                 loss: 0.1010
Episode: 20841/30000 (69.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3172s / 237.1244 s
agent0:                 episode reward: -0.4430,                 loss: nan
agent1:                 episode reward: 0.4430,                 loss: 0.1007
Episode: 20861/30000 (69.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2959s / 237.4203 s
agent0:                 episode reward: -0.3299,                 loss: nan
agent1:                 episode reward: 0.3299,                 loss: 0.1021
Episode: 20881/30000 (69.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2802s / 237.7005 s
agent0:                 episode reward: -0.3631,                 loss: nan
agent1:                 episode reward: 0.3631,                 loss: 0.1019
Episode: 20901/30000 (69.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2840s / 237.9844 s
agent0:                 episode reward: -0.6624,                 loss: nan
agent1:                 episode reward: 0.6624,                 loss: 0.1021
Episode: 20921/30000 (69.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2862s / 238.2707 s
agent0:                 episode reward: -0.5753,                 loss: nan
agent1:                 episode reward: 0.5753,                 loss: 0.1012
Episode: 20941/30000 (69.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2755s / 238.5461 s
agent0:                 episode reward: -0.2315,                 loss: nan
agent1:                 episode reward: 0.2315,                 loss: 0.1008
Episode: 20961/30000 (69.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2825s / 238.8286 s
agent0:                 episode reward: -0.7771,                 loss: nan
agent1:                 episode reward: 0.7771,                 loss: 0.1017
Episode: 20981/30000 (69.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2827s / 239.1113 s
agent0:                 episode reward: -0.6774,                 loss: nan
agent1:                 episode reward: 0.6774,                 loss: 0.1004
Episode: 21001/30000 (70.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2876s / 239.3989 s
agent0:                 episode reward: -0.5888,                 loss: nan
agent1:                 episode reward: 0.5888,                 loss: 0.1007
Episode: 21021/30000 (70.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2836s / 239.6826 s
agent0:                 episode reward: -0.2694,                 loss: nan
agent1:                 episode reward: 0.2694,                 loss: 0.1018
Episode: 21041/30000 (70.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2840s / 239.9665 s
agent0:                 episode reward: -0.9346,                 loss: nan
agent1:                 episode reward: 0.9346,                 loss: 0.1021
Episode: 21061/30000 (70.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3051s / 240.2716 s
agent0:                 episode reward: -0.6550,                 loss: nan
agent1:                 episode reward: 0.6550,                 loss: 0.1008
Episode: 21081/30000 (70.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2808s / 240.5525 s
agent0:                 episode reward: -0.8670,                 loss: nan
agent1:                 episode reward: 0.8670,                 loss: 0.1015
Episode: 21101/30000 (70.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2810s / 240.8334 s
agent0:                 episode reward: -0.1791,                 loss: nan
agent1:                 episode reward: 0.1791,                 loss: 0.1001
Episode: 21121/30000 (70.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2840s / 241.1174 s
agent0:                 episode reward: -0.4091,                 loss: nan
agent1:                 episode reward: 0.4091,                 loss: 0.1031
Episode: 21141/30000 (70.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2861s / 241.4035 s
agent0:                 episode reward: -0.8107,                 loss: nan
agent1:                 episode reward: 0.8107,                 loss: 0.1017
Episode: 21161/30000 (70.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2866s / 241.6901 s
agent0:                 episode reward: -0.8545,                 loss: nan
agent1:                 episode reward: 0.8545,                 loss: 0.1027
Episode: 21181/30000 (70.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2808s / 241.9710 s
agent0:                 episode reward: -0.6952,                 loss: nan
agent1:                 episode reward: 0.6952,                 loss: 0.1023
Episode: 21201/30000 (70.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2777s / 242.2487 s
agent0:                 episode reward: -0.5708,                 loss: nan
agent1:                 episode reward: 0.5708,                 loss: 0.1020
Episode: 21221/30000 (70.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2790s / 242.5277 s
agent0:                 episode reward: -0.8381,                 loss: nan
agent1:                 episode reward: 0.8381,                 loss: 0.1009
Episode: 21241/30000 (70.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2818s / 242.8095 s
agent0:                 episode reward: -0.6018,                 loss: nan
agent1:                 episode reward: 0.6018,                 loss: 0.1006
Episode: 21261/30000 (70.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2816s / 243.0911 s
agent0:                 episode reward: -0.5007,                 loss: nan
agent1:                 episode reward: 0.5007,                 loss: 0.1003
Episode: 21281/30000 (70.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3109s / 243.4020 s
agent0:                 episode reward: -0.6020,                 loss: nan
agent1:                 episode reward: 0.6020,                 loss: 0.1003
Episode: 21301/30000 (71.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2931s / 243.6951 s
agent0:                 episode reward: -0.7152,                 loss: nan
agent1:                 episode reward: 0.7152,                 loss: 0.1009
Episode: 21321/30000 (71.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3026s / 243.9977 s
agent0:                 episode reward: -0.4700,                 loss: nan
agent1:                 episode reward: 0.4700,                 loss: 0.1002
Episode: 21341/30000 (71.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2976s / 244.2953 s
agent0:                 episode reward: -0.3050,                 loss: nan
agent1:                 episode reward: 0.3050,                 loss: 0.1005
Episode: 21361/30000 (71.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3023s / 244.5976 s
agent0:                 episode reward: -0.5221,                 loss: nan
agent1:                 episode reward: 0.5221,                 loss: 0.1024
Episode: 21381/30000 (71.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3052s / 244.9028 s
agent0:                 episode reward: -0.6152,                 loss: nan
agent1:                 episode reward: 0.6152,                 loss: 0.0996
Episode: 21401/30000 (71.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3070s / 245.2098 s
agent0:                 episode reward: -0.5463,                 loss: nan
agent1:                 episode reward: 0.5463,                 loss: 0.1008
Episode: 21421/30000 (71.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2909s / 245.5008 s
agent0:                 episode reward: -0.4183,                 loss: nan
agent1:                 episode reward: 0.4183,                 loss: 0.0994
Episode: 21441/30000 (71.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2870s / 245.7878 s
agent0:                 episode reward: -0.8890,                 loss: nan
agent1:                 episode reward: 0.8890,                 loss: 0.1011
Episode: 21461/30000 (71.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2922s / 246.0799 s
agent0:                 episode reward: -0.6052,                 loss: nan
agent1:                 episode reward: 0.6052,                 loss: 0.0991
Episode: 21481/30000 (71.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3140s / 246.3939 s
agent0:                 episode reward: -0.6872,                 loss: nan
agent1:                 episode reward: 0.6872,                 loss: 0.1003
Episode: 21501/30000 (71.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2929s / 246.6868 s
agent0:                 episode reward: -0.7660,                 loss: nan
agent1:                 episode reward: 0.7660,                 loss: 0.1010
Episode: 21521/30000 (71.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2962s / 246.9830 s
agent0:                 episode reward: -0.5025,                 loss: nan
agent1:                 episode reward: 0.5025,                 loss: 0.1001
Episode: 21541/30000 (71.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2920s / 247.2750 s
agent0:                 episode reward: -0.6305,                 loss: nan
agent1:                 episode reward: 0.6305,                 loss: 0.0995
Episode: 21561/30000 (71.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2869s / 247.5619 s
agent0:                 episode reward: -0.8279,                 loss: nan
agent1:                 episode reward: 0.8279,                 loss: 0.0992
Episode: 21581/30000 (71.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2935s / 247.8554 s
agent0:                 episode reward: -0.6942,                 loss: nan
agent1:                 episode reward: 0.6942,                 loss: 0.1016
Episode: 21601/30000 (72.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2954s / 248.1507 s
agent0:                 episode reward: -0.3552,                 loss: nan
agent1:                 episode reward: 0.3552,                 loss: 0.1016
Episode: 21621/30000 (72.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2905s / 248.4412 s
agent0:                 episode reward: -0.7987,                 loss: nan
agent1:                 episode reward: 0.7987,                 loss: 0.1012
Episode: 21641/30000 (72.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2893s / 248.7304 s
agent0:                 episode reward: -0.6279,                 loss: nan
agent1:                 episode reward: 0.6279,                 loss: 0.1016
Episode: 21661/30000 (72.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2872s / 249.0176 s
agent0:                 episode reward: -0.7122,                 loss: nan
agent1:                 episode reward: 0.7122,                 loss: 0.1000
Episode: 21681/30000 (72.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3076s / 249.3252 s
agent0:                 episode reward: -0.7634,                 loss: nan
agent1:                 episode reward: 0.7634,                 loss: 0.1019
Episode: 21701/30000 (72.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3071s / 249.6323 s
agent0:                 episode reward: -0.8723,                 loss: nan
agent1:                 episode reward: 0.8723,                 loss: 0.1010
Episode: 21721/30000 (72.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2827s / 249.9150 s
agent0:                 episode reward: -0.8005,                 loss: nan
agent1:                 episode reward: 0.8005,                 loss: 0.1008
Episode: 21741/30000 (72.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2809s / 250.1959 s
agent0:                 episode reward: -0.2433,                 loss: nan
agent1:                 episode reward: 0.2433,                 loss: 0.1017
Episode: 21761/30000 (72.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2833s / 250.4792 s
agent0:                 episode reward: -0.7015,                 loss: nan
agent1:                 episode reward: 0.7015,                 loss: 0.1011
Episode: 21781/30000 (72.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2788s / 250.7581 s
agent0:                 episode reward: -0.2676,                 loss: nan
agent1:                 episode reward: 0.2676,                 loss: 0.1013
Episode: 21801/30000 (72.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2830s / 251.0411 s
agent0:                 episode reward: -0.8132,                 loss: nan
agent1:                 episode reward: 0.8132,                 loss: 0.1017
Episode: 21821/30000 (72.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2868s / 251.3279 s
agent0:                 episode reward: -1.0285,                 loss: nan
agent1:                 episode reward: 1.0285,                 loss: 0.1012
Episode: 21841/30000 (72.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3079s / 251.6358 s
agent0:                 episode reward: -0.7807,                 loss: nan
agent1:                 episode reward: 0.7807,                 loss: 0.1011
Episode: 21861/30000 (72.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3058s / 251.9415 s
agent0:                 episode reward: -0.4473,                 loss: nan
agent1:                 episode reward: 0.4473,                 loss: 0.1008
Episode: 21881/30000 (72.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3026s / 252.2441 s
agent0:                 episode reward: -0.6298,                 loss: nan
agent1:                 episode reward: 0.6298,                 loss: 0.0997
Episode: 21901/30000 (73.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3213s / 252.5654 s
agent0:                 episode reward: -0.4477,                 loss: nan
agent1:                 episode reward: 0.4477,                 loss: 0.1003
Episode: 21921/30000 (73.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3040s / 252.8694 s
agent0:                 episode reward: -0.7509,                 loss: nan
agent1:                 episode reward: 0.7509,                 loss: 0.1017
Episode: 21941/30000 (73.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3042s / 253.1736 s
agent0:                 episode reward: -0.8125,                 loss: nan
agent1:                 episode reward: 0.8125,                 loss: 0.0992
Episode: 21961/30000 (73.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3383s / 253.5118 s
agent0:                 episode reward: -0.5440,                 loss: nan
agent1:                 episode reward: 0.5440,                 loss: 0.1012
Episode: 21981/30000 (73.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3012s / 253.8130 s
agent0:                 episode reward: -0.5138,                 loss: nan
agent1:                 episode reward: 0.5138,                 loss: 0.1006
Episode: 22001/30000 (73.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3043s / 254.1173 s
agent0:                 episode reward: -0.3719,                 loss: nan
agent1:                 episode reward: 0.3719,                 loss: 0.1012
Episode: 22021/30000 (73.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3068s / 254.4241 s
agent0:                 episode reward: -0.6407,                 loss: nan
agent1:                 episode reward: 0.6407,                 loss: 0.1003
Episode: 22041/30000 (73.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3013s / 254.7254 s
agent0:                 episode reward: -0.7264,                 loss: nan
agent1:                 episode reward: 0.7264,                 loss: 0.1008
Episode: 22061/30000 (73.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3061s / 255.0315 s
agent0:                 episode reward: -0.5651,                 loss: nan
agent1:                 episode reward: 0.5651,                 loss: 0.1014
Episode: 22081/30000 (73.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3112s / 255.3428 s
agent0:                 episode reward: -0.9059,                 loss: nan
agent1:                 episode reward: 0.9059,                 loss: 0.1010
Episode: 22101/30000 (73.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3299s / 255.6727 s
agent0:                 episode reward: -0.6810,                 loss: nan
agent1:                 episode reward: 0.6810,                 loss: 0.1004
Episode: 22121/30000 (73.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3000s / 255.9727 s
agent0:                 episode reward: -1.1038,                 loss: nan
agent1:                 episode reward: 1.1038,                 loss: 0.1001
Episode: 22141/30000 (73.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2982s / 256.2708 s
agent0:                 episode reward: -0.6897,                 loss: nan
agent1:                 episode reward: 0.6897,                 loss: 0.1004
Episode: 22161/30000 (73.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2987s / 256.5695 s
agent0:                 episode reward: -0.6029,                 loss: nan
agent1:                 episode reward: 0.6029,                 loss: 0.1016
Episode: 22181/30000 (73.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3033s / 256.8728 s
agent0:                 episode reward: -0.6744,                 loss: nan
agent1:                 episode reward: 0.6744,                 loss: 0.1003
Episode: 22201/30000 (74.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3051s / 257.1779 s
agent0:                 episode reward: -0.6167,                 loss: nan
agent1:                 episode reward: 0.6167,                 loss: 0.0984
Episode: 22221/30000 (74.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3034s / 257.4813 s
agent0:                 episode reward: -0.5112,                 loss: nan
agent1:                 episode reward: 0.5112,                 loss: 0.1005
Episode: 22241/30000 (74.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3053s / 257.7866 s
agent0:                 episode reward: -0.5599,                 loss: nan
agent1:                 episode reward: 0.5599,                 loss: 0.1023
Episode: 22261/30000 (74.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3114s / 258.0980 s
agent0:                 episode reward: -0.7121,                 loss: nan
agent1:                 episode reward: 0.7121,                 loss: 0.1020
Episode: 22281/30000 (74.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3035s / 258.4015 s
agent0:                 episode reward: -0.8416,                 loss: nan
agent1:                 episode reward: 0.8416,                 loss: 0.1035
Episode: 22301/30000 (74.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3336s / 258.7351 s
agent0:                 episode reward: -0.7138,                 loss: nan
agent1:                 episode reward: 0.7138,                 loss: 0.1016
Episode: 22321/30000 (74.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3116s / 259.0467 s
agent0:                 episode reward: -0.6616,                 loss: nan
agent1:                 episode reward: 0.6616,                 loss: 0.1015
Episode: 22341/30000 (74.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3270s / 259.3737 s
agent0:                 episode reward: -0.5255,                 loss: nan
agent1:                 episode reward: 0.5255,                 loss: 0.1001
Episode: 22361/30000 (74.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3428s / 259.7165 s
agent0:                 episode reward: -0.6151,                 loss: nan
agent1:                 episode reward: 0.6151,                 loss: 0.1003
Episode: 22381/30000 (74.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3122s / 260.0287 s
agent0:                 episode reward: -0.5817,                 loss: nan
agent1:                 episode reward: 0.5817,                 loss: 0.1025
Episode: 22401/30000 (74.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3549s / 260.3837 s
agent0:                 episode reward: -0.2760,                 loss: nan
agent1:                 episode reward: 0.2760,                 loss: 0.1023
Episode: 22421/30000 (74.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3409s / 260.7246 s
agent0:                 episode reward: -0.8146,                 loss: nan
agent1:                 episode reward: 0.8146,                 loss: 0.1010
Episode: 22441/30000 (74.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3232s / 261.0477 s
agent0:                 episode reward: -0.3067,                 loss: nan
agent1:                 episode reward: 0.3067,                 loss: 0.1028
Episode: 22461/30000 (74.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3029s / 261.3506 s
agent0:                 episode reward: -0.6962,                 loss: nan
agent1:                 episode reward: 0.6962,                 loss: 0.1013
Episode: 22481/30000 (74.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3518s / 261.7025 s
agent0:                 episode reward: -0.6121,                 loss: nan
agent1:                 episode reward: 0.6121,                 loss: 0.1016
Episode: 22501/30000 (75.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3129s / 262.0154 s
agent0:                 episode reward: -0.9224,                 loss: nan
agent1:                 episode reward: 0.9224,                 loss: 0.1017
Episode: 22521/30000 (75.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2983s / 262.3136 s
agent0:                 episode reward: -0.8448,                 loss: nan
agent1:                 episode reward: 0.8448,                 loss: 0.1021
Episode: 22541/30000 (75.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3042s / 262.6178 s
agent0:                 episode reward: -0.4787,                 loss: nan
agent1:                 episode reward: 0.4787,                 loss: 0.1026
Episode: 22561/30000 (75.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3018s / 262.9196 s
agent0:                 episode reward: -0.8835,                 loss: nan
agent1:                 episode reward: 0.8835,                 loss: 0.1011
Episode: 22581/30000 (75.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2919s / 263.2115 s
agent0:                 episode reward: -0.4834,                 loss: nan
agent1:                 episode reward: 0.4834,                 loss: 0.1012
Episode: 22601/30000 (75.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2908s / 263.5023 s
agent0:                 episode reward: -0.5553,                 loss: nan
agent1:                 episode reward: 0.5553,                 loss: 0.0994
Episode: 22621/30000 (75.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2943s / 263.7966 s
agent0:                 episode reward: -0.7253,                 loss: nan
agent1:                 episode reward: 0.7253,                 loss: 0.1002
Episode: 22641/30000 (75.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2974s / 264.0939 s
agent0:                 episode reward: -0.6513,                 loss: nan
agent1:                 episode reward: 0.6513,                 loss: 0.1013
Episode: 22661/30000 (75.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2983s / 264.3922 s
agent0:                 episode reward: -0.7031,                 loss: nan
agent1:                 episode reward: 0.7031,                 loss: 0.1013
Episode: 22681/30000 (75.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3507s / 264.7430 s
agent0:                 episode reward: -0.5779,                 loss: nan
agent1:                 episode reward: 0.5779,                 loss: 0.1004
Episode: 22701/30000 (75.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3120s / 265.0549 s
agent0:                 episode reward: -0.1234,                 loss: nan
agent1:                 episode reward: 0.1234,                 loss: 0.1010
Episode: 22721/30000 (75.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3008s / 265.3557 s
agent0:                 episode reward: -0.7193,                 loss: nan
agent1:                 episode reward: 0.7193,                 loss: 0.1011
Episode: 22741/30000 (75.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2956s / 265.6513 s
agent0:                 episode reward: -0.8498,                 loss: nan
agent1:                 episode reward: 0.8498,                 loss: 0.1019
Episode: 22761/30000 (75.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3039s / 265.9552 s
agent0:                 episode reward: -0.4385,                 loss: nan
agent1:                 episode reward: 0.4385,                 loss: 0.1007
Episode: 22781/30000 (75.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2893s / 266.2445 s
agent0:                 episode reward: -0.8082,                 loss: nan
agent1:                 episode reward: 0.8082,                 loss: 0.1012
Episode: 22801/30000 (76.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2879s / 266.5324 s
agent0:                 episode reward: -0.5853,                 loss: nan
agent1:                 episode reward: 0.5853,                 loss: 0.1023
Episode: 22821/30000 (76.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2939s / 266.8262 s
agent0:                 episode reward: -0.4654,                 loss: nan
agent1:                 episode reward: 0.4654,                 loss: 0.1005
Episode: 22841/30000 (76.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2932s / 267.1194 s
agent0:                 episode reward: -0.4201,                 loss: nan
agent1:                 episode reward: 0.4201,                 loss: 0.0996
Episode: 22861/30000 (76.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3094s / 267.4288 s
agent0:                 episode reward: -0.7465,                 loss: nan
agent1:                 episode reward: 0.7465,                 loss: 0.1017
Episode: 22881/30000 (76.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3333s / 267.7621 s
agent0:                 episode reward: -0.7244,                 loss: nan
agent1:                 episode reward: 0.7244,                 loss: 0.1006
Episode: 22901/30000 (76.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3188s / 268.0809 s
agent0:                 episode reward: -0.7003,                 loss: nan
agent1:                 episode reward: 0.7003,                 loss: 0.1006
Episode: 22921/30000 (76.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3146s / 268.3955 s
agent0:                 episode reward: -0.8147,                 loss: nan
agent1:                 episode reward: 0.8147,                 loss: 0.1019
Episode: 22941/30000 (76.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3166s / 268.7121 s
agent0:                 episode reward: -0.4653,                 loss: nan
agent1:                 episode reward: 0.4653,                 loss: 0.1006
Episode: 22961/30000 (76.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3093s / 269.0214 s
agent0:                 episode reward: -0.9720,                 loss: nan
agent1:                 episode reward: 0.9720,                 loss: 0.1005
Episode: 22981/30000 (76.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3351s / 269.3565 s
agent0:                 episode reward: -0.6549,                 loss: nan
agent1:                 episode reward: 0.6549,                 loss: 0.1003
Episode: 23001/30000 (76.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3149s / 269.6714 s
agent0:                 episode reward: -0.5110,                 loss: nan
agent1:                 episode reward: 0.5110,                 loss: 0.0993
Episode: 23021/30000 (76.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3254s / 269.9968 s
agent0:                 episode reward: -0.5433,                 loss: nan
agent1:                 episode reward: 0.5433,                 loss: 0.1008
Episode: 23041/30000 (76.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3302s / 270.3270 s
agent0:                 episode reward: -0.9304,                 loss: nan
agent1:                 episode reward: 0.9304,                 loss: 0.0995
Episode: 23061/30000 (76.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3172s / 270.6442 s
agent0:                 episode reward: -0.6269,                 loss: nan
agent1:                 episode reward: 0.6269,                 loss: 0.0989
Episode: 23081/30000 (76.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3316s / 270.9758 s
agent0:                 episode reward: -0.5338,                 loss: nan
agent1:                 episode reward: 0.5338,                 loss: 0.1006
Episode: 23101/30000 (77.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3280s / 271.3037 s
agent0:                 episode reward: -0.7956,                 loss: nan
agent1:                 episode reward: 0.7956,                 loss: 0.1007
Episode: 23121/30000 (77.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3119s / 271.6156 s
agent0:                 episode reward: -0.7965,                 loss: nan
agent1:                 episode reward: 0.7965,                 loss: 0.1005
Episode: 23141/30000 (77.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3130s / 271.9286 s
agent0:                 episode reward: -0.6403,                 loss: nan
agent1:                 episode reward: 0.6403,                 loss: 0.0989
Episode: 23161/30000 (77.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3062s / 272.2348 s
agent0:                 episode reward: -0.6813,                 loss: nan
agent1:                 episode reward: 0.6813,                 loss: 0.0987
Episode: 23181/30000 (77.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3079s / 272.5427 s
agent0:                 episode reward: -0.9294,                 loss: nan
agent1:                 episode reward: 0.9294,                 loss: 0.0991
Episode: 23201/30000 (77.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3001s / 272.8428 s
agent0:                 episode reward: -0.7207,                 loss: nan
agent1:                 episode reward: 0.7207,                 loss: 0.1006
Episode: 23221/30000 (77.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3144s / 273.1571 s
agent0:                 episode reward: -0.5036,                 loss: nan
agent1:                 episode reward: 0.5036,                 loss: 0.1004
Episode: 23241/30000 (77.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3070s / 273.4641 s
agent0:                 episode reward: -0.9011,                 loss: nan
agent1:                 episode reward: 0.9011,                 loss: 0.0994
Episode: 23261/30000 (77.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3253s / 273.7895 s
agent0:                 episode reward: -0.7759,                 loss: nan
agent1:                 episode reward: 0.7759,                 loss: 0.0991
Episode: 23281/30000 (77.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3267s / 274.1161 s
agent0:                 episode reward: -0.6234,                 loss: nan
agent1:                 episode reward: 0.6234,                 loss: 0.0994
Episode: 23301/30000 (77.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3162s / 274.4323 s
agent0:                 episode reward: -0.6973,                 loss: nan
agent1:                 episode reward: 0.6973,                 loss: 0.0991
Episode: 23321/30000 (77.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3168s / 274.7491 s
agent0:                 episode reward: -0.3874,                 loss: nan
agent1:                 episode reward: 0.3874,                 loss: 0.1001
Episode: 23341/30000 (77.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3109s / 275.0600 s
agent0:                 episode reward: -0.4077,                 loss: nan
agent1:                 episode reward: 0.4077,                 loss: 0.0990
Episode: 23361/30000 (77.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3103s / 275.3704 s
agent0:                 episode reward: -0.7477,                 loss: nan
agent1:                 episode reward: 0.7477,                 loss: 0.1003
Episode: 23381/30000 (77.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3127s / 275.6831 s
agent0:                 episode reward: -0.5583,                 loss: nan
agent1:                 episode reward: 0.5583,                 loss: 0.0993
Episode: 23401/30000 (78.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3100s / 275.9931 s
agent0:                 episode reward: -0.1854,                 loss: nan
agent1:                 episode reward: 0.1854,                 loss: 0.1011
Episode: 23421/30000 (78.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3219s / 276.3151 s
agent0:                 episode reward: -0.6812,                 loss: nan
agent1:                 episode reward: 0.6812,                 loss: 0.0996
Episode: 23441/30000 (78.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3086s / 276.6236 s
agent0:                 episode reward: -0.7596,                 loss: nan
agent1:                 episode reward: 0.7596,                 loss: 0.0996
Episode: 23461/30000 (78.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3332s / 276.9568 s
agent0:                 episode reward: -0.8821,                 loss: nan
agent1:                 episode reward: 0.8821,                 loss: 0.0995
Episode: 23481/30000 (78.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3143s / 277.2711 s
agent0:                 episode reward: -0.5743,                 loss: nan
agent1:                 episode reward: 0.5743,                 loss: 0.0997
Episode: 23501/30000 (78.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3148s / 277.5859 s
agent0:                 episode reward: -0.6425,                 loss: nan
agent1:                 episode reward: 0.6425,                 loss: 0.1001
Episode: 23521/30000 (78.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3121s / 277.8980 s
agent0:                 episode reward: -0.2976,                 loss: nan
agent1:                 episode reward: 0.2976,                 loss: 0.1004
Episode: 23541/30000 (78.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3135s / 278.2115 s
agent0:                 episode reward: -0.7324,                 loss: nan
agent1:                 episode reward: 0.7324,                 loss: 0.0999
Episode: 23561/30000 (78.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3338s / 278.5453 s
agent0:                 episode reward: -0.7550,                 loss: nan
agent1:                 episode reward: 0.7550,                 loss: 0.1005
Episode: 23581/30000 (78.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3134s / 278.8587 s
agent0:                 episode reward: -0.4207,                 loss: nan
agent1:                 episode reward: 0.4207,                 loss: 0.0998
Episode: 23601/30000 (78.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3127s / 279.1714 s
agent0:                 episode reward: -0.4693,                 loss: nan
agent1:                 episode reward: 0.4693,                 loss: 0.1004
Episode: 23621/30000 (78.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3147s / 279.4862 s
agent0:                 episode reward: -0.6614,                 loss: nan
agent1:                 episode reward: 0.6614,                 loss: 0.0997
Episode: 23641/30000 (78.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3179s / 279.8041 s
agent0:                 episode reward: -0.8481,                 loss: nan
agent1:                 episode reward: 0.8481,                 loss: 0.1003
Episode: 23661/30000 (78.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3415s / 280.1456 s
agent0:                 episode reward: -0.3824,                 loss: nan
agent1:                 episode reward: 0.3824,                 loss: 0.1005
Episode: 23681/30000 (78.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3199s / 280.4655 s
agent0:                 episode reward: -0.6250,                 loss: nan
agent1:                 episode reward: 0.6250,                 loss: 0.1003
Episode: 23701/30000 (79.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3085s / 280.7740 s
agent0:                 episode reward: -0.9599,                 loss: nan
agent1:                 episode reward: 0.9599,                 loss: 0.1012
Episode: 23721/30000 (79.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3118s / 281.0858 s
agent0:                 episode reward: -0.5877,                 loss: nan
agent1:                 episode reward: 0.5877,                 loss: 0.1000
Episode: 23741/30000 (79.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3083s / 281.3941 s
agent0:                 episode reward: -0.7498,                 loss: nan
agent1:                 episode reward: 0.7498,                 loss: 0.1000
Episode: 23761/30000 (79.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3137s / 281.7078 s
agent0:                 episode reward: -0.6585,                 loss: nan
agent1:                 episode reward: 0.6585,                 loss: 0.0997
Episode: 23781/30000 (79.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3161s / 282.0240 s
agent0:                 episode reward: -0.8121,                 loss: nan
agent1:                 episode reward: 0.8121,                 loss: 0.1004
Episode: 23801/30000 (79.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3124s / 282.3363 s
agent0:                 episode reward: -0.4447,                 loss: nan
agent1:                 episode reward: 0.4447,                 loss: 0.0999
Episode: 23821/30000 (79.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3148s / 282.6511 s
agent0:                 episode reward: -0.6320,                 loss: nan
agent1:                 episode reward: 0.6320,                 loss: 0.1002
Episode: 23841/30000 (79.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3219s / 282.9730 s
agent0:                 episode reward: -0.4249,                 loss: nan
agent1:                 episode reward: 0.4249,                 loss: 0.1000
Episode: 23861/30000 (79.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3333s / 283.3063 s
agent0:                 episode reward: -0.6042,                 loss: nan
agent1:                 episode reward: 0.6042,                 loss: 0.0981
Episode: 23881/30000 (79.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3061s / 283.6124 s
agent0:                 episode reward: -0.3194,                 loss: nan
agent1:                 episode reward: 0.3194,                 loss: 0.0996
Episode: 23901/30000 (79.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2939s / 283.9063 s
agent0:                 episode reward: -0.4887,                 loss: nan
agent1:                 episode reward: 0.4887,                 loss: 0.0986
Episode: 23921/30000 (79.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3001s / 284.2064 s
agent0:                 episode reward: -0.8738,                 loss: nan
agent1:                 episode reward: 0.8738,                 loss: 0.0993
Episode: 23941/30000 (79.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3062s / 284.5126 s
agent0:                 episode reward: -0.7101,                 loss: nan
agent1:                 episode reward: 0.7101,                 loss: 0.0996
Episode: 23961/30000 (79.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3000s / 284.8126 s
agent0:                 episode reward: -0.2914,                 loss: nan
agent1:                 episode reward: 0.2914,                 loss: 0.0993
Episode: 23981/30000 (79.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2994s / 285.1120 s
agent0:                 episode reward: -1.0586,                 loss: nan
agent1:                 episode reward: 1.0586,                 loss: 0.1001
Episode: 24001/30000 (80.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3016s / 285.4136 s
agent0:                 episode reward: -0.6418,                 loss: nan
agent1:                 episode reward: 0.6418,                 loss: 0.1003
Episode: 24021/30000 (80.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2949s / 285.7085 s
agent0:                 episode reward: -0.4662,                 loss: nan
agent1:                 episode reward: 0.4662,                 loss: 0.1000
Episode: 24041/30000 (80.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3022s / 286.0107 s
agent0:                 episode reward: -0.7653,                 loss: nan
agent1:                 episode reward: 0.7653,                 loss: 0.0987
Episode: 24061/30000 (80.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3314s / 286.3421 s
agent0:                 episode reward: -0.5717,                 loss: nan
agent1:                 episode reward: 0.5717,                 loss: 0.0993
Episode: 24081/30000 (80.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3222s / 286.6642 s
agent0:                 episode reward: -0.6839,                 loss: nan
agent1:                 episode reward: 0.6839,                 loss: 0.0994
Episode: 24101/30000 (80.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3125s / 286.9767 s
agent0:                 episode reward: -0.4030,                 loss: nan
agent1:                 episode reward: 0.4030,                 loss: 0.0994
Episode: 24121/30000 (80.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3140s / 287.2907 s
agent0:                 episode reward: -0.9587,                 loss: nan
agent1:                 episode reward: 0.9587,                 loss: 0.0994
Episode: 24141/30000 (80.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3159s / 287.6066 s
agent0:                 episode reward: -0.6624,                 loss: nan
agent1:                 episode reward: 0.6624,                 loss: 0.0985
Episode: 24161/30000 (80.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3153s / 287.9220 s
agent0:                 episode reward: -0.6159,                 loss: nan
agent1:                 episode reward: 0.6159,                 loss: 0.0987
Episode: 24181/30000 (80.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3106s / 288.2326 s
agent0:                 episode reward: -0.7009,                 loss: nan
agent1:                 episode reward: 0.7009,                 loss: 0.0986
Episode: 24201/30000 (80.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3137s / 288.5463 s
agent0:                 episode reward: -0.5572,                 loss: nan
agent1:                 episode reward: 0.5572,                 loss: 0.0988
Episode: 24221/30000 (80.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3154s / 288.8617 s
agent0:                 episode reward: -0.6698,                 loss: nan
agent1:                 episode reward: 0.6698,                 loss: 0.0982
Episode: 24241/30000 (80.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3347s / 289.1964 s
agent0:                 episode reward: -0.3308,                 loss: nan
agent1:                 episode reward: 0.3308,                 loss: 0.0988
Episode: 24261/30000 (80.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3278s / 289.5242 s
agent0:                 episode reward: -0.6602,                 loss: nan
agent1:                 episode reward: 0.6602,                 loss: 0.1004
Episode: 24281/30000 (80.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3325s / 289.8567 s
agent0:                 episode reward: -0.5405,                 loss: nan
agent1:                 episode reward: 0.5405,                 loss: 0.0996
Episode: 24301/30000 (81.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3271s / 290.1838 s
agent0:                 episode reward: -0.5687,                 loss: nan
agent1:                 episode reward: 0.5687,                 loss: 0.1000
Episode: 24321/30000 (81.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3224s / 290.5062 s
agent0:                 episode reward: -0.9196,                 loss: nan
agent1:                 episode reward: 0.9196,                 loss: 0.0998
Episode: 24341/30000 (81.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3266s / 290.8327 s
agent0:                 episode reward: -0.5634,                 loss: nan
agent1:                 episode reward: 0.5634,                 loss: 0.0990
Episode: 24361/30000 (81.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3200s / 291.1527 s
agent0:                 episode reward: -0.6435,                 loss: nan
agent1:                 episode reward: 0.6435,                 loss: 0.0986
Episode: 24381/30000 (81.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3230s / 291.4757 s
agent0:                 episode reward: -0.7015,                 loss: nan
agent1:                 episode reward: 0.7015,                 loss: 0.0976
Episode: 24401/30000 (81.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3737s / 291.8494 s
agent0:                 episode reward: -0.4822,                 loss: nan
agent1:                 episode reward: 0.4822,                 loss: 0.0993
Episode: 24421/30000 (81.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3361s / 292.1855 s
agent0:                 episode reward: -0.7719,                 loss: nan
agent1:                 episode reward: 0.7719,                 loss: 0.0995
Episode: 24441/30000 (81.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3248s / 292.5103 s
agent0:                 episode reward: -0.8209,                 loss: nan
agent1:                 episode reward: 0.8209,                 loss: 0.0998
Episode: 24461/30000 (81.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3160s / 292.8262 s
agent0:                 episode reward: -0.4152,                 loss: nan
agent1:                 episode reward: 0.4152,                 loss: 0.0991
Episode: 24481/30000 (81.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3133s / 293.1395 s
agent0:                 episode reward: -0.5921,                 loss: nan
agent1:                 episode reward: 0.5921,                 loss: 0.0993
Episode: 24501/30000 (81.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3042s / 293.4438 s
agent0:                 episode reward: -0.4758,                 loss: nan
agent1:                 episode reward: 0.4758,                 loss: 0.0991
Episode: 24521/30000 (81.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3069s / 293.7507 s
agent0:                 episode reward: -0.8740,                 loss: nan
agent1:                 episode reward: 0.8740,                 loss: 0.0998
Episode: 24541/30000 (81.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3114s / 294.0620 s
agent0:                 episode reward: -0.5081,                 loss: nan
agent1:                 episode reward: 0.5081,                 loss: 0.0989
Episode: 24561/30000 (81.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3098s / 294.3719 s
agent0:                 episode reward: -0.2466,                 loss: nan
agent1:                 episode reward: 0.2466,                 loss: 0.0998
Episode: 24581/30000 (81.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3335s / 294.7054 s
agent0:                 episode reward: -0.8222,                 loss: nan
agent1:                 episode reward: 0.8222,                 loss: 0.0998
Episode: 24601/30000 (82.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3436s / 295.0490 s
agent0:                 episode reward: -0.7350,                 loss: nan
agent1:                 episode reward: 0.7350,                 loss: 0.0998
Episode: 24621/30000 (82.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3710s / 295.4200 s
agent0:                 episode reward: -0.6424,                 loss: nan
agent1:                 episode reward: 0.6424,                 loss: 0.0999
Episode: 24641/30000 (82.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3174s / 295.7374 s
agent0:                 episode reward: -0.9114,                 loss: nan
agent1:                 episode reward: 0.9114,                 loss: 0.1000
Episode: 24661/30000 (82.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3205s / 296.0578 s
agent0:                 episode reward: -0.2485,                 loss: nan
agent1:                 episode reward: 0.2485,                 loss: 0.1004
Episode: 24681/30000 (82.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3209s / 296.3788 s
agent0:                 episode reward: -0.8924,                 loss: nan
agent1:                 episode reward: 0.8924,                 loss: 0.0992
Episode: 24701/30000 (82.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3244s / 296.7032 s
agent0:                 episode reward: -0.3153,                 loss: nan
agent1:                 episode reward: 0.3153,                 loss: 0.0998
Episode: 24721/30000 (82.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3203s / 297.0235 s
agent0:                 episode reward: -1.1102,                 loss: nan
agent1:                 episode reward: 1.1102,                 loss: 0.0982
Episode: 24741/30000 (82.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3207s / 297.3442 s
agent0:                 episode reward: -0.3448,                 loss: nan
agent1:                 episode reward: 0.3448,                 loss: 0.0979
Episode: 24761/30000 (82.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3192s / 297.6634 s
agent0:                 episode reward: -0.7870,                 loss: nan
agent1:                 episode reward: 0.7870,                 loss: 0.0996
Episode: 24781/30000 (82.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3174s / 297.9808 s
agent0:                 episode reward: -0.6740,                 loss: nan
agent1:                 episode reward: 0.6740,                 loss: 0.1002
Episode: 24801/30000 (82.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3339s / 298.3147 s
agent0:                 episode reward: -0.5746,                 loss: nan
agent1:                 episode reward: 0.5746,                 loss: 0.0993
Episode: 24821/30000 (82.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3356s / 298.6503 s
agent0:                 episode reward: -0.8447,                 loss: nan
agent1:                 episode reward: 0.8447,                 loss: 0.0994
Episode: 24841/30000 (82.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3200s / 298.9703 s
agent0:                 episode reward: -0.5499,                 loss: nan
agent1:                 episode reward: 0.5499,                 loss: 0.0996
Episode: 24861/30000 (82.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3234s / 299.2938 s
agent0:                 episode reward: -0.8647,                 loss: nan
agent1:                 episode reward: 0.8647,                 loss: 0.0997
Episode: 24881/30000 (82.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3267s / 299.6205 s
agent0:                 episode reward: -0.3123,                 loss: nan
agent1:                 episode reward: 0.3123,                 loss: 0.0976
Episode: 24901/30000 (83.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3214s / 299.9418 s
agent0:                 episode reward: -0.7442,                 loss: nan
agent1:                 episode reward: 0.7442,                 loss: 0.0995
Episode: 24921/30000 (83.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3182s / 300.2600 s
agent0:                 episode reward: -0.8221,                 loss: nan
agent1:                 episode reward: 0.8221,                 loss: 0.0985
Episode: 24941/30000 (83.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3190s / 300.5791 s
agent0:                 episode reward: -0.6579,                 loss: nan
agent1:                 episode reward: 0.6579,                 loss: 0.0993
Episode: 24961/30000 (83.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3245s / 300.9036 s
agent0:                 episode reward: -0.6133,                 loss: nan
agent1:                 episode reward: 0.6133,                 loss: 0.0982
Episode: 24981/30000 (83.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3219s / 301.2254 s
agent0:                 episode reward: -0.7498,                 loss: nan
agent1:                 episode reward: 0.7498,                 loss: 0.0995
Episode: 25001/30000 (83.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3503s / 301.5757 s
agent0:                 episode reward: -0.8004,                 loss: nan
agent1:                 episode reward: 0.8004,                 loss: 0.0980
Episode: 25021/30000 (83.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3230s / 301.8987 s
agent0:                 episode reward: -0.5046,                 loss: nan
agent1:                 episode reward: 0.5046,                 loss: 0.0985
Episode: 25041/30000 (83.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3220s / 302.2207 s
agent0:                 episode reward: -0.7529,                 loss: nan
agent1:                 episode reward: 0.7529,                 loss: 0.0983
Episode: 25061/30000 (83.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3248s / 302.5455 s
agent0:                 episode reward: -0.7613,                 loss: nan
agent1:                 episode reward: 0.7613,                 loss: 0.0971
Episode: 25081/30000 (83.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3231s / 302.8686 s
agent0:                 episode reward: -0.5392,                 loss: nan
agent1:                 episode reward: 0.5392,                 loss: 0.0980
Episode: 25101/30000 (83.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3263s / 303.1949 s
agent0:                 episode reward: -0.7427,                 loss: nan
agent1:                 episode reward: 0.7427,                 loss: 0.0989
Episode: 25121/30000 (83.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3434s / 303.5383 s
agent0:                 episode reward: -0.5145,                 loss: nan
agent1:                 episode reward: 0.5145,                 loss: 0.0983
Episode: 25141/30000 (83.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3198s / 303.8581 s
agent0:                 episode reward: -0.6619,                 loss: nan
agent1:                 episode reward: 0.6619,                 loss: 0.0981
Episode: 25161/30000 (83.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3257s / 304.1838 s
agent0:                 episode reward: -0.5365,                 loss: nan
agent1:                 episode reward: 0.5365,                 loss: 0.0984
Episode: 25181/30000 (83.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3550s / 304.5388 s
agent0:                 episode reward: -0.7438,                 loss: nan
agent1:                 episode reward: 0.7438,                 loss: 0.0991
Episode: 25201/30000 (84.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3332s / 304.8720 s
agent0:                 episode reward: -0.6135,                 loss: nan
agent1:                 episode reward: 0.6135,                 loss: 0.0980
Episode: 25221/30000 (84.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3216s / 305.1936 s
agent0:                 episode reward: -0.5191,                 loss: nan
agent1:                 episode reward: 0.5191,                 loss: 0.0990
Episode: 25241/30000 (84.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3249s / 305.5186 s
agent0:                 episode reward: -0.5397,                 loss: nan
agent1:                 episode reward: 0.5397,                 loss: 0.0997
Episode: 25261/30000 (84.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3231s / 305.8416 s
agent0:                 episode reward: -0.8918,                 loss: nan
agent1:                 episode reward: 0.8918,                 loss: 0.0985
Episode: 25281/30000 (84.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3261s / 306.1677 s
agent0:                 episode reward: -0.9329,                 loss: nan
agent1:                 episode reward: 0.9329,                 loss: 0.0983
Episode: 25301/30000 (84.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3227s / 306.4904 s
agent0:                 episode reward: -1.0118,                 loss: nan
agent1:                 episode reward: 1.0118,                 loss: 0.0991
Episode: 25321/30000 (84.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3224s / 306.8128 s
agent0:                 episode reward: -0.2039,                 loss: nan
agent1:                 episode reward: 0.2039,                 loss: 0.0986
Episode: 25341/30000 (84.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3264s / 307.1392 s
agent0:                 episode reward: -0.7995,                 loss: nan
agent1:                 episode reward: 0.7995,                 loss: 0.0994
Episode: 25361/30000 (84.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3433s / 307.4826 s
agent0:                 episode reward: -0.7881,                 loss: nan
agent1:                 episode reward: 0.7881,                 loss: 0.0992
Episode: 25381/30000 (84.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3367s / 307.8193 s
agent0:                 episode reward: -0.4736,                 loss: nan
agent1:                 episode reward: 0.4736,                 loss: 0.0999
Episode: 25401/30000 (84.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3196s / 308.1389 s
agent0:                 episode reward: -0.8074,                 loss: nan
agent1:                 episode reward: 0.8074,                 loss: 0.1000
Episode: 25421/30000 (84.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3213s / 308.4602 s
agent0:                 episode reward: -0.7165,                 loss: nan
agent1:                 episode reward: 0.7165,                 loss: 0.0984
Episode: 25441/30000 (84.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3223s / 308.7825 s
agent0:                 episode reward: -0.9787,                 loss: nan
agent1:                 episode reward: 0.9787,                 loss: 0.0990
Episode: 25461/30000 (84.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3240s / 309.1065 s
agent0:                 episode reward: -0.6485,                 loss: nan
agent1:                 episode reward: 0.6485,                 loss: 0.0992
Episode: 25481/30000 (84.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3231s / 309.4297 s
agent0:                 episode reward: -0.4352,                 loss: nan
agent1:                 episode reward: 0.4352,                 loss: 0.1001
Episode: 25501/30000 (85.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3364s / 309.7661 s
agent0:                 episode reward: -0.4413,                 loss: nan
agent1:                 episode reward: 0.4413,                 loss: 0.0998
Episode: 25521/30000 (85.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3268s / 310.0929 s
agent0:                 episode reward: -0.6830,                 loss: nan
agent1:                 episode reward: 0.6830,                 loss: 0.0986
Episode: 25541/30000 (85.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3231s / 310.4160 s
agent0:                 episode reward: -0.5892,                 loss: nan
agent1:                 episode reward: 0.5892,                 loss: 0.0983
Episode: 25561/30000 (85.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3548s / 310.7708 s
agent0:                 episode reward: -0.6504,                 loss: nan
agent1:                 episode reward: 0.6504,                 loss: 0.0993
Episode: 25581/30000 (85.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3251s / 311.0959 s
agent0:                 episode reward: -0.8581,                 loss: nan
agent1:                 episode reward: 0.8581,                 loss: 0.0990
Episode: 25601/30000 (85.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3247s / 311.4206 s
agent0:                 episode reward: -1.2372,                 loss: nan
agent1:                 episode reward: 1.2372,                 loss: 0.0982
Episode: 25621/30000 (85.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3455s / 311.7661 s
agent0:                 episode reward: -0.7359,                 loss: nan
agent1:                 episode reward: 0.7359,                 loss: 0.0980
Episode: 25641/30000 (85.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3381s / 312.1042 s
agent0:                 episode reward: -0.5752,                 loss: nan
agent1:                 episode reward: 0.5752,                 loss: 0.0981
Episode: 25661/30000 (85.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3311s / 312.4353 s
agent0:                 episode reward: -0.5285,                 loss: nan
agent1:                 episode reward: 0.5285,                 loss: 0.0997
Episode: 25681/30000 (85.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3299s / 312.7652 s
agent0:                 episode reward: -0.7411,                 loss: nan
agent1:                 episode reward: 0.7411,                 loss: 0.0986
Episode: 25701/30000 (85.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3320s / 313.0973 s
agent0:                 episode reward: -0.9154,                 loss: nan
agent1:                 episode reward: 0.9154,                 loss: 0.0986
Episode: 25721/30000 (85.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3193s / 313.4165 s
agent0:                 episode reward: -0.7140,                 loss: nan
agent1:                 episode reward: 0.7140,                 loss: 0.1011
Episode: 25741/30000 (85.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3428s / 313.7593 s
agent0:                 episode reward: -0.5428,                 loss: nan
agent1:                 episode reward: 0.5428,                 loss: 0.0980
Episode: 25761/30000 (85.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3312s / 314.0906 s
agent0:                 episode reward: -0.6193,                 loss: nan
agent1:                 episode reward: 0.6193,                 loss: 0.0992
Episode: 25781/30000 (85.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3283s / 314.4189 s
agent0:                 episode reward: -0.8750,                 loss: nan
agent1:                 episode reward: 0.8750,                 loss: 0.0984
Episode: 25801/30000 (86.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3305s / 314.7494 s
agent0:                 episode reward: -0.6001,                 loss: nan
agent1:                 episode reward: 0.6001,                 loss: 0.0992
Episode: 25821/30000 (86.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3293s / 315.0787 s
agent0:                 episode reward: -0.2484,                 loss: nan
agent1:                 episode reward: 0.2484,                 loss: 0.0998
Episode: 25841/30000 (86.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3286s / 315.4073 s
agent0:                 episode reward: -0.6629,                 loss: nan
agent1:                 episode reward: 0.6629,                 loss: 0.1000
Episode: 25861/30000 (86.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3244s / 315.7316 s
agent0:                 episode reward: -0.4925,                 loss: nan
agent1:                 episode reward: 0.4925,                 loss: 0.0989
Episode: 25881/30000 (86.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3289s / 316.0606 s
agent0:                 episode reward: -0.9751,                 loss: nan
agent1:                 episode reward: 0.9751,                 loss: 0.0992
Episode: 25901/30000 (86.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3285s / 316.3890 s
agent0:                 episode reward: -0.5294,                 loss: nan
agent1:                 episode reward: 0.5294,                 loss: 0.0998
Episode: 25921/30000 (86.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3471s / 316.7361 s
agent0:                 episode reward: -0.8549,                 loss: nan
agent1:                 episode reward: 0.8549,                 loss: 0.0991
Episode: 25941/30000 (86.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3413s / 317.0774 s
agent0:                 episode reward: -0.7641,                 loss: nan
agent1:                 episode reward: 0.7641,                 loss: 0.0980
Episode: 25961/30000 (86.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3147s / 317.3920 s
agent0:                 episode reward: -0.5583,                 loss: nan
agent1:                 episode reward: 0.5583,                 loss: 0.0994
Episode: 25981/30000 (86.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3139s / 317.7059 s
agent0:                 episode reward: -0.8234,                 loss: nan
agent1:                 episode reward: 0.8234,                 loss: 0.0981
Episode: 26001/30000 (86.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3186s / 318.0245 s
agent0:                 episode reward: -0.7917,                 loss: nan
agent1:                 episode reward: 0.7917,                 loss: 0.0998
Episode: 26021/30000 (86.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3167s / 318.3412 s
agent0:                 episode reward: -0.4494,                 loss: nan
agent1:                 episode reward: 0.4494,                 loss: 0.0997
Episode: 26041/30000 (86.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3213s / 318.6625 s
agent0:                 episode reward: -0.8082,                 loss: nan
agent1:                 episode reward: 0.8082,                 loss: 0.0999
Episode: 26061/30000 (86.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3180s / 318.9804 s
agent0:                 episode reward: -0.5087,                 loss: nan
agent1:                 episode reward: 0.5087,                 loss: 0.0990
Episode: 26081/30000 (86.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3294s / 319.3098 s
agent0:                 episode reward: -0.9185,                 loss: nan
agent1:                 episode reward: 0.9185,                 loss: 0.0984
Episode: 26101/30000 (87.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3287s / 319.6384 s
agent0:                 episode reward: -0.7152,                 loss: nan
agent1:                 episode reward: 0.7152,                 loss: 0.0992
Episode: 26121/30000 (87.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3670s / 320.0054 s
agent0:                 episode reward: -0.8276,                 loss: nan
agent1:                 episode reward: 0.8276,                 loss: 0.0981
Episode: 26141/30000 (87.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3519s / 320.3573 s
agent0:                 episode reward: -0.8522,                 loss: nan
agent1:                 episode reward: 0.8522,                 loss: 0.0989
Episode: 26161/30000 (87.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3254s / 320.6827 s
agent0:                 episode reward: -0.4827,                 loss: nan
agent1:                 episode reward: 0.4827,                 loss: 0.0987
Episode: 26181/30000 (87.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3302s / 321.0129 s
agent0:                 episode reward: -0.6782,                 loss: nan
agent1:                 episode reward: 0.6782,                 loss: 0.0994
Episode: 26201/30000 (87.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3265s / 321.3393 s
agent0:                 episode reward: -0.8189,                 loss: nan
agent1:                 episode reward: 0.8189,                 loss: 0.0986
Episode: 26221/30000 (87.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3148s / 321.6542 s
agent0:                 episode reward: -0.9313,                 loss: nan
agent1:                 episode reward: 0.9313,                 loss: 0.0988
Episode: 26241/30000 (87.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3166s / 321.9708 s
agent0:                 episode reward: -0.7711,                 loss: nan
agent1:                 episode reward: 0.7711,                 loss: 0.0990
Episode: 26261/30000 (87.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3121s / 322.2828 s
agent0:                 episode reward: -0.6537,                 loss: nan
agent1:                 episode reward: 0.6537,                 loss: 0.0990
Episode: 26281/30000 (87.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3116s / 322.5944 s
agent0:                 episode reward: -0.6704,                 loss: nan
agent1:                 episode reward: 0.6704,                 loss: 0.0986
Episode: 26301/30000 (87.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3659s / 322.9603 s
agent0:                 episode reward: -0.8649,                 loss: nan
agent1:                 episode reward: 0.8649,                 loss: 0.0991
Episode: 26321/30000 (87.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3303s / 323.2906 s
agent0:                 episode reward: -0.6952,                 loss: nan
agent1:                 episode reward: 0.6952,                 loss: 0.1001
Episode: 26341/30000 (87.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3131s / 323.6038 s
agent0:                 episode reward: -0.7396,                 loss: nan
agent1:                 episode reward: 0.7396,                 loss: 0.0985
Episode: 26361/30000 (87.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3137s / 323.9175 s
agent0:                 episode reward: -0.8078,                 loss: nan
agent1:                 episode reward: 0.8078,                 loss: 0.0995
Episode: 26381/30000 (87.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3192s / 324.2366 s
agent0:                 episode reward: -0.8976,                 loss: nan
agent1:                 episode reward: 0.8976,                 loss: 0.0992
Episode: 26401/30000 (88.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3156s / 324.5523 s
agent0:                 episode reward: -0.6877,                 loss: nan
agent1:                 episode reward: 0.6877,                 loss: 0.1000
Episode: 26421/30000 (88.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3197s / 324.8720 s
agent0:                 episode reward: -0.7714,                 loss: nan
agent1:                 episode reward: 0.7714,                 loss: 0.0979
Episode: 26441/30000 (88.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3145s / 325.1865 s
agent0:                 episode reward: -0.5518,                 loss: nan
agent1:                 episode reward: 0.5518,                 loss: 0.1001
Episode: 26461/30000 (88.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3124s / 325.4989 s
agent0:                 episode reward: -0.8935,                 loss: nan
agent1:                 episode reward: 0.8935,                 loss: 0.0979
Episode: 26481/30000 (88.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3354s / 325.8342 s
agent0:                 episode reward: -0.7762,                 loss: nan
agent1:                 episode reward: 0.7762,                 loss: 0.0980
Episode: 26501/30000 (88.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3455s / 326.1798 s
agent0:                 episode reward: -1.0545,                 loss: nan
agent1:                 episode reward: 1.0545,                 loss: 0.0996
Episode: 26521/30000 (88.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3213s / 326.5010 s
agent0:                 episode reward: -0.5639,                 loss: nan
agent1:                 episode reward: 0.5639,                 loss: 0.0989
Episode: 26541/30000 (88.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3235s / 326.8245 s
agent0:                 episode reward: -0.6507,                 loss: nan
agent1:                 episode reward: 0.6507,                 loss: 0.0994
Episode: 26561/30000 (88.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3237s / 327.1482 s
agent0:                 episode reward: -0.4730,                 loss: nan
agent1:                 episode reward: 0.4730,                 loss: 0.0978
Episode: 26581/30000 (88.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3128s / 327.4610 s
agent0:                 episode reward: -1.0033,                 loss: nan
agent1:                 episode reward: 1.0033,                 loss: 0.0975
Episode: 26601/30000 (88.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3134s / 327.7744 s
agent0:                 episode reward: -0.6300,                 loss: nan
agent1:                 episode reward: 0.6300,                 loss: 0.0988
Episode: 26621/30000 (88.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3142s / 328.0886 s
agent0:                 episode reward: -0.7917,                 loss: nan
agent1:                 episode reward: 0.7917,                 loss: 0.0969
Episode: 26641/30000 (88.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3460s / 328.4346 s
agent0:                 episode reward: -0.6748,                 loss: nan
agent1:                 episode reward: 0.6748,                 loss: 0.0993
Episode: 26661/30000 (88.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3335s / 328.7681 s
agent0:                 episode reward: -0.5995,                 loss: nan
agent1:                 episode reward: 0.5995,                 loss: 0.0982
Episode: 26681/30000 (88.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3313s / 329.0994 s
agent0:                 episode reward: -0.4710,                 loss: nan
agent1:                 episode reward: 0.4710,                 loss: 0.0978
Episode: 26701/30000 (89.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3374s / 329.4368 s
agent0:                 episode reward: -0.5227,                 loss: nan
agent1:                 episode reward: 0.5227,                 loss: 0.0986
Episode: 26721/30000 (89.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3392s / 329.7760 s
agent0:                 episode reward: -0.6469,                 loss: nan
agent1:                 episode reward: 0.6469,                 loss: 0.0980
Episode: 26741/30000 (89.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3361s / 330.1121 s
agent0:                 episode reward: -0.8262,                 loss: nan
agent1:                 episode reward: 0.8262,                 loss: 0.0975
Episode: 26761/30000 (89.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3374s / 330.4496 s
agent0:                 episode reward: -0.5932,                 loss: nan
agent1:                 episode reward: 0.5932,                 loss: 0.0986
Episode: 26781/30000 (89.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3375s / 330.7871 s
agent0:                 episode reward: -0.7858,                 loss: nan
agent1:                 episode reward: 0.7858,                 loss: 0.0984
Episode: 26801/30000 (89.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3320s / 331.1191 s
agent0:                 episode reward: -0.9014,                 loss: nan
agent1:                 episode reward: 0.9014,                 loss: 0.0978
Episode: 26821/30000 (89.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3396s / 331.4587 s
agent0:                 episode reward: -0.5827,                 loss: nan
agent1:                 episode reward: 0.5827,                 loss: 0.0981
Episode: 26841/30000 (89.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3595s / 331.8182 s
agent0:                 episode reward: -0.6883,                 loss: nan
agent1:                 episode reward: 0.6883,                 loss: 0.0984
Episode: 26861/30000 (89.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3361s / 332.1543 s
agent0:                 episode reward: -0.1563,                 loss: nan
agent1:                 episode reward: 0.1563,                 loss: 0.0979
Episode: 26881/30000 (89.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3390s / 332.4933 s
agent0:                 episode reward: -0.6701,                 loss: nan
agent1:                 episode reward: 0.6701,                 loss: 0.0970
Episode: 26901/30000 (89.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3406s / 332.8339 s
agent0:                 episode reward: -0.5510,                 loss: nan
agent1:                 episode reward: 0.5510,                 loss: 0.0997
Episode: 26921/30000 (89.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3276s / 333.1615 s
agent0:                 episode reward: -0.6236,                 loss: nan
agent1:                 episode reward: 0.6236,                 loss: 0.0999
Episode: 26941/30000 (89.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3440s / 333.5054 s
agent0:                 episode reward: -1.0773,                 loss: nan
agent1:                 episode reward: 1.0773,                 loss: 0.0991
Episode: 26961/30000 (89.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3424s / 333.8478 s
agent0:                 episode reward: -0.7210,                 loss: nan
agent1:                 episode reward: 0.7210,                 loss: 0.1005
Episode: 26981/30000 (89.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3405s / 334.1883 s
agent0:                 episode reward: -0.6669,                 loss: nan
agent1:                 episode reward: 0.6669,                 loss: 0.0991
Episode: 27001/30000 (90.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3468s / 334.5351 s
agent0:                 episode reward: -0.7043,                 loss: nan
agent1:                 episode reward: 0.7043,                 loss: 0.1008
Episode: 27021/30000 (90.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3690s / 334.9041 s
agent0:                 episode reward: -0.6787,                 loss: nan
agent1:                 episode reward: 0.6787,                 loss: 0.0995
Episode: 27041/30000 (90.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3516s / 335.2557 s
agent0:                 episode reward: -1.1650,                 loss: nan
agent1:                 episode reward: 1.1650,                 loss: 0.0996
Episode: 27061/30000 (90.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3478s / 335.6035 s
agent0:                 episode reward: -0.6273,                 loss: nan
agent1:                 episode reward: 0.6273,                 loss: 0.0999
Episode: 27081/30000 (90.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3511s / 335.9546 s
agent0:                 episode reward: -0.5088,                 loss: nan
agent1:                 episode reward: 0.5088,                 loss: 0.0989
Episode: 27101/30000 (90.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3396s / 336.2942 s
agent0:                 episode reward: -0.5931,                 loss: nan
agent1:                 episode reward: 0.5931,                 loss: 0.0985
Episode: 27121/30000 (90.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3401s / 336.6343 s
agent0:                 episode reward: -0.6978,                 loss: nan
agent1:                 episode reward: 0.6978,                 loss: 0.0999
Episode: 27141/30000 (90.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3693s / 337.0036 s
agent0:                 episode reward: -0.7723,                 loss: nan
agent1:                 episode reward: 0.7723,                 loss: 0.0997
Episode: 27161/30000 (90.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3411s / 337.3447 s
agent0:                 episode reward: -0.6975,                 loss: nan
agent1:                 episode reward: 0.6975,                 loss: 0.0994
Episode: 27181/30000 (90.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3407s / 337.6853 s
agent0:                 episode reward: -0.6553,                 loss: nan
agent1:                 episode reward: 0.6553,                 loss: 0.0992
Episode: 27201/30000 (90.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3653s / 338.0506 s
agent0:                 episode reward: -0.9800,                 loss: nan
agent1:                 episode reward: 0.9800,                 loss: 0.1004
Episode: 27221/30000 (90.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3418s / 338.3924 s
agent0:                 episode reward: -0.6545,                 loss: nan
agent1:                 episode reward: 0.6545,                 loss: 0.0982
Episode: 27241/30000 (90.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3428s / 338.7352 s
agent0:                 episode reward: -0.5495,                 loss: nan
agent1:                 episode reward: 0.5495,                 loss: 0.0987
Episode: 27261/30000 (90.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3268s / 339.0620 s
agent0:                 episode reward: -0.5201,                 loss: nan
agent1:                 episode reward: 0.5201,                 loss: 0.0972
Episode: 27281/30000 (90.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3417s / 339.4038 s
agent0:                 episode reward: -0.6663,                 loss: nan
agent1:                 episode reward: 0.6663,                 loss: 0.0975
Episode: 27301/30000 (91.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3224s / 339.7261 s
agent0:                 episode reward: -0.7986,                 loss: nan
agent1:                 episode reward: 0.7986,                 loss: 0.0977
Episode: 27321/30000 (91.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3174s / 340.0436 s
agent0:                 episode reward: -0.9528,                 loss: nan
agent1:                 episode reward: 0.9528,                 loss: 0.0977
Episode: 27341/30000 (91.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3437s / 340.3872 s
agent0:                 episode reward: -0.7212,                 loss: nan
agent1:                 episode reward: 0.7212,                 loss: 0.0983
Episode: 27361/30000 (91.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3273s / 340.7145 s
agent0:                 episode reward: -0.8920,                 loss: nan
agent1:                 episode reward: 0.8920,                 loss: 0.0978
Episode: 27381/30000 (91.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3661s / 341.0807 s
agent0:                 episode reward: -0.7784,                 loss: nan
agent1:                 episode reward: 0.7784,                 loss: 0.0959
Episode: 27401/30000 (91.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3439s / 341.4245 s
agent0:                 episode reward: -0.8271,                 loss: nan
agent1:                 episode reward: 0.8271,                 loss: 0.0982
Episode: 27421/30000 (91.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3422s / 341.7667 s
agent0:                 episode reward: -0.5107,                 loss: nan
agent1:                 episode reward: 0.5107,                 loss: 0.0963
Episode: 27441/30000 (91.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3398s / 342.1065 s
agent0:                 episode reward: -0.7564,                 loss: nan
agent1:                 episode reward: 0.7564,                 loss: 0.0968
Episode: 27461/30000 (91.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3434s / 342.4500 s
agent0:                 episode reward: -0.7687,                 loss: nan
agent1:                 episode reward: 0.7687,                 loss: 0.0966
Episode: 27481/30000 (91.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3411s / 342.7911 s
agent0:                 episode reward: -1.2007,                 loss: nan
agent1:                 episode reward: 1.2007,                 loss: 0.0981
Episode: 27501/30000 (91.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3400s / 343.1311 s
agent0:                 episode reward: -0.3407,                 loss: nan
agent1:                 episode reward: 0.3407,                 loss: 0.0975
Episode: 27521/30000 (91.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3426s / 343.4737 s
agent0:                 episode reward: -0.7329,                 loss: nan
agent1:                 episode reward: 0.7329,                 loss: 0.0976
Episode: 27541/30000 (91.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3384s / 343.8121 s
agent0:                 episode reward: -0.6492,                 loss: nan
agent1:                 episode reward: 0.6492,                 loss: 0.0968
Episode: 27561/30000 (91.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3721s / 344.1841 s
agent0:                 episode reward: -0.7804,                 loss: nan
agent1:                 episode reward: 0.7804,                 loss: 0.0988
Episode: 27581/30000 (91.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3483s / 344.5324 s
agent0:                 episode reward: -0.6094,                 loss: nan
agent1:                 episode reward: 0.6094,                 loss: 0.0987
Episode: 27601/30000 (92.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3384s / 344.8708 s
agent0:                 episode reward: -0.7762,                 loss: nan
agent1:                 episode reward: 0.7762,                 loss: 0.0987
Episode: 27621/30000 (92.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3620s / 345.2328 s
agent0:                 episode reward: -0.9129,                 loss: nan
agent1:                 episode reward: 0.9129,                 loss: 0.0991
Episode: 27641/30000 (92.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3455s / 345.5783 s
agent0:                 episode reward: -0.6814,                 loss: nan
agent1:                 episode reward: 0.6814,                 loss: 0.0992
Episode: 27661/30000 (92.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3388s / 345.9170 s
agent0:                 episode reward: -0.6732,                 loss: nan
agent1:                 episode reward: 0.6732,                 loss: 0.0987
Episode: 27681/30000 (92.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3385s / 346.2555 s
agent0:                 episode reward: -0.4530,                 loss: nan
agent1:                 episode reward: 0.4530,                 loss: 0.0975
Episode: 27701/30000 (92.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3416s / 346.5971 s
agent0:                 episode reward: -0.4200,                 loss: nan
agent1:                 episode reward: 0.4200,                 loss: 0.0984
Episode: 27721/30000 (92.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3489s / 346.9460 s
agent0:                 episode reward: -0.7196,                 loss: nan
agent1:                 episode reward: 0.7196,                 loss: 0.0975
Episode: 27741/30000 (92.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3529s / 347.2989 s
agent0:                 episode reward: -0.9006,                 loss: nan
agent1:                 episode reward: 0.9006,                 loss: 0.0981
Episode: 27761/30000 (92.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3354s / 347.6343 s
agent0:                 episode reward: -0.5984,                 loss: nan
agent1:                 episode reward: 0.5984,                 loss: 0.0974
Episode: 27781/30000 (92.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3413s / 347.9757 s
agent0:                 episode reward: -0.8009,                 loss: nan
agent1:                 episode reward: 0.8009,                 loss: 0.0986
Episode: 27801/30000 (92.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3402s / 348.3159 s
agent0:                 episode reward: -0.6068,                 loss: nan
agent1:                 episode reward: 0.6068,                 loss: 0.0978
Episode: 27821/30000 (92.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3364s / 348.6523 s
agent0:                 episode reward: -0.7394,                 loss: nan
agent1:                 episode reward: 0.7394,                 loss: 0.0982
Episode: 27841/30000 (92.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3374s / 348.9897 s
agent0:                 episode reward: -0.7620,                 loss: nan
agent1:                 episode reward: 0.7620,                 loss: 0.0983
Episode: 27861/30000 (92.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3362s / 349.3259 s
agent0:                 episode reward: -0.6474,                 loss: nan
agent1:                 episode reward: 0.6474,                 loss: 0.0984
Episode: 27881/30000 (92.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3368s / 349.6627 s
agent0:                 episode reward: -0.4203,                 loss: nan
agent1:                 episode reward: 0.4203,                 loss: 0.0974
Episode: 27901/30000 (93.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3504s / 350.0131 s
agent0:                 episode reward: -0.9098,                 loss: nan
agent1:                 episode reward: 0.9098,                 loss: 0.0968
Episode: 27921/30000 (93.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3506s / 350.3637 s
agent0:                 episode reward: -0.5243,                 loss: nan
agent1:                 episode reward: 0.5243,                 loss: 0.0964
Episode: 27941/30000 (93.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3194s / 350.6831 s
agent0:                 episode reward: -0.4437,                 loss: nan
agent1:                 episode reward: 0.4437,                 loss: 0.0985
Episode: 27961/30000 (93.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3241s / 351.0072 s
agent0:                 episode reward: -0.6547,                 loss: nan
agent1:                 episode reward: 0.6547,                 loss: 0.0997
Episode: 27981/30000 (93.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3216s / 351.3288 s
agent0:                 episode reward: -0.4037,                 loss: nan
agent1:                 episode reward: 0.4037,                 loss: 0.0978
Episode: 28001/30000 (93.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3207s / 351.6494 s
agent0:                 episode reward: -0.9025,                 loss: nan
agent1:                 episode reward: 0.9025,                 loss: 0.0989
Episode: 28021/30000 (93.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3504s / 351.9999 s
agent0:                 episode reward: -0.7651,                 loss: nan
agent1:                 episode reward: 0.7651,                 loss: 0.0991
Episode: 28041/30000 (93.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3595s / 352.3593 s
agent0:                 episode reward: -0.6905,                 loss: nan
agent1:                 episode reward: 0.6905,                 loss: 0.0983
Episode: 28061/30000 (93.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3531s / 352.7124 s
agent0:                 episode reward: -0.2262,                 loss: nan
agent1:                 episode reward: 0.2262,                 loss: 0.0978
Episode: 28081/30000 (93.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3644s / 353.0768 s
agent0:                 episode reward: -0.8041,                 loss: nan
agent1:                 episode reward: 0.8041,                 loss: 0.0983
Episode: 28101/30000 (93.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3735s / 353.4504 s
agent0:                 episode reward: -0.6987,                 loss: nan
agent1:                 episode reward: 0.6987,                 loss: 0.0990
Episode: 28121/30000 (93.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3281s / 353.7785 s
agent0:                 episode reward: -0.8525,                 loss: nan
agent1:                 episode reward: 0.8525,                 loss: 0.0979
Episode: 28141/30000 (93.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3249s / 354.1034 s
agent0:                 episode reward: -0.6628,                 loss: nan
agent1:                 episode reward: 0.6628,                 loss: 0.0979
Episode: 28161/30000 (93.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3309s / 354.4343 s
agent0:                 episode reward: -0.7111,                 loss: nan
agent1:                 episode reward: 0.7111,                 loss: 0.0995
Episode: 28181/30000 (93.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3270s / 354.7612 s
agent0:                 episode reward: -0.7299,                 loss: nan
agent1:                 episode reward: 0.7299,                 loss: 0.0977
Episode: 28201/30000 (94.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3348s / 355.0960 s
agent0:                 episode reward: -0.7877,                 loss: nan
agent1:                 episode reward: 0.7877,                 loss: 0.0981
Episode: 28221/30000 (94.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3432s / 355.4392 s
agent0:                 episode reward: -0.7922,                 loss: nan
agent1:                 episode reward: 0.7922,                 loss: 0.1004
Episode: 28241/30000 (94.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3327s / 355.7719 s
agent0:                 episode reward: -0.9182,                 loss: nan
agent1:                 episode reward: 0.9182,                 loss: 0.0983
Episode: 28261/30000 (94.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3308s / 356.1027 s
agent0:                 episode reward: -0.8650,                 loss: nan
agent1:                 episode reward: 0.8650,                 loss: 0.0971
Episode: 28281/30000 (94.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3493s / 356.4520 s
agent0:                 episode reward: -0.9953,                 loss: nan
agent1:                 episode reward: 0.9953,                 loss: 0.0977
Episode: 28301/30000 (94.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3328s / 356.7848 s
agent0:                 episode reward: -0.6204,                 loss: nan
agent1:                 episode reward: 0.6204,                 loss: 0.0978
Episode: 28321/30000 (94.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3349s / 357.1196 s
agent0:                 episode reward: -0.6499,                 loss: nan
agent1:                 episode reward: 0.6499,                 loss: 0.0971
Episode: 28341/30000 (94.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3366s / 357.4562 s
agent0:                 episode reward: -1.1178,                 loss: nan
agent1:                 episode reward: 1.1178,                 loss: 0.0967
Episode: 28361/30000 (94.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3386s / 357.7948 s
agent0:                 episode reward: -0.6700,                 loss: nan
agent1:                 episode reward: 0.6700,                 loss: 0.0984
Episode: 28381/30000 (94.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3482s / 358.1430 s
agent0:                 episode reward: -0.8496,                 loss: nan
agent1:                 episode reward: 0.8496,                 loss: 0.0978
Episode: 28401/30000 (94.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3363s / 358.4793 s
agent0:                 episode reward: -0.6053,                 loss: nan
agent1:                 episode reward: 0.6053,                 loss: 0.0968
Episode: 28421/30000 (94.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3392s / 358.8185 s
agent0:                 episode reward: -0.7249,                 loss: nan
agent1:                 episode reward: 0.7249,                 loss: 0.0986
Episode: 28441/30000 (94.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3454s / 359.1638 s
agent0:                 episode reward: -0.7415,                 loss: nan
agent1:                 episode reward: 0.7415,                 loss: 0.0990
Episode: 28461/30000 (94.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3687s / 359.5326 s
agent0:                 episode reward: -0.5641,                 loss: nan
agent1:                 episode reward: 0.5641,                 loss: 0.0975
Episode: 28481/30000 (94.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3316s / 359.8642 s
agent0:                 episode reward: -0.5503,                 loss: nan
agent1:                 episode reward: 0.5503,                 loss: 0.0974
Episode: 28501/30000 (95.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3290s / 360.1932 s
agent0:                 episode reward: -0.5561,                 loss: nan
agent1:                 episode reward: 0.5561,                 loss: 0.0972
Episode: 28521/30000 (95.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3416s / 360.5349 s
agent0:                 episode reward: -0.7620,                 loss: nan
agent1:                 episode reward: 0.7620,                 loss: 0.0978
Episode: 28541/30000 (95.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3432s / 360.8781 s
agent0:                 episode reward: -0.6443,                 loss: nan
agent1:                 episode reward: 0.6443,                 loss: 0.0962
Episode: 28561/30000 (95.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3454s / 361.2235 s
agent0:                 episode reward: -1.0591,                 loss: nan
agent1:                 episode reward: 1.0591,                 loss: 0.0989
Episode: 28581/30000 (95.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3395s / 361.5630 s
agent0:                 episode reward: -0.9507,                 loss: nan
agent1:                 episode reward: 0.9507,                 loss: 0.0997
Episode: 28601/30000 (95.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3650s / 361.9281 s
agent0:                 episode reward: -0.4312,                 loss: nan
agent1:                 episode reward: 0.4312,                 loss: 0.0997
Episode: 28621/30000 (95.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3835s / 362.3115 s
agent0:                 episode reward: -0.7329,                 loss: nan
agent1:                 episode reward: 0.7329,                 loss: 0.0984
Episode: 28641/30000 (95.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3572s / 362.6688 s
agent0:                 episode reward: -0.3862,                 loss: nan
agent1:                 episode reward: 0.3862,                 loss: 0.0977
Episode: 28661/30000 (95.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3315s / 363.0003 s
agent0:                 episode reward: -0.5836,                 loss: nan
agent1:                 episode reward: 0.5836,                 loss: 0.0976
Episode: 28681/30000 (95.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3312s / 363.3315 s
agent0:                 episode reward: -0.3086,                 loss: nan
agent1:                 episode reward: 0.3086,                 loss: 0.0991
Episode: 28701/30000 (95.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3339s / 363.6653 s
agent0:                 episode reward: -0.6154,                 loss: nan
agent1:                 episode reward: 0.6154,                 loss: 0.0977
Episode: 28721/30000 (95.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3343s / 363.9996 s
agent0:                 episode reward: -0.7176,                 loss: nan
agent1:                 episode reward: 0.7176,                 loss: 0.0992
Episode: 28741/30000 (95.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3351s / 364.3347 s
agent0:                 episode reward: -0.5653,                 loss: nan
agent1:                 episode reward: 0.5653,                 loss: 0.0982
Episode: 28761/30000 (95.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3296s / 364.6643 s
agent0:                 episode reward: -0.6336,                 loss: nan
agent1:                 episode reward: 0.6336,                 loss: 0.0978
Episode: 28781/30000 (95.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3332s / 364.9975 s
agent0:                 episode reward: 0.0277,                 loss: nan
agent1:                 episode reward: -0.0277,                 loss: 0.0982
Episode: 28801/30000 (96.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3292s / 365.3267 s
agent0:                 episode reward: -0.6563,                 loss: nan
agent1:                 episode reward: 0.6563,                 loss: 0.0997
Episode: 28821/30000 (96.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3288s / 365.6555 s
agent0:                 episode reward: -0.5071,                 loss: nan
agent1:                 episode reward: 0.5071,                 loss: 0.0981
Episode: 28841/30000 (96.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3338s / 365.9893 s
agent0:                 episode reward: -0.7217,                 loss: nan
agent1:                 episode reward: 0.7217,                 loss: 0.0977
Episode: 28861/30000 (96.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3427s / 366.3320 s
agent0:                 episode reward: -1.0085,                 loss: nan
agent1:                 episode reward: 1.0085,                 loss: 0.0978
Episode: 28881/30000 (96.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3395s / 366.6715 s
agent0:                 episode reward: -0.4295,                 loss: nan
agent1:                 episode reward: 0.4295,                 loss: 0.0986
Episode: 28901/30000 (96.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3424s / 367.0139 s
agent0:                 episode reward: -0.6495,                 loss: nan
agent1:                 episode reward: 0.6495,                 loss: 0.0987
Episode: 28921/30000 (96.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3404s / 367.3543 s
agent0:                 episode reward: -0.6345,                 loss: nan
agent1:                 episode reward: 0.6345,                 loss: 0.0979
Episode: 28941/30000 (96.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3425s / 367.6968 s
agent0:                 episode reward: -0.7123,                 loss: nan
agent1:                 episode reward: 0.7123,                 loss: 0.0974
Episode: 28961/30000 (96.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3628s / 368.0596 s
agent0:                 episode reward: -0.8491,                 loss: nan
agent1:                 episode reward: 0.8491,                 loss: 0.0980
Episode: 28981/30000 (96.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3491s / 368.4086 s
agent0:                 episode reward: -0.5438,                 loss: nan
agent1:                 episode reward: 0.5438,                 loss: 0.0981
Episode: 29001/30000 (96.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3410s / 368.7496 s
agent0:                 episode reward: -0.7195,                 loss: nan
agent1:                 episode reward: 0.7195,                 loss: 0.0980
Episode: 29021/30000 (96.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3394s / 369.0890 s
agent0:                 episode reward: -0.4306,                 loss: nan
agent1:                 episode reward: 0.4306,                 loss: 0.0978
Episode: 29041/30000 (96.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3519s / 369.4409 s
agent0:                 episode reward: -0.9166,                 loss: nan
agent1:                 episode reward: 0.9166,                 loss: 0.0982
Episode: 29061/30000 (96.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3426s / 369.7835 s
agent0:                 episode reward: -0.7679,                 loss: nan
agent1:                 episode reward: 0.7679,                 loss: 0.0977
Episode: 29081/30000 (96.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3600s / 370.1434 s
agent0:                 episode reward: -0.7877,                 loss: nan
agent1:                 episode reward: 0.7877,                 loss: 0.0980
Episode: 29101/30000 (97.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3330s / 370.4765 s
agent0:                 episode reward: -0.5602,                 loss: nan
agent1:                 episode reward: 0.5602,                 loss: 0.0989
Episode: 29121/30000 (97.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3330s / 370.8095 s
agent0:                 episode reward: -0.3002,                 loss: nan
agent1:                 episode reward: 0.3002,                 loss: 0.0990
Episode: 29141/30000 (97.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3553s / 371.1647 s
agent0:                 episode reward: -0.8307,                 loss: nan
agent1:                 episode reward: 0.8307,                 loss: 0.0988
Episode: 29161/30000 (97.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3346s / 371.4993 s
agent0:                 episode reward: -0.6504,                 loss: nan
agent1:                 episode reward: 0.6504,                 loss: 0.0986
Episode: 29181/30000 (97.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3272s / 371.8265 s
agent0:                 episode reward: -0.7544,                 loss: nan
agent1:                 episode reward: 0.7544,                 loss: 0.0984
Episode: 29201/30000 (97.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3273s / 372.1538 s
agent0:                 episode reward: -0.7809,                 loss: nan
agent1:                 episode reward: 0.7809,                 loss: 0.0977
Episode: 29221/30000 (97.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3264s / 372.4801 s
agent0:                 episode reward: -0.6016,                 loss: nan
agent1:                 episode reward: 0.6016,                 loss: 0.0979
Episode: 29241/30000 (97.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3306s / 372.8108 s
agent0:                 episode reward: -0.8565,                 loss: nan
agent1:                 episode reward: 0.8565,                 loss: 0.0972
Episode: 29261/30000 (97.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3449s / 373.1556 s
agent0:                 episode reward: -0.7600,                 loss: nan
agent1:                 episode reward: 0.7600,                 loss: 0.0979
Episode: 29281/30000 (97.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3428s / 373.4984 s
agent0:                 episode reward: -0.6817,                 loss: nan
agent1:                 episode reward: 0.6817,                 loss: 0.0971
Episode: 29301/30000 (97.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3477s / 373.8461 s
agent0:                 episode reward: -0.7990,                 loss: nan
agent1:                 episode reward: 0.7990,                 loss: 0.0968
Episode: 29321/30000 (97.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3814s / 374.2275 s
agent0:                 episode reward: -0.5822,                 loss: nan
agent1:                 episode reward: 0.5822,                 loss: 0.0985
Episode: 29341/30000 (97.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3589s / 374.5865 s
agent0:                 episode reward: -0.7712,                 loss: nan
agent1:                 episode reward: 0.7712,                 loss: 0.0970
Episode: 29361/30000 (97.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3342s / 374.9206 s
agent0:                 episode reward: -0.8899,                 loss: nan
agent1:                 episode reward: 0.8899,                 loss: 0.0986
Episode: 29381/30000 (97.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3354s / 375.2560 s
agent0:                 episode reward: -0.7794,                 loss: nan
agent1:                 episode reward: 0.7794,                 loss: 0.0979
Episode: 29401/30000 (98.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3392s / 375.5952 s
agent0:                 episode reward: -0.7060,                 loss: nan
agent1:                 episode reward: 0.7060,                 loss: 0.0969
Episode: 29421/30000 (98.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3357s / 375.9309 s
agent0:                 episode reward: -0.7817,                 loss: nan
agent1:                 episode reward: 0.7817,                 loss: 0.0978
Episode: 29441/30000 (98.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3303s / 376.2613 s
agent0:                 episode reward: -0.4833,                 loss: nan
agent1:                 episode reward: 0.4833,                 loss: 0.0973
Episode: 29461/30000 (98.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3295s / 376.5908 s
agent0:                 episode reward: -0.7566,                 loss: nan
agent1:                 episode reward: 0.7566,                 loss: 0.0986
Episode: 29481/30000 (98.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3289s / 376.9197 s
agent0:                 episode reward: -0.9783,                 loss: nan
agent1:                 episode reward: 0.9783,                 loss: 0.0972
Episode: 29501/30000 (98.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3482s / 377.2680 s
agent0:                 episode reward: -1.0632,                 loss: nan
agent1:                 episode reward: 1.0632,                 loss: 0.0981
Episode: 29521/30000 (98.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3364s / 377.6044 s
agent0:                 episode reward: -0.6924,                 loss: nan
agent1:                 episode reward: 0.6924,                 loss: 0.0973
Episode: 29541/30000 (98.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3313s / 377.9356 s
agent0:                 episode reward: -0.6611,                 loss: nan
agent1:                 episode reward: 0.6611,                 loss: 0.0994
Episode: 29561/30000 (98.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3391s / 378.2747 s
agent0:                 episode reward: -0.7994,                 loss: nan
agent1:                 episode reward: 0.7994,                 loss: 0.0982
Episode: 29581/30000 (98.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3524s / 378.6272 s
agent0:                 episode reward: -0.8735,                 loss: nan
agent1:                 episode reward: 0.8735,                 loss: 0.0989
Episode: 29601/30000 (98.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4066s / 379.0337 s
agent0:                 episode reward: -0.6946,                 loss: nan
agent1:                 episode reward: 0.6946,                 loss: 0.0968
Episode: 29621/30000 (98.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3500s / 379.3837 s
agent0:                 episode reward: -0.7936,                 loss: nan
agent1:                 episode reward: 0.7936,                 loss: 0.0983
Episode: 29641/30000 (98.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3383s / 379.7220 s
agent0:                 episode reward: -0.4677,                 loss: nan
agent1:                 episode reward: 0.4677,                 loss: 0.0978
Episode: 29661/30000 (98.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3371s / 380.0591 s
agent0:                 episode reward: -0.4418,                 loss: nan
agent1:                 episode reward: 0.4418,                 loss: 0.0963
Episode: 29681/30000 (98.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3746s / 380.4338 s/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

agent0:                 episode reward: -0.6423,                 loss: nan
agent1:                 episode reward: 0.6423,                 loss: 0.0985
Episode: 29701/30000 (99.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3376s / 380.7713 s
agent0:                 episode reward: -0.7563,                 loss: nan
agent1:                 episode reward: 0.7563,                 loss: 0.0983
Episode: 29721/30000 (99.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3337s / 381.1050 s
agent0:                 episode reward: -0.3796,                 loss: nan
agent1:                 episode reward: 0.3796,                 loss: 0.0998
Episode: 29741/30000 (99.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3393s / 381.4443 s
agent0:                 episode reward: -0.4793,                 loss: nan
agent1:                 episode reward: 0.4793,                 loss: 0.0968
Episode: 29761/30000 (99.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3329s / 381.7773 s
agent0:                 episode reward: -0.3911,                 loss: nan
agent1:                 episode reward: 0.3911,                 loss: 0.0971
Episode: 29781/30000 (99.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3351s / 382.1123 s
agent0:                 episode reward: -0.5841,                 loss: nan
agent1:                 episode reward: 0.5841,                 loss: 0.0988
Episode: 29801/30000 (99.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3318s / 382.4442 s
agent0:                 episode reward: -0.9360,                 loss: nan
agent1:                 episode reward: 0.9360,                 loss: 0.0970
Episode: 29821/30000 (99.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3482s / 382.7924 s
agent0:                 episode reward: -0.8392,                 loss: nan
agent1:                 episode reward: 0.8392,                 loss: 0.0974
Episode: 29841/30000 (99.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3849s / 383.1773 s
agent0:                 episode reward: -0.8578,                 loss: nan
agent1:                 episode reward: 0.8578,                 loss: 0.0968
Episode: 29861/30000 (99.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3997s / 383.5770 s
agent0:                 episode reward: -0.4750,                 loss: nan
agent1:                 episode reward: 0.4750,                 loss: 0.0980
Episode: 29881/30000 (99.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3608s / 383.9378 s
agent0:                 episode reward: -1.0807,                 loss: nan
agent1:                 episode reward: 1.0807,                 loss: 0.0979
Episode: 29901/30000 (99.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3581s / 384.2959 s
agent0:                 episode reward: -0.6576,                 loss: nan
agent1:                 episode reward: 0.6576,                 loss: 0.0974
Episode: 29921/30000 (99.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3553s / 384.6512 s
agent0:                 episode reward: -0.6780,                 loss: nan
agent1:                 episode reward: 0.6780,                 loss: 0.0960
Episode: 29941/30000 (99.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3476s / 384.9988 s
agent0:                 episode reward: -0.8454,                 loss: nan
agent1:                 episode reward: 0.8454,                 loss: 0.0965
Episode: 29961/30000 (99.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3470s / 385.3458 s
agent0:                 episode reward: -0.4945,                 loss: nan
agent1:                 episode reward: 0.4945,                 loss: 0.0957
Episode: 29981/30000 (99.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3507s / 385.6965 s
agent0:                 episode reward: -0.9516,                 loss: nan
agent1:                 episode reward: 0.9516,                 loss: 0.0969
