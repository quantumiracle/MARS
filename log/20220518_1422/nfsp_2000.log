pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f1fc5fe4da0>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518033032/mdp_arbitrary_mdp_nfsp/2000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518033032/mdp_arbitrary_mdp_nfsp/2000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518033032_exploit_2000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518033032_exploit_2000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7106s / 0.7106 s
agent0:                 episode reward: -0.8304,                 loss: nan
agent1:                 episode reward: 0.8304,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1922s / 0.9028 s
agent0:                 episode reward: -0.4460,                 loss: nan
agent1:                 episode reward: 0.4460,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 1.0999 s
agent0:                 episode reward: -0.7654,                 loss: nan
agent1:                 episode reward: 0.7654,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 1.2979 s
agent0:                 episode reward: -0.5562,                 loss: nan
agent1:                 episode reward: 0.5562,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 1.4960 s
agent0:                 episode reward: -0.3780,                 loss: nan
agent1:                 episode reward: 0.3780,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1935s / 1.6895 s
agent0:                 episode reward: -0.6458,                 loss: nan
agent1:                 episode reward: 0.6458,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2035s / 1.8930 s
agent0:                 episode reward: -0.6193,                 loss: nan
agent1:                 episode reward: 0.6193,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1951s / 2.0882 s
agent0:                 episode reward: -0.6437,                 loss: nan
agent1:                 episode reward: 0.6437,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 2.2860 s
agent0:                 episode reward: -0.4335,                 loss: nan
agent1:                 episode reward: 0.4335,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1935s / 2.4795 s
agent0:                 episode reward: -0.4365,                 loss: nan
agent1:                 episode reward: 0.4365,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 2.6751 s
agent0:                 episode reward: -0.6051,                 loss: nan
agent1:                 episode reward: 0.6051,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 2.8746 s
agent0:                 episode reward: -0.7570,                 loss: nan
agent1:                 episode reward: 0.7570,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 3.0735 s
agent0:                 episode reward: -0.4311,                 loss: nan
agent1:                 episode reward: 0.4311,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 3.2743 s
agent0:                 episode reward: -0.3895,                 loss: nan
agent1:                 episode reward: 0.3895,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 3.4707 s
agent0:                 episode reward: -0.5798,                 loss: nan
agent1:                 episode reward: 0.5798,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 3.6699 s
agent0:                 episode reward: -0.4276,                 loss: nan
agent1:                 episode reward: 0.4276,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 3.8680 s
agent0:                 episode reward: -0.0919,                 loss: nan
agent1:                 episode reward: 0.0919,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1951s / 4.0631 s
agent0:                 episode reward: -1.0001,                 loss: nan
agent1:                 episode reward: 1.0001,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1941s / 4.2572 s
agent0:                 episode reward: -0.7173,                 loss: nan
agent1:                 episode reward: 0.7173,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1917s / 4.4490 s
agent0:                 episode reward: -0.5465,                 loss: nan
agent1:                 episode reward: 0.5465,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 4.6471 s
agent0:                 episode reward: -0.2575,                 loss: nan
agent1:                 episode reward: 0.2575,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 4.8479 s
agent0:                 episode reward: -0.4639,                 loss: nan
agent1:                 episode reward: 0.4639,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 5.0469 s
agent0:                 episode reward: -0.6177,                 loss: nan
agent1:                 episode reward: 0.6177,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 5.2454 s
agent0:                 episode reward: -0.4768,                 loss: nan
agent1:                 episode reward: 0.4768,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 5.4426 s
agent0:                 episode reward: -0.7353,                 loss: nan
agent1:                 episode reward: 0.7353,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 5.6419 s
agent0:                 episode reward: -0.4399,                 loss: nan
agent1:                 episode reward: 0.4399,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2018s / 5.8437 s
agent0:                 episode reward: -0.5745,                 loss: nan
agent1:                 episode reward: 0.5745,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 6.0435 s
agent0:                 episode reward: -0.8315,                 loss: nan
agent1:                 episode reward: 0.8315,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 6.2411 s
agent0:                 episode reward: -0.4639,                 loss: nan
agent1:                 episode reward: 0.4639,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 6.4384 s
agent0:                 episode reward: -0.8129,                 loss: nan
agent1:                 episode reward: 0.8129,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 6.6361 s
agent0:                 episode reward: -0.2711,                 loss: nan
agent1:                 episode reward: 0.2711,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1918s / 6.8279 s
agent0:                 episode reward: -0.7858,                 loss: nan
agent1:                 episode reward: 0.7858,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 7.0243 s
agent0:                 episode reward: -0.9000,                 loss: nan
agent1:                 episode reward: 0.9000,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 7.2239 s
agent0:                 episode reward: -0.6016,                 loss: nan
agent1:                 episode reward: 0.6016,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1937s / 7.4176 s
agent0:                 episode reward: -0.7360,                 loss: nan
agent1:                 episode reward: 0.7360,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 7.6152 s
agent0:                 episode reward: -0.9043,                 loss: nan
agent1:                 episode reward: 0.9043,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 7.8137 s
agent0:                 episode reward: -0.4587,                 loss: nan
agent1:                 episode reward: 0.4587,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 8.0129 s
agent0:                 episode reward: -0.7968,                 loss: nan
agent1:                 episode reward: 0.7968,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 8.2129 s
agent0:                 episode reward: -0.5320,                 loss: nan
agent1:                 episode reward: 0.5320,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 8.4107 s
agent0:                 episode reward: -0.8574,                 loss: nan
agent1:                 episode reward: 0.8574,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 8.6067 s
agent0:                 episode reward: -1.1921,                 loss: nan
agent1:                 episode reward: 1.1921,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 8.8065 s
agent0:                 episode reward: -0.4040,                 loss: nan
agent1:                 episode reward: 0.4040,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 9.0057 s
agent0:                 episode reward: -0.8391,                 loss: nan
agent1:                 episode reward: 0.8391,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 9.2049 s
agent0:                 episode reward: -0.4424,                 loss: nan
agent1:                 episode reward: 0.4424,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1941s / 9.3990 s
agent0:                 episode reward: -0.9630,                 loss: nan
agent1:                 episode reward: 0.9630,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 9.5930 s
agent0:                 episode reward: -0.4381,                 loss: nan
agent1:                 episode reward: 0.4381,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 9.7924 s
agent0:                 episode reward: -0.4377,                 loss: nan
agent1:                 episode reward: 0.4377,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 9.9898 s
agent0:                 episode reward: -0.7305,                 loss: nan
agent1:                 episode reward: 0.7305,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 10.1908 s
agent0:                 episode reward: -0.6883,                 loss: nan
agent1:                 episode reward: 0.6883,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 10.3924 s
agent0:                 episode reward: -0.5488,                 loss: nan
agent1:                 episode reward: 0.5488,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 10.5916 s
agent0:                 episode reward: -0.8514,                 loss: nan
agent1:                 episode reward: 0.8514,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 10.7886 s
agent0:                 episode reward: -0.7952,                 loss: nan
agent1:                 episode reward: 0.7952,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 10.9887 s
agent0:                 episode reward: -0.6500,                 loss: nan
agent1:                 episode reward: 0.6500,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1937s / 11.1824 s
agent0:                 episode reward: -0.6888,                 loss: nan
agent1:                 episode reward: 0.6888,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1923s / 11.3747 s
agent0:                 episode reward: -0.6617,                 loss: nan
agent1:                 episode reward: 0.6617,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 11.5741 s
agent0:                 episode reward: -0.6894,                 loss: nan
agent1:                 episode reward: 0.6894,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1941s / 11.7682 s
agent0:                 episode reward: -0.4494,                 loss: nan
agent1:                 episode reward: 0.4494,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1951s / 11.9632 s
agent0:                 episode reward: -0.6409,                 loss: nan
agent1:                 episode reward: 0.6409,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 12.1622 s
agent0:                 episode reward: -0.4594,                 loss: nan
agent1:                 episode reward: 0.4594,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1932s / 12.3554 s
agent0:                 episode reward: -0.6314,                 loss: nan
agent1:                 episode reward: 0.6314,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 12.5514 s
agent0:                 episode reward: -0.5368,                 loss: nan
agent1:                 episode reward: 0.5368,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 12.7516 s
agent0:                 episode reward: -0.2473,                 loss: nan
agent1:                 episode reward: 0.2473,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2037s / 12.9553 s
agent0:                 episode reward: -0.2719,                 loss: nan
agent1:                 episode reward: 0.2719,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 13.1535 s
agent0:                 episode reward: -0.8456,                 loss: nan
agent1:                 episode reward: 0.8456,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 13.3499 s
agent0:                 episode reward: -0.4869,                 loss: nan
agent1:                 episode reward: 0.4869,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 13.5464 s
agent0:                 episode reward: -0.7398,                 loss: nan
agent1:                 episode reward: 0.7398,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1927s / 13.7391 s
agent0:                 episode reward: -0.5759,                 loss: nan
agent1:                 episode reward: 0.5759,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 13.9370 s
agent0:                 episode reward: -0.1917,                 loss: nan
agent1:                 episode reward: 0.1917,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 14.1349 s
agent0:                 episode reward: -0.6795,                 loss: nan
agent1:                 episode reward: 0.6795,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 14.3309 s
agent0:                 episode reward: -0.5441,                 loss: nan
agent1:                 episode reward: 0.5441,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 14.5334 s
agent0:                 episode reward: -0.1597,                 loss: nan
agent1:                 episode reward: 0.1597,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 14.7313 s
agent0:                 episode reward: -0.5045,                 loss: nan
agent1:                 episode reward: 0.5045,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1923s / 14.9236 s
agent0:                 episode reward: -0.6200,                 loss: nan
agent1:                 episode reward: 0.6200,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 15.1184 s
agent0:                 episode reward: -1.0123,                 loss: nan
agent1:                 episode reward: 1.0123,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 15.3137 s
agent0:                 episode reward: -0.6696,                 loss: nan
agent1:                 episode reward: 0.6696,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 15.5123 s
agent0:                 episode reward: -0.7530,                 loss: nan
agent1:                 episode reward: 0.7530,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 15.7134 s
agent0:                 episode reward: -0.7278,                 loss: nan
agent1:                 episode reward: 0.7278,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1950s / 15.9084 s
agent0:                 episode reward: -0.6792,                 loss: nan
agent1:                 episode reward: 0.6792,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 16.1092 s
agent0:                 episode reward: -0.4520,                 loss: nan
agent1:                 episode reward: 0.4520,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 16.3086 s
agent0:                 episode reward: -0.5513,                 loss: nan
agent1:                 episode reward: 0.5513,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 16.5077 s
agent0:                 episode reward: -0.4861,                 loss: nan
agent1:                 episode reward: 0.4861,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1934s / 16.7012 s
agent0:                 episode reward: -0.5565,                 loss: nan
agent1:                 episode reward: 0.5565,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 16.8968 s
agent0:                 episode reward: -0.7160,                 loss: nan
agent1:                 episode reward: 0.7160,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 17.0980 s
agent0:                 episode reward: -0.3230,                 loss: nan
agent1:                 episode reward: 0.3230,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 17.2950 s
agent0:                 episode reward: -0.4638,                 loss: nan
agent1:                 episode reward: 0.4638,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 17.4897 s
agent0:                 episode reward: -0.4194,                 loss: nan
agent1:                 episode reward: 0.4194,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 17.6880 s
agent0:                 episode reward: -0.7870,                 loss: nan
agent1:                 episode reward: 0.7870,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 17.8882 s
agent0:                 episode reward: -0.7061,                 loss: nan
agent1:                 episode reward: 0.7061,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1923s / 18.0805 s
agent0:                 episode reward: -0.2672,                 loss: nan
agent1:                 episode reward: 0.2672,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 18.2785 s
agent0:                 episode reward: -0.5266,                 loss: nan
agent1:                 episode reward: 0.5266,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 18.4773 s
agent0:                 episode reward: -0.5167,                 loss: nan
agent1:                 episode reward: 0.5167,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 18.6744 s
agent0:                 episode reward: -0.4528,                 loss: nan
agent1:                 episode reward: 0.4528,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 18.8699 s
agent0:                 episode reward: -0.5845,                 loss: nan
agent1:                 episode reward: 0.5845,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 19.0676 s
agent0:                 episode reward: -0.3446,                 loss: nan
agent1:                 episode reward: 0.3446,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 19.2659 s
agent0:                 episode reward: -0.5390,                 loss: nan
agent1:                 episode reward: 0.5390,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1923s / 19.4582 s
agent0:                 episode reward: -0.7874,                 loss: nan
agent1:                 episode reward: 0.7874,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 19.6587 s
agent0:                 episode reward: -0.3616,                 loss: nan
agent1:                 episode reward: 0.3616,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2043s / 19.8631 s
agent0:                 episode reward: -0.5329,                 loss: nan
agent1:                 episode reward: 0.5329,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2049s / 20.0680 s
agent0:                 episode reward: -0.7501,                 loss: nan
agent1:                 episode reward: 0.7501,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 20.2654 s
agent0:                 episode reward: -0.8394,                 loss: nan
agent1:                 episode reward: 0.8394,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 20.4637 s
agent0:                 episode reward: -0.7213,                 loss: nan
agent1:                 episode reward: 0.7213,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 20.6663 s
agent0:                 episode reward: -0.3611,                 loss: nan
agent1:                 episode reward: 0.3611,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 20.8632 s
agent0:                 episode reward: -0.4239,                 loss: nan
agent1:                 episode reward: 0.4239,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2030s / 21.0662 s
agent0:                 episode reward: -0.9134,                 loss: nan
agent1:                 episode reward: 0.9134,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 21.2683 s
agent0:                 episode reward: -0.2414,                 loss: nan
agent1:                 episode reward: 0.2414,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 21.4681 s
agent0:                 episode reward: -0.5873,                 loss: nan
agent1:                 episode reward: 0.5873,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 21.6658 s
agent0:                 episode reward: -0.4835,                 loss: nan
agent1:                 episode reward: 0.4835,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 21.8646 s
agent0:                 episode reward: -0.8900,                 loss: nan
agent1:                 episode reward: 0.8900,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 22.0610 s
agent0:                 episode reward: -0.6247,                 loss: nan
agent1:                 episode reward: 0.6247,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 22.2596 s
agent0:                 episode reward: -0.2598,                 loss: nan
agent1:                 episode reward: 0.2598,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 22.4602 s
agent0:                 episode reward: -0.6563,                 loss: nan
agent1:                 episode reward: 0.6563,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1992s / 22.6594 s
agent0:                 episode reward: -0.2287,                 loss: nan
agent1:                 episode reward: 0.2287,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 22.8587 s
agent0:                 episode reward: -0.5078,                 loss: nan
agent1:                 episode reward: 0.5078,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 23.0603 s
agent0:                 episode reward: -0.8996,                 loss: nan
agent1:                 episode reward: 0.8996,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2034s / 23.2638 s
agent0:                 episode reward: -0.8601,                 loss: nan
agent1:                 episode reward: 0.8601,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 23.4665 s
agent0:                 episode reward: -0.3402,                 loss: nan
agent1:                 episode reward: 0.3402,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 23.6667 s
agent0:                 episode reward: -0.6990,                 loss: nan
agent1:                 episode reward: 0.6990,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 23.8661 s
agent0:                 episode reward: -0.9007,                 loss: nan
agent1:                 episode reward: 0.9007,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 24.0630 s
agent0:                 episode reward: -0.3572,                 loss: nan
agent1:                 episode reward: 0.3572,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 24.2626 s
agent0:                 episode reward: -0.7025,                 loss: nan
agent1:                 episode reward: 0.7025,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 24.4606 s
agent0:                 episode reward: -0.6450,                 loss: nan
agent1:                 episode reward: 0.6450,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 24.6612 s
agent0:                 episode reward: -0.9820,                 loss: nan
agent1:                 episode reward: 0.9820,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 24.8631 s
agent0:                 episode reward: -0.5948,                 loss: nan
agent1:                 episode reward: 0.5948,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2029s / 25.0661 s
agent0:                 episode reward: -0.4933,                 loss: nan
agent1:                 episode reward: 0.4933,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 25.2669 s
agent0:                 episode reward: -0.8331,                 loss: nan
agent1:                 episode reward: 0.8331,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 25.4639 s
agent0:                 episode reward: -0.7913,                 loss: nan
agent1:                 episode reward: 0.7913,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 25.6629 s
agent0:                 episode reward: -0.4505,                 loss: nan
agent1:                 episode reward: 0.4505,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 25.8602 s
agent0:                 episode reward: -0.7747,                 loss: nan
agent1:                 episode reward: 0.7747,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 26.0615 s
agent0:                 episode reward: -0.3548,                 loss: nan
agent1:                 episode reward: 0.3548,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 26.2629 s
agent0:                 episode reward: -0.2829,                 loss: nan
agent1:                 episode reward: 0.2829,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1881s / 26.4511 s
agent0:                 episode reward: -0.6904,                 loss: nan
agent1:                 episode reward: 0.6904,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 26.6523 s
agent0:                 episode reward: -0.7195,                 loss: nan
agent1:                 episode reward: 0.7195,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 26.8487 s
agent0:                 episode reward: -0.5065,                 loss: nan
agent1:                 episode reward: 0.5065,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1931s / 27.0418 s
agent0:                 episode reward: -0.5387,                 loss: nan
agent1:                 episode reward: 0.5387,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 27.2390 s
agent0:                 episode reward: -0.5426,                 loss: nan
agent1:                 episode reward: 0.5426,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 27.4350 s
agent0:                 episode reward: -0.4322,                 loss: nan
agent1:                 episode reward: 0.4322,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1926s / 27.6276 s
agent0:                 episode reward: -0.5977,                 loss: nan
agent1:                 episode reward: 0.5977,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1950s / 27.8226 s
agent0:                 episode reward: -0.6198,                 loss: nan
agent1:                 episode reward: 0.6198,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2218s / 28.0444 s
agent0:                 episode reward: -0.7014,                 loss: nan
agent1:                 episode reward: 0.7014,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2003s / 28.2447 s
agent0:                 episode reward: -0.5569,                 loss: nan
agent1:                 episode reward: 0.5569,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1945s / 28.4392 s
agent0:                 episode reward: -0.5193,                 loss: nan
agent1:                 episode reward: 0.5193,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 28.6374 s
agent0:                 episode reward: -0.4980,                 loss: nan
agent1:                 episode reward: 0.4980,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 28.8315 s
agent0:                 episode reward: -0.3864,                 loss: nan
agent1:                 episode reward: 0.3864,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 29.0304 s
agent0:                 episode reward: -0.3283,                 loss: nan
agent1:                 episode reward: 0.3283,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 29.2271 s
agent0:                 episode reward: -0.2238,                 loss: nan
agent1:                 episode reward: 0.2238,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 29.4278 s
agent0:                 episode reward: -0.6576,                 loss: nan
agent1:                 episode reward: 0.6576,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 29.6288 s
agent0:                 episode reward: -0.7365,                 loss: nan
agent1:                 episode reward: 0.7365,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 29.8264 s
agent0:                 episode reward: -0.8095,                 loss: nan
agent1:                 episode reward: 0.8095,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 30.0228 s
agent0:                 episode reward: -0.3621,                 loss: nan
agent1:                 episode reward: 0.3621,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 30.2210 s
agent0:                 episode reward: -0.8991,                 loss: nan
agent1:                 episode reward: 0.8991,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 30.4193 s
agent0:                 episode reward: -0.4138,                 loss: nan
agent1:                 episode reward: 0.4138,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 30.6146 s
agent0:                 episode reward: -0.4178,                 loss: nan
agent1:                 episode reward: 0.4178,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 30.8165 s
agent0:                 episode reward: -0.0713,                 loss: nan
agent1:                 episode reward: 0.0713,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1924s / 31.0089 s
agent0:                 episode reward: -0.7077,                 loss: nan
agent1:                 episode reward: 0.7077,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1943s / 31.2033 s
agent0:                 episode reward: -0.4504,                 loss: nan
agent1:                 episode reward: 0.4504,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 31.4013 s
agent0:                 episode reward: -0.7470,                 loss: nan
agent1:                 episode reward: 0.7470,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 31.5987 s
agent0:                 episode reward: -0.8115,                 loss: nan
agent1:                 episode reward: 0.8115,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 31.7997 s
agent0:                 episode reward: -0.6231,                 loss: nan
agent1:                 episode reward: 0.6231,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 31.9966 s
agent0:                 episode reward: -0.2927,                 loss: nan
agent1:                 episode reward: 0.2927,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 32.1919 s
agent0:                 episode reward: -0.4453,                 loss: nan
agent1:                 episode reward: 0.4453,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1924s / 32.3843 s
agent0:                 episode reward: -0.3951,                 loss: nan
agent1:                 episode reward: 0.3951,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1895s / 32.5738 s
agent0:                 episode reward: -0.8508,                 loss: nan
agent1:                 episode reward: 0.8508,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1914s / 32.7652 s
agent0:                 episode reward: -1.1984,                 loss: nan
agent1:                 episode reward: 1.1984,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 32.9626 s
agent0:                 episode reward: -0.2760,                 loss: nan
agent1:                 episode reward: 0.2760,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1941s / 33.1568 s
agent0:                 episode reward: -0.8270,                 loss: nan
agent1:                 episode reward: 0.8270,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1926s / 33.3494 s
agent0:                 episode reward: -0.2592,                 loss: nan
agent1:                 episode reward: 0.2592,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1897s / 33.5390 s
agent0:                 episode reward: -0.6159,                 loss: nan
agent1:                 episode reward: 0.6159,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3549s / 33.8939 s
agent0:                 episode reward: -0.3838,                 loss: nan
agent1:                 episode reward: 0.3838,                 loss: 0.4374
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5815s / 34.4754 s
agent0:                 episode reward: 0.0516,                 loss: nan
agent1:                 episode reward: -0.0516,                 loss: 0.4256
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5767s / 35.0521 s
agent0:                 episode reward: -0.5800,                 loss: nan
agent1:                 episode reward: 0.5800,                 loss: 0.4164
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5804s / 35.6325 s
agent0:                 episode reward: -0.3347,                 loss: nan
agent1:                 episode reward: 0.3347,                 loss: 0.4093
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5833s / 36.2159 s
agent0:                 episode reward: -0.6497,                 loss: nan
agent1:                 episode reward: 0.6497,                 loss: 0.4016
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5816s / 36.7974 s
agent0:                 episode reward: -0.8407,                 loss: nan
agent1:                 episode reward: 0.8407,                 loss: 0.3934
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5762s / 37.3736 s
agent0:                 episode reward: -0.7456,                 loss: nan
agent1:                 episode reward: 0.7456,                 loss: 0.3837
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5826s / 37.9562 s
agent0:                 episode reward: -0.8190,                 loss: nan
agent1:                 episode reward: 0.8190,                 loss: 0.3794
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5715s / 38.5277 s
agent0:                 episode reward: -0.6229,                 loss: nan
agent1:                 episode reward: 0.6229,                 loss: 0.3717
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5761s / 39.1037 s
agent0:                 episode reward: -0.2906,                 loss: nan
agent1:                 episode reward: 0.2906,                 loss: 0.3708
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5839s / 39.6876 s
agent0:                 episode reward: -0.2012,                 loss: nan
agent1:                 episode reward: 0.2012,                 loss: 0.3713
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5855s / 40.2731 s
agent0:                 episode reward: -0.8527,                 loss: nan
agent1:                 episode reward: 0.8527,                 loss: 0.3695
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5825s / 40.8556 s
agent0:                 episode reward: -0.8463,                 loss: nan
agent1:                 episode reward: 0.8463,                 loss: 0.3671
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5775s / 41.4331 s
agent0:                 episode reward: -0.5794,                 loss: nan
agent1:                 episode reward: 0.5794,                 loss: 0.3682
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5793s / 42.0124 s
agent0:                 episode reward: -0.2277,                 loss: nan
agent1:                 episode reward: 0.2277,                 loss: 0.3676
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5808s / 42.5933 s
agent0:                 episode reward: -0.4324,                 loss: nan
agent1:                 episode reward: 0.4324,                 loss: 0.3660
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5843s / 43.1776 s
agent0:                 episode reward: -0.7113,                 loss: nan
agent1:                 episode reward: 0.7113,                 loss: 0.3684
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5812s / 43.7588 s
agent0:                 episode reward: -1.0221,                 loss: nan
agent1:                 episode reward: 1.0221,                 loss: 0.3739
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5825s / 44.3413 s
agent0:                 episode reward: -0.9219,                 loss: nan
agent1:                 episode reward: 0.9219,                 loss: 0.3649
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5713s / 44.9126 s
agent0:                 episode reward: -0.9776,                 loss: nan
agent1:                 episode reward: 0.9776,                 loss: 0.3632
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5767s / 45.4894 s
agent0:                 episode reward: -0.5635,                 loss: nan
agent1:                 episode reward: 0.5635,                 loss: 0.3597
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5784s / 46.0678 s
agent0:                 episode reward: -0.3994,                 loss: nan
agent1:                 episode reward: 0.3994,                 loss: 0.3612
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5724s / 46.6401 s
agent0:                 episode reward: -0.6449,                 loss: nan
agent1:                 episode reward: 0.6449,                 loss: 0.3560
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5813s / 47.2215 s
agent0:                 episode reward: -0.8499,                 loss: nan
agent1:                 episode reward: 0.8499,                 loss: 0.3594
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5776s / 47.7991 s
agent0:                 episode reward: -0.5288,                 loss: nan
agent1:                 episode reward: 0.5288,                 loss: 0.3577
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5746s / 48.3737 s
agent0:                 episode reward: -0.9732,                 loss: nan
agent1:                 episode reward: 0.9732,                 loss: 0.3546
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5825s / 48.9562 s
agent0:                 episode reward: -0.5588,                 loss: nan
agent1:                 episode reward: 0.5588,                 loss: 0.3580
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5826s / 49.5388 s
agent0:                 episode reward: -0.7417,                 loss: nan
agent1:                 episode reward: 0.7417,                 loss: 0.3552
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5836s / 50.1224 s
agent0:                 episode reward: -0.7402,                 loss: nan
agent1:                 episode reward: 0.7402,                 loss: 0.3560
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5811s / 50.7036 s
agent0:                 episode reward: -0.9811,                 loss: nan
agent1:                 episode reward: 0.9811,                 loss: 0.3573
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5851s / 51.2887 s
agent0:                 episode reward: -0.5261,                 loss: nan
agent1:                 episode reward: 0.5261,                 loss: 0.3548
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5850s / 51.8737 s
agent0:                 episode reward: -0.7738,                 loss: nan
agent1:                 episode reward: 0.7738,                 loss: 0.3552
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5820s / 52.4557 s
agent0:                 episode reward: -0.5693,                 loss: nan
agent1:                 episode reward: 0.5693,                 loss: 0.3532
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 53.0376 s
agent0:                 episode reward: -0.4403,                 loss: nan
agent1:                 episode reward: 0.4403,                 loss: 0.3605
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 53.6258 s
agent0:                 episode reward: -0.9100,                 loss: nan
agent1:                 episode reward: 0.9100,                 loss: 0.3929
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 54.2154 s
agent0:                 episode reward: -0.5464,                 loss: nan
agent1:                 episode reward: 0.5464,                 loss: 0.3883
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5844s / 54.7998 s
agent0:                 episode reward: -0.2662,                 loss: nan
agent1:                 episode reward: 0.2662,                 loss: 0.3880
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 55.3913 s
agent0:                 episode reward: -0.5219,                 loss: nan
agent1:                 episode reward: 0.5219,                 loss: 0.3871
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5956s / 55.9870 s
agent0:                 episode reward: -0.5297,                 loss: nan
agent1:                 episode reward: 0.5297,                 loss: 0.3861
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5908s / 56.5778 s
agent0:                 episode reward: -0.5915,                 loss: nan
agent1:                 episode reward: 0.5915,                 loss: 0.3871
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5866s / 57.1644 s
agent0:                 episode reward: -0.1920,                 loss: nan
agent1:                 episode reward: 0.1920,                 loss: 0.3872
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5959s / 57.7603 s
agent0:                 episode reward: -0.9872,                 loss: nan
agent1:                 episode reward: 0.9872,                 loss: 0.3864
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5884s / 58.3487 s
agent0:                 episode reward: -0.7407,                 loss: nan
agent1:                 episode reward: 0.7407,                 loss: 0.3863
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 58.9462 s
agent0:                 episode reward: -0.7848,                 loss: nan
agent1:                 episode reward: 0.7848,                 loss: 0.3854
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 59.5413 s
agent0:                 episode reward: -0.4822,                 loss: nan
agent1:                 episode reward: 0.4822,                 loss: 0.3878
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5938s / 60.1351 s
agent0:                 episode reward: -0.8853,                 loss: nan
agent1:                 episode reward: 0.8853,                 loss: 0.3862
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5820s / 60.7171 s
agent0:                 episode reward: -0.2720,                 loss: nan
agent1:                 episode reward: 0.2720,                 loss: 0.3892
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 61.3054 s
agent0:                 episode reward: -0.7704,                 loss: nan
agent1:                 episode reward: 0.7704,                 loss: 0.3888
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5921s / 61.8975 s
agent0:                 episode reward: -0.5675,                 loss: nan
agent1:                 episode reward: 0.5675,                 loss: 0.3881
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5888s / 62.4862 s
agent0:                 episode reward: -0.5377,                 loss: nan
agent1:                 episode reward: 0.5377,                 loss: 0.3859
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5876s / 63.0739 s
agent0:                 episode reward: -0.5962,                 loss: nan
agent1:                 episode reward: 0.5962,                 loss: 0.3834
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5844s / 63.6583 s
agent0:                 episode reward: -0.6873,                 loss: nan
agent1:                 episode reward: 0.6873,                 loss: 0.3818
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5785s / 64.2368 s
agent0:                 episode reward: -0.8337,                 loss: nan
agent1:                 episode reward: 0.8337,                 loss: 0.3780
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5848s / 64.8216 s
agent0:                 episode reward: -0.6149,                 loss: nan
agent1:                 episode reward: 0.6149,                 loss: 0.3785
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5803s / 65.4019 s
agent0:                 episode reward: -0.7980,                 loss: nan
agent1:                 episode reward: 0.7980,                 loss: 0.3793
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5816s / 65.9834 s
agent0:                 episode reward: -0.6812,                 loss: nan
agent1:                 episode reward: 0.6812,                 loss: 0.3791
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 66.5717 s
agent0:                 episode reward: -0.8141,                 loss: nan
agent1:                 episode reward: 0.8141,                 loss: 0.3795
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5843s / 67.1560 s
agent0:                 episode reward: -0.6371,                 loss: nan
agent1:                 episode reward: 0.6371,                 loss: 0.3779
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5897s / 67.7456 s
agent0:                 episode reward: -0.8198,                 loss: nan
agent1:                 episode reward: 0.8198,                 loss: 0.3759
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5783s / 68.3239 s
agent0:                 episode reward: -0.7400,                 loss: nan
agent1:                 episode reward: 0.7400,                 loss: 0.3781
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5771s / 68.9010 s
agent0:                 episode reward: -0.4238,                 loss: nan
agent1:                 episode reward: 0.4238,                 loss: 0.3775
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5806s / 69.4816 s
agent0:                 episode reward: -0.9030,                 loss: nan
agent1:                 episode reward: 0.9030,                 loss: 0.3762
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5841s / 70.0657 s
agent0:                 episode reward: -0.4664,                 loss: nan
agent1:                 episode reward: 0.4664,                 loss: 0.3776
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5840s / 70.6497 s
agent0:                 episode reward: -0.9242,                 loss: nan
agent1:                 episode reward: 0.9242,                 loss: 0.3776
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5759s / 71.2256 s
agent0:                 episode reward: -0.5095,                 loss: nan
agent1:                 episode reward: 0.5095,                 loss: 0.3773
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5843s / 71.8099 s
agent0:                 episode reward: -0.6004,                 loss: nan
agent1:                 episode reward: 0.6004,                 loss: 0.3755
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 72.3952 s
agent0:                 episode reward: -0.8317,                 loss: nan
agent1:                 episode reward: 0.8317,                 loss: 0.3770
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5919s / 72.9871 s
agent0:                 episode reward: -0.3699,                 loss: nan
agent1:                 episode reward: 0.3699,                 loss: 0.3750
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5870s / 73.5741 s
agent0:                 episode reward: -0.5731,                 loss: nan
agent1:                 episode reward: 0.5731,                 loss: 0.3704
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5871s / 74.1612 s
agent0:                 episode reward: -0.7865,                 loss: nan
agent1:                 episode reward: 0.7865,                 loss: 0.3728
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5840s / 74.7452 s
agent0:                 episode reward: -0.8224,                 loss: nan
agent1:                 episode reward: 0.8224,                 loss: 0.3704
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5840s / 75.3292 s
agent0:                 episode reward: -1.0377,                 loss: nan
agent1:                 episode reward: 1.0377,                 loss: 0.3697
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 75.9175 s
agent0:                 episode reward: -0.8199,                 loss: nan
agent1:                 episode reward: 0.8199,                 loss: 0.3686
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5856s / 76.5032 s
agent0:                 episode reward: -0.5029,                 loss: nan
agent1:                 episode reward: 0.5029,                 loss: 0.3716
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 77.0985 s
agent0:                 episode reward: -0.4566,                 loss: nan
agent1:                 episode reward: 0.4566,                 loss: 0.3678
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5865s / 77.6850 s
agent0:                 episode reward: -0.6566,                 loss: nan
agent1:                 episode reward: 0.6566,                 loss: 0.3688
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5839s / 78.2689 s
agent0:                 episode reward: -0.5784,                 loss: nan
agent1:                 episode reward: 0.5784,                 loss: 0.3669
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5833s / 78.8522 s
agent0:                 episode reward: -0.6249,                 loss: nan
agent1:                 episode reward: 0.6249,                 loss: 0.3703
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 79.4375 s
agent0:                 episode reward: -0.6513,                 loss: nan
agent1:                 episode reward: 0.6513,                 loss: 0.3673
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 80.0257 s
agent0:                 episode reward: -0.6198,                 loss: nan
agent1:                 episode reward: 0.6198,                 loss: 0.3670
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 80.6232 s
agent0:                 episode reward: -1.2637,                 loss: nan
agent1:                 episode reward: 1.2637,                 loss: 0.3720
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5808s / 81.2039 s
agent0:                 episode reward: -0.3927,                 loss: nan
agent1:                 episode reward: 0.3927,                 loss: 0.3685
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5821s / 81.7861 s
agent0:                 episode reward: -0.6578,                 loss: nan
agent1:                 episode reward: 0.6578,                 loss: 0.3672
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5900s / 82.3761 s
agent0:                 episode reward: -1.0433,                 loss: nan
agent1:                 episode reward: 1.0433,                 loss: 0.3703
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 82.9683 s
agent0:                 episode reward: -0.3723,                 loss: nan
agent1:                 episode reward: 0.3723,                 loss: 0.3862
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 83.5565 s
agent0:                 episode reward: -0.5835,                 loss: nan
agent1:                 episode reward: 0.5835,                 loss: 0.3840
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5874s / 84.1438 s
agent0:                 episode reward: -0.6658,                 loss: nan
agent1:                 episode reward: 0.6658,                 loss: 0.3855
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5900s / 84.7339 s
agent0:                 episode reward: -0.7747,                 loss: nan
agent1:                 episode reward: 0.7747,                 loss: 0.3846
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5962s / 85.3301 s
agent0:                 episode reward: -0.5834,                 loss: nan
agent1:                 episode reward: 0.5834,                 loss: 0.3867
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5887s / 85.9189 s
agent0:                 episode reward: -0.6375,                 loss: nan
agent1:                 episode reward: 0.6375,                 loss: 0.3860
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5830s / 86.5019 s
agent0:                 episode reward: -0.7346,                 loss: nan
agent1:                 episode reward: 0.7346,                 loss: 0.3853
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5871s / 87.0890 s
agent0:                 episode reward: -0.8796,                 loss: nan
agent1:                 episode reward: 0.8796,                 loss: 0.3836
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5892s / 87.6781 s
agent0:                 episode reward: -0.7677,                 loss: nan
agent1:                 episode reward: 0.7677,                 loss: 0.3846
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 88.2600 s
agent0:                 episode reward: -0.6922,                 loss: nan
agent1:                 episode reward: 0.6922,                 loss: 0.3842
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5903s / 88.8503 s
agent0:                 episode reward: -1.1987,                 loss: nan
agent1:                 episode reward: 1.1987,                 loss: 0.3838
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5887s / 89.4390 s
agent0:                 episode reward: -0.6238,                 loss: nan
agent1:                 episode reward: 0.6238,                 loss: 0.3846
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5871s / 90.0260 s
agent0:                 episode reward: -0.8807,                 loss: nan
agent1:                 episode reward: 0.8807,                 loss: 0.3843
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5945s / 90.6206 s
agent0:                 episode reward: -0.6768,                 loss: nan
agent1:                 episode reward: 0.6768,                 loss: 0.3854
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 91.2158 s
agent0:                 episode reward: -0.6798,                 loss: nan
agent1:                 episode reward: 0.6798,                 loss: 0.3866
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5945s / 91.8104 s
agent0:                 episode reward: -0.5970,                 loss: nan
agent1:                 episode reward: 0.5970,                 loss: 0.3850
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5881s / 92.3985 s
agent0:                 episode reward: -0.5665,                 loss: nan
agent1:                 episode reward: 0.5665,                 loss: 0.3838
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5913s / 92.9898 s
agent0:                 episode reward: -0.7725,                 loss: nan
agent1:                 episode reward: 0.7725,                 loss: 0.3759
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5854s / 93.5752 s
agent0:                 episode reward: -0.5046,                 loss: nan
agent1:                 episode reward: 0.5046,                 loss: 0.3746
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5850s / 94.1601 s
agent0:                 episode reward: -0.8857,                 loss: nan
agent1:                 episode reward: 0.8857,                 loss: 0.3750
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 94.7555 s
agent0:                 episode reward: -0.8813,                 loss: nan
agent1:                 episode reward: 0.8813,                 loss: 0.3755
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 95.3537 s
agent0:                 episode reward: -0.3811,                 loss: nan
agent1:                 episode reward: 0.3811,                 loss: 0.3767
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5900s / 95.9437 s
agent0:                 episode reward: -0.5841,                 loss: nan
agent1:                 episode reward: 0.5841,                 loss: 0.3748
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5850s / 96.5287 s
agent0:                 episode reward: -0.5081,                 loss: nan
agent1:                 episode reward: 0.5081,                 loss: 0.3762
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 97.1180 s
agent0:                 episode reward: -0.8170,                 loss: nan
agent1:                 episode reward: 0.8170,                 loss: 0.3732
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5828s / 97.7008 s
agent0:                 episode reward: -0.9844,                 loss: nan
agent1:                 episode reward: 0.9844,                 loss: 0.3748
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 98.2903 s
agent0:                 episode reward: -0.4273,                 loss: nan
agent1:                 episode reward: 0.4273,                 loss: 0.3758
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5929s / 98.8832 s
agent0:                 episode reward: -0.5662,                 loss: nan
agent1:                 episode reward: 0.5662,                 loss: 0.3756
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5898s / 99.4729 s
agent0:                 episode reward: -0.3212,                 loss: nan
agent1:                 episode reward: 0.3212,                 loss: 0.3767
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5843s / 100.0572 s
agent0:                 episode reward: -0.6324,                 loss: nan
agent1:                 episode reward: 0.6324,                 loss: 0.3754
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5835s / 100.6408 s
agent0:                 episode reward: -0.8057,                 loss: nan
agent1:                 episode reward: 0.8057,                 loss: 0.3768
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5919s / 101.2326 s
agent0:                 episode reward: -0.7660,                 loss: nan
agent1:                 episode reward: 0.7660,                 loss: 0.3752
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 101.8312 s
agent0:                 episode reward: -0.6618,                 loss: nan
agent1:                 episode reward: 0.6618,                 loss: 0.3732
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5875s / 102.4187 s
agent0:                 episode reward: -0.4505,                 loss: nan
agent1:                 episode reward: 0.4505,                 loss: 0.3765
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6001s / 103.0188 s
agent0:                 episode reward: -0.5759,                 loss: nan
agent1:                 episode reward: 0.5759,                 loss: 0.3797
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5881s / 103.6068 s
agent0:                 episode reward: -0.8056,                 loss: nan
agent1:                 episode reward: 0.8056,                 loss: 0.3785
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 104.1990 s
agent0:                 episode reward: -0.6290,                 loss: nan
agent1:                 episode reward: 0.6290,                 loss: 0.3758
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6000s / 104.7990 s
agent0:                 episode reward: -0.4977,                 loss: nan
agent1:                 episode reward: 0.4977,                 loss: 0.3806
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5985s / 105.3975 s
agent0:                 episode reward: -0.5045,                 loss: nan
agent1:                 episode reward: 0.5045,                 loss: 0.3781
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6043s / 106.0018 s
agent0:                 episode reward: -0.8696,                 loss: nan
agent1:                 episode reward: 0.8696,                 loss: 0.3823
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 106.5986 s
agent0:                 episode reward: -1.0601,                 loss: nan
agent1:                 episode reward: 1.0601,                 loss: 0.3789
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5882s / 107.1867 s
agent0:                 episode reward: -0.6450,                 loss: nan
agent1:                 episode reward: 0.6450,                 loss: 0.3824
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5912s / 107.7779 s
agent0:                 episode reward: -0.6547,                 loss: nan
agent1:                 episode reward: 0.6547,                 loss: 0.3799
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 108.3743 s
agent0:                 episode reward: -1.1136,                 loss: nan
agent1:                 episode reward: 1.1136,                 loss: 0.3795
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5924s / 108.9667 s
agent0:                 episode reward: -0.3512,                 loss: nan
agent1:                 episode reward: 0.3512,                 loss: 0.3787
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5997s / 109.5664 s
agent0:                 episode reward: -0.5930,                 loss: nan
agent1:                 episode reward: 0.5930,                 loss: 0.3792
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5884s / 110.1549 s
agent0:                 episode reward: -0.9611,                 loss: nan
agent1:                 episode reward: 0.9611,                 loss: 0.3790
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 110.7525 s
agent0:                 episode reward: -0.5189,                 loss: nan
agent1:                 episode reward: 0.5189,                 loss: 0.3804
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5875s / 111.3400 s
agent0:                 episode reward: -1.1258,                 loss: nan
agent1:                 episode reward: 1.1258,                 loss: 0.3777
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5992s / 111.9392 s
agent0:                 episode reward: -0.6405,                 loss: nan
agent1:                 episode reward: 0.6405,                 loss: 0.3805
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5974s / 112.5366 s
agent0:                 episode reward: -0.4711,                 loss: nan
agent1:                 episode reward: 0.4711,                 loss: 0.3735
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 113.1319 s
agent0:                 episode reward: -0.9527,                 loss: nan
agent1:                 episode reward: 0.9527,                 loss: 0.3728
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5924s / 113.7243 s
agent0:                 episode reward: -0.8044,                 loss: nan
agent1:                 episode reward: 0.8044,                 loss: 0.3703
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 114.3182 s
agent0:                 episode reward: -0.2619,                 loss: nan
agent1:                 episode reward: 0.2619,                 loss: 0.3712
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 114.9077 s
agent0:                 episode reward: -0.6031,                 loss: nan
agent1:                 episode reward: 0.6031,                 loss: 0.3719
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 115.5008 s
agent0:                 episode reward: -0.8318,                 loss: nan
agent1:                 episode reward: 0.8318,                 loss: 0.3715
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 116.0951 s
agent0:                 episode reward: -0.5370,                 loss: nan
agent1:                 episode reward: 0.5370,                 loss: 0.3727
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5973s / 116.6924 s
agent0:                 episode reward: -0.8344,                 loss: nan
agent1:                 episode reward: 0.8344,                 loss: 0.3715
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6066s / 117.2990 s
agent0:                 episode reward: -0.9822,                 loss: nan
agent1:                 episode reward: 0.9822,                 loss: 0.3727
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6008s / 117.8998 s
agent0:                 episode reward: -0.7988,                 loss: nan
agent1:                 episode reward: 0.7988,                 loss: 0.3715
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6047s / 118.5045 s
agent0:                 episode reward: -0.8577,                 loss: nan
agent1:                 episode reward: 0.8577,                 loss: 0.3730
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5956s / 119.1001 s
agent0:                 episode reward: -1.0739,                 loss: nan
agent1:                 episode reward: 1.0739,                 loss: 0.3703
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5925s / 119.6927 s
agent0:                 episode reward: -1.0373,                 loss: nan
agent1:                 episode reward: 1.0373,                 loss: 0.3699
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5908s / 120.2835 s
agent0:                 episode reward: -0.9020,                 loss: nan
agent1:                 episode reward: 0.9020,                 loss: 0.3724
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5900s / 120.8735 s
agent0:                 episode reward: -0.3743,                 loss: nan
agent1:                 episode reward: 0.3743,                 loss: 0.3704
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 121.4634 s
agent0:                 episode reward: -1.0451,                 loss: nan
agent1:                 episode reward: 1.0451,                 loss: 0.3695
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 122.0561 s
agent0:                 episode reward: -0.6899,                 loss: nan
agent1:                 episode reward: 0.6899,                 loss: 0.3748
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5983s / 122.6544 s
agent0:                 episode reward: -0.8118,                 loss: nan
agent1:                 episode reward: 0.8118,                 loss: 0.3799
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5962s / 123.2506 s
agent0:                 episode reward: -1.0530,                 loss: nan
agent1:                 episode reward: 1.0530,                 loss: 0.3827
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5932s / 123.8438 s
agent0:                 episode reward: -0.4108,                 loss: nan
agent1:                 episode reward: 0.4108,                 loss: 0.3829
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5921s / 124.4359 s
agent0:                 episode reward: -0.8038,                 loss: nan
agent1:                 episode reward: 0.8038,                 loss: 0.3788
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5959s / 125.0318 s
agent0:                 episode reward: -1.1600,                 loss: nan
agent1:                 episode reward: 1.1600,                 loss: 0.3807
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5979s / 125.6296 s
agent0:                 episode reward: -0.8733,                 loss: nan
agent1:                 episode reward: 0.8733,                 loss: 0.3820
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5988s / 126.2285 s
agent0:                 episode reward: -0.7212,                 loss: nan
agent1:                 episode reward: 0.7212,                 loss: 0.3797
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6007s / 126.8292 s
agent0:                 episode reward: -0.9263,                 loss: nan
agent1:                 episode reward: 0.9263,                 loss: 0.3822
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5987s / 127.4279 s
agent0:                 episode reward: -0.6558,                 loss: nan
agent1:                 episode reward: 0.6558,                 loss: 0.3803
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5963s / 128.0242 s
agent0:                 episode reward: -0.3412,                 loss: nan
agent1:                 episode reward: 0.3412,                 loss: 0.3828
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 128.6231 s
agent0:                 episode reward: -0.8022,                 loss: nan
agent1:                 episode reward: 0.8022,                 loss: 0.3816
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 129.2199 s
agent0:                 episode reward: -0.3504,                 loss: nan
agent1:                 episode reward: 0.3504,                 loss: 0.3782
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5936s / 129.8135 s
agent0:                 episode reward: -0.5682,                 loss: nan
agent1:                 episode reward: 0.5682,                 loss: 0.3808
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5970s / 130.4105 s
agent0:                 episode reward: -0.3985,                 loss: nan
agent1:                 episode reward: 0.3985,                 loss: 0.3814
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 131.0001 s
agent0:                 episode reward: -1.2511,                 loss: nan
agent1:                 episode reward: 1.2511,                 loss: 0.3814
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 131.5959 s
agent0:                 episode reward: -0.9120,                 loss: nan
agent1:                 episode reward: 0.9120,                 loss: 0.3798
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 132.1941 s
agent0:                 episode reward: -0.9110,                 loss: nan
agent1:                 episode reward: 0.9110,                 loss: 0.3757
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 132.7924 s
agent0:                 episode reward: -0.5315,                 loss: nan
agent1:                 episode reward: 0.5315,                 loss: 0.3718
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5860s / 133.3784 s
agent0:                 episode reward: -0.6118,                 loss: nan
agent1:                 episode reward: 0.6118,                 loss: 0.3740
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 133.9739 s
agent0:                 episode reward: -0.3362,                 loss: nan
agent1:                 episode reward: 0.3362,                 loss: 0.3720
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5999s / 134.5738 s
agent0:                 episode reward: -0.5996,                 loss: nan
agent1:                 episode reward: 0.5996,                 loss: 0.3731
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6051s / 135.1789 s
agent0:                 episode reward: -0.4780,                 loss: nan
agent1:                 episode reward: 0.4780,                 loss: 0.3700
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6023s / 135.7811 s
agent0:                 episode reward: -0.9969,                 loss: nan
agent1:                 episode reward: 0.9969,                 loss: 0.3711
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6033s / 136.3845 s
agent0:                 episode reward: -0.6932,                 loss: nan
agent1:                 episode reward: 0.6932,                 loss: 0.3724
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6063s / 136.9908 s
agent0:                 episode reward: -0.9712,                 loss: nan
agent1:                 episode reward: 0.9712,                 loss: 0.3747
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5963s / 137.5870 s
agent0:                 episode reward: -1.1383,                 loss: nan
agent1:                 episode reward: 1.1383,                 loss: 0.3710
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6040s / 138.1911 s
agent0:                 episode reward: -0.5088,                 loss: nan
agent1:                 episode reward: 0.5088,                 loss: 0.3702
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6009s / 138.7919 s
agent0:                 episode reward: -0.5894,                 loss: nan
agent1:                 episode reward: 0.5894,                 loss: 0.3725
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5992s / 139.3911 s
agent0:                 episode reward: -0.9021,                 loss: nan
agent1:                 episode reward: 0.9021,                 loss: 0.3706
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6039s / 139.9950 s
agent0:                 episode reward: -0.7760,                 loss: nan
agent1:                 episode reward: 0.7760,                 loss: 0.3702
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 140.5963 s
agent0:                 episode reward: -1.0202,                 loss: nan
agent1:                 episode reward: 1.0202,                 loss: 0.3743
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6009s / 141.1971 s
agent0:                 episode reward: -0.7325,                 loss: nan
agent1:                 episode reward: 0.7325,                 loss: 0.3682
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6002s / 141.7973 s
agent0:                 episode reward: -0.7409,                 loss: nan
agent1:                 episode reward: 0.7409,                 loss: 0.3728
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6031s / 142.4005 s
agent0:                 episode reward: -0.3571,                 loss: nan
agent1:                 episode reward: 0.3571,                 loss: 0.3850
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 142.9994 s
agent0:                 episode reward: -0.9449,                 loss: nan
agent1:                 episode reward: 0.9449,                 loss: 0.3851
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6029s / 143.6023 s
agent0:                 episode reward: -0.9276,                 loss: nan
agent1:                 episode reward: 0.9276,                 loss: 0.3844
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6017s / 144.2040 s
agent0:                 episode reward: -0.4989,                 loss: nan
agent1:                 episode reward: 0.4989,                 loss: 0.3848
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5963s / 144.8003 s
agent0:                 episode reward: -0.3189,                 loss: nan
agent1:                 episode reward: 0.3189,                 loss: 0.3832
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6114s / 145.4117 s
agent0:                 episode reward: -0.7763,                 loss: nan
agent1:                 episode reward: 0.7763,                 loss: 0.3828
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 146.0130 s
agent0:                 episode reward: -1.0062,                 loss: nan
agent1:                 episode reward: 1.0062,                 loss: 0.3839
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6036s / 146.6167 s
agent0:                 episode reward: -1.0110,                 loss: nan
agent1:                 episode reward: 1.0110,                 loss: 0.3834
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6022s / 147.2189 s
agent0:                 episode reward: -1.1036,                 loss: nan
agent1:                 episode reward: 1.1036,                 loss: 0.3821
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6003s / 147.8192 s
agent0:                 episode reward: -0.7414,                 loss: nan
agent1:                 episode reward: 0.7414,                 loss: 0.3813
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6127s / 148.4319 s
agent0:                 episode reward: -0.5218,                 loss: nan
agent1:                 episode reward: 0.5218,                 loss: 0.3799
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5998s / 149.0316 s
agent0:                 episode reward: -0.9365,                 loss: nan
agent1:                 episode reward: 0.9365,                 loss: 0.3831
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6019s / 149.6335 s
agent0:                 episode reward: -0.4860,                 loss: nan
agent1:                 episode reward: 0.4860,                 loss: 0.3820
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6123s / 150.2458 s
agent0:                 episode reward: -0.7352,                 loss: nan
agent1:                 episode reward: 0.7352,                 loss: 0.3851
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6152s / 150.8610 s
agent0:                 episode reward: -0.8812,                 loss: nan
agent1:                 episode reward: 0.8812,                 loss: 0.3821
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6117s / 151.4727 s
agent0:                 episode reward: -0.8013,                 loss: nan
agent1:                 episode reward: 0.8013,                 loss: 0.3826
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 152.0715 s
agent0:                 episode reward: -0.8062,                 loss: nan
agent1:                 episode reward: 0.8062,                 loss: 0.3801
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5979s / 152.6695 s
agent0:                 episode reward: -0.6989,                 loss: nan
agent1:                 episode reward: 0.6989,                 loss: 0.3789
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6081s / 153.2776 s
agent0:                 episode reward: -1.0387,                 loss: nan
agent1:                 episode reward: 1.0387,                 loss: 0.3787
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6061s / 153.8836 s
agent0:                 episode reward: -0.5207,                 loss: nan
agent1:                 episode reward: 0.5207,                 loss: 0.3779
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6090s / 154.4927 s
agent0:                 episode reward: -1.0707,                 loss: nan
agent1:                 episode reward: 1.0707,                 loss: 0.3793
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6043s / 155.0970 s
agent0:                 episode reward: -0.6327,                 loss: nan
agent1:                 episode reward: 0.6327,                 loss: 0.3776
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6007s / 155.6977 s
agent0:                 episode reward: -0.6355,                 loss: nan
agent1:                 episode reward: 0.6355,                 loss: 0.3754
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 156.2989 s
agent0:                 episode reward: -0.6235,                 loss: nan
agent1:                 episode reward: 0.6235,                 loss: 0.3782
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6034s / 156.9023 s
agent0:                 episode reward: -0.8266,                 loss: nan
agent1:                 episode reward: 0.8266,                 loss: 0.3766
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 157.4970 s
agent0:                 episode reward: -0.5097,                 loss: nan
agent1:                 episode reward: 0.5097,                 loss: 0.3788
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6027s / 158.0996 s
agent0:                 episode reward: -0.8016,                 loss: nan
agent1:                 episode reward: 0.8016,                 loss: 0.3803
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5995s / 158.6992 s
agent0:                 episode reward: -0.8240,                 loss: nan
agent1:                 episode reward: 0.8240,                 loss: 0.3782
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 159.2980 s
agent0:                 episode reward: -0.6533,                 loss: nan
agent1:                 episode reward: 0.6533,                 loss: 0.3774
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6079s / 159.9060 s
agent0:                 episode reward: -0.4313,                 loss: nan
agent1:                 episode reward: 0.4313,                 loss: 0.3781
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6132s / 160.5192 s
agent0:                 episode reward: -0.7579,                 loss: nan
agent1:                 episode reward: 0.7579,                 loss: 0.3775
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6050s / 161.1241 s
agent0:                 episode reward: -0.6150,                 loss: nan
agent1:                 episode reward: 0.6150,                 loss: 0.3771
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 161.7216 s
agent0:                 episode reward: -1.0240,                 loss: nan
agent1:                 episode reward: 1.0240,                 loss: 0.3796
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 162.3229 s
agent0:                 episode reward: -0.6355,                 loss: nan
agent1:                 episode reward: 0.6355,                 loss: 0.3715
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6027s / 162.9256 s
agent0:                 episode reward: -0.4847,                 loss: nan
agent1:                 episode reward: 0.4847,                 loss: 0.3638
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6061s / 163.5317 s
agent0:                 episode reward: -0.5327,                 loss: nan
agent1:                 episode reward: 0.5327,                 loss: 0.3641
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 164.1338 s
agent0:                 episode reward: -0.5871,                 loss: nan
agent1:                 episode reward: 0.5871,                 loss: 0.3651
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6036s / 164.7374 s
agent0:                 episode reward: -0.5856,                 loss: nan
agent1:                 episode reward: 0.5856,                 loss: 0.3663
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6058s / 165.3432 s
agent0:                 episode reward: -0.8494,                 loss: nan
agent1:                 episode reward: 0.8494,                 loss: 0.3628
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5987s / 165.9418 s
agent0:                 episode reward: -0.6620,                 loss: nan
agent1:                 episode reward: 0.6620,                 loss: 0.3656
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6040s / 166.5458 s
agent0:                 episode reward: -0.6107,                 loss: nan
agent1:                 episode reward: 0.6107,                 loss: 0.3639
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5959s / 167.1417 s
agent0:                 episode reward: -0.8993,                 loss: nan
agent1:                 episode reward: 0.8993,                 loss: 0.3640
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5972s / 167.7390 s
agent0:                 episode reward: -0.6599,                 loss: nan
agent1:                 episode reward: 0.6599,                 loss: 0.3622
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5969s / 168.3359 s
agent0:                 episode reward: -0.7415,                 loss: nan
agent1:                 episode reward: 0.7415,                 loss: 0.3658
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 168.9313 s
agent0:                 episode reward: -0.5851,                 loss: nan
agent1:                 episode reward: 0.5851,                 loss: 0.3659
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5999s / 169.5312 s
agent0:                 episode reward: -0.9669,                 loss: nan
agent1:                 episode reward: 0.9669,                 loss: 0.3626
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5995s / 170.1307 s
agent0:                 episode reward: -0.6878,                 loss: nan
agent1:                 episode reward: 0.6878,                 loss: 0.3636
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6002s / 170.7308 s
agent0:                 episode reward: -0.6103,                 loss: nan
agent1:                 episode reward: 0.6103,                 loss: 0.3619
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6000s / 171.3309 s
agent0:                 episode reward: -1.0951,                 loss: nan
agent1:                 episode reward: 1.0951,                 loss: 0.3656
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5970s / 171.9279 s
agent0:                 episode reward: -0.4887,                 loss: nan
agent1:                 episode reward: 0.4887,                 loss: 0.3653
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6049s / 172.5328 s
agent0:                 episode reward: -0.8634,                 loss: nan
agent1:                 episode reward: 0.8634,                 loss: 0.3800
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6000s / 173.1327 s
agent0:                 episode reward: -0.7213,                 loss: nan
agent1:                 episode reward: 0.7213,                 loss: 0.3829
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5999s / 173.7327 s
agent0:                 episode reward: -0.6373,                 loss: nan
agent1:                 episode reward: 0.6373,                 loss: 0.3828
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6015s / 174.3342 s
agent0:                 episode reward: -0.8479,                 loss: nan
agent1:                 episode reward: 0.8479,                 loss: 0.3823
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 174.9332 s
agent0:                 episode reward: -1.0054,                 loss: nan
agent1:                 episode reward: 1.0054,                 loss: 0.3825
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6113s / 175.5445 s
agent0:                 episode reward: -1.2189,                 loss: nan
agent1:                 episode reward: 1.2189,                 loss: 0.3821
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6140s / 176.1585 s
agent0:                 episode reward: -0.5015,                 loss: nan
agent1:                 episode reward: 0.5015,                 loss: 0.3826
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6100s / 176.7685 s
agent0:                 episode reward: -0.7764,                 loss: nan
agent1:                 episode reward: 0.7764,                 loss: 0.3830
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6132s / 177.3817 s
agent0:                 episode reward: -0.6499,                 loss: nan
agent1:                 episode reward: 0.6499,                 loss: 0.3814
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6054s / 177.9871 s
agent0:                 episode reward: -0.6334,                 loss: nan
agent1:                 episode reward: 0.6334,                 loss: 0.3816
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6082s / 178.5953 s
agent0:                 episode reward: -0.9705,                 loss: nan
agent1:                 episode reward: 0.9705,                 loss: 0.3822
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 179.1965 s
agent0:                 episode reward: -0.5230,                 loss: nan
agent1:                 episode reward: 0.5230,                 loss: 0.3810
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6019s / 179.7984 s
agent0:                 episode reward: -0.1500,                 loss: nan
agent1:                 episode reward: 0.1500,                 loss: 0.3831
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6115s / 180.4099 s
agent0:                 episode reward: -0.7913,                 loss: nan
agent1:                 episode reward: 0.7913,                 loss: 0.3805
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6076s / 181.0175 s
agent0:                 episode reward: -1.0198,                 loss: nan
agent1:                 episode reward: 1.0198,                 loss: 0.3814
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6107s / 181.6283 s
agent0:                 episode reward: -0.8337,                 loss: nan
agent1:                 episode reward: 0.8337,                 loss: 0.3821
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6082s / 182.2365 s
agent0:                 episode reward: -0.8595,                 loss: nan
agent1:                 episode reward: 0.8595,                 loss: 0.3802
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6024s / 182.8389 s
agent0:                 episode reward: -0.5045,                 loss: nan
agent1:                 episode reward: 0.5045,                 loss: 0.3780
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6025s / 183.4414 s
agent0:                 episode reward: -1.1611,                 loss: nan
agent1:                 episode reward: 1.1611,                 loss: 0.3798
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6090s / 184.0504 s
agent0:                 episode reward: -0.5444,                 loss: nan
agent1:                 episode reward: 0.5444,                 loss: 0.3787
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6018s / 184.6522 s
agent0:                 episode reward: -0.6608,                 loss: nan
agent1:                 episode reward: 0.6608,                 loss: 0.3787
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6024s / 185.2545 s
agent0:                 episode reward: -0.8956,                 loss: nan
agent1:                 episode reward: 0.8956,                 loss: 0.3801
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6088s / 185.8634 s
agent0:                 episode reward: -0.7528,                 loss: nan
agent1:                 episode reward: 0.7528,                 loss: 0.3781
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6083s / 186.4717 s
agent0:                 episode reward: -0.6258,                 loss: nan
agent1:                 episode reward: 0.6258,                 loss: 0.3768
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6069s / 187.0785 s
agent0:                 episode reward: -0.6765,                 loss: nan
agent1:                 episode reward: 0.6765,                 loss: 0.3782
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6053s / 187.6838 s
agent0:                 episode reward: -0.7842,                 loss: nan
agent1:                 episode reward: 0.7842,                 loss: 0.3779
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6046s / 188.2884 s
agent0:                 episode reward: -0.4308,                 loss: nan
agent1:                 episode reward: 0.4308,                 loss: 0.3799
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6025s / 188.8910 s
agent0:                 episode reward: -0.5173,                 loss: nan
agent1:                 episode reward: 0.5173,                 loss: 0.3813
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6145s / 189.5054 s
agent0:                 episode reward: -0.7791,                 loss: nan
agent1:                 episode reward: 0.7791,                 loss: 0.3799
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6089s / 190.1144 s
agent0:                 episode reward: -0.7773,                 loss: nan
agent1:                 episode reward: 0.7773,                 loss: 0.3792
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6148s / 190.7291 s
agent0:                 episode reward: -0.5630,                 loss: nan
agent1:                 episode reward: 0.5630,                 loss: 0.3797
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6075s / 191.3366 s
agent0:                 episode reward: -0.2591,                 loss: nan
agent1:                 episode reward: 0.2591,                 loss: 0.3792
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6097s / 191.9464 s
agent0:                 episode reward: -1.0682,                 loss: nan
agent1:                 episode reward: 1.0682,                 loss: 0.3791
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6138s / 192.5602 s
agent0:                 episode reward: -0.7327,                 loss: nan
agent1:                 episode reward: 0.7327,                 loss: 0.3713
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6113s / 193.1715 s
agent0:                 episode reward: -0.8315,                 loss: nan
agent1:                 episode reward: 0.8315,                 loss: 0.3683
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6149s / 193.7863 s
agent0:                 episode reward: -0.7660,                 loss: nan
agent1:                 episode reward: 0.7660,                 loss: 0.3656