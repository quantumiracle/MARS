pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [763, 126, 47, 249, 820]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'eta': 0.1}}
Save models to : /home/zihan/research/MARS/data/model/20220429_0152/pettingzoo_pong_v2_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220429_0152/pettingzoo_pong_v2_nfsp.
Episode: 1/10000 (0.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 3.4892s / 3.4892 s
env0_first_0:                 episode reward: 4.0000,                 loss: nan
env0_second_0:                 episode reward: -4.0000,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
env2_first_0:                 episode reward: 8.0000,                 loss: nan
env2_second_0:                 episode reward: -8.0000,                 loss: nan
env3_first_0:                 episode reward: 6.0000,                 loss: nan
env3_second_0:                 episode reward: -6.0000,                 loss: nan
env4_first_0:                 episode reward: -2.0000,                 loss: nan
env4_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 20.5502s / 24.0394 s
env0_first_0:                 episode reward: -0.5000,                 loss: nan
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
env3_first_0:                 episode reward: 3.5000,                 loss: nan
env3_second_0:                 episode reward: -3.5000,                 loss: nan
env4_first_0:                 episode reward: 0.7500,                 loss: nan
env4_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 63.5950s / 87.6343 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.1341
env0_second_0:                 episode reward: -1.8500,                 loss: 0.1421
env1_first_0:                 episode reward: 4.8500,                 loss: nan
env1_second_0:                 episode reward: -4.8500,                 loss: nan
env2_first_0:                 episode reward: 1.7500,                 loss: nan
env2_second_0:                 episode reward: -1.7500,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 2.2000,                 loss: nan
env4_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 138.9270s / 226.5614 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.0279
env0_second_0:                 episode reward: -2.6000,                 loss: 0.0414
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
env2_first_0:                 episode reward: 2.7500,                 loss: nan
env2_second_0:                 episode reward: -2.7500,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 147.9439s / 374.5053 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.0195
env0_second_0:                 episode reward: -2.5500,                 loss: 0.0246
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 1.9000,                 loss: nan
env4_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 181.2777s / 555.7830 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.0158
env0_second_0:                 episode reward: -2.6500,                 loss: 0.0206
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: 2.4500,                 loss: nan
env3_second_0:                 episode reward: -2.4500,                 loss: nan
env4_first_0:                 episode reward: 0.9000,                 loss: nan
env4_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 193.7127s / 749.4957 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0152
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0192
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
env2_first_0:                 episode reward: 1.4000,                 loss: nan
env2_second_0:                 episode reward: -1.4000,                 loss: nan
env3_first_0:                 episode reward: 2.2000,                 loss: nan
env3_second_0:                 episode reward: -2.2000,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 206.6620s / 956.1577 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0151
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0168
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 1.4000,                 loss: nan
env4_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.7435s / 1176.9012 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0152
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0160
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 0.7000,                 loss: nan
env4_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 232.8410s / 1409.7422 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0153
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0155
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.6000,                 loss: nan
env3_second_0:                 episode reward: -0.6000,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 242.3627s / 1652.1049 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0148
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0153
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -2.5000,                 loss: nan
env2_second_0:                 episode reward: 2.5000,                 loss: nan
env3_first_0:                 episode reward: -2.2000,                 loss: nan
env3_second_0:                 episode reward: 2.2000,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 255.6262s / 1907.7311 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0146
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0148
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.8500,                 loss: nan
env4_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 270.5651s / 2178.2962 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0142
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0146
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 2.2500,                 loss: nan
env4_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 282.1391s / 2460.4353 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.0142
env0_second_0:                 episode reward: -3.1500,                 loss: 0.0147
env1_first_0:                 episode reward: 2.3000,                 loss: nan
env1_second_0:                 episode reward: -2.3000,                 loss: nan
env2_first_0:                 episode reward: 2.1500,                 loss: nan
env2_second_0:                 episode reward: -2.1500,                 loss: nan
env3_first_0:                 episode reward: 3.0500,                 loss: nan
env3_second_0:                 episode reward: -3.0500,                 loss: nan
env4_first_0:                 episode reward: 2.2500,                 loss: nan
env4_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 297.6815s / 2758.1168 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.0144
env0_second_0:                 episode reward: -3.5500,                 loss: 0.0148
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
env2_first_0:                 episode reward: 4.0000,                 loss: nan
env2_second_0:                 episode reward: -4.0000,                 loss: nan
env3_first_0:                 episode reward: 4.4000,                 loss: nan
env3_second_0:                 episode reward: -4.4000,                 loss: nan
env4_first_0:                 episode reward: 2.9000,                 loss: nan
env4_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 312.8529s / 3070.9697 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0139
env0_second_0:                 episode reward: -1.8500,                 loss: 0.0140
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 3.4000,                 loss: nan
env4_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 328.4756s / 3399.4453 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0140
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0138
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 0.7000,                 loss: nan
env3_second_0:                 episode reward: -0.7000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 341.3084s / 3740.7537 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0141
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0140
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 342.9488s / 4083.7025 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0143
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0137
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -0.8000,                 loss: nan
env2_second_0:                 episode reward: 0.8000,                 loss: nan
env3_first_0:                 episode reward: -2.0000,                 loss: nan
env3_second_0:                 episode reward: 2.0000,                 loss: nan
env4_first_0:                 episode reward: -2.8000,                 loss: nan
env4_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 342.0564s / 4425.7589 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0145
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0131
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
env3_first_0:                 episode reward: -1.7000,                 loss: nan
env3_second_0:                 episode reward: 1.7000,                 loss: nan
env4_first_0:                 episode reward: -2.1000,                 loss: nan
env4_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 346.0046s / 4771.7635 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0140
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0138
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -1.9500,                 loss: nan
env2_second_0:                 episode reward: 1.9500,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: -3.0000,                 loss: nan
env4_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 344.0753s / 5115.8388 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0141
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0143
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
env3_first_0:                 episode reward: -3.9500,                 loss: nan
env3_second_0:                 episode reward: 3.9500,                 loss: nan
env4_first_0:                 episode reward: -3.6500,                 loss: nan
env4_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 342.0570s / 5457.8958 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0140
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0144
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
env2_first_0:                 episode reward: -2.9500,                 loss: nan
env2_second_0:                 episode reward: 2.9500,                 loss: nan
env3_first_0:                 episode reward: -4.2500,                 loss: nan
env3_second_0:                 episode reward: 4.2500,                 loss: nan
env4_first_0:                 episode reward: -3.3000,                 loss: nan
env4_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 341.9360s / 5799.8318 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.0142
env0_second_0:                 episode reward: 4.2500,                 loss: 0.0144
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
env2_first_0:                 episode reward: -4.9000,                 loss: nan
env2_second_0:                 episode reward: 4.9000,                 loss: nan
env3_first_0:                 episode reward: -4.0500,                 loss: nan
env3_second_0:                 episode reward: 4.0500,                 loss: nan
env4_first_0:                 episode reward: -3.2500,                 loss: nan
env4_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 340.7788s / 6140.6106 s
env0_first_0:                 episode reward: -5.1500,                 loss: 0.0150
env0_second_0:                 episode reward: 5.1500,                 loss: 0.0148
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
env2_first_0:                 episode reward: -3.9500,                 loss: nan
env2_second_0:                 episode reward: 3.9500,                 loss: nan
env3_first_0:                 episode reward: -4.4500,                 loss: nan
env3_second_0:                 episode reward: 4.4500,                 loss: nan
env4_first_0:                 episode reward: -4.5000,                 loss: nan
env4_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 341.2959s / 6481.9066 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0153
env0_second_0:                 episode reward: 4.0500,                 loss: 0.0152
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -3.8000,                 loss: nan
env2_second_0:                 episode reward: 3.8000,                 loss: nan
env3_first_0:                 episode reward: -4.5000,                 loss: nan
env3_second_0:                 episode reward: 4.5000,                 loss: nan
env4_first_0:                 episode reward: -3.5500,                 loss: nan
env4_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 340.0960s / 6822.0026 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0151
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0147
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
env2_first_0:                 episode reward: -4.3500,                 loss: nan
env2_second_0:                 episode reward: 4.3500,                 loss: nan
env3_first_0:                 episode reward: -4.3000,                 loss: nan
env3_second_0:                 episode reward: 4.3000,                 loss: nan
env4_first_0:                 episode reward: -3.2000,                 loss: nan
env4_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 339.9788s / 7161.9814 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0150
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0149
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
env2_first_0:                 episode reward: -4.3500,                 loss: nan
env2_second_0:                 episode reward: 4.3500,                 loss: nan
env3_first_0:                 episode reward: -3.4500,                 loss: nan
env3_second_0:                 episode reward: 3.4500,                 loss: nan
env4_first_0:                 episode reward: -3.8000,                 loss: nan
env4_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 341.1063s / 7503.0877 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0155
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0164
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
env2_first_0:                 episode reward: -3.4500,                 loss: nan
env2_second_0:                 episode reward: 3.4500,                 loss: nan
env3_first_0:                 episode reward: -2.8000,                 loss: nan
env3_second_0:                 episode reward: 2.8000,                 loss: nan
env4_first_0:                 episode reward: -3.0500,                 loss: nan
env4_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 344.1786s / 7847.2664 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.0172
env0_second_0:                 episode reward: 2.3000,                 loss: 0.0171
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
env2_first_0:                 episode reward: -3.2500,                 loss: nan
env2_second_0:                 episode reward: 3.2500,                 loss: nan
env3_first_0:                 episode reward: -2.5000,                 loss: nan
env3_second_0:                 episode reward: 2.5000,                 loss: nan
env4_first_0:                 episode reward: -2.1000,                 loss: nan
env4_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 341.0368s / 8188.3032 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0173
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0185
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
env2_first_0:                 episode reward: -2.7000,                 loss: nan
env2_second_0:                 episode reward: 2.7000,                 loss: nan
env3_first_0:                 episode reward: -2.8500,                 loss: nan
env3_second_0:                 episode reward: 2.8500,                 loss: nan
env4_first_0:                 episode reward: -3.1500,                 loss: nan
env4_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 342.4924s / 8530.7956 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0191
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0202
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
env2_first_0:                 episode reward: -3.3000,                 loss: nan
env2_second_0:                 episode reward: 3.3000,                 loss: nan
env3_first_0:                 episode reward: -3.1500,                 loss: nan
env3_second_0:                 episode reward: 3.1500,                 loss: nan
env4_first_0:                 episode reward: -3.4500,                 loss: nan
env4_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 341.0291s / 8871.8247 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0201
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0220
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
env2_first_0:                 episode reward: -3.1000,                 loss: nan
env2_second_0:                 episode reward: 3.1000,                 loss: nan
env3_first_0:                 episode reward: -2.1500,                 loss: nan
env3_second_0:                 episode reward: 2.1500,                 loss: nan
env4_first_0:                 episode reward: -2.8500,                 loss: nan
env4_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 341.2186s / 9213.0433 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0226
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0232
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
env2_first_0:                 episode reward: -2.4000,                 loss: nan
env2_second_0:                 episode reward: 2.4000,                 loss: nan
env3_first_0:                 episode reward: -2.3000,                 loss: nan
env3_second_0:                 episode reward: 2.3000,                 loss: nan
env4_first_0:                 episode reward: -2.1000,                 loss: nan
env4_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 344.1998s / 9557.2431 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0233
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0241
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
env3_first_0:                 episode reward: -1.6500,                 loss: nan
env3_second_0:                 episode reward: 1.6500,                 loss: nan
env4_first_0:                 episode reward: -2.1500,                 loss: nan
env4_second_0:                 episode reward: 2.1500,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 341.7867s / 9899.0297 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0231
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0260
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
env3_first_0:                 episode reward: -1.7500,                 loss: nan
env3_second_0:                 episode reward: 1.7500,                 loss: nan
env4_first_0:                 episode reward: -1.6000,                 loss: nan
env4_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 343.9044s / 10242.9341 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0240
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0274
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
env2_first_0:                 episode reward: -2.9500,                 loss: nan
env2_second_0:                 episode reward: 2.9500,                 loss: nan
env3_first_0:                 episode reward: -2.2500,                 loss: nan
env3_second_0:                 episode reward: 2.2500,                 loss: nan
env4_first_0:                 episode reward: -1.4000,                 loss: nan
env4_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 345.0657s / 10587.9998 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0236
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0288
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
env3_first_0:                 episode reward: -1.5000,                 loss: nan
env3_second_0:                 episode reward: 1.5000,                 loss: nan
env4_first_0:                 episode reward: -2.0000,                 loss: nan
env4_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 346.2529s / 10934.2527 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0249
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0269
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
env3_first_0:                 episode reward: -1.2500,                 loss: nan
env3_second_0:                 episode reward: 1.2500,                 loss: nan
env4_first_0:                 episode reward: -1.2000,                 loss: nan
env4_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 344.2502s / 11278.5029 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0265
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0272
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.8000,                 loss: nan
env4_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 344.4322s / 11622.9351 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0276
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0272
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -1.0500,                 loss: nan
env3_second_0:                 episode reward: 1.0500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 343.3082s / 11966.2432 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0291
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0308
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -1.2000,                 loss: nan
env3_second_0:                 episode reward: 1.2000,                 loss: nan
env4_first_0:                 episode reward: -0.8000,                 loss: nan
env4_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 346.1560s / 12312.3992 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0310
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0330
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 344.8827s / 12657.2819 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0316
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0356
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -1.2500,                 loss: nan
env3_second_0:                 episode reward: 1.2500,                 loss: nan
env4_first_0:                 episode reward: -1.5000,                 loss: nan
env4_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 346.2903s / 13003.5722 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0329
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0370
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -1.4500,                 loss: nan
env4_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 346.0737s / 13349.6459 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0363
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0398
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
env3_first_0:                 episode reward: -1.7500,                 loss: nan
env3_second_0:                 episode reward: 1.7500,                 loss: nan
env4_first_0:                 episode reward: -0.9500,                 loss: nan
env4_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 348.1911s / 13697.8369 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0302
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0401
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 345.6914s / 14043.5283 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0316
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0393
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -1.4500,                 loss: nan
env4_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 347.5321s / 14391.0604 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0310
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0385
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: -1.2000,                 loss: nan
env2_second_0:                 episode reward: 1.2000,                 loss: nan
env3_first_0:                 episode reward: -0.9500,                 loss: nan
env3_second_0:                 episode reward: 0.9500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 348.3695s / 14739.4299 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0351
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0345
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: -1.6000,                 loss: nan
env4_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 346.1443s / 15085.5742 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0362
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0335
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
env3_first_0:                 episode reward: -1.4500,                 loss: nan
env3_second_0:                 episode reward: 1.4500,                 loss: nan
env4_first_0:                 episode reward: -1.5500,                 loss: nan
env4_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 348.5694s / 15434.1435 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0371
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0341
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -0.5000,                 loss: nan
env4_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 346.5592s / 15780.7027 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0399
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0325
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -1.0000,                 loss: nan
env4_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 349.4909s / 16130.1937 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0397
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0353
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.7500,                 loss: nan
env2_second_0:                 episode reward: 0.7500,                 loss: nan
env3_first_0:                 episode reward: -0.8000,                 loss: nan
env3_second_0:                 episode reward: 0.8000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 346.2896s / 16476.4833 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0389
env0_second_0:                 episode reward: -1.9000,                 loss: 0.0350
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 1.7000,                 loss: nan
env3_second_0:                 episode reward: -1.7000,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 346.8963s / 16823.3795 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0394
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0370
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
env3_first_0:                 episode reward: 0.8500,                 loss: nan
env3_second_0:                 episode reward: -0.8500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 346.0418s / 17169.4213 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0408
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0343
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 348.0122s / 17517.4335 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0392
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0335
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 349.0986s / 17866.5320 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0414
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0371
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 345.3733s / 18211.9054 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0411
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0430
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.9500,                 loss: nan
env3_second_0:                 episode reward: 0.9500,                 loss: nan
env4_first_0:                 episode reward: -0.5000,                 loss: nan
env4_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 347.9725s / 18559.8779 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0478
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0463
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
env3_first_0:                 episode reward: -1.5500,                 loss: nan
env3_second_0:                 episode reward: 1.5500,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 347.6874s / 18907.5653 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0433
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0459
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: -2.0500,                 loss: nan
env2_second_0:                 episode reward: 2.0500,                 loss: nan
env3_first_0:                 episode reward: -2.0500,                 loss: nan
env3_second_0:                 episode reward: 2.0500,                 loss: nan
env4_first_0:                 episode reward: -1.8500,                 loss: nan
env4_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 349.4282s / 19256.9935 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0352
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0398
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
env2_first_0:                 episode reward: -1.7000,                 loss: nan
env2_second_0:                 episode reward: 1.7000,                 loss: nan
env3_first_0:                 episode reward: -0.7500,                 loss: nan
env3_second_0:                 episode reward: 0.7500,                 loss: nan
env4_first_0:                 episode reward: -2.0000,                 loss: nan
env4_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 346.7307s / 19603.7241 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0363
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0324
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: 1.1000,                 loss: nan
env2_second_0:                 episode reward: -1.1000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 347.6986s / 19951.4227 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0386
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0329
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.6000,                 loss: nan
env4_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 347.3089s / 20298.7316 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.0392
env0_second_0:                 episode reward: 2.3000,                 loss: 0.0367
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
env2_first_0:                 episode reward: -2.0000,                 loss: nan
env2_second_0:                 episode reward: 2.0000,                 loss: nan
env3_first_0:                 episode reward: -2.3500,                 loss: nan
env3_second_0:                 episode reward: 2.3500,                 loss: nan
env4_first_0:                 episode reward: -2.1000,                 loss: nan
env4_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 348.7418s / 20647.4735 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0369
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0392
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: -0.6500,                 loss: nan
env4_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 349.8536s / 20997.3271 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0379
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0402
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 1.1000,                 loss: nan
env2_second_0:                 episode reward: -1.1000,                 loss: nan
env3_first_0:                 episode reward: 1.3000,                 loss: nan
env3_second_0:                 episode reward: -1.3000,                 loss: nan
env4_first_0:                 episode reward: 1.5500,                 loss: nan
env4_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 347.4602s / 21344.7873 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0410
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0406
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
env3_first_0:                 episode reward: 1.5500,                 loss: nan
env3_second_0:                 episode reward: -1.5500,                 loss: nan
env4_first_0:                 episode reward: 1.9500,                 loss: nan
env4_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 347.0564s / 21691.8437 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0455
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0381
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 348.1128s / 22039.9566 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0432
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0355
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
env2_first_0:                 episode reward: -2.9000,                 loss: nan
env2_second_0:                 episode reward: 2.9000,                 loss: nan
env3_first_0:                 episode reward: -3.2500,                 loss: nan
env3_second_0:                 episode reward: 3.2500,                 loss: nan
env4_first_0:                 episode reward: -3.2000,                 loss: nan
env4_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 350.0496s / 22390.0062 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0356
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0305
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
env3_first_0:                 episode reward: -1.8000,                 loss: nan
env3_second_0:                 episode reward: 1.8000,                 loss: nan
env4_first_0:                 episode reward: -2.2500,                 loss: nan
env4_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 353.6848s / 22743.6910 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0301
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0320
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.7500,                 loss: nan
env4_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 348.3206s / 23092.0116 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0277
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0340
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
env2_first_0:                 episode reward: 1.1000,                 loss: nan
env2_second_0:                 episode reward: -1.1000,                 loss: nan
env3_first_0:                 episode reward: 0.7000,                 loss: nan
env3_second_0:                 episode reward: -0.7000,                 loss: nan
env4_first_0:                 episode reward: 1.6000,                 loss: nan
env4_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 345.6216s / 23437.6332 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0292
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0428
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 348.9991s / 23786.6323 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0287
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0433
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 1.9500,                 loss: nan
env3_second_0:                 episode reward: -1.9500,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 349.8465s / 24136.4788 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0307
env0_second_0:                 episode reward: -1.6000,                 loss: 0.0342
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
env2_first_0:                 episode reward: 2.3000,                 loss: nan
env2_second_0:                 episode reward: -2.3000,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 1.5000,                 loss: nan
env4_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 349.5359s / 24486.0148 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0298
env0_second_0:                 episode reward: -2.5000,                 loss: 0.0303
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
env2_first_0:                 episode reward: 2.6500,                 loss: nan
env2_second_0:                 episode reward: -2.6500,                 loss: nan
env3_first_0:                 episode reward: 2.7500,                 loss: nan
env3_second_0:                 episode reward: -2.7500,                 loss: nan
env4_first_0:                 episode reward: 2.9000,                 loss: nan
env4_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 349.3736s / 24835.3884 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0246
env0_second_0:                 episode reward: -1.8500,                 loss: 0.0333
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
env2_first_0:                 episode reward: 2.4000,                 loss: nan
env2_second_0:                 episode reward: -2.4000,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 348.0870s / 25183.4754 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0222
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0342
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 349.4025s / 25532.8779 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0216
env0_second_0:                 episode reward: 3.1500,                 loss: 0.0325
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
env2_first_0:                 episode reward: -3.5500,                 loss: nan
env2_second_0:                 episode reward: 3.5500,                 loss: nan
env3_first_0:                 episode reward: -3.4000,                 loss: nan
env3_second_0:                 episode reward: 3.4000,                 loss: nan
env4_first_0:                 episode reward: -3.2500,                 loss: nan
env4_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 350.8163s / 25883.6942 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0228
env0_second_0:                 episode reward: 2.4500,                 loss: 0.0350
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
env3_first_0:                 episode reward: -2.4000,                 loss: nan
env3_second_0:                 episode reward: 2.4000,                 loss: nan
env4_first_0:                 episode reward: -2.6500,                 loss: nan
env4_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 349.4786s / 26233.1727 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0253
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0359
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 351.1977s / 26584.3704 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0255
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0333
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
env2_first_0:                 episode reward: -2.4500,                 loss: nan
env2_second_0:                 episode reward: 2.4500,                 loss: nan
env3_first_0:                 episode reward: -2.5500,                 loss: nan
env3_second_0:                 episode reward: 2.5500,                 loss: nan
env4_first_0:                 episode reward: -2.4000,                 loss: nan
env4_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 350.2639s / 26934.6343 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.0248
env0_second_0:                 episode reward: 4.5500,                 loss: 0.0283
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
env2_first_0:                 episode reward: -4.6000,                 loss: nan
env2_second_0:                 episode reward: 4.6000,                 loss: nan
env3_first_0:                 episode reward: -4.2000,                 loss: nan
env3_second_0:                 episode reward: 4.2000,                 loss: nan
env4_first_0:                 episode reward: -4.7000,                 loss: nan
env4_second_0:                 episode reward: 4.7000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 347.5233s / 27282.1576 s
env0_first_0:                 episode reward: -5.1500,                 loss: 0.0239
env0_second_0:                 episode reward: 5.1500,                 loss: 0.0317
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
env2_first_0:                 episode reward: -4.7500,                 loss: nan
env2_second_0:                 episode reward: 4.7500,                 loss: nan
env3_first_0:                 episode reward: -5.0000,                 loss: nan
env3_second_0:                 episode reward: 5.0000,                 loss: nan
env4_first_0:                 episode reward: -4.8000,                 loss: nan
env4_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 350.0479s / 27632.2055 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0227
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0323
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
env2_first_0:                 episode reward: -3.8500,                 loss: nan
env2_second_0:                 episode reward: 3.8500,                 loss: nan
env3_first_0:                 episode reward: -3.5000,                 loss: nan
env3_second_0:                 episode reward: 3.5000,                 loss: nan
env4_first_0:                 episode reward: -3.8500,                 loss: nan
env4_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 347.3580s / 27979.5635 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.0223
env0_second_0:                 episode reward: 1.8000,                 loss: 0.0305
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
env3_first_0:                 episode reward: -1.5500,                 loss: nan
env3_second_0:                 episode reward: 1.5500,                 loss: nan
env4_first_0:                 episode reward: -1.4000,                 loss: nan
env4_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 346.5540s / 28326.1175 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0232
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0321
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
env2_first_0:                 episode reward: -2.2500,                 loss: nan
env2_second_0:                 episode reward: 2.2500,                 loss: nan
env3_first_0:                 episode reward: -2.8500,                 loss: nan
env3_second_0:                 episode reward: 2.8500,                 loss: nan
env4_first_0:                 episode reward: -2.5500,                 loss: nan
env4_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 350.3076s / 28676.4252 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0232
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0306
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -1.0000,                 loss: nan
env3_second_0:                 episode reward: 1.0000,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 348.5432s / 29024.9684 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0221
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0297
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 1.3000,                 loss: nan
env3_second_0:                 episode reward: -1.3000,                 loss: nan
env4_first_0:                 episode reward: 0.7000,                 loss: nan
env4_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 346.3788s / 29371.3472 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0220
env0_second_0:                 episode reward: -2.7000,                 loss: 0.0289
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
env2_first_0:                 episode reward: 3.6000,                 loss: nan
env2_second_0:                 episode reward: -3.6000,                 loss: nan
env3_first_0:                 episode reward: 3.4500,                 loss: nan
env3_second_0:                 episode reward: -3.4500,                 loss: nan
env4_first_0:                 episode reward: 3.0000,                 loss: nan
env4_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 343.8718s / 29715.2190 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0227
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0275
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 348.4550s / 30063.6740 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.0240
env0_second_0:                 episode reward: 2.2000,                 loss: 0.0249
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: -2.4500,                 loss: nan
env2_second_0:                 episode reward: 2.4500,                 loss: nan
env3_first_0:                 episode reward: -2.3000,                 loss: nan
env3_second_0:                 episode reward: 2.3000,                 loss: nan
env4_first_0:                 episode reward: -2.1000,                 loss: nan
env4_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 342.3018s / 30405.9758 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0267
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0243
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
env2_first_0:                 episode reward: -3.1500,                 loss: nan
env2_second_0:                 episode reward: 3.1500,                 loss: nan
env3_first_0:                 episode reward: -3.0500,                 loss: nan
env3_second_0:                 episode reward: 3.0500,                 loss: nan
env4_first_0:                 episode reward: -3.2500,                 loss: nan
env4_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 344.3696s / 30750.3454 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0332
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0250
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
env2_first_0:                 episode reward: -3.4500,                 loss: nan
env2_second_0:                 episode reward: 3.4500,                 loss: nan
env3_first_0:                 episode reward: -3.4500,                 loss: nan
env3_second_0:                 episode reward: 3.4500,                 loss: nan
env4_first_0:                 episode reward: -3.7500,                 loss: nan
env4_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 345.0035s / 31095.3489 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0356
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0285
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
env3_first_0:                 episode reward: -2.3500,                 loss: nan
env3_second_0:                 episode reward: 2.3500,                 loss: nan
env4_first_0:                 episode reward: -2.3500,                 loss: nan
env4_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 347.2305s / 31442.5794 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0376
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0335
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: 0.9500,                 loss: nan
env3_second_0:                 episode reward: -0.9500,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 348.9161s / 31791.4955 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0390
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0350
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 0.6000,                 loss: nan
env3_second_0:                 episode reward: -0.6000,                 loss: nan
env4_first_0:                 episode reward: 1.0000,                 loss: nan
env4_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 348.9183s / 32140.4137 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0389
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0361
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
env3_first_0:                 episode reward: -0.8500,                 loss: nan
env3_second_0:                 episode reward: 0.8500,                 loss: nan
env4_first_0:                 episode reward: -1.0000,                 loss: nan
env4_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 347.0496s / 32487.4633 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.0352
env0_second_0:                 episode reward: 2.6000,                 loss: 0.0314
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
env2_first_0:                 episode reward: -2.7000,                 loss: nan
env2_second_0:                 episode reward: 2.7000,                 loss: nan
env3_first_0:                 episode reward: -2.3500,                 loss: nan
env3_second_0:                 episode reward: 2.3500,                 loss: nan
env4_first_0:                 episode reward: -2.6500,                 loss: nan
env4_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 347.0515s / 32834.5148 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0348
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0283
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
env3_first_0:                 episode reward: -1.2000,                 loss: nan
env3_second_0:                 episode reward: 1.2000,                 loss: nan
env4_first_0:                 episode reward: -1.5000,                 loss: nan
env4_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 351.0116s / 33185.5264 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0340
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0276
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 350.0544s / 33535.5809 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0316
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0300
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 352.5154s / 33888.0963 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.0274
env0_second_0:                 episode reward: -3.5000,                 loss: 0.0364
env1_first_0:                 episode reward: 3.6500,                 loss: nan
env1_second_0:                 episode reward: -3.6500,                 loss: nan
env2_first_0:                 episode reward: 3.5000,                 loss: nan
env2_second_0:                 episode reward: -3.5000,                 loss: nan
env3_first_0:                 episode reward: 3.9000,                 loss: nan
env3_second_0:                 episode reward: -3.9000,                 loss: nan
env4_first_0:                 episode reward: 3.4500,                 loss: nan
env4_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 350.0453s / 34238.1416 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0252
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0378
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -2.0000,                 loss: nan
env2_second_0:                 episode reward: 2.0000,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: -2.2000,                 loss: nan
env4_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 352.1952s / 34590.3368 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0242
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0344
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.8000,                 loss: nan
env4_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 348.2391s / 34938.5759 s
env0_first_0:                 episode reward: 5.0500,                 loss: 0.0214
env0_second_0:                 episode reward: -5.0500,                 loss: 0.0279
env1_first_0:                 episode reward: 4.7500,                 loss: nan
env1_second_0:                 episode reward: -4.7500,                 loss: nan
env2_first_0:                 episode reward: 4.5000,                 loss: nan
env2_second_0:                 episode reward: -4.5000,                 loss: nan
env3_first_0:                 episode reward: 3.9000,                 loss: nan
env3_second_0:                 episode reward: -3.9000,                 loss: nan
env4_first_0:                 episode reward: 4.7000,                 loss: nan
env4_second_0:                 episode reward: -4.7000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 349.4246s / 35288.0005 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0198
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0243
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
env2_first_0:                 episode reward: -2.2500,                 loss: nan
env2_second_0:                 episode reward: 2.2500,                 loss: nan
env3_first_0:                 episode reward: -2.6500,                 loss: nan
env3_second_0:                 episode reward: 2.6500,                 loss: nan
env4_first_0:                 episode reward: -2.6500,                 loss: nan
env4_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 348.7632s / 35636.7637 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0197
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0248
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
env2_first_0:                 episode reward: -3.7000,                 loss: nan
env2_second_0:                 episode reward: 3.7000,                 loss: nan
env3_first_0:                 episode reward: -3.7500,                 loss: nan
env3_second_0:                 episode reward: 3.7500,                 loss: nan
env4_first_0:                 episode reward: -3.7000,                 loss: nan
env4_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 347.9263s / 35984.6900 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.0196
env0_second_0:                 episode reward: -2.4500,                 loss: 0.0288
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
env2_first_0:                 episode reward: 2.4500,                 loss: nan
env2_second_0:                 episode reward: -2.4500,                 loss: nan
env3_first_0:                 episode reward: 2.5000,                 loss: nan
env3_second_0:                 episode reward: -2.5000,                 loss: nan
env4_first_0:                 episode reward: 2.4500,                 loss: nan
env4_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 352.6376s / 36337.3275 s
env0_first_0:                 episode reward: 3.3500,                 loss: 0.0197
env0_second_0:                 episode reward: -3.3500,                 loss: 0.0334
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
env2_first_0:                 episode reward: 3.2000,                 loss: nan
env2_second_0:                 episode reward: -3.2000,                 loss: nan
env3_first_0:                 episode reward: 3.0000,                 loss: nan
env3_second_0:                 episode reward: -3.0000,                 loss: nan
env4_first_0:                 episode reward: 2.8000,                 loss: nan
env4_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 347.2743s / 36684.6018 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.0201
env0_second_0:                 episode reward: -3.2000,                 loss: 0.0344
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
env2_first_0:                 episode reward: 3.3000,                 loss: nan
env2_second_0:                 episode reward: -3.3000,                 loss: nan
env3_first_0:                 episode reward: 3.5000,                 loss: nan
env3_second_0:                 episode reward: -3.5000,                 loss: nan
env4_first_0:                 episode reward: 3.3500,                 loss: nan
env4_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 349.6291s / 37034.2310 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0196
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0337
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 348.2226s / 37382.4536 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0191
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0289
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 1.0500,                 loss: nan
env3_second_0:                 episode reward: -1.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 349.8699s / 37732.3235 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.0190
env0_second_0:                 episode reward: 2.8000,                 loss: 0.0269
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
env2_first_0:                 episode reward: -2.9000,                 loss: nan
env2_second_0:                 episode reward: 2.9000,                 loss: nan
env3_first_0:                 episode reward: -2.8500,                 loss: nan
env3_second_0:                 episode reward: 2.8500,                 loss: nan
env4_first_0:                 episode reward: -3.0000,                 loss: nan
env4_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 349.3210s / 38081.6445 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0190
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0289
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
env3_first_0:                 episode reward: -1.9000,                 loss: nan
env3_second_0:                 episode reward: 1.9000,                 loss: nan
env4_first_0:                 episode reward: -1.7500,                 loss: nan
env4_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 347.4539s / 38429.0984 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0184
env0_second_0:                 episode reward: -1.9000,                 loss: 0.0321
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
env3_first_0:                 episode reward: 2.3000,                 loss: nan
env3_second_0:                 episode reward: -2.3000,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 347.4969s / 38776.5952 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.0183
env0_second_0:                 episode reward: -3.3000,                 loss: 0.0330
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
env2_first_0:                 episode reward: 3.6500,                 loss: nan
env2_second_0:                 episode reward: -3.6500,                 loss: nan
env3_first_0:                 episode reward: 3.2500,                 loss: nan
env3_second_0:                 episode reward: -3.2500,                 loss: nan
env4_first_0:                 episode reward: 3.2500,                 loss: nan
env4_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 346.6079s / 39123.2031 s
env0_first_0:                 episode reward: 5.2000,                 loss: 0.0165
env0_second_0:                 episode reward: -5.2000,                 loss: 0.0345
env1_first_0:                 episode reward: 5.1000,                 loss: nan
env1_second_0:                 episode reward: -5.1000,                 loss: nan
env2_first_0:                 episode reward: 5.5000,                 loss: nan
env2_second_0:                 episode reward: -5.5000,                 loss: nan
env3_first_0:                 episode reward: 5.0000,                 loss: nan
env3_second_0:                 episode reward: -5.0000,                 loss: nan
env4_first_0:                 episode reward: 5.3000,                 loss: nan
env4_second_0:                 episode reward: -5.3000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 347.5984s / 39470.8015 s
env0_first_0:                 episode reward: 4.6500,                 loss: 0.0165
env0_second_0:                 episode reward: -4.6500,                 loss: 0.0316
env1_first_0:                 episode reward: 4.3500,                 loss: nan
env1_second_0:                 episode reward: -4.3500,                 loss: nan
env2_first_0:                 episode reward: 4.7000,                 loss: nan
env2_second_0:                 episode reward: -4.7000,                 loss: nan
env3_first_0:                 episode reward: 4.5000,                 loss: nan
env3_second_0:                 episode reward: -4.5000,                 loss: nan
env4_first_0:                 episode reward: 4.1000,                 loss: nan
env4_second_0:                 episode reward: -4.1000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 349.8134s / 39820.6149 s
env0_first_0:                 episode reward: 4.6000,                 loss: 0.0157
env0_second_0:                 episode reward: -4.6000,                 loss: 0.0248
env1_first_0:                 episode reward: 4.6500,                 loss: nan
env1_second_0:                 episode reward: -4.6500,                 loss: nan
env2_first_0:                 episode reward: 4.6500,                 loss: nan
env2_second_0:                 episode reward: -4.6500,                 loss: nan
env3_first_0:                 episode reward: 4.7000,                 loss: nan
env3_second_0:                 episode reward: -4.7000,                 loss: nan
env4_first_0:                 episode reward: 4.7000,                 loss: nan
env4_second_0:                 episode reward: -4.7000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 345.6395s / 40166.2543 s
env0_first_0:                 episode reward: -4.7000,                 loss: 0.0157
env0_second_0:                 episode reward: 4.7000,                 loss: 0.0204
env1_first_0:                 episode reward: -4.9500,                 loss: nan
env1_second_0:                 episode reward: 4.9500,                 loss: nan
env2_first_0:                 episode reward: -4.7000,                 loss: nan
env2_second_0:                 episode reward: 4.7000,                 loss: nan
env3_first_0:                 episode reward: -4.7500,                 loss: nan
env3_second_0:                 episode reward: 4.7500,                 loss: nan
env4_first_0:                 episode reward: -4.7500,                 loss: nan
env4_second_0:                 episode reward: 4.7500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 346.4092s / 40512.6635 s
env0_first_0:                 episode reward: -5.4000,                 loss: 0.0164
env0_second_0:                 episode reward: 5.4000,                 loss: 0.0226
env1_first_0:                 episode reward: -5.6000,                 loss: nan
env1_second_0:                 episode reward: 5.6000,                 loss: nan
env2_first_0:                 episode reward: -5.3500,                 loss: nan
env2_second_0:                 episode reward: 5.3500,                 loss: nan
env3_first_0:                 episode reward: -5.3500,                 loss: nan
env3_second_0:                 episode reward: 5.3500,                 loss: nan
env4_first_0:                 episode reward: -5.5500,                 loss: nan
env4_second_0:                 episode reward: 5.5500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 347.0987s / 40859.7622 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0163
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0255
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 351.5895s / 41211.3517 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0160
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0275
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
env2_first_0:                 episode reward: -4.2000,                 loss: nan
env2_second_0:                 episode reward: 4.2000,                 loss: nan
env3_first_0:                 episode reward: -4.4000,                 loss: nan
env3_second_0:                 episode reward: 4.4000,                 loss: nan
env4_first_0:                 episode reward: -4.2000,                 loss: nan
env4_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 347.4423s / 41558.7940 s
env0_first_0:                 episode reward: -5.8000,                 loss: 0.0169
env0_second_0:                 episode reward: 5.8000,                 loss: 0.0280
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
env2_first_0:                 episode reward: -5.7500,                 loss: nan
env2_second_0:                 episode reward: 5.7500,                 loss: nan
env3_first_0:                 episode reward: -5.7500,                 loss: nan
env3_second_0:                 episode reward: 5.7500,                 loss: nan
env4_first_0:                 episode reward: -5.8000,                 loss: nan
env4_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 346.0777s / 41904.8717 s
env0_first_0:                 episode reward: -5.6500,                 loss: 0.0169
env0_second_0:                 episode reward: 5.6500,                 loss: 0.0297
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
env2_first_0:                 episode reward: -5.7000,                 loss: nan
env2_second_0:                 episode reward: 5.7000,                 loss: nan
env3_first_0:                 episode reward: -5.8000,                 loss: nan
env3_second_0:                 episode reward: 5.8000,                 loss: nan
env4_first_0:                 episode reward: -5.8000,                 loss: nan
env4_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 335.8672s / 42240.7389 s
env0_first_0:                 episode reward: -5.3000,                 loss: 0.0172
env0_second_0:                 episode reward: 5.3000,                 loss: 0.0274
env1_first_0:                 episode reward: -5.2000,                 loss: nan
env1_second_0:                 episode reward: 5.2000,                 loss: nan
env2_first_0:                 episode reward: -5.1500,                 loss: nan
env2_second_0:                 episode reward: 5.1500,                 loss: nan
env3_first_0:                 episode reward: -5.1500,                 loss: nan
env3_second_0:                 episode reward: 5.1500,                 loss: nan
env4_first_0:                 episode reward: -5.0500,                 loss: nan
env4_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 333.5723s / 42574.3112 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0172
env0_second_0:                 episode reward: 2.0000,                 loss: 0.0285
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
env3_first_0:                 episode reward: -1.7500,                 loss: nan
env3_second_0:                 episode reward: 1.7500,                 loss: nan
env4_first_0:                 episode reward: -1.7500,                 loss: nan
env4_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 314.4263s / 42888.7374 s
env0_first_0:                 episode reward: 5.7000,                 loss: 0.0162
env0_second_0:                 episode reward: -5.7000,                 loss: 0.0325
env1_first_0:                 episode reward: 5.8500,                 loss: nan
env1_second_0:                 episode reward: -5.8500,                 loss: nan
env2_first_0:                 episode reward: 5.8500,                 loss: nan
env2_second_0:                 episode reward: -5.8500,                 loss: nan
env3_first_0:                 episode reward: 5.5500,                 loss: nan
env3_second_0:                 episode reward: -5.5500,                 loss: nan
env4_first_0:                 episode reward: 5.8500,                 loss: nan
env4_second_0:                 episode reward: -5.8500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 302.4220s / 43191.1595 s
env0_first_0:                 episode reward: 5.7500,                 loss: 0.0150
env0_second_0:                 episode reward: -5.7500,                 loss: 0.0321
env1_first_0:                 episode reward: 5.7500,                 loss: nan
env1_second_0:                 episode reward: -5.7500,                 loss: nan
env2_first_0:                 episode reward: 5.8500,                 loss: nan
env2_second_0:                 episode reward: -5.8500,                 loss: nan
env3_first_0:                 episode reward: 5.9500,                 loss: nan
env3_second_0:                 episode reward: -5.9500,                 loss: nan
env4_first_0:                 episode reward: 5.9000,                 loss: nan
env4_second_0:                 episode reward: -5.9000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.7841s / 43483.9435 s
env0_first_0:                 episode reward: 5.6500,                 loss: 0.0142
env0_second_0:                 episode reward: -5.6500,                 loss: 0.0289
env1_first_0:                 episode reward: 5.5500,                 loss: nan
env1_second_0:                 episode reward: -5.5500,                 loss: nan
env2_first_0:                 episode reward: 5.6500,                 loss: nan
env2_second_0:                 episode reward: -5.6500,                 loss: nan
env3_first_0:                 episode reward: 5.6500,                 loss: nan
env3_second_0:                 episode reward: -5.6500,                 loss: nan
env4_first_0:                 episode reward: 5.7000,                 loss: nan
env4_second_0:                 episode reward: -5.7000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 295.3147s / 43779.2582 s
env0_first_0:                 episode reward: 3.8000,                 loss: 0.0146
env0_second_0:                 episode reward: -3.8000,                 loss: 0.0257
env1_first_0:                 episode reward: 3.8500,                 loss: nan
env1_second_0:                 episode reward: -3.8500,                 loss: nan
env2_first_0:                 episode reward: 3.8000,                 loss: nan
env2_second_0:                 episode reward: -3.8000,                 loss: nan
env3_first_0:                 episode reward: 3.8000,                 loss: nan
env3_second_0:                 episode reward: -3.8000,                 loss: nan
env4_first_0:                 episode reward: 3.8500,                 loss: nan
env4_second_0:                 episode reward: -3.8500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 291.9676s / 44071.2258 s
env0_first_0:                 episode reward: 4.9500,                 loss: 0.0147
env0_second_0:                 episode reward: -4.9500,                 loss: 0.0187
env1_first_0:                 episode reward: 5.3000,                 loss: nan
env1_second_0:                 episode reward: -5.3000,                 loss: nan
env2_first_0:                 episode reward: 5.3000,                 loss: nan
env2_second_0:                 episode reward: -5.3000,                 loss: nan
env3_first_0:                 episode reward: 4.9500,                 loss: nan
env3_second_0:                 episode reward: -4.9500,                 loss: nan
env4_first_0:                 episode reward: 5.3000,                 loss: nan
env4_second_0:                 episode reward: -5.3000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.4641s / 44365.6898 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0152
env0_second_0:                 episode reward: -1.3500,                 loss: 0.0185
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
env2_first_0:                 episode reward: 1.7500,                 loss: nan
env2_second_0:                 episode reward: -1.7500,                 loss: nan
env3_first_0:                 episode reward: 1.4000,                 loss: nan
env3_second_0:                 episode reward: -1.4000,                 loss: nan
env4_first_0:                 episode reward: 1.3500,                 loss: nan
env4_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.9127s / 44658.6025 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0156
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0236
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.6617s / 44951.2642 s
env0_first_0:                 episode reward: 5.7500,                 loss: 0.0160
env0_second_0:                 episode reward: -5.7500,                 loss: 0.0221
env1_first_0:                 episode reward: 5.8000,                 loss: nan
env1_second_0:                 episode reward: -5.8000,                 loss: nan
env2_first_0:                 episode reward: 5.3500,                 loss: nan
env2_second_0:                 episode reward: -5.3500,                 loss: nan
env3_first_0:                 episode reward: 5.3000,                 loss: nan
env3_second_0:                 episode reward: -5.3000,                 loss: nan
env4_first_0:                 episode reward: 5.4000,                 loss: nan
env4_second_0:                 episode reward: -5.4000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.9050s / 45244.1691 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.0172
env0_second_0:                 episode reward: -3.0000,                 loss: 0.0217
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
env2_first_0:                 episode reward: 3.2000,                 loss: nan
env2_second_0:                 episode reward: -3.2000,                 loss: nan
env3_first_0:                 episode reward: 3.2500,                 loss: nan
env3_second_0:                 episode reward: -3.2500,                 loss: nan
env4_first_0:                 episode reward: 3.1500,                 loss: nan
env4_second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.4346s / 45536.6037 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0169
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0212
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
env2_first_0:                 episode reward: -2.8000,                 loss: nan
env2_second_0:                 episode reward: 2.8000,                 loss: nan
env3_first_0:                 episode reward: -3.1000,                 loss: nan
env3_second_0:                 episode reward: 3.1000,                 loss: nan
env4_first_0:                 episode reward: -3.0500,                 loss: nan
env4_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.3589s / 45830.9626 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.0178
env0_second_0:                 episode reward: 4.5000,                 loss: 0.0207
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
env2_first_0:                 episode reward: -4.6500,                 loss: nan
env2_second_0:                 episode reward: 4.6500,                 loss: nan
env3_first_0:                 episode reward: -4.5500,                 loss: nan
env3_second_0:                 episode reward: 4.5500,                 loss: nan
env4_first_0:                 episode reward: -4.5500,                 loss: nan
env4_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.6321s / 46124.5947 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0175
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0190
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
env2_first_0:                 episode reward: -4.1000,                 loss: nan
env2_second_0:                 episode reward: 4.1000,                 loss: nan
env3_first_0:                 episode reward: -3.9500,                 loss: nan
env3_second_0:                 episode reward: 3.9500,                 loss: nan
env4_first_0:                 episode reward: -4.0000,                 loss: nan
env4_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.9282s / 46417.5229 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0168
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0188
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
env2_first_0:                 episode reward: -3.4500,                 loss: nan
env2_second_0:                 episode reward: 3.4500,                 loss: nan
env3_first_0:                 episode reward: -3.2500,                 loss: nan
env3_second_0:                 episode reward: 3.2500,                 loss: nan
env4_first_0:                 episode reward: -2.8000,                 loss: nan
env4_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.1959s / 46710.7188 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0184
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0195
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.7500,                 loss: nan
env2_second_0:                 episode reward: 0.7500,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.6360s / 47005.3547 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0183
env0_second_0:                 episode reward: -2.0000,                 loss: 0.0199
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
env3_first_0:                 episode reward: 2.4000,                 loss: nan
env3_second_0:                 episode reward: -2.4000,                 loss: nan
env4_first_0:                 episode reward: 2.2500,                 loss: nan
env4_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 291.8035s / 47297.1582 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0187
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0201
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
env2_first_0:                 episode reward: -3.5500,                 loss: nan
env2_second_0:                 episode reward: 3.5500,                 loss: nan
env3_first_0:                 episode reward: -3.2500,                 loss: nan
env3_second_0:                 episode reward: 3.2500,                 loss: nan
env4_first_0:                 episode reward: -3.5500,                 loss: nan
env4_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.8386s / 47589.9968 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0186
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0197
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
env3_first_0:                 episode reward: -1.5000,                 loss: nan
env3_second_0:                 episode reward: 1.5000,                 loss: nan
env4_first_0:                 episode reward: -1.5000,                 loss: nan
env4_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.0623s / 47884.0591 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0184
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0199
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
env2_first_0:                 episode reward: -2.2500,                 loss: nan
env2_second_0:                 episode reward: 2.2500,                 loss: nan
env3_first_0:                 episode reward: -2.6000,                 loss: nan
env3_second_0:                 episode reward: 2.6000,                 loss: nan
env4_first_0:                 episode reward: -2.2000,                 loss: nan
env4_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.1810s / 48178.2401 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0193
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0202
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -1.0500,                 loss: nan
env4_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 291.7932s / 48470.0333 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0209
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0214
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.5500,                 loss: nan
env3_second_0:                 episode reward: 0.5500,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.6653s / 48764.6985 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0216
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0220
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.2684s / 49058.9669 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0222
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0234
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.1500,                 loss: nan
env3_second_0:                 episode reward: -0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.2000,                 loss: nan
env4_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.0459s / 49352.0129 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0222
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0245
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.0008s / 49645.0137 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0235
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0249
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.7004s / 49938.7140 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0261
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0251
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 295.0301s / 50233.7442 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0302
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0258
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.0000,                 loss: nan
env3_second_0:                 episode reward: 0.0000,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.5895s / 50526.3336 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0309
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0276
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 0.9500,                 loss: nan
env3_second_0:                 episode reward: -0.9500,                 loss: nan
env4_first_0:                 episode reward: 1.4000,                 loss: nan
env4_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.1898s / 50818.5235 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0319
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0284
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 295.2326s / 51113.7561 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0327
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0286
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.3300s / 51408.0861 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0332
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0285
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: -1.2000,                 loss: nan
env2_second_0:                 episode reward: 1.2000,                 loss: nan
env3_first_0:                 episode reward: -1.4000,                 loss: nan
env3_second_0:                 episode reward: 1.4000,                 loss: nan
env4_first_0:                 episode reward: -1.1500,                 loss: nan
env4_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.5894s / 51700.6755 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0333
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0289
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.3500,                 loss: nan
env4_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.3444s / 51994.0199 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0357
env0_second_0:                 episode reward: -2.3500,                 loss: 0.0307
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
env2_first_0:                 episode reward: 2.4000,                 loss: nan
env2_second_0:                 episode reward: -2.4000,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 2.3500,                 loss: nan
env4_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 296.0500s / 52290.0699 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0322
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0325
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
env2_first_0:                 episode reward: 0.9000,                 loss: nan
env2_second_0:                 episode reward: -0.9000,                 loss: nan
env3_first_0:                 episode reward: 0.9000,                 loss: nan
env3_second_0:                 episode reward: -0.9000,                 loss: nan
env4_first_0:                 episode reward: 0.9000,                 loss: nan
env4_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.9122s / 52583.9821 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0294
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0343
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.1905s / 52877.1726 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0254
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0326
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 0.9500,                 loss: nan
env3_second_0:                 episode reward: -0.9500,                 loss: nan
env4_first_0:                 episode reward: 1.2000,                 loss: nan
env4_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 295.2617s / 53172.4343 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0242
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0325
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
env3_first_0:                 episode reward: -0.7500,                 loss: nan
env3_second_0:                 episode reward: 0.7500,                 loss: nan
env4_first_0:                 episode reward: -0.9500,                 loss: nan
env4_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.9976s / 53465.4319 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0244
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0319
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
env3_first_0:                 episode reward: -1.5000,                 loss: nan
env3_second_0:                 episode reward: 1.5000,                 loss: nan
env4_first_0:                 episode reward: -1.6000,                 loss: nan
env4_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.7282s / 53760.1601 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0244
env0_second_0:                 episode reward: 1.6500,                 loss: 0.0318
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
env2_first_0:                 episode reward: -1.8000,                 loss: nan
env2_second_0:                 episode reward: 1.8000,                 loss: nan
env3_first_0:                 episode reward: -1.7000,                 loss: nan
env3_second_0:                 episode reward: 1.7000,                 loss: nan
env4_first_0:                 episode reward: -1.5000,                 loss: nan
env4_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.7367s / 54052.8968 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0256
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0312
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
env2_first_0:                 episode reward: -2.4500,                 loss: nan
env2_second_0:                 episode reward: 2.4500,                 loss: nan
env3_first_0:                 episode reward: -2.6000,                 loss: nan
env3_second_0:                 episode reward: 2.6000,                 loss: nan
env4_first_0:                 episode reward: -2.3500,                 loss: nan
env4_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.1636s / 54345.0604 s
env0_first_0:                 episode reward: -6.3500,                 loss: 0.0266
env0_second_0:                 episode reward: 6.3500,                 loss: 0.0314
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
env2_first_0:                 episode reward: -6.3500,                 loss: nan
env2_second_0:                 episode reward: 6.3500,                 loss: nan
env3_first_0:                 episode reward: -6.3500,                 loss: nan
env3_second_0:                 episode reward: 6.3500,                 loss: nan
env4_first_0:                 episode reward: -6.3500,                 loss: nan
env4_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.2526s / 54638.3130 s
env0_first_0:                 episode reward: -5.3500,                 loss: 0.0285
env0_second_0:                 episode reward: 5.3500,                 loss: 0.0322
env1_first_0:                 episode reward: -5.3500,                 loss: nan
env1_second_0:                 episode reward: 5.3500,                 loss: nan
env2_first_0:                 episode reward: -5.3500,                 loss: nan
env2_second_0:                 episode reward: 5.3500,                 loss: nan
env3_first_0:                 episode reward: -5.3500,                 loss: nan
env3_second_0:                 episode reward: 5.3500,                 loss: nan
env4_first_0:                 episode reward: -5.3500,                 loss: nan
env4_second_0:                 episode reward: 5.3500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.6851s / 54930.9981 s
env0_first_0:                 episode reward: -5.1500,                 loss: 0.0324
env0_second_0:                 episode reward: 5.1500,                 loss: 0.0305
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
env2_first_0:                 episode reward: -5.1500,                 loss: nan
env2_second_0:                 episode reward: 5.1500,                 loss: nan
env3_first_0:                 episode reward: -5.1500,                 loss: nan
env3_second_0:                 episode reward: 5.1500,                 loss: nan
env4_first_0:                 episode reward: -5.1500,                 loss: nan
env4_second_0:                 episode reward: 5.1500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.0008s / 55224.9989 s
env0_first_0:                 episode reward: -5.0500,                 loss: 0.0322
env0_second_0:                 episode reward: 5.0500,                 loss: 0.0293
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
env2_first_0:                 episode reward: -5.2500,                 loss: nan
env2_second_0:                 episode reward: 5.2500,                 loss: nan
env3_first_0:                 episode reward: -5.0500,                 loss: nan
env3_second_0:                 episode reward: 5.0500,                 loss: nan
env4_first_0:                 episode reward: -5.2500,                 loss: nan
env4_second_0:                 episode reward: 5.2500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.4481s / 55518.4471 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0285
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0273
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: -1.3500,                 loss: nan
env2_second_0:                 episode reward: 1.3500,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -1.3500,                 loss: nan
env4_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.9769s / 55811.4239 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0265
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0270
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
env3_first_0:                 episode reward: -2.6500,                 loss: nan
env3_second_0:                 episode reward: 2.6500,                 loss: nan
env4_first_0:                 episode reward: -2.4500,                 loss: nan
env4_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.9218s / 56105.3457 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0279
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0271
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.6534s / 56398.9992 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0281
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0280
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
env2_first_0:                 episode reward: -2.7500,                 loss: nan
env2_second_0:                 episode reward: 2.7500,                 loss: nan
env3_first_0:                 episode reward: -2.9000,                 loss: nan
env3_second_0:                 episode reward: 2.9000,                 loss: nan
env4_first_0:                 episode reward: -2.5500,                 loss: nan
env4_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.4312s / 56692.4304 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.0272
env0_second_0:                 episode reward: -3.5000,                 loss: 0.0291
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
env2_first_0:                 episode reward: 3.5500,                 loss: nan
env2_second_0:                 episode reward: -3.5500,                 loss: nan
env3_first_0:                 episode reward: 3.5500,                 loss: nan
env3_second_0:                 episode reward: -3.5500,                 loss: nan
env4_first_0:                 episode reward: 3.6000,                 loss: nan
env4_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 290.8178s / 56983.2482 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0272
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0251
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
env3_first_0:                 episode reward: 0.8500,                 loss: nan
env3_second_0:                 episode reward: -0.8500,                 loss: nan
env4_first_0:                 episode reward: 0.8500,                 loss: nan
env4_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.6564s / 57276.9046 s
env0_first_0:                 episode reward: 4.0500,                 loss: 0.0246
env0_second_0:                 episode reward: -4.0500,                 loss: 0.0209
env1_first_0:                 episode reward: 3.9500,                 loss: nan
env1_second_0:                 episode reward: -3.9500,                 loss: nan
env2_first_0:                 episode reward: 3.7500,                 loss: nan
env2_second_0:                 episode reward: -3.7500,                 loss: nan
env3_first_0:                 episode reward: 4.0500,                 loss: nan
env3_second_0:                 episode reward: -4.0500,                 loss: nan
env4_first_0:                 episode reward: 3.8500,                 loss: nan
env4_second_0:                 episode reward: -3.8500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 290.9139s / 57567.8185 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0223
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0188
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 1.1000,                 loss: nan
env2_second_0:                 episode reward: -1.1000,                 loss: nan
env3_first_0:                 episode reward: 0.9500,                 loss: nan
env3_second_0:                 episode reward: -0.9500,                 loss: nan
env4_first_0:                 episode reward: 0.9000,                 loss: nan
env4_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.7004s / 57861.5189 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0232
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0187
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
env3_first_0:                 episode reward: -1.0000,                 loss: nan
env3_second_0:                 episode reward: 1.0000,                 loss: nan
env4_first_0:                 episode reward: -1.1000,                 loss: nan
env4_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.3018s / 58154.8206 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0231
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0204
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 0.9000,                 loss: nan
env3_second_0:                 episode reward: -0.9000,                 loss: nan
env4_first_0:                 episode reward: 0.5500,                 loss: nan
env4_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.3020s / 58448.1227 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0217
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0210
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 1.3000,                 loss: nan
env3_second_0:                 episode reward: -1.3000,                 loss: nan
env4_first_0:                 episode reward: 1.3000,                 loss: nan
env4_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 291.2427s / 58739.3653 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0220
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0199
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -0.7500,                 loss: nan
env2_second_0:                 episode reward: 0.7500,                 loss: nan
env3_first_0:                 episode reward: -0.9000,                 loss: nan
env3_second_0:                 episode reward: 0.9000,                 loss: nan
env4_first_0:                 episode reward: -0.7500,                 loss: nan
env4_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.2229s / 59032.5883 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0219
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0194
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 291.7104s / 59324.2987 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0231
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0198
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 1.0500,                 loss: nan
env4_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 290.3081s / 59614.6068 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0242
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0221
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
env2_first_0:                 episode reward: 1.0500,                 loss: nan
env2_second_0:                 episode reward: -1.0500,                 loss: nan
env3_first_0:                 episode reward: 1.2000,                 loss: nan
env3_second_0:                 episode reward: -1.2000,                 loss: nan
env4_first_0:                 episode reward: 1.2000,                 loss: nan
env4_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.9764s / 59907.5831 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0258
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0238
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.6500,                 loss: nan
env3_second_0:                 episode reward: -0.6500,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.7760s / 60200.3591 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0278
env0_second_0:                 episode reward: -1.4500,                 loss: 0.0252
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 0.9500,                 loss: nan
env4_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 295.1883s / 60495.5474 s
env0_first_0:                 episode reward: 3.1000,                 loss: 0.0284
env0_second_0:                 episode reward: -3.1000,                 loss: 0.0269
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
env2_first_0:                 episode reward: 3.1500,                 loss: nan
env2_second_0:                 episode reward: -3.1500,                 loss: nan
env3_first_0:                 episode reward: 3.1000,                 loss: nan
env3_second_0:                 episode reward: -3.1000,                 loss: nan
env4_first_0:                 episode reward: 3.0000,                 loss: nan
env4_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 291.4717s / 60787.0191 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.0294
env0_second_0:                 episode reward: -2.0500,                 loss: 0.0284
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
env3_first_0:                 episode reward: 2.2500,                 loss: nan
env3_second_0:                 episode reward: -2.2500,                 loss: nan
env4_first_0:                 episode reward: 2.2500,                 loss: nan
env4_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.5903s / 61079.6094 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0302
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0295
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 1.0500,                 loss: nan
env3_second_0:                 episode reward: -1.0500,                 loss: nan
env4_first_0:                 episode reward: 1.2500,                 loss: nan
env4_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.1463s / 61371.7557 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0291
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0298
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
env2_first_0:                 episode reward: 1.2000,                 loss: nan
env2_second_0:                 episode reward: -1.2000,                 loss: nan
env3_first_0:                 episode reward: 1.2000,                 loss: nan
env3_second_0:                 episode reward: -1.2000,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.0808s / 61665.8365 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0283
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0294
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
env2_first_0:                 episode reward: 1.3500,                 loss: nan
env2_second_0:                 episode reward: -1.3500,                 loss: nan
env3_first_0:                 episode reward: 1.0500,                 loss: nan
env3_second_0:                 episode reward: -1.0500,                 loss: nan
env4_first_0:                 episode reward: 1.2000,                 loss: nan
env4_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.3423s / 61960.1788 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0286
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0309
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
env3_first_0:                 episode reward: 0.8000,                 loss: nan
env3_second_0:                 episode reward: -0.8000,                 loss: nan
env4_first_0:                 episode reward: 0.8500,                 loss: nan
env4_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.1676s / 62254.3464 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0305
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0299
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 1.0000,                 loss: nan
env3_second_0:                 episode reward: -1.0000,                 loss: nan
env4_first_0:                 episode reward: 0.6000,                 loss: nan
env4_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.2039s / 62546.5503 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0351
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0315
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
env2_first_0:                 episode reward: 0.9500,                 loss: nan
env2_second_0:                 episode reward: -0.9500,                 loss: nan
env3_first_0:                 episode reward: 0.9500,                 loss: nan
env3_second_0:                 episode reward: -0.9500,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.8007s / 62840.3509 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0348
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0302
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.6466s / 63134.9976 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0361
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0306
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.2547s / 63428.2522 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.0333
env0_second_0:                 episode reward: -2.1000,                 loss: 0.0316
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.3952s / 63722.6474 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.0325
env0_second_0:                 episode reward: -3.7000,                 loss: 0.0324
env1_first_0:                 episode reward: 3.7000,                 loss: nan
env1_second_0:                 episode reward: -3.7000,                 loss: nan
env2_first_0:                 episode reward: 3.7500,                 loss: nan
env2_second_0:                 episode reward: -3.7500,                 loss: nan
env3_first_0:                 episode reward: 3.7500,                 loss: nan
env3_second_0:                 episode reward: -3.7500,                 loss: nan
env4_first_0:                 episode reward: 3.7000,                 loss: nan
env4_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.4536s / 64016.1011 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.0297
env0_second_0:                 episode reward: -2.0500,                 loss: 0.0319
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
env2_first_0:                 episode reward: 2.1500,                 loss: nan
env2_second_0:                 episode reward: -2.1500,                 loss: nan
env3_first_0:                 episode reward: 2.1500,                 loss: nan
env3_second_0:                 episode reward: -2.1500,                 loss: nan
env4_first_0:                 episode reward: 2.2000,                 loss: nan
env4_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.8478s / 64308.9488 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0300
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0330
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
env2_first_0:                 episode reward: 0.9500,                 loss: nan
env2_second_0:                 episode reward: -0.9500,                 loss: nan
env3_first_0:                 episode reward: 1.1500,                 loss: nan
env3_second_0:                 episode reward: -1.1500,                 loss: nan
env4_first_0:                 episode reward: 1.0000,                 loss: nan
env4_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 293.8372s / 64602.7860 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0263
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0352
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.9500,                 loss: nan
env4_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.5008s / 64897.2868 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.0216
env0_second_0:                 episode reward: -1.7500,                 loss: 0.0356
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 2.1000,                 loss: nan
env4_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 295.6076s / 65192.8944 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0181
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0343
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 0.6000,                 loss: nan
env3_second_0:                 episode reward: -0.6000,                 loss: nan
env4_first_0:                 episode reward: 0.7500,                 loss: nan
env4_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 295.0282s / 65487.9226 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0172
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0360
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: -1.0500,                 loss: nan
env4_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.5016s / 65782.4242 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0169
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0378
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
env2_first_0:                 episode reward: -3.6000,                 loss: nan
env2_second_0:                 episode reward: 3.6000,                 loss: nan
env3_first_0:                 episode reward: -3.3500,                 loss: nan
env3_second_0:                 episode reward: 3.3500,                 loss: nan
env4_first_0:                 episode reward: -3.6000,                 loss: nan
env4_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 295.8434s / 66078.2675 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0178
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0378
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 296.2071s / 66374.4746 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0186
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0371
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
env2_first_0:                 episode reward: -3.5500,                 loss: nan
env2_second_0:                 episode reward: 3.5500,                 loss: nan
env3_first_0:                 episode reward: -3.4000,                 loss: nan
env3_second_0:                 episode reward: 3.4000,                 loss: nan
env4_first_0:                 episode reward: -3.4000,                 loss: nan
env4_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.0592s / 66668.5338 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0195
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0344
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
env2_first_0:                 episode reward: -4.0500,                 loss: nan
env2_second_0:                 episode reward: 4.0500,                 loss: nan
env3_first_0:                 episode reward: -4.3000,                 loss: nan
env3_second_0:                 episode reward: 4.3000,                 loss: nan
env4_first_0:                 episode reward: -4.3500,                 loss: nan
env4_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.8624s / 66963.3962 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.0200
env0_second_0:                 episode reward: 2.7500,                 loss: 0.0339
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
env2_first_0:                 episode reward: -2.9000,                 loss: nan
env2_second_0:                 episode reward: 2.9000,                 loss: nan
env3_first_0:                 episode reward: -2.9000,                 loss: nan
env3_second_0:                 episode reward: 2.9000,                 loss: nan
env4_first_0:                 episode reward: -2.7500,                 loss: nan
env4_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 296.1343s / 67259.5305 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0211
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0312
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
env2_first_0:                 episode reward: -3.2000,                 loss: nan
env2_second_0:                 episode reward: 3.2000,                 loss: nan
env3_first_0:                 episode reward: -2.7500,                 loss: nan
env3_second_0:                 episode reward: 2.7500,                 loss: nan
env4_first_0:                 episode reward: -3.0000,                 loss: nan
env4_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.6017s / 67552.1322 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0222
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0320
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
env3_first_0:                 episode reward: -1.3500,                 loss: nan
env3_second_0:                 episode reward: 1.3500,                 loss: nan
env4_first_0:                 episode reward: -1.4000,                 loss: nan
env4_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.7604s / 67846.8926 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0229
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0325
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.5000,                 loss: nan
env4_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.5317s / 68141.4243 s
env0_first_0:                 episode reward: 4.2000,                 loss: 0.0221
env0_second_0:                 episode reward: -4.2000,                 loss: 0.0317
env1_first_0:                 episode reward: 4.1000,                 loss: nan
env1_second_0:                 episode reward: -4.1000,                 loss: nan
env2_first_0:                 episode reward: 4.3000,                 loss: nan
env2_second_0:                 episode reward: -4.3000,                 loss: nan
env3_first_0:                 episode reward: 4.1000,                 loss: nan
env3_second_0:                 episode reward: -4.1000,                 loss: nan
env4_first_0:                 episode reward: 4.2000,                 loss: nan
env4_second_0:                 episode reward: -4.2000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 295.1558s / 68436.5800 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.0220
env0_second_0:                 episode reward: -2.8000,                 loss: 0.0305
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
env2_first_0:                 episode reward: 2.9500,                 loss: nan
env2_second_0:                 episode reward: -2.9500,                 loss: nan
env3_first_0:                 episode reward: 2.7000,                 loss: nan
env3_second_0:                 episode reward: -2.7000,                 loss: nan
env4_first_0:                 episode reward: 2.6000,                 loss: nan
env4_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.9810s / 68729.5610 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0226
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0312
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
env3_first_0:                 episode reward: -1.5000,                 loss: nan
env3_second_0:                 episode reward: 1.5000,                 loss: nan
env4_first_0:                 episode reward: -1.2500,                 loss: nan
env4_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 294.6860s / 69024.2470 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0227
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0318
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 295.1237s / 69319.3707 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0243
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0305
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.3500,                 loss: nan
env3_second_0:                 episode reward: 0.3500,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 292.6652s / 69612.0359 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0270
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0311
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 0.8000,                 loss: nan
env3_second_0:                 episode reward: -0.8000,                 loss: nan
env4_first_0:                 episode reward: 0.7500,                 loss: nan
env4_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 288.8297s / 69900.8657 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0277
env0_second_0:                 episode reward: -1.8000,                 loss: 0.0306
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 1.7500,                 loss: nan
env3_second_0:                 episode reward: -1.7500,                 loss: nan
env4_first_0:                 episode reward: 1.8000,                 loss: nan
env4_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 288.1255s / 70188.9911 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.0270
env0_second_0:                 episode reward: -2.8000,                 loss: 0.0299
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
env2_first_0:                 episode reward: 2.8500,                 loss: nan
env2_second_0:                 episode reward: -2.8500,                 loss: nan
env3_first_0:                 episode reward: 2.8500,                 loss: nan
env3_second_0:                 episode reward: -2.8500,                 loss: nan
env4_first_0:                 episode reward: 2.6500,                 loss: nan
env4_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 287.8911s / 70476.8822 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0263
env0_second_0:                 episode reward: -1.3500,                 loss: 0.0297
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
env2_first_0:                 episode reward: 2.2500,                 loss: nan
env2_second_0:                 episode reward: -2.2500,                 loss: nan
env3_first_0:                 episode reward: 2.2500,                 loss: nan
env3_second_0:                 episode reward: -2.2500,                 loss: nan
env4_first_0:                 episode reward: 1.9500,                 loss: nan
env4_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 286.0709s / 70762.9531 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0251
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0301
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
env3_first_0:                 episode reward: 0.6000,                 loss: nan
env3_second_0:                 episode reward: -0.6000,                 loss: nan
env4_first_0:                 episode reward: 0.5500,                 loss: nan
env4_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 286.2433s / 71049.1965 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0251
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0302
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: -1.0000,                 loss: nan
env4_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 285.2593s / 71334.4558 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0236
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0336
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 0.9500,                 loss: nan
env4_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 284.1091s / 71618.5649 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0209
env0_second_0:                 episode reward: -2.5000,                 loss: 0.0331
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
env3_first_0:                 episode reward: 2.3500,                 loss: nan
env3_second_0:                 episode reward: -2.3500,                 loss: nan
env4_first_0:                 episode reward: 2.2500,                 loss: nan
env4_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 288.9154s / 71907.4803 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.0196
env0_second_0:                 episode reward: -3.0500,                 loss: 0.0335
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
env2_first_0:                 episode reward: 3.0000,                 loss: nan
env2_second_0:                 episode reward: -3.0000,                 loss: nan
env3_first_0:                 episode reward: 3.0500,                 loss: nan
env3_second_0:                 episode reward: -3.0500,                 loss: nan
env4_first_0:                 episode reward: 3.1000,                 loss: nan
env4_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 286.2281s / 72193.7083 s
env0_first_0:                 episode reward: 3.8000,                 loss: 0.0173
env0_second_0:                 episode reward: -3.8000,                 loss: 0.0343
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
env2_first_0:                 episode reward: 3.8000,                 loss: nan
env2_second_0:                 episode reward: -3.8000,                 loss: nan
env3_first_0:                 episode reward: 3.9500,                 loss: nan
env3_second_0:                 episode reward: -3.9500,                 loss: nan
env4_first_0:                 episode reward: 4.0000,                 loss: nan
env4_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 284.5938s / 72478.3022 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.0158
env0_second_0:                 episode reward: -3.5500,                 loss: 0.0358
env1_first_0:                 episode reward: 3.7000,                 loss: nan
env1_second_0:                 episode reward: -3.7000,                 loss: nan
env2_first_0:                 episode reward: 3.6000,                 loss: nan
env2_second_0:                 episode reward: -3.6000,                 loss: nan
env3_first_0:                 episode reward: 3.6000,                 loss: nan
env3_second_0:                 episode reward: -3.6000,                 loss: nan
env4_first_0:                 episode reward: 3.5500,                 loss: nan
env4_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 279.0223s / 72757.3245 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.0147
env0_second_0:                 episode reward: -3.0500,                 loss: 0.0376
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 2.6000,                 loss: nan
env2_second_0:                 episode reward: -2.6000,                 loss: nan
env3_first_0:                 episode reward: 2.5500,                 loss: nan
env3_second_0:                 episode reward: -2.5500,                 loss: nan
env4_first_0:                 episode reward: 3.0000,                 loss: nan
env4_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 280.0306s / 73037.3550 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0150
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0375
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -1.1500,                 loss: nan
env4_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 277.8898s / 73315.2448 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0157
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0378
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 280.3659s / 73595.6107 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0156
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0374
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 0.7000,                 loss: nan
env4_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 278.9580s / 73874.5687 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0151
env0_second_0:                 episode reward: -2.0000,                 loss: 0.0361
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
env2_first_0:                 episode reward: 2.3500,                 loss: nan
env2_second_0:                 episode reward: -2.3500,                 loss: nan
env3_first_0:                 episode reward: 2.2000,                 loss: nan
env3_second_0:                 episode reward: -2.2000,                 loss: nan
env4_first_0:                 episode reward: 2.0500,                 loss: nan
env4_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 280.5062s / 74155.0750 s
env0_first_0:                 episode reward: 3.8000,                 loss: 0.0148
env0_second_0:                 episode reward: -3.8000,                 loss: 0.0321
env1_first_0:                 episode reward: 4.1000,                 loss: nan
env1_second_0:                 episode reward: -4.1000,                 loss: nan
env2_first_0:                 episode reward: 3.5500,                 loss: nan
env2_second_0:                 episode reward: -3.5500,                 loss: nan
env3_first_0:                 episode reward: 3.6500,                 loss: nan
env3_second_0:                 episode reward: -3.6500,                 loss: nan
env4_first_0:                 episode reward: 3.7000,                 loss: nan
env4_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 282.2140s / 74437.2889 s
env0_first_0:                 episode reward: 3.1000,                 loss: 0.0154
env0_second_0:                 episode reward: -3.1000,                 loss: 0.0289
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
env2_first_0:                 episode reward: 3.2000,                 loss: nan
env2_second_0:                 episode reward: -3.2000,                 loss: nan
env3_first_0:                 episode reward: 2.9500,                 loss: nan
env3_second_0:                 episode reward: -2.9500,                 loss: nan
env4_first_0:                 episode reward: 3.4000,                 loss: nan
env4_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 277.6423s / 74714.9312 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0154
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0280
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 279.0274s / 74993.9586 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.0156
env0_second_0:                 episode reward: 2.2500,                 loss: 0.0278
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
env2_first_0:                 episode reward: -2.2000,                 loss: nan
env2_second_0:                 episode reward: 2.2000,                 loss: nan
env3_first_0:                 episode reward: -1.8500,                 loss: nan
env3_second_0:                 episode reward: 1.8500,                 loss: nan
env4_first_0:                 episode reward: -2.4000,                 loss: nan
env4_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 276.7169s / 75270.6756 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0158
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0290
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 278.3751s / 75549.0506 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.0165
env0_second_0:                 episode reward: 2.8000,                 loss: 0.0284
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
env2_first_0:                 episode reward: -2.4000,                 loss: nan
env2_second_0:                 episode reward: 2.4000,                 loss: nan
env3_first_0:                 episode reward: -2.6000,                 loss: nan
env3_second_0:                 episode reward: 2.6000,                 loss: nan
env4_first_0:                 episode reward: -2.4500,                 loss: nan
env4_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 275.8941s / 75824.9447 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0165
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0262
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
env3_first_0:                 episode reward: -1.6500,                 loss: nan
env3_second_0:                 episode reward: 1.6500,                 loss: nan
env4_first_0:                 episode reward: -1.7000,                 loss: nan
env4_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 279.6538s / 76104.5985 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0159
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0274
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: -0.6500,                 loss: nan
env4_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 279.9791s / 76384.5776 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0164
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0305
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
env2_first_0:                 episode reward: -1.2000,                 loss: nan
env2_second_0:                 episode reward: 1.2000,                 loss: nan
env3_first_0:                 episode reward: -1.2000,                 loss: nan
env3_second_0:                 episode reward: 1.2000,                 loss: nan
env4_first_0:                 episode reward: -1.3000,                 loss: nan
env4_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 279.6544s / 76664.2321 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0161
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0320
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
env2_first_0:                 episode reward: -2.1000,                 loss: nan
env2_second_0:                 episode reward: 2.1000,                 loss: nan
env3_first_0:                 episode reward: -2.2000,                 loss: nan
env3_second_0:                 episode reward: 2.2000,                 loss: nan
env4_first_0:                 episode reward: -2.1000,                 loss: nan
env4_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 271.8842s / 76936.1162 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.0166
env0_second_0:                 episode reward: 2.7500,                 loss: 0.0297
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
env2_first_0:                 episode reward: -2.6000,                 loss: nan
env2_second_0:                 episode reward: 2.6000,                 loss: nan
env3_first_0:                 episode reward: -2.8000,                 loss: nan
env3_second_0:                 episode reward: 2.8000,                 loss: nan
env4_first_0:                 episode reward: -2.8000,                 loss: nan
env4_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 273.2075s / 77209.3238 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0169
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0259
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
env2_first_0:                 episode reward: -3.2500,                 loss: nan
env2_second_0:                 episode reward: 3.2500,                 loss: nan
env3_first_0:                 episode reward: -3.2500,                 loss: nan
env3_second_0:                 episode reward: 3.2500,                 loss: nan
env4_first_0:                 episode reward: -3.2500,                 loss: nan
env4_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 282.0807s / 77491.4045 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0181
env0_second_0:                 episode reward: 1.7500,                 loss: 0.0248
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: -2.1000,                 loss: nan
env2_second_0:                 episode reward: 2.1000,                 loss: nan
env3_first_0:                 episode reward: -1.7500,                 loss: nan
env3_second_0:                 episode reward: 1.7500,                 loss: nan
env4_first_0:                 episode reward: -1.8500,                 loss: nan
env4_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 279.1323s / 77770.5368 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0184
env0_second_0:                 episode reward: 2.0000,                 loss: 0.0251
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
env2_first_0:                 episode reward: -2.1500,                 loss: nan
env2_second_0:                 episode reward: 2.1500,                 loss: nan
env3_first_0:                 episode reward: -2.1500,                 loss: nan
env3_second_0:                 episode reward: 2.1500,                 loss: nan
env4_first_0:                 episode reward: -2.0500,                 loss: nan
env4_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 273.3882s / 78043.9250 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0194
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0267
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
env2_first_0:                 episode reward: -1.5500,                 loss: nan
env2_second_0:                 episode reward: 1.5500,                 loss: nan
env3_first_0:                 episode reward: -1.6000,                 loss: nan
env3_second_0:                 episode reward: 1.6000,                 loss: nan
env4_first_0:                 episode reward: -1.5500,                 loss: nan
env4_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 274.8482s / 78318.7732 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0202
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0293
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
env2_first_0:                 episode reward: -2.4000,                 loss: nan
env2_second_0:                 episode reward: 2.4000,                 loss: nan
env3_first_0:                 episode reward: -2.2500,                 loss: nan
env3_second_0:                 episode reward: 2.2500,                 loss: nan
env4_first_0:                 episode reward: -2.4000,                 loss: nan
env4_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 272.7028s / 78591.4761 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0217
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0310
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
env2_first_0:                 episode reward: -3.7000,                 loss: nan
env2_second_0:                 episode reward: 3.7000,                 loss: nan
env3_first_0:                 episode reward: -3.3000,                 loss: nan
env3_second_0:                 episode reward: 3.3000,                 loss: nan
env4_first_0:                 episode reward: -3.8000,                 loss: nan
env4_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 269.2464s / 78860.7225 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0252
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0303
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
env2_first_0:                 episode reward: -3.5500,                 loss: nan
env2_second_0:                 episode reward: 3.5500,                 loss: nan
env3_first_0:                 episode reward: -3.4500,                 loss: nan
env3_second_0:                 episode reward: 3.4500,                 loss: nan
env4_first_0:                 episode reward: -3.4000,                 loss: nan
env4_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 274.8822s / 79135.6047 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0296
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0276
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
env2_first_0:                 episode reward: -4.0000,                 loss: nan
env2_second_0:                 episode reward: 4.0000,                 loss: nan
env3_first_0:                 episode reward: -4.1500,                 loss: nan
env3_second_0:                 episode reward: 4.1500,                 loss: nan
env4_first_0:                 episode reward: -4.0000,                 loss: nan
env4_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 274.4247s / 79410.0294 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0332
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0266
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
env3_first_0:                 episode reward: -3.1500,                 loss: nan
env3_second_0:                 episode reward: 3.1500,                 loss: nan
env4_first_0:                 episode reward: -2.5500,                 loss: nan
env4_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 271.2657s / 79681.2952 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0332
env0_second_0:                 episode reward: 4.3000,                 loss: 0.0273
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
env2_first_0:                 episode reward: -4.3500,                 loss: nan
env2_second_0:                 episode reward: 4.3500,                 loss: nan
env3_first_0:                 episode reward: -4.2000,                 loss: nan
env3_second_0:                 episode reward: 4.2000,                 loss: nan
env4_first_0:                 episode reward: -4.3500,                 loss: nan
env4_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 269.2571s / 79950.5523 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0302
env0_second_0:                 episode reward: 1.7000,                 loss: 0.0273
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -1.7500,                 loss: nan
env2_second_0:                 episode reward: 1.7500,                 loss: nan
env3_first_0:                 episode reward: -1.7000,                 loss: nan
env3_second_0:                 episode reward: 1.7000,                 loss: nan
env4_first_0:                 episode reward: -1.8000,                 loss: nan
env4_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 272.0192s / 80222.5715 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0282
env0_second_0:                 episode reward: 2.4500,                 loss: 0.0290
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
env3_first_0:                 episode reward: -2.7000,                 loss: nan
env3_second_0:                 episode reward: 2.7000,                 loss: nan
env4_first_0:                 episode reward: -2.6500,                 loss: nan
env4_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 271.4667s / 80494.0382 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.0271
env0_second_0:                 episode reward: 2.8000,                 loss: 0.0286
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
env2_first_0:                 episode reward: -2.8000,                 loss: nan
env2_second_0:                 episode reward: 2.8000,                 loss: nan
env3_first_0:                 episode reward: -2.8000,                 loss: nan
env3_second_0:                 episode reward: 2.8000,                 loss: nan
env4_first_0:                 episode reward: -2.8000,                 loss: nan
env4_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 272.6612s / 80766.6994 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0275
env0_second_0:                 episode reward: 2.4500,                 loss: 0.0284
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
env2_first_0:                 episode reward: -2.5500,                 loss: nan
env2_second_0:                 episode reward: 2.5500,                 loss: nan
env3_first_0:                 episode reward: -2.6000,                 loss: nan
env3_second_0:                 episode reward: 2.6000,                 loss: nan
env4_first_0:                 episode reward: -2.7000,                 loss: nan
env4_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1553s / 81035.8547 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0265
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0295
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
env2_first_0:                 episode reward: -2.5000,                 loss: nan
env2_second_0:                 episode reward: 2.5000,                 loss: nan
env3_first_0:                 episode reward: -2.7000,                 loss: nan
env3_second_0:                 episode reward: 2.7000,                 loss: nan
env4_first_0:                 episode reward: -2.5500,                 loss: nan
env4_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 271.1585s / 81307.0132 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0273
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0306
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
env2_first_0:                 episode reward: -2.9000,                 loss: nan
env2_second_0:                 episode reward: 2.9000,                 loss: nan
env3_first_0:                 episode reward: -2.6500,                 loss: nan
env3_second_0:                 episode reward: 2.6500,                 loss: nan
env4_first_0:                 episode reward: -2.7000,                 loss: nan
env4_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 272.3421s / 81579.3553 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0278
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0323
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
env3_first_0:                 episode reward: -1.4500,                 loss: nan
env3_second_0:                 episode reward: 1.4500,                 loss: nan
env4_first_0:                 episode reward: -1.3000,                 loss: nan
env4_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 272.3138s / 81851.6691 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0269
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0307
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 1.0000,                 loss: nan
env3_second_0:                 episode reward: -1.0000,                 loss: nan
env4_first_0:                 episode reward: 0.9500,                 loss: nan
env4_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 272.3217s / 82123.9908 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0260
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0296
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
env2_first_0:                 episode reward: -2.8000,                 loss: nan
env2_second_0:                 episode reward: 2.8000,                 loss: nan
env3_first_0:                 episode reward: -2.6500,                 loss: nan
env3_second_0:                 episode reward: 2.6500,                 loss: nan
env4_first_0:                 episode reward: -2.5500,                 loss: nan
env4_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 273.0442s / 82397.0349 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.0250
env0_second_0:                 episode reward: 3.9000,                 loss: 0.0280
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
env2_first_0:                 episode reward: -4.0000,                 loss: nan
env2_second_0:                 episode reward: 4.0000,                 loss: nan
env3_first_0:                 episode reward: -3.9000,                 loss: nan
env3_second_0:                 episode reward: 3.9000,                 loss: nan
env4_first_0:                 episode reward: -3.8000,                 loss: nan
env4_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 271.9188s / 82668.9537 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0235
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0285
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
env2_first_0:                 episode reward: -3.1500,                 loss: nan
env2_second_0:                 episode reward: 3.1500,                 loss: nan
env3_first_0:                 episode reward: -2.8500,                 loss: nan
env3_second_0:                 episode reward: 2.8500,                 loss: nan
env4_first_0:                 episode reward: -3.2500,                 loss: nan
env4_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 274.8086s / 82943.7623 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0236
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0281
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.6000,                 loss: nan
env3_second_0:                 episode reward: -0.6000,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 271.9028s / 83215.6651 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0246
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0288
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: -1.7000,                 loss: nan
env2_second_0:                 episode reward: 1.7000,                 loss: nan
env3_first_0:                 episode reward: -1.5000,                 loss: nan
env3_second_0:                 episode reward: 1.5000,                 loss: nan
env4_first_0:                 episode reward: -1.3500,                 loss: nan
env4_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 269.8749s / 83485.5400 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0254
env0_second_0:                 episode reward: -1.6000,                 loss: 0.0284
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 1.8500,                 loss: nan
env4_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 270.6657s / 83756.2057 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0258
env0_second_0:                 episode reward: -1.9000,                 loss: 0.0288
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.5000,                 loss: nan
env4_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 273.5055s / 84029.7112 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0264
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0292
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
env2_first_0:                 episode reward: -1.4000,                 loss: nan
env2_second_0:                 episode reward: 1.4000,                 loss: nan
env3_first_0:                 episode reward: -1.2500,                 loss: nan
env3_second_0:                 episode reward: 1.2500,                 loss: nan
env4_first_0:                 episode reward: -1.5000,                 loss: nan
env4_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 274.2285s / 84303.9397 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0258
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0279
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
env2_first_0:                 episode reward: -3.7500,                 loss: nan
env2_second_0:                 episode reward: 3.7500,                 loss: nan
env3_first_0:                 episode reward: -3.7500,                 loss: nan
env3_second_0:                 episode reward: 3.7500,                 loss: nan
env4_first_0:                 episode reward: -3.7500,                 loss: nan
env4_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 269.8854s / 84573.8251 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0257
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0282
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
env2_first_0:                 episode reward: -2.4000,                 loss: nan
env2_second_0:                 episode reward: 2.4000,                 loss: nan
env3_first_0:                 episode reward: -2.4000,                 loss: nan
env3_second_0:                 episode reward: 2.4000,                 loss: nan
env4_first_0:                 episode reward: -2.5500,                 loss: nan
env4_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 272.4513s / 84846.2764 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.0263
env0_second_0:                 episode reward: -2.2000,                 loss: 0.0278
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 2.7000,                 loss: nan
env2_second_0:                 episode reward: -2.7000,                 loss: nan
env3_first_0:                 episode reward: 2.4000,                 loss: nan
env3_second_0:                 episode reward: -2.4000,                 loss: nan
env4_first_0:                 episode reward: 2.3500,                 loss: nan
env4_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7339s / 85115.0103 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0247
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0274
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: 0.6000,                 loss: nan
env3_second_0:                 episode reward: -0.6000,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9505s / 85383.9608 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0236
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0278
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 1.0500,                 loss: nan
env3_second_0:                 episode reward: -1.0500,                 loss: nan
env4_first_0:                 episode reward: 0.8000,                 loss: nan
env4_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1089s / 85652.0698 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0238
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0277
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 264.0582s / 85916.1280 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0227
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0282
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
env3_first_0:                 episode reward: -1.9000,                 loss: nan
env3_second_0:                 episode reward: 1.9000,                 loss: nan
env4_first_0:                 episode reward: -1.8000,                 loss: nan
env4_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 258.9025s / 86175.0305 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0232
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0262
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -1.7000,                 loss: nan
env2_second_0:                 episode reward: 1.7000,                 loss: nan
env3_first_0:                 episode reward: -1.6000,                 loss: nan
env3_second_0:                 episode reward: 1.6000,                 loss: nan
env4_first_0:                 episode reward: -1.4000,                 loss: nan
env4_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 251.5297s / 86426.5602 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0236
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0266
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
env2_first_0:                 episode reward: -2.9500,                 loss: nan
env2_second_0:                 episode reward: 2.9500,                 loss: nan
env3_first_0:                 episode reward: -2.8500,                 loss: nan
env3_second_0:                 episode reward: 2.8500,                 loss: nan
env4_first_0:                 episode reward: -2.8000,                 loss: nan
env4_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 249.9489s / 86676.5091 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0234
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0261
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
env3_first_0:                 episode reward: -1.9500,                 loss: nan
env3_second_0:                 episode reward: 1.9500,                 loss: nan
env4_first_0:                 episode reward: -1.9500,                 loss: nan
env4_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 249.6889s / 86926.1980 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0235
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0261
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 244.3093s / 87170.5073 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0227
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0270
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
env3_first_0:                 episode reward: -1.6500,                 loss: nan
env3_second_0:                 episode reward: 1.6500,                 loss: nan
env4_first_0:                 episode reward: -1.4500,                 loss: nan
env4_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 243.0275s / 87413.5348 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0219
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0270
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
env3_first_0:                 episode reward: -1.4000,                 loss: nan
env3_second_0:                 episode reward: 1.4000,                 loss: nan
env4_first_0:                 episode reward: -1.3000,                 loss: nan
env4_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 241.7844s / 87655.3192 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0231
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0261
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
env3_first_0:                 episode reward: -0.0500,                 loss: nan
env3_second_0:                 episode reward: 0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 232.2615s / 87887.5807 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0227
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0256
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
env2_first_0:                 episode reward: -1.5500,                 loss: nan
env2_second_0:                 episode reward: 1.5500,                 loss: nan
env3_first_0:                 episode reward: -1.0500,                 loss: nan
env3_second_0:                 episode reward: 1.0500,                 loss: nan
env4_first_0:                 episode reward: -1.5000,                 loss: nan
env4_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 230.8730s / 88118.4537 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0247
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0249
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 225.9175s / 88344.3712 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0263
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0258
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
env3_first_0:                 episode reward: -1.5500,                 loss: nan
env3_second_0:                 episode reward: 1.5500,                 loss: nan
env4_first_0:                 episode reward: -1.5500,                 loss: nan
env4_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 228.0538s / 88572.4250 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0258
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0274
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 226.3134s / 88798.7384 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0254
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0301
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 222.3679s / 89021.1063 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0284
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0298
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 226.3657s / 89247.4719 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0292
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0317
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
env3_first_0:                 episode reward: -0.7500,                 loss: nan
env3_second_0:                 episode reward: 0.7500,                 loss: nan
env4_first_0:                 episode reward: -0.7500,                 loss: nan
env4_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 227.0179s / 89474.4898 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0295
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0318
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.4500,                 loss: nan
env4_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 224.0867s / 89698.5765 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0310
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0320
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.1000,                 loss: nan
env4_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.8056s / 89917.3821 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0318
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0328
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
env3_first_0:                 episode reward: -2.4500,                 loss: nan
env3_second_0:                 episode reward: 2.4500,                 loss: nan
env4_first_0:                 episode reward: -1.4500,                 loss: nan
env4_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.4656s / 90133.8477 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0348
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0342
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.7500,                 loss: nan
env2_second_0:                 episode reward: 0.7500,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.4000,                 loss: nan
env4_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.7533s / 90352.6010 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0357
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0356
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
env3_first_0:                 episode reward: -1.5000,                 loss: nan
env3_second_0:                 episode reward: 1.5000,                 loss: nan
env4_first_0:                 episode reward: -1.5000,                 loss: nan
env4_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 215.7845s / 90568.3855 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0327
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0352
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.8000,                 loss: nan
env4_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.0605s / 90785.4460 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0314
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0357
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
env3_first_0:                 episode reward: -0.6500,                 loss: nan
env3_second_0:                 episode reward: 0.6500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.6855s / 91005.1315 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0287
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0352
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
env2_first_0:                 episode reward: -4.1000,                 loss: nan
env2_second_0:                 episode reward: 4.1000,                 loss: nan
env3_first_0:                 episode reward: -3.4500,                 loss: nan
env3_second_0:                 episode reward: 3.4500,                 loss: nan
env4_first_0:                 episode reward: -3.8000,                 loss: nan
env4_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.5562s / 91222.6877 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0285
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0327
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
env3_first_0:                 episode reward: 0.3500,                 loss: nan
env3_second_0:                 episode reward: -0.3500,                 loss: nan
env4_first_0:                 episode reward: 0.2500,                 loss: nan
env4_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.4934s / 91441.1811 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0282
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0289
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: 0.9000,                 loss: nan
env2_second_0:                 episode reward: -0.9000,                 loss: nan
env3_first_0:                 episode reward: 1.0500,                 loss: nan
env3_second_0:                 episode reward: -1.0500,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.0799s / 91657.2609 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0277
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0254
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: -0.1500,                 loss: nan
env3_second_0:                 episode reward: 0.1500,                 loss: nan
env4_first_0:                 episode reward: -0.2000,                 loss: nan
env4_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 221.3848s / 91878.6457 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0283
env0_second_0:                 episode reward: -1.9500,                 loss: 0.0245
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.8000,                 loss: nan
env3_second_0:                 episode reward: -1.8000,                 loss: nan
env4_first_0:                 episode reward: 1.6500,                 loss: nan
env4_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 221.8067s / 92100.4524 s
env0_first_0:                 episode reward: 3.4000,                 loss: 0.0247
env0_second_0:                 episode reward: -3.4000,                 loss: 0.0254
env1_first_0:                 episode reward: 4.1000,                 loss: nan
env1_second_0:                 episode reward: -4.1000,                 loss: nan
env2_first_0:                 episode reward: 3.5500,                 loss: nan
env2_second_0:                 episode reward: -3.5500,                 loss: nan
env3_first_0:                 episode reward: 3.5500,                 loss: nan
env3_second_0:                 episode reward: -3.5500,                 loss: nan
env4_first_0:                 episode reward: 3.6000,                 loss: nan
env4_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.5440s / 92317.9964 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0227
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0250
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 1.6500,                 loss: nan
env3_second_0:                 episode reward: -1.6500,                 loss: nan
env4_first_0:                 episode reward: 1.6000,                 loss: nan
env4_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.6256s / 92535.6220 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0198
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0252
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
env2_first_0:                 episode reward: 1.3500,                 loss: nan
env2_second_0:                 episode reward: -1.3500,                 loss: nan
env3_first_0:                 episode reward: 1.3500,                 loss: nan
env3_second_0:                 episode reward: -1.3500,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.0618s / 92752.6838 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0198
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0258
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
env3_first_0:                 episode reward: -0.7500,                 loss: nan
env3_second_0:                 episode reward: 0.7500,                 loss: nan
env4_first_0:                 episode reward: -0.8500,                 loss: nan
env4_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.8359s / 92970.5196 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0203
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0232
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
env3_first_0:                 episode reward: -0.8000,                 loss: nan
env3_second_0:                 episode reward: 0.8000,                 loss: nan
env4_first_0:                 episode reward: -0.6500,                 loss: nan
env4_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 215.5150s / 93186.0346 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0220
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0246
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
env2_first_0:                 episode reward: -1.3500,                 loss: nan
env2_second_0:                 episode reward: 1.3500,                 loss: nan
env3_first_0:                 episode reward: -1.3500,                 loss: nan
env3_second_0:                 episode reward: 1.3500,                 loss: nan
env4_first_0:                 episode reward: -1.5000,                 loss: nan
env4_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.2306s / 93404.2652 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0231
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0260
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
env3_first_0:                 episode reward: -1.0000,                 loss: nan
env3_second_0:                 episode reward: 1.0000,                 loss: nan
env4_first_0:                 episode reward: -1.0500,                 loss: nan
env4_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.0651s / 93620.3304 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0245
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0262
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
env2_first_0:                 episode reward: -2.5500,                 loss: nan
env2_second_0:                 episode reward: 2.5500,                 loss: nan
env3_first_0:                 episode reward: -2.4500,                 loss: nan
env3_second_0:                 episode reward: 2.4500,                 loss: nan
env4_first_0:                 episode reward: -2.6000,                 loss: nan
env4_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 214.4241s / 93834.7545 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0237
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0284
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
env2_first_0:                 episode reward: -2.7000,                 loss: nan
env2_second_0:                 episode reward: 2.7000,                 loss: nan
env3_first_0:                 episode reward: -2.7000,                 loss: nan
env3_second_0:                 episode reward: 2.7000,                 loss: nan
env4_first_0:                 episode reward: -2.6000,                 loss: nan
env4_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.6623s / 94051.4168 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.0231
env0_second_0:                 episode reward: 2.2500,                 loss: 0.0278
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
env2_first_0:                 episode reward: -2.1000,                 loss: nan
env2_second_0:                 episode reward: 2.1000,                 loss: nan
env3_first_0:                 episode reward: -1.9500,                 loss: nan
env3_second_0:                 episode reward: 1.9500,                 loss: nan
env4_first_0:                 episode reward: -1.9500,                 loss: nan
env4_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 215.7525s / 94267.1693 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0238
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0287
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -1.7000,                 loss: nan
env2_second_0:                 episode reward: 1.7000,                 loss: nan
env3_first_0:                 episode reward: -1.8500,                 loss: nan
env3_second_0:                 episode reward: 1.8500,                 loss: nan
env4_first_0:                 episode reward: -1.7500,                 loss: nan
env4_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.7678s / 94484.9371 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0232
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0293
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
env2_first_0:                 episode reward: -3.2500,                 loss: nan
env2_second_0:                 episode reward: 3.2500,                 loss: nan
env3_first_0:                 episode reward: -2.8500,                 loss: nan
env3_second_0:                 episode reward: 2.8500,                 loss: nan
env4_first_0:                 episode reward: -2.8000,                 loss: nan
env4_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 215.8070s / 94700.7441 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0237
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0314
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
env3_first_0:                 episode reward: -1.4000,                 loss: nan
env3_second_0:                 episode reward: 1.4000,                 loss: nan
env4_first_0:                 episode reward: -1.2500,                 loss: nan
env4_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.9905s / 94920.7346 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0241
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0298
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
env2_first_0:                 episode reward: -2.0500,                 loss: nan
env2_second_0:                 episode reward: 2.0500,                 loss: nan
env3_first_0:                 episode reward: -2.1000,                 loss: nan
env3_second_0:                 episode reward: 2.1000,                 loss: nan
env4_first_0:                 episode reward: -2.1000,                 loss: nan
env4_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.7932s / 95141.5279 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0244
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0290
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
env2_first_0:                 episode reward: -2.5000,                 loss: nan
env2_second_0:                 episode reward: 2.5000,                 loss: nan
env3_first_0:                 episode reward: -2.1500,                 loss: nan
env3_second_0:                 episode reward: 2.1500,                 loss: nan
env4_first_0:                 episode reward: -2.0500,                 loss: nan
env4_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.7783s / 95361.3061 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0235
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0284
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
env3_first_0:                 episode reward: -1.6500,                 loss: nan
env3_second_0:                 episode reward: 1.6500,                 loss: nan
env4_first_0:                 episode reward: -1.6500,                 loss: nan
env4_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.3130s / 95578.6191 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0241
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0288
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
env2_first_0:                 episode reward: -2.0500,                 loss: nan
env2_second_0:                 episode reward: 2.0500,                 loss: nan
env3_first_0:                 episode reward: -1.4500,                 loss: nan
env3_second_0:                 episode reward: 1.4500,                 loss: nan
env4_first_0:                 episode reward: -1.6500,                 loss: nan
env4_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.3002s / 95795.9193 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0260
env0_second_0:                 episode reward: 2.0000,                 loss: 0.0294
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -2.0000,                 loss: nan
env2_second_0:                 episode reward: 2.0000,                 loss: nan
env3_first_0:                 episode reward: -2.0000,                 loss: nan
env3_second_0:                 episode reward: 2.0000,                 loss: nan
env4_first_0:                 episode reward: -1.9500,                 loss: nan
env4_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.1094s / 96013.0287 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0255
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0288
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -2.5500,                 loss: nan
env2_second_0:                 episode reward: 2.5500,                 loss: nan
env3_first_0:                 episode reward: -2.6500,                 loss: nan
env3_second_0:                 episode reward: 2.6500,                 loss: nan
env4_first_0:                 episode reward: -2.6500,                 loss: nan
env4_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.0754s / 96231.1042 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0265
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0279
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
env3_first_0:                 episode reward: -1.4500,                 loss: nan
env3_second_0:                 episode reward: 1.4500,                 loss: nan
env4_first_0:                 episode reward: -1.6000,                 loss: nan
env4_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.2588s / 96449.3630 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0284
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0282
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 0.6500,                 loss: nan
env3_second_0:                 episode reward: -0.6500,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.7548s / 96668.1178 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0283
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0284
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.0000,                 loss: nan
env4_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.2670s / 96887.3848 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0284
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0300
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
env2_first_0:                 episode reward: -1.7500,                 loss: nan
env2_second_0:                 episode reward: 1.7500,                 loss: nan
env3_first_0:                 episode reward: -2.2000,                 loss: nan
env3_second_0:                 episode reward: 2.2000,                 loss: nan
env4_first_0:                 episode reward: -1.8500,                 loss: nan
env4_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.2875s / 97106.6723 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0305
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0326
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
env2_first_0:                 episode reward: -3.4000,                 loss: nan
env2_second_0:                 episode reward: 3.4000,                 loss: nan
env3_first_0:                 episode reward: -3.3500,                 loss: nan
env3_second_0:                 episode reward: 3.3500,                 loss: nan
env4_first_0:                 episode reward: -3.3500,                 loss: nan
env4_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.4193s / 97324.0916 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0307
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0351
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
env2_first_0:                 episode reward: -4.0000,                 loss: nan
env2_second_0:                 episode reward: 4.0000,                 loss: nan
env3_first_0:                 episode reward: -4.0000,                 loss: nan
env3_second_0:                 episode reward: 4.0000,                 loss: nan
env4_first_0:                 episode reward: -3.4500,                 loss: nan
env4_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.8884s / 97541.9801 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0327
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0340
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
env2_first_0:                 episode reward: -2.7000,                 loss: nan
env2_second_0:                 episode reward: 2.7000,                 loss: nan
env3_first_0:                 episode reward: -3.0500,                 loss: nan
env3_second_0:                 episode reward: 3.0500,                 loss: nan
env4_first_0:                 episode reward: -2.8500,                 loss: nan
env4_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 215.0503s / 97757.0304 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0335
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0339
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
env2_first_0:                 episode reward: -3.5500,                 loss: nan
env2_second_0:                 episode reward: 3.5500,                 loss: nan
env3_first_0:                 episode reward: -3.5500,                 loss: nan
env3_second_0:                 episode reward: 3.5500,                 loss: nan
env4_first_0:                 episode reward: -3.7500,                 loss: nan
env4_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.4490s / 97976.4794 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.0331
env0_second_0:                 episode reward: 2.2500,                 loss: 0.0343
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
env2_first_0:                 episode reward: -2.3500,                 loss: nan
env2_second_0:                 episode reward: 2.3500,                 loss: nan
env3_first_0:                 episode reward: -2.2000,                 loss: nan
env3_second_0:                 episode reward: 2.2000,                 loss: nan
env4_first_0:                 episode reward: -2.3500,                 loss: nan
env4_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.0854s / 98195.5648 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0333
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0337
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
env3_first_0:                 episode reward: -1.4500,                 loss: nan
env3_second_0:                 episode reward: 1.4500,                 loss: nan
env4_first_0:                 episode reward: -1.6500,                 loss: nan
env4_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.6724s / 98415.2372 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0327
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0326
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
env3_first_0:                 episode reward: -1.0000,                 loss: nan
env3_second_0:                 episode reward: 1.0000,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.5741s / 98633.8113 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0312
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0341
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
env2_first_0:                 episode reward: -1.2000,                 loss: nan
env2_second_0:                 episode reward: 1.2000,                 loss: nan
env3_first_0:                 episode reward: -1.7000,                 loss: nan
env3_second_0:                 episode reward: 1.7000,                 loss: nan
env4_first_0:                 episode reward: -1.5000,                 loss: nan
env4_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.6904s / 98850.5017 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0302
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0335
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.3000,                 loss: nan
env3_second_0:                 episode reward: 0.3000,                 loss: nan
env4_first_0:                 episode reward: -0.7000,                 loss: nan
env4_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.8474s / 99067.3491 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0303
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0322
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -1.1000,                 loss: nan
env4_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.7748s / 99284.1239 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0307
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0284
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
env2_first_0:                 episode reward: -1.2500,                 loss: nan
env2_second_0:                 episode reward: 1.2500,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: -1.0500,                 loss: nan
env4_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.3279s / 99502.4518 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0305
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0276
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
env2_first_0:                 episode reward: -1.4000,                 loss: nan
env2_second_0:                 episode reward: 1.4000,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -1.2500,                 loss: nan
env4_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.4424s / 99719.8943 s
env0_first_0:                 episode reward: 4.5000,                 loss: 0.0288
env0_second_0:                 episode reward: -4.5000,                 loss: 0.0284
env1_first_0:                 episode reward: 4.5000,                 loss: nan
env1_second_0:                 episode reward: -4.5000,                 loss: nan
env2_first_0:                 episode reward: 4.6000,                 loss: nan
env2_second_0:                 episode reward: -4.6000,                 loss: nan
env3_first_0:                 episode reward: 4.3000,                 loss: nan
env3_second_0:                 episode reward: -4.3000,                 loss: nan
env4_first_0:                 episode reward: 4.3000,                 loss: nan
env4_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.9996s / 99937.8939 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.0257
env0_second_0:                 episode reward: -3.4500,                 loss: 0.0288
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
env2_first_0:                 episode reward: 2.7000,                 loss: nan
env2_second_0:                 episode reward: -2.7000,                 loss: nan
env3_first_0:                 episode reward: 3.1000,                 loss: nan
env3_second_0:                 episode reward: -3.1000,                 loss: nan
env4_first_0:                 episode reward: 3.1000,                 loss: nan
env4_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 221.6011s / 100159.4950 s
env0_first_0:                 episode reward: 4.0500,                 loss: 0.0243
env0_second_0:                 episode reward: -4.0500,                 loss: 0.0298
env1_first_0:                 episode reward: 3.8000,                 loss: nan
env1_second_0:                 episode reward: -3.8000,                 loss: nan
env2_first_0:                 episode reward: 3.6500,                 loss: nan
env2_second_0:                 episode reward: -3.6500,                 loss: nan
env3_first_0:                 episode reward: 3.6500,                 loss: nan
env3_second_0:                 episode reward: -3.6500,                 loss: nan
env4_first_0:                 episode reward: 3.8000,                 loss: nan
env4_second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.3528s / 100376.8478 s
env0_first_0:                 episode reward: 4.2000,                 loss: 0.0231
env0_second_0:                 episode reward: -4.2000,                 loss: 0.0319
env1_first_0:                 episode reward: 4.1000,                 loss: nan
env1_second_0:                 episode reward: -4.1000,                 loss: nan
env2_first_0:                 episode reward: 4.1500,                 loss: nan
env2_second_0:                 episode reward: -4.1500,                 loss: nan
env3_first_0:                 episode reward: 4.2000,                 loss: nan
env3_second_0:                 episode reward: -4.2000,                 loss: nan
env4_first_0:                 episode reward: 4.1000,                 loss: nan
env4_second_0:                 episode reward: -4.1000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.3052s / 100597.1531 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0217
env0_second_0:                 episode reward: -1.6000,                 loss: 0.0304
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.8500,                 loss: nan
env3_second_0:                 episode reward: -1.8500,                 loss: nan
env4_first_0:                 episode reward: 1.4000,                 loss: nan
env4_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.9274s / 100815.0804 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0209
env0_second_0:                 episode reward: -1.6500,                 loss: 0.0304
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
env3_first_0:                 episode reward: 1.2000,                 loss: nan
env3_second_0:                 episode reward: -1.2000,                 loss: nan
env4_first_0:                 episode reward: 1.1500,                 loss: nan
env4_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.4353s / 101033.5157 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0200
env0_second_0:                 episode reward: -1.6000,                 loss: 0.0299
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.8000,                 loss: nan
env4_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.9865s / 101251.5022 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.0184
env0_second_0:                 episode reward: -2.7500,                 loss: 0.0298
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 2.7500,                 loss: nan
env2_second_0:                 episode reward: -2.7500,                 loss: nan
env3_first_0:                 episode reward: 2.7500,                 loss: nan
env3_second_0:                 episode reward: -2.7500,                 loss: nan
env4_first_0:                 episode reward: 2.7500,                 loss: nan
env4_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.5679s / 101471.0702 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.0167
env0_second_0:                 episode reward: -2.4500,                 loss: 0.0301
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
env2_first_0:                 episode reward: 2.3500,                 loss: nan
env2_second_0:                 episode reward: -2.3500,                 loss: nan
env3_first_0:                 episode reward: 2.5000,                 loss: nan
env3_second_0:                 episode reward: -2.5000,                 loss: nan
env4_first_0:                 episode reward: 2.3500,                 loss: nan
env4_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.0918s / 101687.1620 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0162
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0268
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 1.0500,                 loss: nan
env2_second_0:                 episode reward: -1.0500,                 loss: nan
env3_first_0:                 episode reward: 0.7500,                 loss: nan
env3_second_0:                 episode reward: -0.7500,                 loss: nan
env4_first_0:                 episode reward: 0.9500,                 loss: nan
env4_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.1948s / 101907.3568 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0157
env0_second_0:                 episode reward: 4.0500,                 loss: 0.0232
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
env2_first_0:                 episode reward: -4.2500,                 loss: nan
env2_second_0:                 episode reward: 4.2500,                 loss: nan
env3_first_0:                 episode reward: -4.1500,                 loss: nan
env3_second_0:                 episode reward: 4.1500,                 loss: nan
env4_first_0:                 episode reward: -4.0500,                 loss: nan
env4_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.8268s / 102126.1836 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0161
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0223
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.4048s / 102346.5883 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0163
env0_second_0:                 episode reward: -1.6500,                 loss: 0.0243
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 1.4000,                 loss: nan
env2_second_0:                 episode reward: -1.4000,                 loss: nan
env3_first_0:                 episode reward: 1.4500,                 loss: nan
env3_second_0:                 episode reward: -1.4500,                 loss: nan
env4_first_0:                 episode reward: 1.7000,                 loss: nan
env4_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.9900s / 102563.5784 s
env0_first_0:                 episode reward: 5.1500,                 loss: 0.0160
env0_second_0:                 episode reward: -5.1500,                 loss: 0.0271
env1_first_0:                 episode reward: 4.8500,                 loss: nan
env1_second_0:                 episode reward: -4.8500,                 loss: nan
env2_first_0:                 episode reward: 5.2000,                 loss: nan
env2_second_0:                 episode reward: -5.2000,                 loss: nan
env3_first_0:                 episode reward: 5.1000,                 loss: nan
env3_second_0:                 episode reward: -5.1000,                 loss: nan
env4_first_0:                 episode reward: 4.6500,                 loss: nan
env4_second_0:                 episode reward: -4.6500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.6467s / 102780.2251 s
env0_first_0:                 episode reward: 4.8000,                 loss: 0.0149
env0_second_0:                 episode reward: -4.8000,                 loss: 0.0290
env1_first_0:                 episode reward: 4.7000,                 loss: nan
env1_second_0:                 episode reward: -4.7000,                 loss: nan
env2_first_0:                 episode reward: 4.7500,                 loss: nan
env2_second_0:                 episode reward: -4.7500,                 loss: nan
env3_first_0:                 episode reward: 5.0000,                 loss: nan
env3_second_0:                 episode reward: -5.0000,                 loss: nan
env4_first_0:                 episode reward: 4.7000,                 loss: nan
env4_second_0:                 episode reward: -4.7000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.9102s / 102999.1353 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.0147
env0_second_0:                 episode reward: -3.6500,                 loss: 0.0303
env1_first_0:                 episode reward: 4.2000,                 loss: nan
env1_second_0:                 episode reward: -4.2000,                 loss: nan
env2_first_0:                 episode reward: 4.0500,                 loss: nan
env2_second_0:                 episode reward: -4.0500,                 loss: nan
env3_first_0:                 episode reward: 3.8500,                 loss: nan
env3_second_0:                 episode reward: -3.8500,                 loss: nan
env4_first_0:                 episode reward: 4.0500,                 loss: nan
env4_second_0:                 episode reward: -4.0500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.9042s / 103220.0395 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.0144
env0_second_0:                 episode reward: -2.8000,                 loss: 0.0292
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
env2_first_0:                 episode reward: 3.1000,                 loss: nan
env2_second_0:                 episode reward: -3.1000,                 loss: nan
env3_first_0:                 episode reward: 2.1500,                 loss: nan
env3_second_0:                 episode reward: -2.1500,                 loss: nan
env4_first_0:                 episode reward: 2.8000,                 loss: nan
env4_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.6350s / 103439.6744 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0145
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0275
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
env2_first_0:                 episode reward: -2.3500,                 loss: nan
env2_second_0:                 episode reward: 2.3500,                 loss: nan
env3_first_0:                 episode reward: -2.0500,                 loss: nan
env3_second_0:                 episode reward: 2.0500,                 loss: nan
env4_first_0:                 episode reward: -2.4000,                 loss: nan
env4_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.5417s / 103660.2161 s
env0_first_0:                 episode reward: -4.7000,                 loss: 0.0152
env0_second_0:                 episode reward: 4.7000,                 loss: 0.0262
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
env2_first_0:                 episode reward: -4.4000,                 loss: nan
env2_second_0:                 episode reward: 4.4000,                 loss: nan
env3_first_0:                 episode reward: -4.4000,                 loss: nan
env3_second_0:                 episode reward: 4.4000,                 loss: nan
env4_first_0:                 episode reward: -4.7500,                 loss: nan
env4_second_0:                 episode reward: 4.7500,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.8794s / 103877.0955 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0153
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0269
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
env2_first_0:                 episode reward: -3.2500,                 loss: nan
env2_second_0:                 episode reward: 3.2500,                 loss: nan
env3_first_0:                 episode reward: -3.4000,                 loss: nan
env3_second_0:                 episode reward: 3.4000,                 loss: nan
env4_first_0:                 episode reward: -3.4500,                 loss: nan
env4_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.9395s / 104098.0350 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0152
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0287
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -2.2500,                 loss: nan
env2_second_0:                 episode reward: 2.2500,                 loss: nan
env3_first_0:                 episode reward: -2.4500,                 loss: nan
env3_second_0:                 episode reward: 2.4500,                 loss: nan
env4_first_0:                 episode reward: -2.5000,                 loss: nan
env4_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.1532s / 104317.1882 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0152
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0291
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -2.3000,                 loss: nan
env2_second_0:                 episode reward: 2.3000,                 loss: nan
env3_first_0:                 episode reward: -2.4500,                 loss: nan
env3_second_0:                 episode reward: 2.4500,                 loss: nan
env4_first_0:                 episode reward: -2.2500,                 loss: nan
env4_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.8547s / 104534.0429 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0161
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0288
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
env2_first_0:                 episode reward: -3.6000,                 loss: nan
env2_second_0:                 episode reward: 3.6000,                 loss: nan
env3_first_0:                 episode reward: -3.6000,                 loss: nan
env3_second_0:                 episode reward: 3.6000,                 loss: nan
env4_first_0:                 episode reward: -3.6000,                 loss: nan
env4_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.8825s / 104750.9253 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0159
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0300
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
env2_first_0:                 episode reward: -2.8000,                 loss: nan
env2_second_0:                 episode reward: 2.8000,                 loss: nan
env3_first_0:                 episode reward: -3.0000,                 loss: nan
env3_second_0:                 episode reward: 3.0000,                 loss: nan
env4_first_0:                 episode reward: -2.7500,                 loss: nan
env4_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.3295s / 104969.2548 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0169
env0_second_0:                 episode reward: 3.1500,                 loss: 0.0289
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
env2_first_0:                 episode reward: -3.1500,                 loss: nan
env2_second_0:                 episode reward: 3.1500,                 loss: nan
env3_first_0:                 episode reward: -3.1000,                 loss: nan
env3_second_0:                 episode reward: 3.1000,                 loss: nan
env4_first_0:                 episode reward: -3.1500,                 loss: nan
env4_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.4812s / 105188.7360 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.0179
env0_second_0:                 episode reward: 2.2000,                 loss: 0.0283
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
env2_first_0:                 episode reward: -2.2000,                 loss: nan
env2_second_0:                 episode reward: 2.2000,                 loss: nan
env3_first_0:                 episode reward: -2.2000,                 loss: nan
env3_second_0:                 episode reward: 2.2000,                 loss: nan
env4_first_0:                 episode reward: -2.2000,                 loss: nan
env4_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.8781s / 105409.6141 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0183
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0275
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
env3_first_0:                 episode reward: -2.8500,                 loss: nan
env3_second_0:                 episode reward: 2.8500,                 loss: nan
env4_first_0:                 episode reward: -2.3000,                 loss: nan
env4_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 221.4175s / 105631.0316 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0168
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0273
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
env2_first_0:                 episode reward: -3.4000,                 loss: nan
env2_second_0:                 episode reward: 3.4000,                 loss: nan
env3_first_0:                 episode reward: -3.4000,                 loss: nan
env3_second_0:                 episode reward: 3.4000,                 loss: nan
env4_first_0:                 episode reward: -3.5000,                 loss: nan
env4_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.0058s / 105850.0374 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.0181
env0_second_0:                 episode reward: 4.2500,                 loss: 0.0275
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
env2_first_0:                 episode reward: -4.4000,                 loss: nan
env2_second_0:                 episode reward: 4.4000,                 loss: nan
env3_first_0:                 episode reward: -4.4000,                 loss: nan
env3_second_0:                 episode reward: 4.4000,                 loss: nan
env4_first_0:                 episode reward: -4.7500,                 loss: nan
env4_second_0:                 episode reward: 4.7500,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.4351s / 106068.4726 s
env0_first_0:                 episode reward: -5.3000,                 loss: 0.0195
env0_second_0:                 episode reward: 5.3000,                 loss: 0.0280
env1_first_0:                 episode reward: -5.2000,                 loss: nan
env1_second_0:                 episode reward: 5.2000,                 loss: nan
env2_first_0:                 episode reward: -5.2000,                 loss: nan
env2_second_0:                 episode reward: 5.2000,                 loss: nan
env3_first_0:                 episode reward: -5.2000,                 loss: nan
env3_second_0:                 episode reward: 5.2000,                 loss: nan
env4_first_0:                 episode reward: -5.3000,                 loss: nan
env4_second_0:                 episode reward: 5.3000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.8239s / 106287.2965 s
env0_first_0:                 episode reward: -6.1000,                 loss: 0.0217
env0_second_0:                 episode reward: 6.1000,                 loss: 0.0287
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
env2_first_0:                 episode reward: -6.3000,                 loss: nan
env2_second_0:                 episode reward: 6.3000,                 loss: nan
env3_first_0:                 episode reward: -6.3000,                 loss: nan
env3_second_0:                 episode reward: 6.3000,                 loss: nan
env4_first_0:                 episode reward: -6.0000,                 loss: nan
env4_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.5082s / 106504.8047 s
env0_first_0:                 episode reward: -3.6000,                 loss: 0.0247
env0_second_0:                 episode reward: 3.6000,                 loss: 0.0292
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
env2_first_0:                 episode reward: -3.4500,                 loss: nan
env2_second_0:                 episode reward: 3.4500,                 loss: nan
env3_first_0:                 episode reward: -3.6000,                 loss: nan
env3_second_0:                 episode reward: 3.6000,                 loss: nan
env4_first_0:                 episode reward: -3.6000,                 loss: nan
env4_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.5611s / 106723.3658 s
env0_first_0:                 episode reward: -4.7500,                 loss: 0.0274
env0_second_0:                 episode reward: 4.7500,                 loss: 0.0296
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
env2_first_0:                 episode reward: -4.9500,                 loss: nan
env2_second_0:                 episode reward: 4.9500,                 loss: nan
env3_first_0:                 episode reward: -5.1000,                 loss: nan
env3_second_0:                 episode reward: 5.1000,                 loss: nan
env4_first_0:                 episode reward: -4.8500,                 loss: nan
env4_second_0:                 episode reward: 4.8500,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.3544s / 106943.7202 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0283
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0303
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
env2_first_0:                 episode reward: -3.4000,                 loss: nan
env2_second_0:                 episode reward: 3.4000,                 loss: nan
env3_first_0:                 episode reward: -3.4000,                 loss: nan
env3_second_0:                 episode reward: 3.4000,                 loss: nan
env4_first_0:                 episode reward: -3.3000,                 loss: nan
env4_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.6868s / 107162.4070 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0265
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0298
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -1.7000,                 loss: nan
env2_second_0:                 episode reward: 1.7000,                 loss: nan
env3_first_0:                 episode reward: -1.7000,                 loss: nan
env3_second_0:                 episode reward: 1.7000,                 loss: nan
env4_first_0:                 episode reward: -1.5500,                 loss: nan
env4_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 222.0003s / 107384.4073 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0240
env0_second_0:                 episode reward: 3.1500,                 loss: 0.0306
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
env2_first_0:                 episode reward: -3.2000,                 loss: nan
env2_second_0:                 episode reward: 3.2000,                 loss: nan
env3_first_0:                 episode reward: -2.9500,                 loss: nan
env3_second_0:                 episode reward: 2.9500,                 loss: nan
env4_first_0:                 episode reward: -3.1500,                 loss: nan
env4_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 223.4791s / 107607.8864 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0233
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0309
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
env2_first_0:                 episode reward: -2.3500,                 loss: nan
env2_second_0:                 episode reward: 2.3500,                 loss: nan
env3_first_0:                 episode reward: -2.6000,                 loss: nan
env3_second_0:                 episode reward: 2.6000,                 loss: nan
env4_first_0:                 episode reward: -2.6000,                 loss: nan
env4_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.7008s / 107827.5872 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.0228
env0_second_0:                 episode reward: 2.2500,                 loss: 0.0305
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
env3_first_0:                 episode reward: -2.4000,                 loss: nan
env3_second_0:                 episode reward: 2.4000,                 loss: nan
env4_first_0:                 episode reward: -2.2500,                 loss: nan
env4_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 221.4934s / 108049.0805 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0216
env0_second_0:                 episode reward: 1.6500,                 loss: 0.0316
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
env2_first_0:                 episode reward: -1.5500,                 loss: nan
env2_second_0:                 episode reward: 1.5500,                 loss: nan
env3_first_0:                 episode reward: -1.5500,                 loss: nan
env3_second_0:                 episode reward: 1.5500,                 loss: nan
env4_first_0:                 episode reward: -1.5500,                 loss: nan
env4_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.1945s / 108269.2751 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0221
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0316
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.5408s / 108488.8159 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0235
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0274
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
env3_first_0:                 episode reward: 0.3000,                 loss: nan
env3_second_0:                 episode reward: -0.3000,                 loss: nan
env4_first_0:                 episode reward: 0.4500,                 loss: nan
env4_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.9026s / 108709.7185 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.0234
env0_second_0:                 episode reward: 2.7500,                 loss: 0.0253
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
env2_first_0:                 episode reward: -2.8000,                 loss: nan
env2_second_0:                 episode reward: 2.8000,                 loss: nan
env3_first_0:                 episode reward: -2.8000,                 loss: nan
env3_second_0:                 episode reward: 2.8000,                 loss: nan
env4_first_0:                 episode reward: -2.8000,                 loss: nan
env4_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.8802s / 108927.5988 s
env0_first_0:                 episode reward: -4.7000,                 loss: 0.0238
env0_second_0:                 episode reward: 4.7000,                 loss: 0.0243
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
env2_first_0:                 episode reward: -4.7500,                 loss: nan
env2_second_0:                 episode reward: 4.7500,                 loss: nan
env3_first_0:                 episode reward: -4.7000,                 loss: nan
env3_second_0:                 episode reward: 4.7000,                 loss: nan
env4_first_0:                 episode reward: -4.7500,                 loss: nan
env4_second_0:                 episode reward: 4.7500,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.2380s / 109145.8367 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0242
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0230
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
env2_first_0:                 episode reward: -2.3500,                 loss: nan
env2_second_0:                 episode reward: 2.3500,                 loss: nan
env3_first_0:                 episode reward: -2.4500,                 loss: nan
env3_second_0:                 episode reward: 2.4500,                 loss: nan
env4_first_0:                 episode reward: -2.4000,                 loss: nan
env4_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 221.4796s / 109367.3163 s
env0_first_0:                 episode reward: -4.6000,                 loss: 0.0250
env0_second_0:                 episode reward: 4.6000,                 loss: 0.0229
env1_first_0:                 episode reward: -4.7500,                 loss: nan
env1_second_0:                 episode reward: 4.7500,                 loss: nan
env2_first_0:                 episode reward: -4.6000,                 loss: nan
env2_second_0:                 episode reward: 4.6000,                 loss: nan
env3_first_0:                 episode reward: -4.6000,                 loss: nan
env3_second_0:                 episode reward: 4.6000,                 loss: nan
env4_first_0:                 episode reward: -4.8000,                 loss: nan
env4_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.2954s / 109587.6118 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0247
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0232
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
env2_first_0:                 episode reward: -2.3000,                 loss: nan
env2_second_0:                 episode reward: 2.3000,                 loss: nan
env3_first_0:                 episode reward: -2.7500,                 loss: nan
env3_second_0:                 episode reward: 2.7500,                 loss: nan
env4_first_0:                 episode reward: -2.6000,                 loss: nan
env4_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.4025s / 109807.0143 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0264
env0_second_0:                 episode reward: 2.9000,                 loss: 0.0234
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
env2_first_0:                 episode reward: -2.7000,                 loss: nan
env2_second_0:                 episode reward: 2.7000,                 loss: nan
env3_first_0:                 episode reward: -2.9000,                 loss: nan
env3_second_0:                 episode reward: 2.9000,                 loss: nan
env4_first_0:                 episode reward: -2.7000,                 loss: nan
env4_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.2497s / 110025.2640 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0271
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0255
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
env2_first_0:                 episode reward: -3.2500,                 loss: nan
env2_second_0:                 episode reward: 3.2500,                 loss: nan
env3_first_0:                 episode reward: -3.4000,                 loss: nan
env3_second_0:                 episode reward: 3.4000,                 loss: nan
env4_first_0:                 episode reward: -3.7500,                 loss: nan
env4_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.4946s / 110245.7587 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0267
env0_second_0:                 episode reward: 4.3000,                 loss: 0.0246
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
env2_first_0:                 episode reward: -4.3000,                 loss: nan
env2_second_0:                 episode reward: 4.3000,                 loss: nan
env3_first_0:                 episode reward: -4.3500,                 loss: nan
env3_second_0:                 episode reward: 4.3500,                 loss: nan
env4_first_0:                 episode reward: -4.3000,                 loss: nan
env4_second_0:                 episode reward: 4.3000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.4053s / 110465.1639 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.0261
env0_second_0:                 episode reward: 2.7500,                 loss: 0.0244
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
env2_first_0:                 episode reward: -2.6000,                 loss: nan
env2_second_0:                 episode reward: 2.6000,                 loss: nan
env3_first_0:                 episode reward: -2.7500,                 loss: nan
env3_second_0:                 episode reward: 2.7500,                 loss: nan
env4_first_0:                 episode reward: -2.7500,                 loss: nan
env4_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.3769s / 110685.5409 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.0276
env0_second_0:                 episode reward: 2.2000,                 loss: 0.0248
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
env3_first_0:                 episode reward: -1.8000,                 loss: nan
env3_second_0:                 episode reward: 1.8000,                 loss: nan
env4_first_0:                 episode reward: -1.6500,                 loss: nan
env4_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.8999s / 110905.4408 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0291
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0259
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
env2_first_0:                 episode reward: -3.0000,                 loss: nan
env2_second_0:                 episode reward: 3.0000,                 loss: nan
env3_first_0:                 episode reward: -2.9000,                 loss: nan
env3_second_0:                 episode reward: 2.9000,                 loss: nan
env4_first_0:                 episode reward: -2.9000,                 loss: nan
env4_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.1021s / 111124.5429 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0281
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0270
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
env3_first_0:                 episode reward: -1.5000,                 loss: nan
env3_second_0:                 episode reward: 1.5000,                 loss: nan
env4_first_0:                 episode reward: -1.6000,                 loss: nan
env4_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.0923s / 111343.6352 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0284
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0275
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: -1.1000,                 loss: nan
env4_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.7459s / 111561.3811 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0302
env0_second_0:                 episode reward: 1.6500,                 loss: 0.0278
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
env2_first_0:                 episode reward: -1.7000,                 loss: nan
env2_second_0:                 episode reward: 1.7000,                 loss: nan
env3_first_0:                 episode reward: -1.6500,                 loss: nan
env3_second_0:                 episode reward: 1.6500,                 loss: nan
env4_first_0:                 episode reward: -1.6500,                 loss: nan
env4_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.9669s / 111780.3480 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0321
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0292
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
env2_first_0:                 episode reward: -1.3500,                 loss: nan
env2_second_0:                 episode reward: 1.3500,                 loss: nan
env3_first_0:                 episode reward: -1.3500,                 loss: nan
env3_second_0:                 episode reward: 1.3500,                 loss: nan
env4_first_0:                 episode reward: -1.3000,                 loss: nan
env4_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.7481s / 111999.0961 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.0320
env0_second_0:                 episode reward: 2.3000,                 loss: 0.0296
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
env2_first_0:                 episode reward: -2.2000,                 loss: nan
env2_second_0:                 episode reward: 2.2000,                 loss: nan
env3_first_0:                 episode reward: -2.2500,                 loss: nan
env3_second_0:                 episode reward: 2.2500,                 loss: nan
env4_first_0:                 episode reward: -2.6000,                 loss: nan
env4_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.1076s / 112217.2036 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0328
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0319
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
env2_first_0:                 episode reward: -3.6500,                 loss: nan
env2_second_0:                 episode reward: 3.6500,                 loss: nan
env3_first_0:                 episode reward: -3.3500,                 loss: nan
env3_second_0:                 episode reward: 3.3500,                 loss: nan
env4_first_0:                 episode reward: -3.8000,                 loss: nan
env4_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 221.8495s / 112439.0531 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.0332
env0_second_0:                 episode reward: 2.7500,                 loss: 0.0319
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
env2_first_0:                 episode reward: -2.4000,                 loss: nan
env2_second_0:                 episode reward: 2.4000,                 loss: nan
env3_first_0:                 episode reward: -2.6000,                 loss: nan
env3_second_0:                 episode reward: 2.6000,                 loss: nan
env4_first_0:                 episode reward: -2.4000,                 loss: nan
env4_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.2931s / 112659.3462 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0358
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0320
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
env2_first_0:                 episode reward: 1.1500,                 loss: nan
env2_second_0:                 episode reward: -1.1500,                 loss: nan
env3_first_0:                 episode reward: 1.1500,                 loss: nan
env3_second_0:                 episode reward: -1.1500,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.7671s / 112879.1134 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0355
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0315
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -0.9500,                 loss: nan
env3_second_0:                 episode reward: 0.9500,                 loss: nan
env4_first_0:                 episode reward: -0.9000,                 loss: nan
env4_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.0573s / 113099.1707 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0366
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0308
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.8319s / 113316.0026 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0363
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0301
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
env2_first_0:                 episode reward: -1.2000,                 loss: nan
env2_second_0:                 episode reward: 1.2000,                 loss: nan
env3_first_0:                 episode reward: -1.3000,                 loss: nan
env3_second_0:                 episode reward: 1.3000,                 loss: nan
env4_first_0:                 episode reward: -1.3500,                 loss: nan
env4_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.4224s / 113535.4250 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.0374
env0_second_0:                 episode reward: 1.8000,                 loss: 0.0306
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
env2_first_0:                 episode reward: -1.8000,                 loss: nan
env2_second_0:                 episode reward: 1.8000,                 loss: nan
env3_first_0:                 episode reward: -1.8000,                 loss: nan
env3_second_0:                 episode reward: 1.8000,                 loss: nan
env4_first_0:                 episode reward: -1.6500,                 loss: nan
env4_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.8335s / 113754.2586 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0379
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0314
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -1.3000,                 loss: nan
env4_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.0940s / 113970.3526 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0381
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0311
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
env3_first_0:                 episode reward: -0.7000,                 loss: nan
env3_second_0:                 episode reward: 0.7000,                 loss: nan
env4_first_0:                 episode reward: -0.5000,                 loss: nan
env4_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 221.3714s / 114191.7240 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0336
env0_second_0:                 episode reward: -1.9500,                 loss: 0.0335
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
env2_first_0:                 episode reward: 1.6000,                 loss: nan
env2_second_0:                 episode reward: -1.6000,                 loss: nan
env3_first_0:                 episode reward: 1.6000,                 loss: nan
env3_second_0:                 episode reward: -1.6000,                 loss: nan
env4_first_0:                 episode reward: 1.8000,                 loss: nan
env4_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 222.3670s / 114414.0910 s
env0_first_0:                 episode reward: 4.8000,                 loss: 0.0270
env0_second_0:                 episode reward: -4.8000,                 loss: 0.0339
env1_first_0:                 episode reward: 4.5000,                 loss: nan
env1_second_0:                 episode reward: -4.5000,                 loss: nan
env2_first_0:                 episode reward: 4.4000,                 loss: nan
env2_second_0:                 episode reward: -4.4000,                 loss: nan
env3_first_0:                 episode reward: 4.6500,                 loss: nan
env3_second_0:                 episode reward: -4.6500,                 loss: nan
env4_first_0:                 episode reward: 4.5500,                 loss: nan
env4_second_0:                 episode reward: -4.5500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.0911s / 114632.1821 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0210
env0_second_0:                 episode reward: -1.9000,                 loss: 0.0321
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
env3_first_0:                 episode reward: 1.8500,                 loss: nan
env3_second_0:                 episode reward: -1.8500,                 loss: nan
env4_first_0:                 episode reward: 1.6500,                 loss: nan
env4_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.1050s / 114851.2871 s
env0_first_0:                 episode reward: -5.4500,                 loss: 0.0183
env0_second_0:                 episode reward: 5.4500,                 loss: 0.0296
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
env2_first_0:                 episode reward: -5.7000,                 loss: nan
env2_second_0:                 episode reward: 5.7000,                 loss: nan
env3_first_0:                 episode reward: -5.7000,                 loss: nan
env3_second_0:                 episode reward: 5.7000,                 loss: nan
env4_first_0:                 episode reward: -5.4500,                 loss: nan
env4_second_0:                 episode reward: 5.4500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.8745s / 115071.1616 s
env0_first_0:                 episode reward: -5.5000,                 loss: 0.0173
env0_second_0:                 episode reward: 5.5000,                 loss: 0.0290
env1_first_0:                 episode reward: -5.5000,                 loss: nan
env1_second_0:                 episode reward: 5.5000,                 loss: nan
env2_first_0:                 episode reward: -5.5000,                 loss: nan
env2_second_0:                 episode reward: 5.5000,                 loss: nan
env3_first_0:                 episode reward: -5.5000,                 loss: nan
env3_second_0:                 episode reward: 5.5000,                 loss: nan
env4_first_0:                 episode reward: -5.5000,                 loss: nan
env4_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.7834s / 115289.9450 s
env0_first_0:                 episode reward: -4.8500,                 loss: 0.0169
env0_second_0:                 episode reward: 4.8500,                 loss: 0.0296
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
env2_first_0:                 episode reward: -5.2500,                 loss: nan
env2_second_0:                 episode reward: 5.2500,                 loss: nan
env3_first_0:                 episode reward: -5.0500,                 loss: nan
env3_second_0:                 episode reward: 5.0500,                 loss: nan
env4_first_0:                 episode reward: -5.0500,                 loss: nan
env4_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.6014s / 115510.5463 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0171
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0293
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
env2_first_0:                 episode reward: -3.0500,                 loss: nan
env2_second_0:                 episode reward: 3.0500,                 loss: nan
env3_first_0:                 episode reward: -3.2000,                 loss: nan
env3_second_0:                 episode reward: 3.2000,                 loss: nan
env4_first_0:                 episode reward: -2.9000,                 loss: nan
env4_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.7469s / 115728.2933 s
env0_first_0:                 episode reward: 5.3000,                 loss: 0.0168
env0_second_0:                 episode reward: -5.3000,                 loss: 0.0301
env1_first_0:                 episode reward: 5.0500,                 loss: nan
env1_second_0:                 episode reward: -5.0500,                 loss: nan
env2_first_0:                 episode reward: 5.1500,                 loss: nan
env2_second_0:                 episode reward: -5.1500,                 loss: nan
env3_first_0:                 episode reward: 5.1000,                 loss: nan
env3_second_0:                 episode reward: -5.1000,                 loss: nan
env4_first_0:                 episode reward: 4.9500,                 loss: nan
env4_second_0:                 episode reward: -4.9500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.2097s / 115948.5030 s
env0_first_0:                 episode reward: 4.8500,                 loss: 0.0168
env0_second_0:                 episode reward: -4.8500,                 loss: 0.0288
env1_first_0:                 episode reward: 4.8500,                 loss: nan
env1_second_0:                 episode reward: -4.8500,                 loss: nan
env2_first_0:                 episode reward: 4.8500,                 loss: nan
env2_second_0:                 episode reward: -4.8500,                 loss: nan
env3_first_0:                 episode reward: 4.8500,                 loss: nan
env3_second_0:                 episode reward: -4.8500,                 loss: nan
env4_first_0:                 episode reward: 4.8500,                 loss: nan
env4_second_0:                 episode reward: -4.8500,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.0848s / 116165.5878 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0171
env0_second_0:                 episode reward: -2.0000,                 loss: 0.0274
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
env2_first_0:                 episode reward: 1.8000,                 loss: nan
env2_second_0:                 episode reward: -1.8000,                 loss: nan
env3_first_0:                 episode reward: 2.1000,                 loss: nan
env3_second_0:                 episode reward: -2.1000,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.6739s / 116384.2617 s
env0_first_0:                 episode reward: -4.7500,                 loss: 0.0175
env0_second_0:                 episode reward: 4.7500,                 loss: 0.0263
env1_first_0:                 episode reward: -4.7500,                 loss: nan
env1_second_0:                 episode reward: 4.7500,                 loss: nan
env2_first_0:                 episode reward: -4.5000,                 loss: nan
env2_second_0:                 episode reward: 4.5000,                 loss: nan
env3_first_0:                 episode reward: -4.7000,                 loss: nan
env3_second_0:                 episode reward: 4.7000,                 loss: nan
env4_first_0:                 episode reward: -4.8000,                 loss: nan
env4_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 221.9294s / 116606.1911 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0176
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0306
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
env2_first_0:                 episode reward: -1.9500,                 loss: nan
env2_second_0:                 episode reward: 1.9500,                 loss: nan
env3_first_0:                 episode reward: -1.9500,                 loss: nan
env3_second_0:                 episode reward: 1.9500,                 loss: nan
env4_first_0:                 episode reward: -1.8000,                 loss: nan
env4_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.9844s / 116825.1755 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0186
env0_second_0:                 episode reward: 1.6500,                 loss: 0.0291
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
env2_first_0:                 episode reward: -1.3500,                 loss: nan
env2_second_0:                 episode reward: 1.3500,                 loss: nan
env3_first_0:                 episode reward: -1.3500,                 loss: nan
env3_second_0:                 episode reward: 1.3500,                 loss: nan
env4_first_0:                 episode reward: -1.5000,                 loss: nan
env4_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.8561s / 117045.0316 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0185
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0259
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.3000,                 loss: nan
env4_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.2535s / 117263.2851 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0182
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0257
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
env3_first_0:                 episode reward: 0.2000,                 loss: nan
env3_second_0:                 episode reward: -0.2000,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 221.8347s / 117485.1198 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0182
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0258
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
env3_first_0:                 episode reward: -1.4500,                 loss: nan
env3_second_0:                 episode reward: 1.4500,                 loss: nan
env4_first_0:                 episode reward: -1.1000,                 loss: nan
env4_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.4182s / 117701.5380 s
env0_first_0:                 episode reward: -4.4000,                 loss: 0.0180
env0_second_0:                 episode reward: 4.4000,                 loss: 0.0246
env1_first_0:                 episode reward: -4.4000,                 loss: nan
env1_second_0:                 episode reward: 4.4000,                 loss: nan
env2_first_0:                 episode reward: -4.3500,                 loss: nan
env2_second_0:                 episode reward: 4.3500,                 loss: nan
env3_first_0:                 episode reward: -4.3500,                 loss: nan
env3_second_0:                 episode reward: 4.3500,                 loss: nan
env4_first_0:                 episode reward: -4.4000,                 loss: nan
env4_second_0:                 episode reward: 4.4000,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.0585s / 117920.5965 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0184
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0234
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
env2_first_0:                 episode reward: -3.3500,                 loss: nan
env2_second_0:                 episode reward: 3.3500,                 loss: nan
env3_first_0:                 episode reward: -3.2500,                 loss: nan
env3_second_0:                 episode reward: 3.2500,                 loss: nan
env4_first_0:                 episode reward: -3.3500,                 loss: nan
env4_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.3632s / 118138.9597 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0192
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0255
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
env2_first_0:                 episode reward: -3.5000,                 loss: nan
env2_second_0:                 episode reward: 3.5000,                 loss: nan
env3_first_0:                 episode reward: -3.4500,                 loss: nan
env3_second_0:                 episode reward: 3.4500,                 loss: nan
env4_first_0:                 episode reward: -3.6000,                 loss: nan
env4_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.1622s / 118357.1218 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0200
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0257
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
env2_first_0:                 episode reward: -3.3500,                 loss: nan
env2_second_0:                 episode reward: 3.3500,                 loss: nan
env3_first_0:                 episode reward: -3.2500,                 loss: nan
env3_second_0:                 episode reward: 3.2500,                 loss: nan
env4_first_0:                 episode reward: -3.2000,                 loss: nan
env4_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.8795s / 118577.0013 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0205
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0269
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
env3_first_0:                 episode reward: 1.3000,                 loss: nan
env3_second_0:                 episode reward: -1.3000,                 loss: nan
env4_first_0:                 episode reward: 1.3000,                 loss: nan
env4_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 221.3202s / 118798.3216 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.0193
env0_second_0:                 episode reward: -2.8500,                 loss: 0.0265
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 3.2500,                 loss: nan
env2_second_0:                 episode reward: -3.2500,                 loss: nan
env3_first_0:                 episode reward: 2.8000,                 loss: nan
env3_second_0:                 episode reward: -2.8000,                 loss: nan
env4_first_0:                 episode reward: 3.0000,                 loss: nan
env4_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 222.8924s / 119021.2139 s
env0_first_0:                 episode reward: 2.2500,                 loss: 0.0186
env0_second_0:                 episode reward: -2.2500,                 loss: 0.0247
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
env2_first_0:                 episode reward: 2.2500,                 loss: nan
env2_second_0:                 episode reward: -2.2500,                 loss: nan
env3_first_0:                 episode reward: 2.2500,                 loss: nan
env3_second_0:                 episode reward: -2.2500,                 loss: nan
env4_first_0:                 episode reward: 2.2500,                 loss: nan
env4_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.5163s / 119238.7302 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0201
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0258
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: 1.0500,                 loss: nan
env2_second_0:                 episode reward: -1.0500,                 loss: nan
env3_first_0:                 episode reward: 1.1000,                 loss: nan
env3_second_0:                 episode reward: -1.1000,                 loss: nan
env4_first_0:                 episode reward: 0.9500,                 loss: nan
env4_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.3859s / 119458.1161 s
env0_first_0:                 episode reward: 4.5500,                 loss: 0.0200
env0_second_0:                 episode reward: -4.5500,                 loss: 0.0280
env1_first_0:                 episode reward: 4.5500,                 loss: nan
env1_second_0:                 episode reward: -4.5500,                 loss: nan
env2_first_0:                 episode reward: 4.3000,                 loss: nan
env2_second_0:                 episode reward: -4.3000,                 loss: nan
env3_first_0:                 episode reward: 4.7500,                 loss: nan
env3_second_0:                 episode reward: -4.7500,                 loss: nan
env4_first_0:                 episode reward: 4.3000,                 loss: nan
env4_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.1292s / 119676.2453 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0195
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0258
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
env3_first_0:                 episode reward: -0.1000,                 loss: nan
env3_second_0:                 episode reward: 0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.0556s / 119892.3009 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0206
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0246
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -1.5500,                 loss: nan
env2_second_0:                 episode reward: 1.5500,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -0.8500,                 loss: nan
env4_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.5909s / 120109.8918 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0206
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0239
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
env3_first_0:                 episode reward: -0.9500,                 loss: nan
env3_second_0:                 episode reward: 0.9500,                 loss: nan
env4_first_0:                 episode reward: -0.9500,                 loss: nan
env4_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.1196s / 120330.0114 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0212
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0268
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -1.4000,                 loss: nan
env3_second_0:                 episode reward: 1.4000,                 loss: nan
env4_first_0:                 episode reward: -1.0500,                 loss: nan
env4_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.9235s / 120549.9349 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0203
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0295
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
env2_first_0:                 episode reward: -1.9500,                 loss: nan
env2_second_0:                 episode reward: 1.9500,                 loss: nan
env3_first_0:                 episode reward: -2.0500,                 loss: nan
env3_second_0:                 episode reward: 2.0500,                 loss: nan
env4_first_0:                 episode reward: -1.9500,                 loss: nan
env4_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 219.2743s / 120769.2092 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0198
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0283
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
env3_first_0:                 episode reward: -0.2500,                 loss: nan
env3_second_0:                 episode reward: 0.2500,                 loss: nan
env4_first_0:                 episode reward: -0.1500,                 loss: nan
env4_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.3739s / 120986.5831 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.0196
env0_second_0:                 episode reward: -3.2000,                 loss: 0.0295
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
env2_first_0:                 episode reward: 3.1500,                 loss: nan
env2_second_0:                 episode reward: -3.1500,                 loss: nan
env3_first_0:                 episode reward: 3.0000,                 loss: nan
env3_second_0:                 episode reward: -3.0000,                 loss: nan
env4_first_0:                 episode reward: 3.2000,                 loss: nan
env4_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.6469s / 121203.2300 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.0185
env0_second_0:                 episode reward: -3.6000,                 loss: 0.0298
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
env2_first_0:                 episode reward: 3.6500,                 loss: nan
env2_second_0:                 episode reward: -3.6500,                 loss: nan
env3_first_0:                 episode reward: 3.6000,                 loss: nan
env3_second_0:                 episode reward: -3.6000,                 loss: nan
env4_first_0:                 episode reward: 3.4500,                 loss: nan
env4_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.7470s / 121420.9770 s
env0_first_0:                 episode reward: 3.8000,                 loss: 0.0175
env0_second_0:                 episode reward: -3.8000,                 loss: 0.0257
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
env2_first_0:                 episode reward: 3.7500,                 loss: nan
env2_second_0:                 episode reward: -3.7500,                 loss: nan
env3_first_0:                 episode reward: 3.8000,                 loss: nan
env3_second_0:                 episode reward: -3.8000,                 loss: nan
env4_first_0:                 episode reward: 3.7500,                 loss: nan
env4_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 220.7434s / 121641.7203 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.0172
env0_second_0:                 episode reward: 2.3000,                 loss: 0.0242
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
env2_first_0:                 episode reward: -2.5000,                 loss: nan
env2_second_0:                 episode reward: 2.5000,                 loss: nan
env3_first_0:                 episode reward: -2.3000,                 loss: nan
env3_second_0:                 episode reward: 2.3000,                 loss: nan
env4_first_0:                 episode reward: -2.5000,                 loss: nan
env4_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 221.1725s / 121862.8928 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0172
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0252
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
env2_first_0:                 episode reward: -1.8000,                 loss: nan
env2_second_0:                 episode reward: 1.8000,                 loss: nan
env3_first_0:                 episode reward: -2.3500,                 loss: nan
env3_second_0:                 episode reward: 2.3500,                 loss: nan
env4_first_0:                 episode reward: -2.3500,                 loss: nan
env4_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.7350s / 122081.6278 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0175
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0272
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
env3_first_0:                 episode reward: -0.4000,                 loss: nan
env3_second_0:                 episode reward: 0.4000,                 loss: nan
env4_first_0:                 episode reward: -0.5500,                 loss: nan
env4_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 224.1385s / 122305.7663 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.0176
env0_second_0:                 episode reward: -3.0500,                 loss: 0.0295
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
env2_first_0:                 episode reward: 3.0500,                 loss: nan
env2_second_0:                 episode reward: -3.0500,                 loss: nan
env3_first_0:                 episode reward: 2.5500,                 loss: nan
env3_second_0:                 episode reward: -2.5500,                 loss: nan
env4_first_0:                 episode reward: 2.7000,                 loss: nan
env4_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 218.1689s / 122523.9352 s
env0_first_0:                 episode reward: 4.6000,                 loss: 0.0167
env0_second_0:                 episode reward: -4.6000,                 loss: 0.0264
env1_first_0:                 episode reward: 4.4000,                 loss: nan
env1_second_0:                 episode reward: -4.4000,                 loss: nan
env2_first_0:                 episode reward: 4.6000,                 loss: nan
env2_second_0:                 episode reward: -4.6000,                 loss: nan
env3_first_0:                 episode reward: 4.5000,                 loss: nan
env3_second_0:                 episode reward: -4.5000,                 loss: nan
env4_first_0:                 episode reward: 4.4000,                 loss: nan
env4_second_0:                 episode reward: -4.4000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.2776s / 122740.2128 s
env0_first_0:                 episode reward: 3.9500,                 loss: 0.0165
env0_second_0:                 episode reward: -3.9500,                 loss: 0.0230
env1_first_0:                 episode reward: 3.8500,                 loss: nan
env1_second_0:                 episode reward: -3.8500,                 loss: nan
env2_first_0:                 episode reward: 3.8500,                 loss: nan
env2_second_0:                 episode reward: -3.8500,                 loss: nan
env3_first_0:                 episode reward: 4.0500,                 loss: nan
env3_second_0:                 episode reward: -4.0500,                 loss: nan
env4_first_0:                 episode reward: 4.1000,                 loss: nan
env4_second_0:                 episode reward: -4.1000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.1605s / 122956.3733 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.0155
env0_second_0:                 episode reward: -2.8000,                 loss: 0.0206
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
env2_first_0:                 episode reward: 3.2000,                 loss: nan
env2_second_0:                 episode reward: -3.2000,                 loss: nan
env3_first_0:                 episode reward: 3.1000,                 loss: nan
env3_second_0:                 episode reward: -3.1000,                 loss: nan
env4_first_0:                 episode reward: 2.7500,                 loss: nan
env4_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.9589s / 123173.3322 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0158
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0207
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.1000,                 loss: nan
env3_second_0:                 episode reward: -0.1000,                 loss: nan
env4_first_0:                 episode reward: 0.1000,                 loss: nan
env4_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.9342s / 123391.2664 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0161
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0230
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
env3_first_0:                 episode reward: -0.4500,                 loss: nan
env3_second_0:                 episode reward: 0.4500,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.0534s / 123607.3198 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0161
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0257
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
env3_first_0:                 episode reward: 1.8500,                 loss: nan
env3_second_0:                 episode reward: -1.8500,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.8829s / 123825.2027 s
env0_first_0:                 episode reward: 4.0500,                 loss: 0.0152
env0_second_0:                 episode reward: -4.0500,                 loss: 0.0311
env1_first_0:                 episode reward: 3.8500,                 loss: nan
env1_second_0:                 episode reward: -3.8500,                 loss: nan
env2_first_0:                 episode reward: 3.7500,                 loss: nan
env2_second_0:                 episode reward: -3.7500,                 loss: nan
env3_first_0:                 episode reward: 3.9000,                 loss: nan
env3_second_0:                 episode reward: -3.9000,                 loss: nan
env4_first_0:                 episode reward: 3.8500,                 loss: nan
env4_second_0:                 episode reward: -3.8500,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.7011s / 124041.9038 s
env0_first_0:                 episode reward: 4.4000,                 loss: 0.0149
env0_second_0:                 episode reward: -4.4000,                 loss: 0.0320
env1_first_0:                 episode reward: 4.7000,                 loss: nan
env1_second_0:                 episode reward: -4.7000,                 loss: nan
env2_first_0:                 episode reward: 4.7000,                 loss: nan
env2_second_0:                 episode reward: -4.7000,                 loss: nan
env3_first_0:                 episode reward: 4.4000,                 loss: nan
env3_second_0:                 episode reward: -4.4000,                 loss: nan
env4_first_0:                 episode reward: 4.7000,                 loss: nan
env4_second_0:                 episode reward: -4.7000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.3815s / 124259.2852 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0148
env0_second_0:                 episode reward: -2.7000,                 loss: 0.0252
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
env2_first_0:                 episode reward: 2.8000,                 loss: nan
env2_second_0:                 episode reward: -2.8000,                 loss: nan
env3_first_0:                 episode reward: 3.2000,                 loss: nan
env3_second_0:                 episode reward: -3.2000,                 loss: nan
env4_first_0:                 episode reward: 3.2000,                 loss: nan
env4_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.8853s / 124477.1706 s
env0_first_0:                 episode reward: 4.7500,                 loss: 0.0151
env0_second_0:                 episode reward: -4.7500,                 loss: 0.0223
env1_first_0:                 episode reward: 4.7000,                 loss: nan
env1_second_0:                 episode reward: -4.7000,                 loss: nan
env2_first_0:                 episode reward: 4.8000,                 loss: nan
env2_second_0:                 episode reward: -4.8000,                 loss: nan
env3_first_0:                 episode reward: 4.7000,                 loss: nan
env3_second_0:                 episode reward: -4.7000,                 loss: nan
env4_first_0:                 episode reward: 4.7500,                 loss: nan
env4_second_0:                 episode reward: -4.7500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 215.7704s / 124692.9409 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0158
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0231
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
env2_first_0:                 episode reward: -2.4500,                 loss: nan
env2_second_0:                 episode reward: 2.4500,                 loss: nan
env3_first_0:                 episode reward: -2.5500,                 loss: nan
env3_second_0:                 episode reward: 2.5500,                 loss: nan
env4_first_0:                 episode reward: -2.6000,                 loss: nan
env4_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 214.4236s / 124907.3645 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0160
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0266
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
env3_first_0:                 episode reward: -1.1000,                 loss: nan
env3_second_0:                 episode reward: 1.1000,                 loss: nan
env4_first_0:                 episode reward: -1.0000,                 loss: nan
env4_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 215.4862s / 125122.8507 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0163
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0285
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
env3_first_0:                 episode reward: -1.1500,                 loss: nan
env3_second_0:                 episode reward: 1.1500,                 loss: nan
env4_first_0:                 episode reward: -0.7500,                 loss: nan
env4_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 215.7248s / 125338.5755 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0168
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0275
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
env3_first_0:                 episode reward: 1.2500,                 loss: nan
env3_second_0:                 episode reward: -1.2500,                 loss: nan
env4_first_0:                 episode reward: 1.3000,                 loss: nan
env4_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 215.6055s / 125554.1811 s
env0_first_0:                 episode reward: 3.9000,                 loss: 0.0161
env0_second_0:                 episode reward: -3.9000,                 loss: 0.0267
env1_first_0:                 episode reward: 4.1000,                 loss: nan
env1_second_0:                 episode reward: -4.1000,                 loss: nan
env2_first_0:                 episode reward: 3.9000,                 loss: nan
env2_second_0:                 episode reward: -3.9000,                 loss: nan
env3_first_0:                 episode reward: 4.1000,                 loss: nan
env3_second_0:                 episode reward: -4.1000,                 loss: nan
env4_first_0:                 episode reward: 3.9000,                 loss: nan
env4_second_0:                 episode reward: -3.9000,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.5768s / 125771.7579 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0160
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0266
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: -0.2500,                 loss: nan
env4_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 215.1555s / 125986.9134 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0162
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0274
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.5500,                 loss: nan
env2_second_0:                 episode reward: -0.5500,                 loss: nan
env3_first_0:                 episode reward: 0.6500,                 loss: nan
env3_second_0:                 episode reward: -0.6500,                 loss: nan
env4_first_0:                 episode reward: 0.8000,                 loss: nan
env4_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.5009s / 126203.4142 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0168
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0290
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
env2_first_0:                 episode reward: 1.2000,                 loss: nan
env2_second_0:                 episode reward: -1.2000,                 loss: nan
env3_first_0:                 episode reward: 0.8500,                 loss: nan
env3_second_0:                 episode reward: -0.8500,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 214.9857s / 126418.3999 s
env0_first_0:                 episode reward: 4.2000,                 loss: 0.0172
env0_second_0:                 episode reward: -4.2000,                 loss: 0.0316
env1_first_0:                 episode reward: 4.1000,                 loss: nan
env1_second_0:                 episode reward: -4.1000,                 loss: nan
env2_first_0:                 episode reward: 4.3000,                 loss: nan
env2_second_0:                 episode reward: -4.3000,                 loss: nan
env3_first_0:                 episode reward: 4.1000,                 loss: nan
env3_second_0:                 episode reward: -4.1000,                 loss: nan
env4_first_0:                 episode reward: 4.5000,                 loss: nan
env4_second_0:                 episode reward: -4.5000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.6472s / 126635.0472 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.0169
env0_second_0:                 episode reward: -3.7000,                 loss: 0.0338
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
env2_first_0:                 episode reward: 3.3000,                 loss: nan
env2_second_0:                 episode reward: -3.3000,                 loss: nan
env3_first_0:                 episode reward: 3.3000,                 loss: nan
env3_second_0:                 episode reward: -3.3000,                 loss: nan
env4_first_0:                 episode reward: 3.6000,                 loss: nan
env4_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 215.4402s / 126850.4873 s
env0_first_0:                 episode reward: 4.2500,                 loss: 0.0166
env0_second_0:                 episode reward: -4.2500,                 loss: 0.0322
env1_first_0:                 episode reward: 5.1000,                 loss: nan
env1_second_0:                 episode reward: -5.1000,                 loss: nan
env2_first_0:                 episode reward: 4.6500,                 loss: nan
env2_second_0:                 episode reward: -4.6500,                 loss: nan
env3_first_0:                 episode reward: 4.8500,                 loss: nan
env3_second_0:                 episode reward: -4.8500,                 loss: nan
env4_first_0:                 episode reward: 4.6000,                 loss: nan
env4_second_0:                 episode reward: -4.6000,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.2785s / 127066.7658 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0161
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0289
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
env3_first_0:                 episode reward: 0.5000,                 loss: nan
env3_second_0:                 episode reward: -0.5000,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 213.5756s / 127280.3414 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.0165
env0_second_0:                 episode reward: 2.6000,                 loss: 0.0261
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
env2_first_0:                 episode reward: -2.6000,                 loss: nan
env2_second_0:                 episode reward: 2.6000,                 loss: nan
env3_first_0:                 episode reward: -2.5000,                 loss: nan
env3_second_0:                 episode reward: 2.5000,                 loss: nan
env4_first_0:                 episode reward: -2.5000,                 loss: nan
env4_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 215.1270s / 127495.4685 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0165
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0246
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
env3_first_0:                 episode reward: -1.5500,                 loss: nan
env3_second_0:                 episode reward: 1.5500,                 loss: nan
env4_first_0:                 episode reward: -1.3000,                 loss: nan
env4_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 214.2568s / 127709.7253 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0173
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0272
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
env2_first_0:                 episode reward: -3.3000,                 loss: nan
env2_second_0:                 episode reward: 3.3000,                 loss: nan
env3_first_0:                 episode reward: -3.0000,                 loss: nan
env3_second_0:                 episode reward: 3.0000,                 loss: nan
env4_first_0:                 episode reward: -3.1500,                 loss: nan
env4_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.3636s / 127927.0889 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.0167
env0_second_0:                 episode reward: 2.6000,                 loss: 0.0279
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
env2_first_0:                 episode reward: -2.5000,                 loss: nan
env2_second_0:                 episode reward: 2.5000,                 loss: nan
env3_first_0:                 episode reward: -2.6000,                 loss: nan
env3_second_0:                 episode reward: 2.6000,                 loss: nan
env4_first_0:                 episode reward: -2.3500,                 loss: nan
env4_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 214.3276s / 128141.4165 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0179
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0277
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
env2_first_0:                 episode reward: 1.4000,                 loss: nan
env2_second_0:                 episode reward: -1.4000,                 loss: nan
env3_first_0:                 episode reward: 1.4000,                 loss: nan
env3_second_0:                 episode reward: -1.4000,                 loss: nan
env4_first_0:                 episode reward: 1.0500,                 loss: nan
env4_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.3843s / 128358.8009 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0182
env0_second_0:                 episode reward: -1.5500,                 loss: 0.0251
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
env3_first_0:                 episode reward: 1.4500,                 loss: nan
env3_second_0:                 episode reward: -1.4500,                 loss: nan
env4_first_0:                 episode reward: 1.4500,                 loss: nan
env4_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.0565s / 128574.8573 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0186
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0233
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
env3_first_0:                 episode reward: 0.4000,                 loss: nan
env3_second_0:                 episode reward: -0.4000,                 loss: nan
env4_first_0:                 episode reward: 0.4000,                 loss: nan
env4_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 214.8933s / 128789.7506 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0194
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0249
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
env3_first_0:                 episode reward: -0.5000,                 loss: nan
env3_second_0:                 episode reward: 0.5000,                 loss: nan
env4_first_0:                 episode reward: -0.3000,                 loss: nan
env4_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.7883s / 129006.5388 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.0202
env0_second_0:                 episode reward: -3.0500,                 loss: 0.0272
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
env2_first_0:                 episode reward: 3.0000,                 loss: nan
env2_second_0:                 episode reward: -3.0000,                 loss: nan
env3_first_0:                 episode reward: 3.2500,                 loss: nan
env3_second_0:                 episode reward: -3.2500,                 loss: nan
env4_first_0:                 episode reward: 3.3000,                 loss: nan
env4_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 212.5427s / 129219.0816 s
env0_first_0:                 episode reward: 4.2000,                 loss: 0.0199
env0_second_0:                 episode reward: -4.2000,                 loss: 0.0273
env1_first_0:                 episode reward: 3.9000,                 loss: nan
env1_second_0:                 episode reward: -3.9000,                 loss: nan
env2_first_0:                 episode reward: 3.9000,                 loss: nan
env2_second_0:                 episode reward: -3.9000,                 loss: nan
env3_first_0:                 episode reward: 4.1000,                 loss: nan
env3_second_0:                 episode reward: -4.1000,                 loss: nan
env4_first_0:                 episode reward: 4.2000,                 loss: nan
env4_second_0:                 episode reward: -4.2000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.3667s / 129435.4483 s
env0_first_0:                 episode reward: 4.2500,                 loss: 0.0191
env0_second_0:                 episode reward: -4.2500,                 loss: 0.0268
env1_first_0:                 episode reward: 4.2500,                 loss: nan
env1_second_0:                 episode reward: -4.2500,                 loss: nan
env2_first_0:                 episode reward: 4.2500,                 loss: nan
env2_second_0:                 episode reward: -4.2500,                 loss: nan
env3_first_0:                 episode reward: 4.3000,                 loss: nan
env3_second_0:                 episode reward: -4.3000,                 loss: nan
env4_first_0:                 episode reward: 4.2000,                 loss: nan
env4_second_0:                 episode reward: -4.2000,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.2283s / 129651.6766 s
env0_first_0:                 episode reward: 4.2000,                 loss: 0.0183
env0_second_0:                 episode reward: -4.2000,                 loss: 0.0237
env1_first_0:                 episode reward: 4.4500,                 loss: nan
env1_second_0:                 episode reward: -4.4500,                 loss: nan
env2_first_0:                 episode reward: 3.9000,                 loss: nan
env2_second_0:                 episode reward: -3.9000,                 loss: nan
env3_first_0:                 episode reward: 3.7500,                 loss: nan
env3_second_0:                 episode reward: -3.7500,                 loss: nan
env4_first_0:                 episode reward: 4.3000,                 loss: nan
env4_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 214.3140s / 129865.9906 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.0186
env0_second_0:                 episode reward: -3.5000,                 loss: 0.0214
env1_first_0:                 episode reward: 3.6500,                 loss: nan
env1_second_0:                 episode reward: -3.6500,                 loss: nan
env2_first_0:                 episode reward: 3.5000,                 loss: nan
env2_second_0:                 episode reward: -3.5000,                 loss: nan
env3_first_0:                 episode reward: 3.2500,                 loss: nan
env3_second_0:                 episode reward: -3.2500,                 loss: nan
env4_first_0:                 episode reward: 3.7000,                 loss: nan
env4_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 215.6537s / 130081.6443 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0190
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0211
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
env3_first_0:                 episode reward: 1.3000,                 loss: nan
env3_second_0:                 episode reward: -1.3000,                 loss: nan
env4_first_0:                 episode reward: 1.1000,                 loss: nan
env4_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 215.2914s / 130296.9357 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0192
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0228
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
env3_first_0:                 episode reward: 0.0500,                 loss: nan
env3_second_0:                 episode reward: -0.0500,                 loss: nan
env4_first_0:                 episode reward: 0.0500,                 loss: nan
env4_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 214.0010s / 130510.9367 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0199
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0245
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
env2_first_0:                 episode reward: -2.2000,                 loss: nan
env2_second_0:                 episode reward: 2.2000,                 loss: nan
env3_first_0:                 episode reward: -2.3000,                 loss: nan
env3_second_0:                 episode reward: 2.3000,                 loss: nan
env4_first_0:                 episode reward: -2.2500,                 loss: nan
env4_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 213.0338s / 130723.9705 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0202
env0_second_0:                 episode reward: 2.5500,                 loss: 0.0263
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
env2_first_0:                 episode reward: -2.5500,                 loss: nan
env2_second_0:                 episode reward: 2.5500,                 loss: nan
env3_first_0:                 episode reward: -2.5500,                 loss: nan
env3_second_0:                 episode reward: 2.5500,                 loss: nan
env4_first_0:                 episode reward: -2.5500,                 loss: nan
env4_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 222.9082s / 130946.8787 s
env0_first_0:                 episode reward: 4.2500,                 loss: 0.0191
env0_second_0:                 episode reward: -4.2500,                 loss: 0.0272
env1_first_0:                 episode reward: 4.1500,                 loss: nan
env1_second_0:                 episode reward: -4.1500,                 loss: nan
env2_first_0:                 episode reward: 4.5000,                 loss: nan
env2_second_0:                 episode reward: -4.5000,                 loss: nan
env3_first_0:                 episode reward: 4.4000,                 loss: nan
env3_second_0:                 episode reward: -4.4000,                 loss: nan
env4_first_0:                 episode reward: 4.4500,                 loss: nan
env4_second_0:                 episode reward: -4.4500,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 217.9499s / 131164.8286 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.0190
env0_second_0:                 episode reward: -2.4000,                 loss: 0.0245
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
env3_first_0:                 episode reward: 2.4000,                 loss: nan
env3_second_0:                 episode reward: -2.4000,                 loss: nan
env4_first_0:                 episode reward: 2.0000,                 loss: nan
env4_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 215.1198s / 131379.9484 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0193
env0_second_0:                 episode reward: 4.1500,                 loss: 0.0231
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
env2_first_0:                 episode reward: -3.9500,                 loss: nan
env2_second_0:                 episode reward: 3.9500,                 loss: nan
env3_first_0:                 episode reward: -4.0500,                 loss: nan
env3_second_0:                 episode reward: 4.0500,                 loss: nan
env4_first_0:                 episode reward: -3.9500,                 loss: nan
env4_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 215.7304s / 131595.6788 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0194
env0_second_0:                 episode reward: 4.0500,                 loss: 0.0225
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
env2_first_0:                 episode reward: -4.0500,                 loss: nan
env2_second_0:                 episode reward: 4.0500,                 loss: nan
env3_first_0:                 episode reward: -4.0500,                 loss: nan
env3_second_0:                 episode reward: 4.0500,                 loss: nan
env4_first_0:                 episode reward: -4.0500,                 loss: nan
env4_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 214.3618s / 131810.0406 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0190
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0239
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
env3_first_0:                 episode reward: 0.6500,                 loss: nan
env3_second_0:                 episode reward: -0.6500,                 loss: nan
env4_first_0:                 episode reward: 0.6500,                 loss: nan
env4_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 215.7197s / 132025.7604 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0186
env0_second_0:                 episode reward: -2.7000,                 loss: 0.0242
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
env2_first_0:                 episode reward: 2.7000,                 loss: nan
env2_second_0:                 episode reward: -2.7000,                 loss: nan
env3_first_0:                 episode reward: 2.5000,                 loss: nan
env3_second_0:                 episode reward: -2.5000,                 loss: nan
env4_first_0:                 episode reward: 2.7000,                 loss: nan
env4_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 215.8561s / 132241.6165 s
env0_first_0:                 episode reward: 4.7500,                 loss: 0.0185
env0_second_0:                 episode reward: -4.7500,                 loss: 0.0234
env1_first_0:                 episode reward: 4.8500,                 loss: nan
env1_second_0:                 episode reward: -4.8500,                 loss: nan
env2_first_0:                 episode reward: 4.8000,                 loss: nan
env2_second_0:                 episode reward: -4.8000,                 loss: nan
env3_first_0:                 episode reward: 4.8000,                 loss: nan
env3_second_0:                 episode reward: -4.8000,                 loss: nan
env4_first_0:                 episode reward: 4.9500,                 loss: nan
env4_second_0:                 episode reward: -4.9500,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 213.9395s / 132455.5560 s
env0_first_0:                 episode reward: 5.0500,                 loss: 0.0178
env0_second_0:                 episode reward: -5.0500,                 loss: 0.0208
env1_first_0:                 episode reward: 5.0500,                 loss: nan
env1_second_0:                 episode reward: -5.0500,                 loss: nan
env2_first_0:                 episode reward: 4.8000,                 loss: nan
env2_second_0:                 episode reward: -4.8000,                 loss: nan
env3_first_0:                 episode reward: 5.2500,                 loss: nan
env3_second_0:                 episode reward: -5.2500,                 loss: nan
env4_first_0:                 episode reward: 4.8500,                 loss: nan
env4_second_0:                 episode reward: -4.8500,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.3226s / 132671.8786 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.0180
env0_second_0:                 episode reward: -2.4500,                 loss: 0.0191
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
env2_first_0:                 episode reward: 2.3000,                 loss: nan
env2_second_0:                 episode reward: -2.3000,                 loss: nan
env3_first_0:                 episode reward: 2.5500,                 loss: nan
env3_second_0:                 episode reward: -2.5500,                 loss: nan
env4_first_0:                 episode reward: 2.4500,                 loss: nan
env4_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 216.8126s / 132888.6911 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.0181
env0_second_0:                 episode reward: 2.2000,                 loss: 0.0202
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
env2_first_0:                 episode reward: -2.1500,                 loss: nan
env2_second_0:                 episode reward: 2.1500,                 loss: nan
env3_first_0:                 episode reward: -2.2500,                 loss: nan
env3_second_0:                 episode reward: 2.2500,                 loss: nan
env4_first_0:                 episode reward: -2.2000,                 loss: nan
env4_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 213.3394s / 133102.0305 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0186
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0228
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
env2_first_0:                 episode reward: -3.7000,                 loss: nan
env2_second_0:                 episode reward: 3.7000,                 loss: nan
env3_first_0:                 episode reward: -3.7000,                 loss: nan
env3_second_0:                 episode reward: 3.7000,                 loss: nan
env4_first_0:                 episode reward: -3.6500,                 loss: nan
env4_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 214.3761s / 133316.4066 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0191
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0255
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
env3_first_0:                 episode reward: 1.5000,                 loss: nan
env3_second_0:                 episode reward: -1.5000,                 loss: nan
env4_first_0:                 episode reward: 1.8000,                 loss: nan
env4_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 212.6172s / 133529.0238 s
env0_first_0:                 episode reward: 4.7000,                 loss: 0.0186
env0_second_0:                 episode reward: -4.7000,                 loss: 0.0285
env1_first_0:                 episode reward: 4.4000,                 loss: nan
env1_second_0:                 episode reward: -4.4000,                 loss: nan
env2_first_0:                 episode reward: 4.5000,                 loss: nan
env2_second_0:                 episode reward: -4.5000,                 loss: nan
env3_first_0:                 episode reward: 4.6000,                 loss: nan
env3_second_0:                 episode reward: -4.6000,                 loss: nan
env4_first_0:                 episode reward: 4.6000,                 loss: nan
env4_second_0:                 episode reward: -4.6000,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 212.9995s / 133742.0233 s
env0_first_0:                 episode reward: 4.3000,                 loss: 0.0179
env0_second_0:                 episode reward: -4.3000,                 loss: 0.0276
env1_first_0:                 episode reward: 4.4000,                 loss: nan
env1_second_0:                 episode reward: -4.4000,                 loss: nan
env2_first_0:                 episode reward: 4.2000,                 loss: nan
env2_second_0:                 episode reward: -4.2000,                 loss: nan
env3_first_0:                 episode reward: 4.2000,                 loss: nan
env3_second_0:                 episode reward: -4.2000,                 loss: nan
env4_first_0:                 episode reward: 4.3000,                 loss: nan
env4_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 212.3105s / 133954.3338 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0182
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0258Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
/home/zihan/research/MARS/mars/rollout.py:21: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  rollout_normal(env, model, save_id, args)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/shape_base.py:420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arrays = [asanyarray(arr) for arr in arrays]
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
env3_first_0:                 episode reward: 0.4500,                 loss: nan
env3_second_0:                 episode reward: -0.4500,                 loss: nan
env4_first_0:                 episode reward: 0.5000,                 loss: nan
env4_second_0:                 episode reward: -0.5000,                 loss: nan
