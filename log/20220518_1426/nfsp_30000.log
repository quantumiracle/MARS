pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f6d5a214c50>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518033032/mdp_arbitrary_mdp_nfsp/30000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518033032/mdp_arbitrary_mdp_nfsp/30000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518033032_exploit_30000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518033032_exploit_30000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6759s / 0.6759 s
agent0:                 episode reward: -0.5509,                 loss: nan
agent1:                 episode reward: 0.5509,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 0.8741 s
agent0:                 episode reward: -0.2850,                 loss: nan
agent1:                 episode reward: 0.2850,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 1.0688 s
agent0:                 episode reward: 0.0739,                 loss: nan
agent1:                 episode reward: -0.0739,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 1.2659 s
agent0:                 episode reward: -0.2254,                 loss: nan
agent1:                 episode reward: 0.2254,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 1.4639 s
agent0:                 episode reward: -0.0313,                 loss: nan
agent1:                 episode reward: 0.0313,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1936s / 1.6576 s
agent0:                 episode reward: -0.1250,                 loss: nan
agent1:                 episode reward: 0.1250,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 1.8535 s
agent0:                 episode reward: 0.0841,                 loss: nan
agent1:                 episode reward: -0.0841,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 2.0545 s
agent0:                 episode reward: -0.0639,                 loss: nan
agent1:                 episode reward: 0.0639,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 2.2560 s
agent0:                 episode reward: 0.4161,                 loss: nan
agent1:                 episode reward: -0.4161,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 2.4542 s
agent0:                 episode reward: 0.1083,                 loss: nan
agent1:                 episode reward: -0.1083,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 2.6501 s
agent0:                 episode reward: -0.1589,                 loss: nan
agent1:                 episode reward: 0.1589,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 2.8499 s
agent0:                 episode reward: -0.2784,                 loss: nan
agent1:                 episode reward: 0.2784,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 3.0471 s
agent0:                 episode reward: 0.5400,                 loss: nan
agent1:                 episode reward: -0.5400,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 3.2434 s
agent0:                 episode reward: 0.1719,                 loss: nan
agent1:                 episode reward: -0.1719,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 3.4435 s
agent0:                 episode reward: 0.2557,                 loss: nan
agent1:                 episode reward: -0.2557,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2041s / 3.6476 s
agent0:                 episode reward: 0.2418,                 loss: nan
agent1:                 episode reward: -0.2418,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1952s / 3.8428 s
agent0:                 episode reward: 0.1741,                 loss: nan
agent1:                 episode reward: -0.1741,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 4.0411 s
agent0:                 episode reward: 0.1584,                 loss: nan
agent1:                 episode reward: -0.1584,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 4.2399 s
agent0:                 episode reward: -0.4288,                 loss: nan
agent1:                 episode reward: 0.4288,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 4.4373 s
agent0:                 episode reward: 0.0527,                 loss: nan
agent1:                 episode reward: -0.0527,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2021s / 4.6395 s
agent0:                 episode reward: 0.4790,                 loss: nan
agent1:                 episode reward: -0.4790,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2030s / 4.8425 s
agent0:                 episode reward: -0.0568,                 loss: nan
agent1:                 episode reward: 0.0568,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 5.0402 s
agent0:                 episode reward: 0.0603,                 loss: nan
agent1:                 episode reward: -0.0603,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 5.2388 s
agent0:                 episode reward: 0.1014,                 loss: nan
agent1:                 episode reward: -0.1014,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 5.4396 s
agent0:                 episode reward: -0.0601,                 loss: nan
agent1:                 episode reward: 0.0601,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 5.6351 s
agent0:                 episode reward: -0.2793,                 loss: nan
agent1:                 episode reward: 0.2793,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 5.8344 s
agent0:                 episode reward: -0.1049,                 loss: nan
agent1:                 episode reward: 0.1049,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 6.0331 s
agent0:                 episode reward: 0.3399,                 loss: nan
agent1:                 episode reward: -0.3399,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 6.2318 s
agent0:                 episode reward: -0.0508,                 loss: nan
agent1:                 episode reward: 0.0508,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 6.4302 s
agent0:                 episode reward: -0.4364,                 loss: nan
agent1:                 episode reward: 0.4364,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1988s / 6.6290 s
agent0:                 episode reward: -0.0453,                 loss: nan
agent1:                 episode reward: 0.0453,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 6.8309 s
agent0:                 episode reward: -0.1853,                 loss: nan
agent1:                 episode reward: 0.1853,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 7.0317 s
agent0:                 episode reward: -0.3677,                 loss: nan
agent1:                 episode reward: 0.3677,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 7.2296 s
agent0:                 episode reward: 0.0916,                 loss: nan
agent1:                 episode reward: -0.0916,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2025s / 7.4321 s
agent0:                 episode reward: -0.1351,                 loss: nan
agent1:                 episode reward: 0.1351,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 7.6306 s
agent0:                 episode reward: -0.4712,                 loss: nan
agent1:                 episode reward: 0.4712,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 7.8248 s
agent0:                 episode reward: -0.0155,                 loss: nan
agent1:                 episode reward: 0.0155,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2029s / 8.0278 s
agent0:                 episode reward: -0.4066,                 loss: nan
agent1:                 episode reward: 0.4066,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 8.2279 s
agent0:                 episode reward: -0.1220,                 loss: nan
agent1:                 episode reward: 0.1220,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 8.4246 s
agent0:                 episode reward: 0.0757,                 loss: nan
agent1:                 episode reward: -0.0757,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 8.6227 s
agent0:                 episode reward: -0.4896,                 loss: nan
agent1:                 episode reward: 0.4896,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 8.8188 s
agent0:                 episode reward: 0.0698,                 loss: nan
agent1:                 episode reward: -0.0698,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 9.0172 s
agent0:                 episode reward: -0.3214,                 loss: nan
agent1:                 episode reward: 0.3214,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 9.2141 s
agent0:                 episode reward: 0.0251,                 loss: nan
agent1:                 episode reward: -0.0251,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 9.4167 s
agent0:                 episode reward: -0.7774,                 loss: nan
agent1:                 episode reward: 0.7774,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 9.6186 s
agent0:                 episode reward: 0.2168,                 loss: nan
agent1:                 episode reward: -0.2168,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 9.8140 s
agent0:                 episode reward: -0.7389,                 loss: nan
agent1:                 episode reward: 0.7389,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 10.0119 s
agent0:                 episode reward: -0.5400,                 loss: nan
agent1:                 episode reward: 0.5400,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 10.2092 s
agent0:                 episode reward: -0.2855,                 loss: nan
agent1:                 episode reward: 0.2855,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 10.4081 s
agent0:                 episode reward: 0.0225,                 loss: nan
agent1:                 episode reward: -0.0225,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 10.6057 s
agent0:                 episode reward: 0.0767,                 loss: nan
agent1:                 episode reward: -0.0767,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 10.8063 s
agent0:                 episode reward: -0.0431,                 loss: nan
agent1:                 episode reward: 0.0431,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 11.0022 s
agent0:                 episode reward: -0.1269,                 loss: nan
agent1:                 episode reward: 0.1269,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 11.2019 s
agent0:                 episode reward: 0.1772,                 loss: nan
agent1:                 episode reward: -0.1772,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1853s / 11.3873 s
agent0:                 episode reward: 0.1042,                 loss: nan
agent1:                 episode reward: -0.1042,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 11.5860 s
agent0:                 episode reward: -0.2250,                 loss: nan
agent1:                 episode reward: 0.2250,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 11.7815 s
agent0:                 episode reward: 0.0175,                 loss: nan
agent1:                 episode reward: -0.0175,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 11.9822 s
agent0:                 episode reward: -0.2697,                 loss: nan
agent1:                 episode reward: 0.2697,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1922s / 12.1744 s
agent0:                 episode reward: 0.0015,                 loss: nan
agent1:                 episode reward: -0.0015,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 12.3716 s
agent0:                 episode reward: -0.4944,                 loss: nan
agent1:                 episode reward: 0.4944,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 12.5685 s
agent0:                 episode reward: 0.0305,                 loss: nan
agent1:                 episode reward: -0.0305,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 12.7669 s
agent0:                 episode reward: -0.0957,                 loss: nan
agent1:                 episode reward: 0.0957,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 12.9642 s
agent0:                 episode reward: 0.4344,                 loss: nan
agent1:                 episode reward: -0.4344,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 13.1615 s
agent0:                 episode reward: 0.0888,                 loss: nan
agent1:                 episode reward: -0.0888,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1974s / 13.3589 s
agent0:                 episode reward: -0.2468,                 loss: nan
agent1:                 episode reward: 0.2468,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 13.5577 s
agent0:                 episode reward: -0.0818,                 loss: nan
agent1:                 episode reward: 0.0818,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 13.7575 s
agent0:                 episode reward: 0.0304,                 loss: nan
agent1:                 episode reward: -0.0304,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 13.9551 s
agent0:                 episode reward: -0.2435,                 loss: nan
agent1:                 episode reward: 0.2435,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 14.1521 s
agent0:                 episode reward: -0.0859,                 loss: nan
agent1:                 episode reward: 0.0859,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 14.3534 s
agent0:                 episode reward: -0.3035,                 loss: nan
agent1:                 episode reward: 0.3035,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1966s / 14.5500 s
agent0:                 episode reward: 0.5802,                 loss: nan
agent1:                 episode reward: -0.5802,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 14.7509 s
agent0:                 episode reward: 0.3593,                 loss: nan
agent1:                 episode reward: -0.3593,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 14.9472 s
agent0:                 episode reward: 0.2035,                 loss: nan
agent1:                 episode reward: -0.2035,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 15.1448 s
agent0:                 episode reward: 0.2852,                 loss: nan
agent1:                 episode reward: -0.2852,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 15.3409 s
agent0:                 episode reward: 0.0022,                 loss: nan
agent1:                 episode reward: -0.0022,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2034s / 15.5443 s
agent0:                 episode reward: -0.3646,                 loss: nan
agent1:                 episode reward: 0.3646,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1853s / 15.7296 s
agent0:                 episode reward: 0.6788,                 loss: nan
agent1:                 episode reward: -0.6788,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 15.9280 s
agent0:                 episode reward: 0.1183,                 loss: nan
agent1:                 episode reward: -0.1183,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 16.1255 s
agent0:                 episode reward: -0.1634,                 loss: nan
agent1:                 episode reward: 0.1634,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 16.3230 s
agent0:                 episode reward: -0.5981,                 loss: nan
agent1:                 episode reward: 0.5981,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 16.5200 s
agent0:                 episode reward: -0.0039,                 loss: nan
agent1:                 episode reward: 0.0039,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 16.7169 s
agent0:                 episode reward: -0.0083,                 loss: nan
agent1:                 episode reward: 0.0083,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 16.9124 s
agent0:                 episode reward: -0.5007,                 loss: nan
agent1:                 episode reward: 0.5007,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 17.1123 s
agent0:                 episode reward: -0.0130,                 loss: nan
agent1:                 episode reward: 0.0130,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1933s / 17.3055 s
agent0:                 episode reward: 0.0186,                 loss: nan
agent1:                 episode reward: -0.0186,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 17.5063 s
agent0:                 episode reward: -0.0506,                 loss: nan
agent1:                 episode reward: 0.0506,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 17.7039 s
agent0:                 episode reward: -0.0897,                 loss: nan
agent1:                 episode reward: 0.0897,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 17.8992 s
agent0:                 episode reward: 0.0592,                 loss: nan
agent1:                 episode reward: -0.0592,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2044s / 18.1036 s
agent0:                 episode reward: 0.1719,                 loss: nan
agent1:                 episode reward: -0.1719,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 18.3017 s
agent0:                 episode reward: -0.1910,                 loss: nan
agent1:                 episode reward: 0.1910,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 18.5011 s
agent0:                 episode reward: 0.0326,                 loss: nan
agent1:                 episode reward: -0.0326,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 18.7038 s
agent0:                 episode reward: 0.4323,                 loss: nan
agent1:                 episode reward: -0.4323,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 18.9008 s
agent0:                 episode reward: -0.0660,                 loss: nan
agent1:                 episode reward: 0.0660,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1944s / 19.0952 s
agent0:                 episode reward: 0.1056,                 loss: nan
agent1:                 episode reward: -0.1056,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1944s / 19.2896 s
agent0:                 episode reward: 0.0741,                 loss: nan
agent1:                 episode reward: -0.0741,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 19.4836 s
agent0:                 episode reward: -0.0039,                 loss: nan
agent1:                 episode reward: 0.0039,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 19.6845 s
agent0:                 episode reward: -0.2374,                 loss: nan
agent1:                 episode reward: 0.2374,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 19.8807 s
agent0:                 episode reward: -0.4666,                 loss: nan
agent1:                 episode reward: 0.4666,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 20.0774 s
agent0:                 episode reward: -0.3008,                 loss: nan
agent1:                 episode reward: 0.3008,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1906s / 20.2680 s
agent0:                 episode reward: -0.2542,                 loss: nan
agent1:                 episode reward: 0.2542,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 20.4649 s
agent0:                 episode reward: -0.3799,                 loss: nan
agent1:                 episode reward: 0.3799,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1956s / 20.6605 s
agent0:                 episode reward: 0.1012,                 loss: nan
agent1:                 episode reward: -0.1012,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 20.8594 s
agent0:                 episode reward: -0.2761,                 loss: nan
agent1:                 episode reward: 0.2761,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2027s / 21.0621 s
agent0:                 episode reward: -0.0262,                 loss: nan
agent1:                 episode reward: 0.0262,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 21.2598 s
agent0:                 episode reward: 0.2505,                 loss: nan
agent1:                 episode reward: -0.2505,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 21.4561 s
agent0:                 episode reward: -0.0887,                 loss: nan
agent1:                 episode reward: 0.0887,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 21.6563 s
agent0:                 episode reward: 0.5116,                 loss: nan
agent1:                 episode reward: -0.5116,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 21.8550 s
agent0:                 episode reward: -0.4011,                 loss: nan
agent1:                 episode reward: 0.4011,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 22.0513 s
agent0:                 episode reward: 0.2439,                 loss: nan
agent1:                 episode reward: -0.2439,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1944s / 22.2457 s
agent0:                 episode reward: 0.3057,                 loss: nan
agent1:                 episode reward: -0.3057,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 22.4440 s
agent0:                 episode reward: 0.0084,                 loss: nan
agent1:                 episode reward: -0.0084,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 22.6397 s
agent0:                 episode reward: -0.1250,                 loss: nan
agent1:                 episode reward: 0.1250,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2038s / 22.8435 s
agent0:                 episode reward: -0.1854,                 loss: nan
agent1:                 episode reward: 0.1854,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2023s / 23.0458 s
agent0:                 episode reward: -0.3434,                 loss: nan
agent1:                 episode reward: 0.3434,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2036s / 23.2495 s
agent0:                 episode reward: -0.6582,                 loss: nan
agent1:                 episode reward: 0.6582,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 23.4443 s
agent0:                 episode reward: 0.2740,                 loss: nan
agent1:                 episode reward: -0.2740,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 23.6445 s
agent0:                 episode reward: -0.2128,                 loss: nan
agent1:                 episode reward: 0.2128,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 23.8441 s
agent0:                 episode reward: 0.1287,                 loss: nan
agent1:                 episode reward: -0.1287,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1941s / 24.0381 s
agent0:                 episode reward: 0.0267,                 loss: nan
agent1:                 episode reward: -0.0267,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 24.2400 s
agent0:                 episode reward: -0.2537,                 loss: nan
agent1:                 episode reward: 0.2537,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 24.4397 s
agent0:                 episode reward: 0.1603,                 loss: nan
agent1:                 episode reward: -0.1603,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 24.6375 s
agent0:                 episode reward: -0.0731,                 loss: nan
agent1:                 episode reward: 0.0731,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2002s / 24.8376 s
agent0:                 episode reward: 0.2602,                 loss: nan
agent1:                 episode reward: -0.2602,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 25.0361 s
agent0:                 episode reward: -0.1287,                 loss: nan
agent1:                 episode reward: 0.1287,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 25.2362 s
agent0:                 episode reward: 0.0028,                 loss: nan
agent1:                 episode reward: -0.0028,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 25.4358 s
agent0:                 episode reward: 0.1511,                 loss: nan
agent1:                 episode reward: -0.1511,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 25.6368 s
agent0:                 episode reward: -0.1817,                 loss: nan
agent1:                 episode reward: 0.1817,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 25.8358 s
agent0:                 episode reward: -0.5197,                 loss: nan
agent1:                 episode reward: 0.5197,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1941s / 26.0299 s
agent0:                 episode reward: 0.2012,                 loss: nan
agent1:                 episode reward: -0.2012,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1950s / 26.2249 s
agent0:                 episode reward: 0.1536,                 loss: nan
agent1:                 episode reward: -0.1536,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 26.4243 s
agent0:                 episode reward: -0.0803,                 loss: nan
agent1:                 episode reward: 0.0803,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 26.6215 s
agent0:                 episode reward: 0.0255,                 loss: nan
agent1:                 episode reward: -0.0255,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 26.8190 s
agent0:                 episode reward: 0.1138,                 loss: nan
agent1:                 episode reward: -0.1138,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1998s / 27.0188 s
agent0:                 episode reward: -0.0526,                 loss: nan
agent1:                 episode reward: 0.0526,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1948s / 27.2135 s
agent0:                 episode reward: -0.1165,                 loss: nan
agent1:                 episode reward: 0.1165,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 27.4132 s
agent0:                 episode reward: -0.2192,                 loss: nan
agent1:                 episode reward: 0.2192,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 27.6111 s
agent0:                 episode reward: -0.1356,                 loss: nan
agent1:                 episode reward: 0.1356,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 27.8080 s
agent0:                 episode reward: 0.1517,                 loss: nan
agent1:                 episode reward: -0.1517,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2144s / 28.0224 s
agent0:                 episode reward: -0.1474,                 loss: nan
agent1:                 episode reward: 0.1474,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1880s / 28.2104 s
agent0:                 episode reward: -0.0185,                 loss: nan
agent1:                 episode reward: 0.0185,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 28.4073 s
agent0:                 episode reward: -0.3844,                 loss: nan
agent1:                 episode reward: 0.3844,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2014s / 28.6086 s
agent0:                 episode reward: -0.1673,                 loss: nan
agent1:                 episode reward: 0.1673,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2003s / 28.8089 s
agent0:                 episode reward: -0.2908,                 loss: nan
agent1:                 episode reward: 0.2908,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 29.0122 s
agent0:                 episode reward: 0.1048,                 loss: nan
agent1:                 episode reward: -0.1048,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 29.2135 s
agent0:                 episode reward: 0.1893,                 loss: nan
agent1:                 episode reward: -0.1893,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 29.4115 s
agent0:                 episode reward: -0.0953,                 loss: nan
agent1:                 episode reward: 0.0953,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 29.6091 s
agent0:                 episode reward: -0.2207,                 loss: nan
agent1:                 episode reward: 0.2207,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 29.8097 s
agent0:                 episode reward: -0.4329,                 loss: nan
agent1:                 episode reward: 0.4329,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 30.0101 s
agent0:                 episode reward: -0.2061,                 loss: nan
agent1:                 episode reward: 0.2061,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2012s / 30.2113 s
agent0:                 episode reward: -0.0064,                 loss: nan
agent1:                 episode reward: 0.0064,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 30.4120 s
agent0:                 episode reward: 0.5341,                 loss: nan
agent1:                 episode reward: -0.5341,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1924s / 30.6045 s
agent0:                 episode reward: 0.3536,                 loss: nan
agent1:                 episode reward: -0.3536,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 30.8054 s
agent0:                 episode reward: 0.2086,                 loss: nan
agent1:                 episode reward: -0.2086,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2019s / 31.0073 s
agent0:                 episode reward: -0.0492,                 loss: nan
agent1:                 episode reward: 0.0492,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1978s / 31.2051 s
agent0:                 episode reward: -0.0150,                 loss: nan
agent1:                 episode reward: 0.0150,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2042s / 31.4093 s
agent0:                 episode reward: -0.0679,                 loss: nan
agent1:                 episode reward: 0.0679,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 31.6089 s
agent0:                 episode reward: -0.0043,                 loss: nan
agent1:                 episode reward: 0.0043,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2033s / 31.8121 s
agent0:                 episode reward: -0.3409,                 loss: nan
agent1:                 episode reward: 0.3409,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 32.0137 s
agent0:                 episode reward: 0.2177,                 loss: nan
agent1:                 episode reward: -0.2177,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 32.2124 s
agent0:                 episode reward: 0.5739,                 loss: nan
agent1:                 episode reward: -0.5739,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 32.4150 s
agent0:                 episode reward: -0.1304,                 loss: nan
agent1:                 episode reward: 0.1304,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 32.6154 s
agent0:                 episode reward: -0.3104,                 loss: nan
agent1:                 episode reward: 0.3104,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2029s / 32.8183 s
agent0:                 episode reward: -0.0671,                 loss: nan
agent1:                 episode reward: 0.0671,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 33.0172 s
agent0:                 episode reward: 0.4328,                 loss: nan
agent1:                 episode reward: -0.4328,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 33.2168 s
agent0:                 episode reward: -0.2483,                 loss: nan
agent1:                 episode reward: 0.2483,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 33.4167 s
agent0:                 episode reward: -0.1287,                 loss: nan
agent1:                 episode reward: 0.1287,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2006s / 33.6173 s
agent0:                 episode reward: -0.2916,                 loss: nan
agent1:                 episode reward: 0.2916,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3580s / 33.9754 s
agent0:                 episode reward: -0.0529,                 loss: nan
agent1:                 episode reward: 0.0529,                 loss: 0.4594
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5889s / 34.5642 s
agent0:                 episode reward: -0.1956,                 loss: nan
agent1:                 episode reward: 0.1956,                 loss: 0.4480
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5828s / 35.1470 s
agent0:                 episode reward: -0.0616,                 loss: nan
agent1:                 episode reward: 0.0616,                 loss: 0.4334
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5823s / 35.7293 s
agent0:                 episode reward: -0.3859,                 loss: nan
agent1:                 episode reward: 0.3859,                 loss: 0.4217
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5839s / 36.3131 s
agent0:                 episode reward: -0.3565,                 loss: nan
agent1:                 episode reward: 0.3565,                 loss: 0.4023
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5869s / 36.9000 s
agent0:                 episode reward: -0.4034,                 loss: nan
agent1:                 episode reward: 0.4034,                 loss: 0.3902
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5828s / 37.4828 s
agent0:                 episode reward: -0.3735,                 loss: nan
agent1:                 episode reward: 0.3735,                 loss: 0.3772
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5842s / 38.0670 s
agent0:                 episode reward: -0.4162,                 loss: nan
agent1:                 episode reward: 0.4162,                 loss: 0.3711
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5875s / 38.6546 s
agent0:                 episode reward: -0.5512,                 loss: nan
agent1:                 episode reward: 0.5512,                 loss: 0.3670
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5891s / 39.2437 s
agent0:                 episode reward: 0.0555,                 loss: nan
agent1:                 episode reward: -0.0555,                 loss: 0.3729
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 39.8256 s
agent0:                 episode reward: -0.4135,                 loss: nan
agent1:                 episode reward: 0.4135,                 loss: 0.3729
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5866s / 40.4122 s
agent0:                 episode reward: -0.3072,                 loss: nan
agent1:                 episode reward: 0.3072,                 loss: 0.3694
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5944s / 41.0066 s
agent0:                 episode reward: -0.3735,                 loss: nan
agent1:                 episode reward: 0.3735,                 loss: 0.3685
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5806s / 41.5872 s
agent0:                 episode reward: -0.3688,                 loss: nan
agent1:                 episode reward: 0.3688,                 loss: 0.3678
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 42.1691 s
agent0:                 episode reward: -0.0413,                 loss: nan
agent1:                 episode reward: 0.0413,                 loss: 0.3686
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 42.7621 s
agent0:                 episode reward: -0.0647,                 loss: nan
agent1:                 episode reward: 0.0647,                 loss: 0.3698
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5836s / 43.3457 s
agent0:                 episode reward: -0.0305,                 loss: nan
agent1:                 episode reward: 0.0305,                 loss: 0.3661
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5834s / 43.9292 s
agent0:                 episode reward: -0.6013,                 loss: nan
agent1:                 episode reward: 0.6013,                 loss: 0.3602
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5823s / 44.5114 s
agent0:                 episode reward: -0.4781,                 loss: nan
agent1:                 episode reward: 0.4781,                 loss: 0.3484
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5811s / 45.0925 s
agent0:                 episode reward: -0.5819,                 loss: nan
agent1:                 episode reward: 0.5819,                 loss: 0.3451
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5917s / 45.6842 s
agent0:                 episode reward: -0.8119,                 loss: nan
agent1:                 episode reward: 0.8119,                 loss: 0.3442
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5851s / 46.2693 s
agent0:                 episode reward: 0.2782,                 loss: nan
agent1:                 episode reward: -0.2782,                 loss: 0.3434
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5847s / 46.8540 s
agent0:                 episode reward: -0.5279,                 loss: nan
agent1:                 episode reward: 0.5279,                 loss: 0.3424
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5871s / 47.4411 s
agent0:                 episode reward: 0.0032,                 loss: nan
agent1:                 episode reward: -0.0032,                 loss: 0.3466
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 48.0230 s
agent0:                 episode reward: -0.3829,                 loss: nan
agent1:                 episode reward: 0.3829,                 loss: 0.3433
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5814s / 48.6044 s
agent0:                 episode reward: -0.5220,                 loss: nan
agent1:                 episode reward: 0.5220,                 loss: 0.3432
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5867s / 49.1911 s
agent0:                 episode reward: -0.6943,                 loss: nan
agent1:                 episode reward: 0.6943,                 loss: 0.3421
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5867s / 49.7778 s
agent0:                 episode reward: -0.4419,                 loss: nan
agent1:                 episode reward: 0.4419,                 loss: 0.3394
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5856s / 50.3634 s
agent0:                 episode reward: -0.3807,                 loss: nan
agent1:                 episode reward: 0.3807,                 loss: 0.3401
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 50.9453 s
agent0:                 episode reward: -0.4809,                 loss: nan
agent1:                 episode reward: 0.4809,                 loss: 0.3401
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5799s / 51.5251 s
agent0:                 episode reward: -0.2303,                 loss: nan
agent1:                 episode reward: 0.2303,                 loss: 0.3381
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5890s / 52.1141 s
agent0:                 episode reward: -0.4423,                 loss: nan
agent1:                 episode reward: 0.4423,                 loss: 0.3393
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5844s / 52.6985 s
agent0:                 episode reward: -0.5791,                 loss: nan
agent1:                 episode reward: 0.5791,                 loss: 0.3380
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 53.2870 s
agent0:                 episode reward: -0.5945,                 loss: nan
agent1:                 episode reward: 0.5945,                 loss: 0.3397
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 53.8793 s
agent0:                 episode reward: -0.7417,                 loss: nan
agent1:                 episode reward: 0.7417,                 loss: 0.3692
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5837s / 54.4631 s
agent0:                 episode reward: -0.2901,                 loss: nan
agent1:                 episode reward: 0.2901,                 loss: 0.3643
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5891s / 55.0521 s
agent0:                 episode reward: -0.5705,                 loss: nan
agent1:                 episode reward: 0.5705,                 loss: 0.3617
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5903s / 55.6424 s
agent0:                 episode reward: -0.4934,                 loss: nan
agent1:                 episode reward: 0.4934,                 loss: 0.3640
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5862s / 56.2287 s
agent0:                 episode reward: -0.7819,                 loss: nan
agent1:                 episode reward: 0.7819,                 loss: 0.3639
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5811s / 56.8097 s
agent0:                 episode reward: 0.2613,                 loss: nan
agent1:                 episode reward: -0.2613,                 loss: 0.3654
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5756s / 57.3853 s
agent0:                 episode reward: -0.3981,                 loss: nan
agent1:                 episode reward: 0.3981,                 loss: 0.3647
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 57.9733 s
agent0:                 episode reward: -0.9288,                 loss: nan
agent1:                 episode reward: 0.9288,                 loss: 0.3614
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5866s / 58.5599 s
agent0:                 episode reward: -0.4037,                 loss: nan
agent1:                 episode reward: 0.4037,                 loss: 0.3605
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5832s / 59.1432 s
agent0:                 episode reward: -0.4489,                 loss: nan
agent1:                 episode reward: 0.4489,                 loss: 0.3633
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 59.7363 s
agent0:                 episode reward: -0.0581,                 loss: nan
agent1:                 episode reward: 0.0581,                 loss: 0.3643
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 60.3258 s
agent0:                 episode reward: -0.5394,                 loss: nan
agent1:                 episode reward: 0.5394,                 loss: 0.3664
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 60.9180 s
agent0:                 episode reward: -0.3724,                 loss: nan
agent1:                 episode reward: 0.3724,                 loss: 0.3617
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 61.5106 s
agent0:                 episode reward: -0.6758,                 loss: nan
agent1:                 episode reward: 0.6758,                 loss: 0.3592
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5827s / 62.0934 s
agent0:                 episode reward: 0.4131,                 loss: nan
agent1:                 episode reward: -0.4131,                 loss: 0.3602
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5885s / 62.6819 s
agent0:                 episode reward: -0.5832,                 loss: nan
agent1:                 episode reward: 0.5832,                 loss: 0.3611
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5940s / 63.2758 s
agent0:                 episode reward: -0.3582,                 loss: nan
agent1:                 episode reward: 0.3582,                 loss: 0.3602
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 63.8674 s
agent0:                 episode reward: -0.4009,                 loss: nan
agent1:                 episode reward: 0.4009,                 loss: 0.3490
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5944s / 64.4617 s
agent0:                 episode reward: -0.5988,                 loss: nan
agent1:                 episode reward: 0.5988,                 loss: 0.3503
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 65.0535 s
agent0:                 episode reward: -0.3940,                 loss: nan
agent1:                 episode reward: 0.3940,                 loss: 0.3510
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5887s / 65.6422 s
agent0:                 episode reward: -0.3651,                 loss: nan
agent1:                 episode reward: 0.3651,                 loss: 0.3485
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5868s / 66.2291 s
agent0:                 episode reward: -0.7050,                 loss: nan
agent1:                 episode reward: 0.7050,                 loss: 0.3475
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5840s / 66.8131 s
agent0:                 episode reward: -0.3748,                 loss: nan
agent1:                 episode reward: 0.3748,                 loss: 0.3512
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 67.4058 s
agent0:                 episode reward: -0.2007,                 loss: nan
agent1:                 episode reward: 0.2007,                 loss: 0.3495
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5862s / 67.9921 s
agent0:                 episode reward: -0.2458,                 loss: nan
agent1:                 episode reward: 0.2458,                 loss: 0.3498
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 68.5820 s
agent0:                 episode reward: -0.5503,                 loss: nan
agent1:                 episode reward: 0.5503,                 loss: 0.3477
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 69.1697 s
agent0:                 episode reward: -0.3118,                 loss: nan
agent1:                 episode reward: 0.3118,                 loss: 0.3504
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 69.7577 s
agent0:                 episode reward: -0.6052,                 loss: nan
agent1:                 episode reward: 0.6052,                 loss: 0.3487
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5881s / 70.3458 s
agent0:                 episode reward: -0.1523,                 loss: nan
agent1:                 episode reward: 0.1523,                 loss: 0.3479
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 70.9395 s
agent0:                 episode reward: -0.6762,                 loss: nan
agent1:                 episode reward: 0.6762,                 loss: 0.3462
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 71.5305 s
agent0:                 episode reward: -0.3150,                 loss: nan
agent1:                 episode reward: 0.3150,                 loss: 0.3467
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 72.1240 s
agent0:                 episode reward: -0.4665,                 loss: nan
agent1:                 episode reward: 0.4665,                 loss: 0.3467
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 72.7169 s
agent0:                 episode reward: -0.4811,                 loss: nan
agent1:                 episode reward: 0.4811,                 loss: 0.3443
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5890s / 73.3060 s
agent0:                 episode reward: -0.6331,                 loss: nan
agent1:                 episode reward: 0.6331,                 loss: 0.3531
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5823s / 73.8882 s
agent0:                 episode reward: -0.4872,                 loss: nan
agent1:                 episode reward: 0.4872,                 loss: 0.3457
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5905s / 74.4787 s
agent0:                 episode reward: -0.6268,                 loss: nan
agent1:                 episode reward: 0.6268,                 loss: 0.3498
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5924s / 75.0711 s
agent0:                 episode reward: -0.7741,                 loss: nan
agent1:                 episode reward: 0.7741,                 loss: 0.3475
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5811s / 75.6522 s
agent0:                 episode reward: -0.3786,                 loss: nan
agent1:                 episode reward: 0.3786,                 loss: 0.3479
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5822s / 76.2344 s
agent0:                 episode reward: -0.6107,                 loss: nan
agent1:                 episode reward: 0.6107,                 loss: 0.3472
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5978s / 76.8322 s
agent0:                 episode reward: -0.2021,                 loss: nan
agent1:                 episode reward: 0.2021,                 loss: 0.3461
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 77.4237 s
agent0:                 episode reward: -0.4640,                 loss: nan
agent1:                 episode reward: 0.4640,                 loss: 0.3442
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 78.0157 s
agent0:                 episode reward: -0.3512,                 loss: nan
agent1:                 episode reward: 0.3512,                 loss: 0.3444
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5890s / 78.6046 s
agent0:                 episode reward: -0.1980,                 loss: nan
agent1:                 episode reward: 0.1980,                 loss: 0.3457
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5875s / 79.1921 s
agent0:                 episode reward: -0.7029,                 loss: nan
agent1:                 episode reward: 0.7029,                 loss: 0.3435
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5887s / 79.7808 s
agent0:                 episode reward: -0.2679,                 loss: nan
agent1:                 episode reward: 0.2679,                 loss: 0.3453
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5843s / 80.3651 s
agent0:                 episode reward: -0.3569,                 loss: nan
agent1:                 episode reward: 0.3569,                 loss: 0.3425
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 80.9588 s
agent0:                 episode reward: -0.4659,                 loss: nan
agent1:                 episode reward: 0.4659,                 loss: 0.3450
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5802s / 81.5390 s
agent0:                 episode reward: -0.4066,                 loss: nan
agent1:                 episode reward: 0.4066,                 loss: 0.3452
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5865s / 82.1254 s
agent0:                 episode reward: -0.4197,                 loss: nan
agent1:                 episode reward: 0.4197,                 loss: 0.3479
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 82.7181 s
agent0:                 episode reward: -0.6748,                 loss: nan
agent1:                 episode reward: 0.6748,                 loss: 0.3474
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5887s / 83.3068 s
agent0:                 episode reward: -0.2228,                 loss: nan
agent1:                 episode reward: 0.2228,                 loss: 0.3602
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 83.9007 s
agent0:                 episode reward: -0.3732,                 loss: nan
agent1:                 episode reward: 0.3732,                 loss: 0.3605
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5872s / 84.4879 s
agent0:                 episode reward: -0.7276,                 loss: nan
agent1:                 episode reward: 0.7276,                 loss: 0.3598
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 85.0821 s
agent0:                 episode reward: -0.3931,                 loss: nan
agent1:                 episode reward: 0.3931,                 loss: 0.3571
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5978s / 85.6798 s
agent0:                 episode reward: -0.2894,                 loss: nan
agent1:                 episode reward: 0.2894,                 loss: 0.3561
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5972s / 86.2770 s
agent0:                 episode reward: -0.5014,                 loss: nan
agent1:                 episode reward: 0.5014,                 loss: 0.3589
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6014s / 86.8784 s
agent0:                 episode reward: -0.6324,                 loss: nan
agent1:                 episode reward: 0.6324,                 loss: 0.3624
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 87.4718 s
agent0:                 episode reward: -0.3364,                 loss: nan
agent1:                 episode reward: 0.3364,                 loss: 0.3558
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5879s / 88.0597 s
agent0:                 episode reward: -0.7025,                 loss: nan
agent1:                 episode reward: 0.7025,                 loss: 0.3590
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5803s / 88.6400 s
agent0:                 episode reward: -0.6934,                 loss: nan
agent1:                 episode reward: 0.6934,                 loss: 0.3589
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5860s / 89.2260 s
agent0:                 episode reward: -0.1550,                 loss: nan
agent1:                 episode reward: 0.1550,                 loss: 0.3556
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5957s / 89.8216 s
agent0:                 episode reward: -0.8321,                 loss: nan
agent1:                 episode reward: 0.8321,                 loss: 0.3587
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5864s / 90.4081 s
agent0:                 episode reward: -0.1645,                 loss: nan
agent1:                 episode reward: 0.1645,                 loss: 0.3572
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5865s / 90.9945 s
agent0:                 episode reward: -0.3316,                 loss: nan
agent1:                 episode reward: 0.3316,                 loss: 0.3578
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 91.5764 s
agent0:                 episode reward: -0.2932,                 loss: nan
agent1:                 episode reward: 0.2932,                 loss: 0.3564
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5946s / 92.1711 s
agent0:                 episode reward: -0.3515,                 loss: nan
agent1:                 episode reward: 0.3515,                 loss: 0.3596
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 92.7606 s
agent0:                 episode reward: -0.3250,                 loss: nan
agent1:                 episode reward: 0.3250,                 loss: 0.3543
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 93.3521 s
agent0:                 episode reward: -0.6174,                 loss: nan
agent1:                 episode reward: 0.6174,                 loss: 0.3469
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5843s / 93.9364 s
agent0:                 episode reward: -0.2123,                 loss: nan
agent1:                 episode reward: 0.2123,                 loss: 0.3459
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5927s / 94.5291 s
agent0:                 episode reward: -0.7382,                 loss: nan
agent1:                 episode reward: 0.7382,                 loss: 0.3452
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5799s / 95.1090 s
agent0:                 episode reward: -0.4880,                 loss: nan
agent1:                 episode reward: 0.4880,                 loss: 0.3448
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5901s / 95.6991 s
agent0:                 episode reward: -0.5498,                 loss: nan
agent1:                 episode reward: 0.5498,                 loss: 0.3459
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5851s / 96.2842 s
agent0:                 episode reward: -0.6360,                 loss: nan
agent1:                 episode reward: 0.6360,                 loss: 0.3434
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5883s / 96.8726 s
agent0:                 episode reward: -0.2293,                 loss: nan
agent1:                 episode reward: 0.2293,                 loss: 0.3452
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5881s / 97.4607 s
agent0:                 episode reward: -0.4171,                 loss: nan
agent1:                 episode reward: 0.4171,                 loss: 0.3446
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5811s / 98.0418 s
agent0:                 episode reward: -0.6418,                 loss: nan
agent1:                 episode reward: 0.6418,                 loss: 0.3448
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5878s / 98.6296 s
agent0:                 episode reward: -0.4256,                 loss: nan
agent1:                 episode reward: 0.4256,                 loss: 0.3446
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 99.2173 s
agent0:                 episode reward: -0.4777,                 loss: nan
agent1:                 episode reward: 0.4777,                 loss: 0.3455
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5864s / 99.8037 s
agent0:                 episode reward: 0.1071,                 loss: nan
agent1:                 episode reward: -0.1071,                 loss: 0.3432
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5909s / 100.3946 s
agent0:                 episode reward: -0.1748,                 loss: nan
agent1:                 episode reward: 0.1748,                 loss: 0.3455
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 100.9893 s
agent0:                 episode reward: -0.2066,                 loss: nan
agent1:                 episode reward: 0.2066,                 loss: 0.3451
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5824s / 101.5717 s
agent0:                 episode reward: -0.3718,                 loss: nan
agent1:                 episode reward: 0.3718,                 loss: 0.3453
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5851s / 102.1568 s
agent0:                 episode reward: -0.6146,                 loss: nan
agent1:                 episode reward: 0.6146,                 loss: 0.3481
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 102.7543 s
agent0:                 episode reward: -0.3453,                 loss: nan
agent1:                 episode reward: 0.3453,                 loss: 0.3516
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5901s / 103.3445 s
agent0:                 episode reward: -0.4101,                 loss: nan
agent1:                 episode reward: 0.4101,                 loss: 0.3524
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 103.9409 s
agent0:                 episode reward: -0.4596,                 loss: nan
agent1:                 episode reward: 0.4596,                 loss: 0.3514
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6001s / 104.5410 s
agent0:                 episode reward: -0.1430,                 loss: nan
agent1:                 episode reward: 0.1430,                 loss: 0.3530
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5949s / 105.1358 s
agent0:                 episode reward: -0.7537,                 loss: nan
agent1:                 episode reward: 0.7537,                 loss: 0.3512
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 105.7343 s
agent0:                 episode reward: -0.3067,                 loss: nan
agent1:                 episode reward: 0.3067,                 loss: 0.3525
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 106.3282 s
agent0:                 episode reward: -0.3238,                 loss: nan
agent1:                 episode reward: 0.3238,                 loss: 0.3533
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5949s / 106.9230 s
agent0:                 episode reward: -0.4610,                 loss: nan
agent1:                 episode reward: 0.4610,                 loss: 0.3517
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 107.5212 s
agent0:                 episode reward: -0.2134,                 loss: nan
agent1:                 episode reward: 0.2134,                 loss: 0.3538
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5965s / 108.1177 s
agent0:                 episode reward: -0.3484,                 loss: nan
agent1:                 episode reward: 0.3484,                 loss: 0.3498
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6007s / 108.7185 s
agent0:                 episode reward: -0.5628,                 loss: nan
agent1:                 episode reward: 0.5628,                 loss: 0.3524
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5931s / 109.3116 s
agent0:                 episode reward: -0.6285,                 loss: nan
agent1:                 episode reward: 0.6285,                 loss: 0.3498
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 109.9044 s
agent0:                 episode reward: -0.3497,                 loss: nan
agent1:                 episode reward: 0.3497,                 loss: 0.3509
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6014s / 110.5058 s
agent0:                 episode reward: -0.5797,                 loss: nan
agent1:                 episode reward: 0.5797,                 loss: 0.3542
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 111.1009 s
agent0:                 episode reward: -0.3832,                 loss: nan
agent1:                 episode reward: 0.3832,                 loss: 0.3526
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 111.7005 s
agent0:                 episode reward: -0.6698,                 loss: nan
agent1:                 episode reward: 0.6698,                 loss: 0.3482
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5948s / 112.2953 s
agent0:                 episode reward: -0.0257,                 loss: nan
agent1:                 episode reward: 0.0257,                 loss: 0.3504
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6028s / 112.8981 s
agent0:                 episode reward: -0.4663,                 loss: nan
agent1:                 episode reward: 0.4663,                 loss: 0.3549
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 113.4940 s
agent0:                 episode reward: -0.8197,                 loss: nan
agent1:                 episode reward: 0.8197,                 loss: 0.3526
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6028s / 114.0968 s
agent0:                 episode reward: -0.7222,                 loss: nan
agent1:                 episode reward: 0.7222,                 loss: 0.3496
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6035s / 114.7003 s
agent0:                 episode reward: -0.1767,                 loss: nan
agent1:                 episode reward: 0.1767,                 loss: 0.3515
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 115.3024 s
agent0:                 episode reward: -0.5361,                 loss: nan
agent1:                 episode reward: 0.5361,                 loss: 0.3528
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6038s / 115.9062 s
agent0:                 episode reward: -0.5401,                 loss: nan
agent1:                 episode reward: 0.5401,                 loss: 0.3506
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5988s / 116.5050 s
agent0:                 episode reward: -0.4908,                 loss: nan
agent1:                 episode reward: 0.4908,                 loss: 0.3521
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 117.1036 s
agent0:                 episode reward: -0.5871,                 loss: nan
agent1:                 episode reward: 0.5871,                 loss: 0.3519
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5946s / 117.6982 s
agent0:                 episode reward: -0.3035,                 loss: nan
agent1:                 episode reward: 0.3035,                 loss: 0.3527
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 118.2919 s
agent0:                 episode reward: -0.6731,                 loss: nan
agent1:                 episode reward: 0.6731,                 loss: 0.3525
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5962s / 118.8881 s
agent0:                 episode reward: -0.5565,                 loss: nan
agent1:                 episode reward: 0.5565,                 loss: 0.3512
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6041s / 119.4923 s
agent0:                 episode reward: -0.7742,                 loss: nan
agent1:                 episode reward: 0.7742,                 loss: 0.3496
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5909s / 120.0831 s
agent0:                 episode reward: -0.4666,                 loss: nan
agent1:                 episode reward: 0.4666,                 loss: 0.3514
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6006s / 120.6837 s
agent0:                 episode reward: -0.4161,                 loss: nan
agent1:                 episode reward: 0.4161,                 loss: 0.3503
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5937s / 121.2774 s
agent0:                 episode reward: -0.5649,                 loss: nan
agent1:                 episode reward: 0.5649,                 loss: 0.3510
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6028s / 121.8803 s
agent0:                 episode reward: -0.4585,                 loss: nan
agent1:                 episode reward: 0.4585,                 loss: 0.3525
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6055s / 122.4858 s
agent0:                 episode reward: -0.2909,                 loss: nan
agent1:                 episode reward: 0.2909,                 loss: 0.3498
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5973s / 123.0831 s
agent0:                 episode reward: -0.6655,                 loss: nan
agent1:                 episode reward: 0.6655,                 loss: 0.3438
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6030s / 123.6861 s
agent0:                 episode reward: -0.4915,                 loss: nan
agent1:                 episode reward: 0.4915,                 loss: 0.3430
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 124.2815 s
agent0:                 episode reward: -0.1355,                 loss: nan
agent1:                 episode reward: 0.1355,                 loss: 0.3470
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 124.8790 s
agent0:                 episode reward: -0.3589,                 loss: nan
agent1:                 episode reward: 0.3589,                 loss: 0.3443
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 125.4771 s
agent0:                 episode reward: -0.7789,                 loss: nan
agent1:                 episode reward: 0.7789,                 loss: 0.3459
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5892s / 126.0663 s
agent0:                 episode reward: -0.4043,                 loss: nan
agent1:                 episode reward: 0.4043,                 loss: 0.3470
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5978s / 126.6641 s
agent0:                 episode reward: -0.1888,                 loss: nan
agent1:                 episode reward: 0.1888,                 loss: 0.3443
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 127.2575 s
agent0:                 episode reward: -0.4900,                 loss: nan
agent1:                 episode reward: 0.4900,                 loss: 0.3463
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 127.8527 s
agent0:                 episode reward: -0.3241,                 loss: nan
agent1:                 episode reward: 0.3241,                 loss: 0.3471
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 128.4406 s
agent0:                 episode reward: -0.7277,                 loss: nan
agent1:                 episode reward: 0.7277,                 loss: 0.3442
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6004s / 129.0411 s
agent0:                 episode reward: -0.7057,                 loss: nan
agent1:                 episode reward: 0.7057,                 loss: 0.3450
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5997s / 129.6408 s
agent0:                 episode reward: -0.6700,                 loss: nan
agent1:                 episode reward: 0.6700,                 loss: 0.3444
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 130.2394 s
agent0:                 episode reward: -0.5918,                 loss: nan
agent1:                 episode reward: 0.5918,                 loss: 0.3436
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 130.8415 s
agent0:                 episode reward: -0.9527,                 loss: nan
agent1:                 episode reward: 0.9527,                 loss: 0.3414
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5995s / 131.4410 s
agent0:                 episode reward: -1.0157,                 loss: nan
agent1:                 episode reward: 1.0157,                 loss: 0.3420
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5957s / 132.0367 s
agent0:                 episode reward: -0.7994,                 loss: nan
agent1:                 episode reward: 0.7994,                 loss: 0.3439
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5932s / 132.6300 s
agent0:                 episode reward: -0.2030,                 loss: nan
agent1:                 episode reward: 0.2030,                 loss: 0.3423
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6127s / 133.2426 s
agent0:                 episode reward: -0.5034,                 loss: nan
agent1:                 episode reward: 0.5034,                 loss: 0.3449
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 133.8412 s
agent0:                 episode reward: -0.3998,                 loss: nan
agent1:                 episode reward: 0.3998,                 loss: 0.3429
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5979s / 134.4392 s
agent0:                 episode reward: -0.3898,                 loss: nan
agent1:                 episode reward: 0.3898,                 loss: 0.3473
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5977s / 135.0369 s
agent0:                 episode reward: -0.6526,                 loss: nan
agent1:                 episode reward: 0.6526,                 loss: 0.3420
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 135.6349 s
agent0:                 episode reward: -0.4314,                 loss: nan
agent1:                 episode reward: 0.4314,                 loss: 0.3431
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 136.2338 s
agent0:                 episode reward: -0.3840,                 loss: nan
agent1:                 episode reward: 0.3840,                 loss: 0.3439
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 136.8289 s
agent0:                 episode reward: -0.7486,                 loss: nan
agent1:                 episode reward: 0.7486,                 loss: 0.3470
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5940s / 137.4228 s
agent0:                 episode reward: -0.5216,                 loss: nan
agent1:                 episode reward: 0.5216,                 loss: 0.3470
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5938s / 138.0167 s
agent0:                 episode reward: -0.5042,                 loss: nan
agent1:                 episode reward: 0.5042,                 loss: 0.3421
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5999s / 138.6166 s
agent0:                 episode reward: -0.2080,                 loss: nan
agent1:                 episode reward: 0.2080,                 loss: 0.3448
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5924s / 139.2090 s
agent0:                 episode reward: -0.3869,                 loss: nan
agent1:                 episode reward: 0.3869,                 loss: 0.3416
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6017s / 139.8106 s
agent0:                 episode reward: -0.8843,                 loss: nan
agent1:                 episode reward: 0.8843,                 loss: 0.3456
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 140.4053 s
agent0:                 episode reward: -0.4771,                 loss: nan
agent1:                 episode reward: 0.4771,                 loss: 0.3465
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5963s / 141.0016 s
agent0:                 episode reward: -0.5796,                 loss: nan
agent1:                 episode reward: 0.5796,                 loss: 0.3487
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6037s / 141.6053 s
agent0:                 episode reward: -0.4838,                 loss: nan
agent1:                 episode reward: 0.4838,                 loss: 0.3438
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6047s / 142.2100 s
agent0:                 episode reward: -0.8242,                 loss: nan
agent1:                 episode reward: 0.8242,                 loss: 0.3457
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 142.8031 s
agent0:                 episode reward: -0.4409,                 loss: nan
agent1:                 episode reward: 0.4409,                 loss: 0.3517
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 143.4027 s
agent0:                 episode reward: -0.8211,                 loss: nan
agent1:                 episode reward: 0.8211,                 loss: 0.3536
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 143.9982 s
agent0:                 episode reward: -0.5883,                 loss: nan
agent1:                 episode reward: 0.5883,                 loss: 0.3513
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6008s / 144.5990 s
agent0:                 episode reward: -0.7499,                 loss: nan
agent1:                 episode reward: 0.7499,                 loss: 0.3514
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5995s / 145.1985 s
agent0:                 episode reward: -0.1210,                 loss: nan
agent1:                 episode reward: 0.1210,                 loss: 0.3503
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 145.7965 s
agent0:                 episode reward: -0.3771,                 loss: nan
agent1:                 episode reward: 0.3771,                 loss: 0.3530
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6054s / 146.4019 s
agent0:                 episode reward: -0.3930,                 loss: nan
agent1:                 episode reward: 0.3930,                 loss: 0.3523
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5977s / 146.9996 s
agent0:                 episode reward: -0.3439,                 loss: nan
agent1:                 episode reward: 0.3439,                 loss: 0.3498
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6005s / 147.6001 s
agent0:                 episode reward: -0.8083,                 loss: nan
agent1:                 episode reward: 0.8083,                 loss: 0.3529
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6024s / 148.2025 s
agent0:                 episode reward: -0.2968,                 loss: nan
agent1:                 episode reward: 0.2968,                 loss: 0.3496
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5979s / 148.8004 s
agent0:                 episode reward: -0.7199,                 loss: nan
agent1:                 episode reward: 0.7199,                 loss: 0.3538
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5980s / 149.3984 s
agent0:                 episode reward: -0.8348,                 loss: nan
agent1:                 episode reward: 0.8348,                 loss: 0.3543
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5996s / 149.9980 s
agent0:                 episode reward: -0.4514,                 loss: nan
agent1:                 episode reward: 0.4514,                 loss: 0.3511
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5899s / 150.5879 s
agent0:                 episode reward: -0.6731,                 loss: nan
agent1:                 episode reward: 0.6731,                 loss: 0.3543
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5905s / 151.1784 s
agent0:                 episode reward: -0.8772,                 loss: nan
agent1:                 episode reward: 0.8772,                 loss: 0.3515
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5986s / 151.7769 s
agent0:                 episode reward: -0.8116,                 loss: nan
agent1:                 episode reward: 0.8116,                 loss: 0.3507
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 152.3733 s
agent0:                 episode reward: -0.4766,                 loss: nan
agent1:                 episode reward: 0.4766,                 loss: 0.3495
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 152.9644 s
agent0:                 episode reward: -0.6695,                 loss: nan
agent1:                 episode reward: 0.6695,                 loss: 0.3427
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5969s / 153.5613 s
agent0:                 episode reward: -0.7657,                 loss: nan
agent1:                 episode reward: 0.7657,                 loss: 0.3402
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6026s / 154.1640 s
agent0:                 episode reward: -0.5549,                 loss: nan
agent1:                 episode reward: 0.5549,                 loss: 0.3399
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5936s / 154.7576 s
agent0:                 episode reward: -0.6566,                 loss: nan
agent1:                 episode reward: 0.6566,                 loss: 0.3395
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6040s / 155.3616 s
agent0:                 episode reward: -0.6470,                 loss: nan
agent1:                 episode reward: 0.6470,                 loss: 0.3409
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5988s / 155.9604 s
agent0:                 episode reward: -0.3710,                 loss: nan
agent1:                 episode reward: 0.3710,                 loss: 0.3395
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5965s / 156.5569 s
agent0:                 episode reward: -0.8425,                 loss: nan
agent1:                 episode reward: 0.8425,                 loss: 0.3394
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5985s / 157.1554 s
agent0:                 episode reward: -0.5476,                 loss: nan
agent1:                 episode reward: 0.5476,                 loss: 0.3373
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5965s / 157.7519 s
agent0:                 episode reward: -0.4433,                 loss: nan
agent1:                 episode reward: 0.4433,                 loss: 0.3401
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6093s / 158.3612 s
agent0:                 episode reward: -0.2703,                 loss: nan
agent1:                 episode reward: 0.2703,                 loss: 0.3397
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5958s / 158.9570 s
agent0:                 episode reward: -0.5785,                 loss: nan
agent1:                 episode reward: 0.5785,                 loss: 0.3367
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5962s / 159.5532 s
agent0:                 episode reward: -0.3811,                 loss: nan
agent1:                 episode reward: 0.3811,                 loss: 0.3385
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6041s / 160.1573 s
agent0:                 episode reward: -0.5674,                 loss: nan
agent1:                 episode reward: 0.5674,                 loss: 0.3392
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6026s / 160.7599 s
agent0:                 episode reward: -0.4938,                 loss: nan
agent1:                 episode reward: 0.4938,                 loss: 0.3376
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 161.3588 s
agent0:                 episode reward: -0.9401,                 loss: nan
agent1:                 episode reward: 0.9401,                 loss: 0.3422
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6003s / 161.9591 s
agent0:                 episode reward: -0.9361,                 loss: nan
agent1:                 episode reward: 0.9361,                 loss: 0.3419
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6005s / 162.5596 s
agent0:                 episode reward: -0.6811,                 loss: nan
agent1:                 episode reward: 0.6811,                 loss: 0.3346
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6019s / 163.1615 s
agent0:                 episode reward: -0.1667,                 loss: nan
agent1:                 episode reward: 0.1667,                 loss: 0.3290
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 163.7636 s
agent0:                 episode reward: -0.6101,                 loss: nan
agent1:                 episode reward: 0.6101,                 loss: 0.3287
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6036s / 164.3672 s
agent0:                 episode reward: -0.5266,                 loss: nan
agent1:                 episode reward: 0.5266,                 loss: 0.3314
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6037s / 164.9709 s
agent0:                 episode reward: -0.4483,                 loss: nan
agent1:                 episode reward: 0.4483,                 loss: 0.3278
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6158s / 165.5867 s
agent0:                 episode reward: -1.0858,                 loss: nan
agent1:                 episode reward: 1.0858,                 loss: 0.3331
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 166.1857 s
agent0:                 episode reward: -0.5054,                 loss: nan
agent1:                 episode reward: 0.5054,                 loss: 0.3300
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 166.7868 s
agent0:                 episode reward: -0.4515,                 loss: nan
agent1:                 episode reward: 0.4515,                 loss: 0.3296
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6045s / 167.3913 s
agent0:                 episode reward: -0.3637,                 loss: nan
agent1:                 episode reward: 0.3637,                 loss: 0.3305
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6089s / 168.0003 s
agent0:                 episode reward: -0.2553,                 loss: nan
agent1:                 episode reward: 0.2553,                 loss: 0.3280
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6069s / 168.6071 s
agent0:                 episode reward: -0.2483,                 loss: nan
agent1:                 episode reward: 0.2483,                 loss: 0.3259
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6045s / 169.2117 s
agent0:                 episode reward: -0.5165,                 loss: nan
agent1:                 episode reward: 0.5165,                 loss: 0.3297
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6040s / 169.8157 s
agent0:                 episode reward: -0.9414,                 loss: nan
agent1:                 episode reward: 0.9414,                 loss: 0.3281
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6023s / 170.4180 s
agent0:                 episode reward: -0.6027,                 loss: nan
agent1:                 episode reward: 0.6027,                 loss: 0.3293
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6088s / 171.0268 s
agent0:                 episode reward: -0.5401,                 loss: nan
agent1:                 episode reward: 0.5401,                 loss: 0.3280
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5974s / 171.6242 s
agent0:                 episode reward: -0.4056,                 loss: nan
agent1:                 episode reward: 0.4056,                 loss: 0.3313
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6115s / 172.2357 s
agent0:                 episode reward: -0.5859,                 loss: nan
agent1:                 episode reward: 0.5859,                 loss: 0.3294
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6162s / 172.8519 s
agent0:                 episode reward: -0.4839,                 loss: nan
agent1:                 episode reward: 0.4839,                 loss: 0.3429
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6116s / 173.4635 s
agent0:                 episode reward: -0.3228,                 loss: nan
agent1:                 episode reward: 0.3228,                 loss: 0.3452
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6047s / 174.0682 s
agent0:                 episode reward: -1.0544,                 loss: nan
agent1:                 episode reward: 1.0544,                 loss: 0.3416
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6052s / 174.6734 s
agent0:                 episode reward: -0.4000,                 loss: nan
agent1:                 episode reward: 0.4000,                 loss: 0.3406
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6157s / 175.2891 s
agent0:                 episode reward: -0.7417,                 loss: nan
agent1:                 episode reward: 0.7417,                 loss: 0.3421
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5993s / 175.8884 s
agent0:                 episode reward: -0.9255,                 loss: nan
agent1:                 episode reward: 0.9255,                 loss: 0.3448
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6062s / 176.4946 s
agent0:                 episode reward: -0.6570,                 loss: nan
agent1:                 episode reward: 0.6570,                 loss: 0.3435
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6011s / 177.0958 s
agent0:                 episode reward: -1.0087,                 loss: nan
agent1:                 episode reward: 1.0087,                 loss: 0.3435
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6017s / 177.6975 s
agent0:                 episode reward: -0.2137,                 loss: nan
agent1:                 episode reward: 0.2137,                 loss: 0.3429
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5964s / 178.2939 s
agent0:                 episode reward: -0.9853,                 loss: nan
agent1:                 episode reward: 0.9853,                 loss: 0.3438
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6126s / 178.9065 s
agent0:                 episode reward: -0.4357,                 loss: nan
agent1:                 episode reward: 0.4357,                 loss: 0.3429
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6190s / 179.5255 s
agent0:                 episode reward: -0.7868,                 loss: nan
agent1:                 episode reward: 0.7868,                 loss: 0.3446
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6089s / 180.1344 s
agent0:                 episode reward: -0.4367,                 loss: nan
agent1:                 episode reward: 0.4367,                 loss: 0.3436
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6110s / 180.7454 s
agent0:                 episode reward: -0.7573,                 loss: nan
agent1:                 episode reward: 0.7573,                 loss: 0.3410
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6020s / 181.3474 s
agent0:                 episode reward: -0.9386,                 loss: nan
agent1:                 episode reward: 0.9386,                 loss: 0.3441
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6104s / 181.9578 s
agent0:                 episode reward: -0.7357,                 loss: nan
agent1:                 episode reward: 0.7357,                 loss: 0.3487
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6028s / 182.5607 s
agent0:                 episode reward: -0.9697,                 loss: nan
agent1:                 episode reward: 0.9697,                 loss: 0.3388
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6067s / 183.1673 s
agent0:                 episode reward: -0.5948,                 loss: nan
agent1:                 episode reward: 0.5948,                 loss: 0.3358
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6024s / 183.7697 s
agent0:                 episode reward: -0.8527,                 loss: nan
agent1:                 episode reward: 0.8527,                 loss: 0.3307
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6050s / 184.3748 s
agent0:                 episode reward: -0.3697,                 loss: nan
agent1:                 episode reward: 0.3697,                 loss: 0.3340
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6084s / 184.9832 s
agent0:                 episode reward: -0.4923,                 loss: nan
agent1:                 episode reward: 0.4923,                 loss: 0.3323
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5997s / 185.5829 s
agent0:                 episode reward: -0.3074,                 loss: nan
agent1:                 episode reward: 0.3074,                 loss: 0.3343
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6043s / 186.1872 s
agent0:                 episode reward: -0.3902,                 loss: nan
agent1:                 episode reward: 0.3902,                 loss: 0.3330
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6062s / 186.7934 s
agent0:                 episode reward: -0.4678,                 loss: nan
agent1:                 episode reward: 0.4678,                 loss: 0.3349
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6066s / 187.4000 s
agent0:                 episode reward: -0.7753,                 loss: nan
agent1:                 episode reward: 0.7753,                 loss: 0.3338
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6053s / 188.0053 s
agent0:                 episode reward: -0.5586,                 loss: nan
agent1:                 episode reward: 0.5586,                 loss: 0.3312
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5988s / 188.6041 s
agent0:                 episode reward: -0.9786,                 loss: nan
agent1:                 episode reward: 0.9786,                 loss: 0.3308
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6022s / 189.2063 s
agent0:                 episode reward: -0.2749,                 loss: nan
agent1:                 episode reward: 0.2749,                 loss: 0.3349
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6056s / 189.8119 s
agent0:                 episode reward: -0.6444,                 loss: nan
agent1:                 episode reward: 0.6444,                 loss: 0.3296
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6230s / 190.4350 s
agent0:                 episode reward: -0.5195,                 loss: nan
agent1:                 episode reward: 0.5195,                 loss: 0.3330
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6170s / 191.0520 s
agent0:                 episode reward: -0.4632,                 loss: nan
agent1:                 episode reward: 0.4632,                 loss: 0.3268
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6172s / 191.6692 s
agent0:                 episode reward: -0.1933,                 loss: nan
agent1:                 episode reward: 0.1933,                 loss: 0.3368
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6047s / 192.2739 s
agent0:                 episode reward: -0.4117,                 loss: nan
agent1:                 episode reward: 0.4117,                 loss: 0.3334
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6132s / 192.8871 s
agent0:                 episode reward: -0.4434,                 loss: nan
agent1:                 episode reward: 0.4434,                 loss: 0.3275
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6043s / 193.4914 s
agent0:                 episode reward: -0.6847,                 loss: nan
agent1:                 episode reward: 0.6847,                 loss: 0.3255
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6034s / 194.0948 s
agent0:                 episode reward: -0.4198,                 loss: nan
agent1:                 episode reward: 0.4198,                 loss: 0.3221
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6093s / 194.7041 s
agent0:                 episode reward: -0.7596,                 loss: nan
agent1:                 episode reward: 0.7596,                 loss: 0.3237
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6091s / 195.3132 s
agent0:                 episode reward: -0.5759,                 loss: nan
agent1:                 episode reward: 0.5759,                 loss: 0.3231
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6132s / 195.9264 s
agent0:                 episode reward: -0.4758,                 loss: nan
agent1:                 episode reward: 0.4758,                 loss: 0.3258
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6050s / 196.5314 s
agent0:                 episode reward: -0.5964,                 loss: nan
agent1:                 episode reward: 0.5964,                 loss: 0.3245
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6079s / 197.1393 s
agent0:                 episode reward: -0.5134,                 loss: nan
agent1:                 episode reward: 0.5134,                 loss: 0.3237
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6156s / 197.7549 s
agent0:                 episode reward: -1.0941,                 loss: nan
agent1:                 episode reward: 1.0941,                 loss: 0.3226
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6128s / 198.3677 s
agent0:                 episode reward: -0.7153,                 loss: nan
agent1:                 episode reward: 0.7153,                 loss: 0.3235
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6123s / 198.9800 s
agent0:                 episode reward: -0.7932,                 loss: nan
agent1:                 episode reward: 0.7932,                 loss: 0.3258
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6159s / 199.5959 s
agent0:                 episode reward: -0.5061,                 loss: nan
agent1:                 episode reward: 0.5061,                 loss: 0.3222
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6177s / 200.2136 s
agent0:                 episode reward: -0.8039,                 loss: nan
agent1:                 episode reward: 0.8039,                 loss: 0.3220
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6176s / 200.8312 s
agent0:                 episode reward: -0.1936,                 loss: nan
agent1:                 episode reward: 0.1936,                 loss: 0.3233
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6084s / 201.4397 s
agent0:                 episode reward: -0.7687,                 loss: nan
agent1:                 episode reward: 0.7687,                 loss: 0.3238
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6072s / 202.0468 s
agent0:                 episode reward: -0.2622,                 loss: nan
agent1:                 episode reward: 0.2622,                 loss: 0.3227
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6123s / 202.6592 s
agent0:                 episode reward: -0.6178,                 loss: nan
agent1:                 episode reward: 0.6178,                 loss: 0.3233
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6161s / 203.2753 s
agent0:                 episode reward: -0.2951,                 loss: nan
agent1:                 episode reward: 0.2951,                 loss: 0.3518
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6127s / 203.8880 s
agent0:                 episode reward: -1.0562,                 loss: nan
agent1:                 episode reward: 1.0562,                 loss: 0.3477
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6158s / 204.5038 s
agent0:                 episode reward: -0.7541,                 loss: nan
agent1:                 episode reward: 0.7541,                 loss: 0.3507
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6186s / 205.1225 s
agent0:                 episode reward: -0.5710,                 loss: nan
agent1:                 episode reward: 0.5710,                 loss: 0.3505
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6110s / 205.7335 s
agent0:                 episode reward: -0.2986,                 loss: nan
agent1:                 episode reward: 0.2986,                 loss: 0.3500
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6128s / 206.3462 s
agent0:                 episode reward: -0.5140,                 loss: nan
agent1:                 episode reward: 0.5140,                 loss: 0.3490
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6143s / 206.9605 s
agent0:                 episode reward: -0.5868,                 loss: nan
agent1:                 episode reward: 0.5868,                 loss: 0.3486
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6167s / 207.5772 s
agent0:                 episode reward: -0.4453,                 loss: nan
agent1:                 episode reward: 0.4453,                 loss: 0.3469
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6101s / 208.1873 s
agent0:                 episode reward: -0.5503,                 loss: nan
agent1:                 episode reward: 0.5503,                 loss: 0.3489
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6192s / 208.8066 s
agent0:                 episode reward: -0.9083,                 loss: nan
agent1:                 episode reward: 0.9083,                 loss: 0.3497
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6266s / 209.4332 s
agent0:                 episode reward: -0.9434,                 loss: nan
agent1:                 episode reward: 0.9434,                 loss: 0.3477
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6068s / 210.0400 s
agent0:                 episode reward: -0.2638,                 loss: nan
agent1:                 episode reward: 0.2638,                 loss: 0.3521
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6168s / 210.6568 s
agent0:                 episode reward: -0.6275,                 loss: nan
agent1:                 episode reward: 0.6275,                 loss: 0.3482
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6180s / 211.2749 s
agent0:                 episode reward: -0.4732,                 loss: nan
agent1:                 episode reward: 0.4732,                 loss: 0.3494
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6172s / 211.8921 s
agent0:                 episode reward: -0.7992,                 loss: nan
agent1:                 episode reward: 0.7992,                 loss: 0.3478
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6157s / 212.5078 s
agent0:                 episode reward: -0.3576,                 loss: nan
agent1:                 episode reward: 0.3576,                 loss: 0.3473
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6190s / 213.1268 s
agent0:                 episode reward: -0.5725,                 loss: nan
agent1:                 episode reward: 0.5725,                 loss: 0.3417
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6128s / 213.7395 s
agent0:                 episode reward: -0.8507,                 loss: nan
agent1:                 episode reward: 0.8507,                 loss: 0.3261
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6155s / 214.3550 s
agent0:                 episode reward: -0.3283,                 loss: nan
agent1:                 episode reward: 0.3283,                 loss: 0.3269
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6131s / 214.9681 s
agent0:                 episode reward: -0.4891,                 loss: nan
agent1:                 episode reward: 0.4891,                 loss: 0.3266
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6142s / 215.5823 s
agent0:                 episode reward: -0.5286,                 loss: nan
agent1:                 episode reward: 0.5286,                 loss: 0.3251
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6162s / 216.1985 s
agent0:                 episode reward: -0.4862,                 loss: nan
agent1:                 episode reward: 0.4862,                 loss: 0.3270
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6144s / 216.8129 s
agent0:                 episode reward: -0.6709,                 loss: nan
agent1:                 episode reward: 0.6709,                 loss: 0.3236
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6155s / 217.4284 s
agent0:                 episode reward: -0.6298,                 loss: nan
agent1:                 episode reward: 0.6298,                 loss: 0.3295
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6251s / 218.0535 s
agent0:                 episode reward: -0.7680,                 loss: nan
agent1:                 episode reward: 0.7680,                 loss: 0.3279
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6232s / 218.6767 s
agent0:                 episode reward: -0.6117,                 loss: nan
agent1:                 episode reward: 0.6117,                 loss: 0.3274
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6189s / 219.2956 s
agent0:                 episode reward: -0.4943,                 loss: nan
agent1:                 episode reward: 0.4943,                 loss: 0.3256
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6217s / 219.9172 s
agent0:                 episode reward: -0.5754,                 loss: nan
agent1:                 episode reward: 0.5754,                 loss: 0.3257
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6191s / 220.5363 s
agent0:                 episode reward: -0.8601,                 loss: nan
agent1:                 episode reward: 0.8601,                 loss: 0.3288
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6203s / 221.1566 s
agent0:                 episode reward: -0.3904,                 loss: nan
agent1:                 episode reward: 0.3904,                 loss: 0.3283
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6200s / 221.7767 s
agent0:                 episode reward: -0.9442,                 loss: nan
agent1:                 episode reward: 0.9442,                 loss: 0.3275
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6224s / 222.3991 s
agent0:                 episode reward: -0.4154,                 loss: nan
agent1:                 episode reward: 0.4154,                 loss: 0.3278
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6234s / 223.0225 s
agent0:                 episode reward: -0.6156,                 loss: nan
agent1:                 episode reward: 0.6156,                 loss: 0.3264
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6181s / 223.6406 s
agent0:                 episode reward: -0.9112,                 loss: nan
agent1:                 episode reward: 0.9112,                 loss: 0.3297
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6188s / 224.2594 s
agent0:                 episode reward: -0.8908,                 loss: nan
agent1:                 episode reward: 0.8908,                 loss: 0.3309
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6207s / 224.8802 s
agent0:                 episode reward: -0.6294,                 loss: nan
agent1:                 episode reward: 0.6294,                 loss: 0.3303
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6113s / 225.4914 s
agent0:                 episode reward: -1.1543,                 loss: nan
agent1:                 episode reward: 1.1543,                 loss: 0.3307
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6131s / 226.1045 s
agent0:                 episode reward: -0.5009,                 loss: nan
agent1:                 episode reward: 0.5009,                 loss: 0.3306
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6177s / 226.7222 s
agent0:                 episode reward: -0.5971,                 loss: nan
agent1:                 episode reward: 0.5971,                 loss: 0.3252
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6262s / 227.3485 s
agent0:                 episode reward: -0.5976,                 loss: nan
agent1:                 episode reward: 0.5976,                 loss: 0.3269
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6240s / 227.9725 s
agent0:                 episode reward: -0.4165,                 loss: nan
agent1:                 episode reward: 0.4165,                 loss: 0.3296
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6242s / 228.5967 s
agent0:                 episode reward: -0.7518,                 loss: nan
agent1:                 episode reward: 0.7518,                 loss: 0.3290
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6302s / 229.2269 s
agent0:                 episode reward: -0.9966,                 loss: nan
agent1:                 episode reward: 0.9966,                 loss: 0.3318
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6237s / 229.8505 s
agent0:                 episode reward: -0.5684,                 loss: nan
agent1:                 episode reward: 0.5684,                 loss: 0.3289
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6263s / 230.4768 s
agent0:                 episode reward: -0.3833,                 loss: nan
agent1:                 episode reward: 0.3833,                 loss: 0.3273
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6252s / 231.1020 s
agent0:                 episode reward: -0.3150,                 loss: nan
agent1:                 episode reward: 0.3150,                 loss: 0.3275
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6294s / 231.7313 s
agent0:                 episode reward: -0.6425,                 loss: nan
agent1:                 episode reward: 0.6425,                 loss: 0.3247
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6209s / 232.3522 s
agent0:                 episode reward: -0.6866,                 loss: nan
agent1:                 episode reward: 0.6866,                 loss: 0.3281
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6351s / 232.9873 s
agent0:                 episode reward: -0.6093,                 loss: nan
agent1:                 episode reward: 0.6093,                 loss: 0.3263
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6282s / 233.6155 s
agent0:                 episode reward: -0.5563,                 loss: nan
agent1:                 episode reward: 0.5563,                 loss: 0.3329
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6267s / 234.2422 s
agent0:                 episode reward: -0.4652,                 loss: nan
agent1:                 episode reward: 0.4652,                 loss: 0.3534
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6312s / 234.8734 s
agent0:                 episode reward: -0.5477,                 loss: nan
agent1:                 episode reward: 0.5477,                 loss: 0.3509
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6184s / 235.4918 s
agent0:                 episode reward: -0.5419,                 loss: nan
agent1:                 episode reward: 0.5419,                 loss: 0.3485
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6242s / 236.1160 s
agent0:                 episode reward: -0.7250,                 loss: nan
agent1:                 episode reward: 0.7250,                 loss: 0.3498
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6272s / 236.7433 s
agent0:                 episode reward: -1.0273,                 loss: nan
agent1:                 episode reward: 1.0273,                 loss: 0.3522
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6255s / 237.3688 s
agent0:                 episode reward: -0.4660,                 loss: nan
agent1:                 episode reward: 0.4660,                 loss: 0.3534
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6266s / 237.9954 s
agent0:                 episode reward: -0.6871,                 loss: nan
agent1:                 episode reward: 0.6871,                 loss: 0.3502
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6274s / 238.6228 s
agent0:                 episode reward: -0.7498,                 loss: nan
agent1:                 episode reward: 0.7498,                 loss: 0.3507
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6207s / 239.2435 s
agent0:                 episode reward: -0.8044,                 loss: nan
agent1:                 episode reward: 0.8044,                 loss: 0.3522
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6211s / 239.8646 s
agent0:                 episode reward: -0.9106,                 loss: nan
agent1:                 episode reward: 0.9106,                 loss: 0.3492
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6197s / 240.4843 s
agent0:                 episode reward: -0.5972,                 loss: nan
agent1:                 episode reward: 0.5972,                 loss: 0.3521
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6176s / 241.1019 s
agent0:                 episode reward: -0.7769,                 loss: nan
agent1:                 episode reward: 0.7769,                 loss: 0.3524
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6223s / 241.7241 s
agent0:                 episode reward: -0.4066,                 loss: nan
agent1:                 episode reward: 0.4066,                 loss: 0.3519
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6242s / 242.3483 s
agent0:                 episode reward: -1.0986,                 loss: nan
agent1:                 episode reward: 1.0986,                 loss: 0.3509
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6224s / 242.9707 s
agent0:                 episode reward: -0.5844,                 loss: nan
agent1:                 episode reward: 0.5844,                 loss: 0.3506
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6227s / 243.5934 s
agent0:                 episode reward: -0.7194,                 loss: nan
agent1:                 episode reward: 0.7194,                 loss: 0.3489
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6338s / 244.2273 s
agent0:                 episode reward: -0.6543,                 loss: nan
agent1:                 episode reward: 0.6543,                 loss: 0.3440
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6223s / 244.8496 s
agent0:                 episode reward: -0.1074,                 loss: nan
agent1:                 episode reward: 0.1074,                 loss: 0.3287
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6205s / 245.4701 s
agent0:                 episode reward: -0.5090,                 loss: nan
agent1:                 episode reward: 0.5090,                 loss: 0.3250
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6267s / 246.0968 s
agent0:                 episode reward: -0.5664,                 loss: nan
agent1:                 episode reward: 0.5664,                 loss: 0.3265
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6194s / 246.7162 s
agent0:                 episode reward: -0.2679,                 loss: nan
agent1:                 episode reward: 0.2679,                 loss: 0.3242
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6241s / 247.3403 s
agent0:                 episode reward: -0.7452,                 loss: nan
agent1:                 episode reward: 0.7452,                 loss: 0.3295
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6395s / 247.9798 s
agent0:                 episode reward: -0.6330,                 loss: nan
agent1:                 episode reward: 0.6330,                 loss: 0.3252
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6230s / 248.6028 s
agent0:                 episode reward: -0.6789,                 loss: nan
agent1:                 episode reward: 0.6789,                 loss: 0.3284
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6270s / 249.2298 s
agent0:                 episode reward: -0.4965,                 loss: nan
agent1:                 episode reward: 0.4965,                 loss: 0.3283
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6256s / 249.8553 s
agent0:                 episode reward: -0.6761,                 loss: nan
agent1:                 episode reward: 0.6761,                 loss: 0.3242
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6268s / 250.4821 s
agent0:                 episode reward: -0.6492,                 loss: nan
agent1:                 episode reward: 0.6492,                 loss: 0.3219
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6352s / 251.1173 s
agent0:                 episode reward: -0.5835,                 loss: nan
agent1:                 episode reward: 0.5835,                 loss: 0.3261
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6324s / 251.7497 s
agent0:                 episode reward: -0.7886,                 loss: nan
agent1:                 episode reward: 0.7886,                 loss: 0.3238
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6301s / 252.3798 s
agent0:                 episode reward: -0.6880,                 loss: nan
agent1:                 episode reward: 0.6880,                 loss: 0.3262
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6314s / 253.0113 s
agent0:                 episode reward: -0.3458,                 loss: nan
agent1:                 episode reward: 0.3458,                 loss: 0.3272
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6295s / 253.6407 s
agent0:                 episode reward: -0.5403,                 loss: nan
agent1:                 episode reward: 0.5403,                 loss: 0.3225
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6342s / 254.2750 s
agent0:                 episode reward: -0.7657,                 loss: nan
agent1:                 episode reward: 0.7657,                 loss: 0.3224
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6359s / 254.9109 s
agent0:                 episode reward: -0.7819,                 loss: nan
agent1:                 episode reward: 0.7819,                 loss: 0.3424
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6350s / 255.5459 s
agent0:                 episode reward: -0.7789,                 loss: nan
agent1:                 episode reward: 0.7789,                 loss: 0.3419
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6277s / 256.1736 s
agent0:                 episode reward: -0.7191,                 loss: nan
agent1:                 episode reward: 0.7191,                 loss: 0.3447
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6366s / 256.8101 s
agent0:                 episode reward: -0.1831,                 loss: nan
agent1:                 episode reward: 0.1831,                 loss: 0.3451
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6341s / 257.4442 s
agent0:                 episode reward: -0.7725,                 loss: nan
agent1:                 episode reward: 0.7725,                 loss: 0.3442
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6317s / 258.0760 s
agent0:                 episode reward: -0.8301,                 loss: nan
agent1:                 episode reward: 0.8301,                 loss: 0.3451
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6382s / 258.7141 s
agent0:                 episode reward: -0.3265,                 loss: nan
agent1:                 episode reward: 0.3265,                 loss: 0.3417
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6355s / 259.3496 s
agent0:                 episode reward: -0.4018,                 loss: nan
agent1:                 episode reward: 0.4018,                 loss: 0.3445
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6320s / 259.9815 s
agent0:                 episode reward: -0.7238,                 loss: nan
agent1:                 episode reward: 0.7238,                 loss: 0.3441
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6282s / 260.6097 s
agent0:                 episode reward: -0.6955,                 loss: nan
agent1:                 episode reward: 0.6955,                 loss: 0.3457
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6357s / 261.2454 s
agent0:                 episode reward: -0.5392,                 loss: nan
agent1:                 episode reward: 0.5392,                 loss: 0.3464
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6372s / 261.8826 s
agent0:                 episode reward: -0.7133,                 loss: nan
agent1:                 episode reward: 0.7133,                 loss: 0.3427
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6375s / 262.5201 s
agent0:                 episode reward: -0.3546,                 loss: nan
agent1:                 episode reward: 0.3546,                 loss: 0.3439
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6338s / 263.1539 s
agent0:                 episode reward: -0.4536,                 loss: nan
agent1:                 episode reward: 0.4536,                 loss: 0.3430
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6392s / 263.7931 s
agent0:                 episode reward: -0.4322,                 loss: nan
agent1:                 episode reward: 0.4322,                 loss: 0.3442
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6289s / 264.4220 s
agent0:                 episode reward: -0.5582,                 loss: nan
agent1:                 episode reward: 0.5582,                 loss: 0.3456
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6367s / 265.0588 s
agent0:                 episode reward: -0.7424,                 loss: nan
agent1:                 episode reward: 0.7424,                 loss: 0.3416
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6382s / 265.6970 s
agent0:                 episode reward: -0.7850,                 loss: nan
agent1:                 episode reward: 0.7850,                 loss: 0.3439
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6440s / 266.3410 s
agent0:                 episode reward: -0.5776,                 loss: nan
agent1:                 episode reward: 0.5776,                 loss: 0.3438
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6399s / 266.9809 s
agent0:                 episode reward: -0.5781,                 loss: nan
agent1:                 episode reward: 0.5781,                 loss: 0.3432
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6345s / 267.6154 s
agent0:                 episode reward: -0.6735,                 loss: nan
agent1:                 episode reward: 0.6735,                 loss: 0.3437
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6418s / 268.2572 s
agent0:                 episode reward: -0.5046,                 loss: nan
agent1:                 episode reward: 0.5046,                 loss: 0.3454
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6348s / 268.8920 s
agent0:                 episode reward: -0.7884,                 loss: nan
agent1:                 episode reward: 0.7884,                 loss: 0.3419
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6505s / 269.5424 s
agent0:                 episode reward: -0.5460,                 loss: nan
agent1:                 episode reward: 0.5460,                 loss: 0.3394
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6328s / 270.1753 s
agent0:                 episode reward: -0.5303,                 loss: nan
agent1:                 episode reward: 0.5303,                 loss: 0.3433
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6364s / 270.8116 s
agent0:                 episode reward: -0.4996,                 loss: nan
agent1:                 episode reward: 0.4996,                 loss: 0.3408
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6351s / 271.4467 s
agent0:                 episode reward: -0.6149,                 loss: nan
agent1:                 episode reward: 0.6149,                 loss: 0.3425
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6327s / 272.0794 s
agent0:                 episode reward: -0.6127,                 loss: nan
agent1:                 episode reward: 0.6127,                 loss: 0.3420
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6423s / 272.7217 s
agent0:                 episode reward: -0.5857,                 loss: nan
agent1:                 episode reward: 0.5857,                 loss: 0.3456
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6487s / 273.3704 s
agent0:                 episode reward: -0.3752,                 loss: nan
agent1:                 episode reward: 0.3752,                 loss: 0.3405
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6406s / 274.0110 s
agent0:                 episode reward: -0.7492,                 loss: nan
agent1:                 episode reward: 0.7492,                 loss: 0.3468
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6370s / 274.6480 s
agent0:                 episode reward: -0.1153,                 loss: nan
agent1:                 episode reward: 0.1153,                 loss: 0.3423
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6448s / 275.2928 s
agent0:                 episode reward: -0.4928,                 loss: nan
agent1:                 episode reward: 0.4928,                 loss: 0.3442
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6368s / 275.9296 s
agent0:                 episode reward: -0.7788,                 loss: nan
agent1:                 episode reward: 0.7788,                 loss: 0.3368
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6458s / 276.5755 s
agent0:                 episode reward: -0.5508,                 loss: nan
agent1:                 episode reward: 0.5508,                 loss: 0.3308
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6411s / 277.2166 s
agent0:                 episode reward: -0.7054,                 loss: nan
agent1:                 episode reward: 0.7054,                 loss: 0.3306
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6449s / 277.8615 s
agent0:                 episode reward: -0.7646,                 loss: nan
agent1:                 episode reward: 0.7646,                 loss: 0.3306
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6405s / 278.5020 s
agent0:                 episode reward: -0.5363,                 loss: nan
agent1:                 episode reward: 0.5363,                 loss: 0.3294
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6511s / 279.1531 s
agent0:                 episode reward: -0.7043,                 loss: nan
agent1:                 episode reward: 0.7043,                 loss: 0.3285
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6415s / 279.7946 s
agent0:                 episode reward: -0.6427,                 loss: nan
agent1:                 episode reward: 0.6427,                 loss: 0.3292
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6477s / 280.4423 s
agent0:                 episode reward: -0.4458,                 loss: nan
agent1:                 episode reward: 0.4458,                 loss: 0.3274
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6297s / 281.0720 s
agent0:                 episode reward: -0.2684,                 loss: nan
agent1:                 episode reward: 0.2684,                 loss: 0.3280
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6473s / 281.7193 s
agent0:                 episode reward: -0.6754,                 loss: nan
agent1:                 episode reward: 0.6754,                 loss: 0.3284
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6441s / 282.3633 s
agent0:                 episode reward: -0.6146,                 loss: nan
agent1:                 episode reward: 0.6146,                 loss: 0.3308
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6446s / 283.0079 s
agent0:                 episode reward: -0.5231,                 loss: nan
agent1:                 episode reward: 0.5231,                 loss: 0.3288
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6469s / 283.6549 s
agent0:                 episode reward: -0.6385,                 loss: nan
agent1:                 episode reward: 0.6385,                 loss: 0.3266
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6466s / 284.3015 s
agent0:                 episode reward: -0.6185,                 loss: nan
agent1:                 episode reward: 0.6185,                 loss: 0.3309
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6491s / 284.9506 s
agent0:                 episode reward: -0.4902,                 loss: nan
agent1:                 episode reward: 0.4902,                 loss: 0.3276
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6492s / 285.5998 s
agent0:                 episode reward: -0.4518,                 loss: nan
agent1:                 episode reward: 0.4518,                 loss: 0.3291
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6422s / 286.2420 s
agent0:                 episode reward: -1.0451,                 loss: nan
agent1:                 episode reward: 1.0451,                 loss: 0.3258
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6474s / 286.8894 s
agent0:                 episode reward: -1.1724,                 loss: nan
agent1:                 episode reward: 1.1724,                 loss: 0.3417
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6506s / 287.5401 s
agent0:                 episode reward: -0.8089,                 loss: nan
agent1:                 episode reward: 0.8089,                 loss: 0.3464
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6531s / 288.1931 s
agent0:                 episode reward: -0.8672,                 loss: nan
agent1:                 episode reward: 0.8672,                 loss: 0.3439
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6511s / 288.8443 s
agent0:                 episode reward: -0.6233,                 loss: nan
agent1:                 episode reward: 0.6233,                 loss: 0.3473
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6443s / 289.4885 s
agent0:                 episode reward: -0.6956,                 loss: nan
agent1:                 episode reward: 0.6956,                 loss: 0.3492
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6444s / 290.1329 s
agent0:                 episode reward: -0.3769,                 loss: nan
agent1:                 episode reward: 0.3769,                 loss: 0.3452
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6399s / 290.7727 s
agent0:                 episode reward: -0.9378,                 loss: nan
agent1:                 episode reward: 0.9378,                 loss: 0.3463
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6409s / 291.4137 s
agent0:                 episode reward: -0.6686,                 loss: nan
agent1:                 episode reward: 0.6686,                 loss: 0.3498
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6448s / 292.0584 s
agent0:                 episode reward: -0.7154,                 loss: nan
agent1:                 episode reward: 0.7154,                 loss: 0.3442
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6462s / 292.7046 s
agent0:                 episode reward: -0.8779,                 loss: nan
agent1:                 episode reward: 0.8779,                 loss: 0.3475
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6314s / 293.3360 s
agent0:                 episode reward: -0.7807,                 loss: nan
agent1:                 episode reward: 0.7807,                 loss: 0.3473
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6383s / 293.9743 s
agent0:                 episode reward: -0.2829,                 loss: nan
agent1:                 episode reward: 0.2829,                 loss: 0.3441
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6438s / 294.6181 s
agent0:                 episode reward: -0.7901,                 loss: nan
agent1:                 episode reward: 0.7901,                 loss: 0.3482
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6433s / 295.2614 s
agent0:                 episode reward: -0.9643,                 loss: nan
agent1:                 episode reward: 0.9643,                 loss: 0.3460
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6506s / 295.9120 s
agent0:                 episode reward: -0.2829,                 loss: nan
agent1:                 episode reward: 0.2829,                 loss: 0.3444
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6517s / 296.5636 s
agent0:                 episode reward: -0.8283,                 loss: nan
agent1:                 episode reward: 0.8283,                 loss: 0.3467
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6479s / 297.2115 s
agent0:                 episode reward: -0.3934,                 loss: nan
agent1:                 episode reward: 0.3934,                 loss: 0.3446
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6489s / 297.8604 s
agent0:                 episode reward: -0.8301,                 loss: nan
agent1:                 episode reward: 0.8301,                 loss: 0.3355
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6845s / 298.5450 s
agent0:                 episode reward: -0.8880,                 loss: nan
agent1:                 episode reward: 0.8880,                 loss: 0.3351
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6441s / 299.1890 s
agent0:                 episode reward: -0.8796,                 loss: nan
agent1:                 episode reward: 0.8796,                 loss: 0.3378
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6445s / 299.8336 s
agent0:                 episode reward: -0.7981,                 loss: nan
agent1:                 episode reward: 0.7981,                 loss: 0.3370
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6457s / 300.4792 s
agent0:                 episode reward: -0.5532,                 loss: nan
agent1:                 episode reward: 0.5532,                 loss: 0.3382
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6503s / 301.1295 s
agent0:                 episode reward: -0.3283,                 loss: nan
agent1:                 episode reward: 0.3283,                 loss: 0.3360
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6475s / 301.7771 s
agent0:                 episode reward: -0.4757,                 loss: nan
agent1:                 episode reward: 0.4757,                 loss: 0.3362
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6526s / 302.4297 s
agent0:                 episode reward: -0.4574,                 loss: nan
agent1:                 episode reward: 0.4574,                 loss: 0.3368
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6526s / 303.0822 s
agent0:                 episode reward: -0.7363,                 loss: nan
agent1:                 episode reward: 0.7363,                 loss: 0.3351
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6455s / 303.7277 s
agent0:                 episode reward: -0.3155,                 loss: nan
agent1:                 episode reward: 0.3155,                 loss: 0.3353
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6443s / 304.3721 s
agent0:                 episode reward: -0.5981,                 loss: nan
agent1:                 episode reward: 0.5981,                 loss: 0.3376
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6417s / 305.0137 s
agent0:                 episode reward: -0.3047,                 loss: nan
agent1:                 episode reward: 0.3047,                 loss: 0.3391
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6426s / 305.6563 s
agent0:                 episode reward: -0.6141,                 loss: nan
agent1:                 episode reward: 0.6141,                 loss: 0.3359
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6582s / 306.3145 s
agent0:                 episode reward: -0.5642,                 loss: nan
agent1:                 episode reward: 0.5642,                 loss: 0.3359
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6490s / 306.9635 s
agent0:                 episode reward: -0.6637,                 loss: nan
agent1:                 episode reward: 0.6637,                 loss: 0.3340
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6443s / 307.6078 s
agent0:                 episode reward: -0.9458,                 loss: nan
agent1:                 episode reward: 0.9458,                 loss: 0.3385
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6503s / 308.2581 s
agent0:                 episode reward: -0.7526,                 loss: nan
agent1:                 episode reward: 0.7526,                 loss: 0.3381
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6504s / 308.9085 s
agent0:                 episode reward: -0.7121,                 loss: nan
agent1:                 episode reward: 0.7121,                 loss: 0.3377
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6471s / 309.5556 s
agent0:                 episode reward: -0.8650,                 loss: nan
agent1:                 episode reward: 0.8650,                 loss: 0.3363
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6493s / 310.2049 s
agent0:                 episode reward: -0.7332,                 loss: nan
agent1:                 episode reward: 0.7332,                 loss: 0.3404
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6439s / 310.8487 s
agent0:                 episode reward: -0.6405,                 loss: nan
agent1:                 episode reward: 0.6405,                 loss: 0.3376
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6416s / 311.4903 s
agent0:                 episode reward: -0.8053,                 loss: nan
agent1:                 episode reward: 0.8053,                 loss: 0.3390
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6478s / 312.1381 s
agent0:                 episode reward: -0.6263,                 loss: nan
agent1:                 episode reward: 0.6263,                 loss: 0.3365
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6419s / 312.7800 s
agent0:                 episode reward: -0.4817,                 loss: nan
agent1:                 episode reward: 0.4817,                 loss: 0.3408
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6447s / 313.4247 s
agent0:                 episode reward: -0.5189,                 loss: nan
agent1:                 episode reward: 0.5189,                 loss: 0.3404
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6395s / 314.0642 s
agent0:                 episode reward: -0.3270,                 loss: nan
agent1:                 episode reward: 0.3270,                 loss: 0.3378
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6546s / 314.7188 s
agent0:                 episode reward: -0.7399,                 loss: nan
agent1:                 episode reward: 0.7399,                 loss: 0.3370
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6432s / 315.3620 s
agent0:                 episode reward: -0.2567,                 loss: nan
agent1:                 episode reward: 0.2567,                 loss: 0.3367
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6442s / 316.0062 s
agent0:                 episode reward: -0.4222,                 loss: nan
agent1:                 episode reward: 0.4222,                 loss: 0.3411
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6477s / 316.6538 s
agent0:                 episode reward: -0.8471,                 loss: nan
agent1:                 episode reward: 0.8471,                 loss: 0.3372
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6472s / 317.3010 s
agent0:                 episode reward: -0.6894,                 loss: nan
agent1:                 episode reward: 0.6894,                 loss: 0.3370
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6529s / 317.9539 s
agent0:                 episode reward: -0.7244,                 loss: nan
agent1:                 episode reward: 0.7244,                 loss: 0.3399
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6506s / 318.6045 s
agent0:                 episode reward: -0.5140,                 loss: nan
agent1:                 episode reward: 0.5140,                 loss: 0.3387
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6667s / 319.2712 s
agent0:                 episode reward: -0.6506,                 loss: nan
agent1:                 episode reward: 0.6506,                 loss: 0.3448
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6487s / 319.9199 s
agent0:                 episode reward: -0.4023,                 loss: nan
agent1:                 episode reward: 0.4023,                 loss: 0.3482
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6543s / 320.5742 s
agent0:                 episode reward: -0.3939,                 loss: nan
agent1:                 episode reward: 0.3939,                 loss: 0.3506
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6460s / 321.2202 s
agent0:                 episode reward: -0.5302,                 loss: nan
agent1:                 episode reward: 0.5302,                 loss: 0.3499
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6522s / 321.8723 s
agent0:                 episode reward: -0.6135,                 loss: nan
agent1:                 episode reward: 0.6135,                 loss: 0.3471
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6535s / 322.5258 s
agent0:                 episode reward: -0.8926,                 loss: nan
agent1:                 episode reward: 0.8926,                 loss: 0.3516
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6482s / 323.1740 s
agent0:                 episode reward: -0.6840,                 loss: nan
agent1:                 episode reward: 0.6840,                 loss: 0.3492
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6470s / 323.8210 s
agent0:                 episode reward: -0.6292,                 loss: nan
agent1:                 episode reward: 0.6292,                 loss: 0.3484
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6493s / 324.4703 s
agent0:                 episode reward: -0.6639,                 loss: nan
agent1:                 episode reward: 0.6639,                 loss: 0.3518
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6567s / 325.1270 s
agent0:                 episode reward: -0.5333,                 loss: nan
agent1:                 episode reward: 0.5333,                 loss: 0.3493
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6501s / 325.7772 s
agent0:                 episode reward: -0.4143,                 loss: nan
agent1:                 episode reward: 0.4143,                 loss: 0.3473
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6536s / 326.4307 s
agent0:                 episode reward: -0.3027,                 loss: nan
agent1:                 episode reward: 0.3027,                 loss: 0.3478
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6564s / 327.0871 s
agent0:                 episode reward: -0.6090,                 loss: nan
agent1:                 episode reward: 0.6090,                 loss: 0.3480
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6485s / 327.7356 s
agent0:                 episode reward: -0.6559,                 loss: nan
agent1:                 episode reward: 0.6559,                 loss: 0.3471
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6495s / 328.3851 s
agent0:                 episode reward: -0.3175,                 loss: nan
agent1:                 episode reward: 0.3175,                 loss: 0.3508
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6594s / 329.0445 s
agent0:                 episode reward: -0.3243,                 loss: nan
agent1:                 episode reward: 0.3243,                 loss: 0.3461
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6634s / 329.7078 s
agent0:                 episode reward: -0.5641,                 loss: nan
agent1:                 episode reward: 0.5641,                 loss: 0.3475
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6527s / 330.3605 s
agent0:                 episode reward: -0.3480,                 loss: nan
agent1:                 episode reward: 0.3480,                 loss: 0.3473
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6581s / 331.0186 s
agent0:                 episode reward: -0.8421,                 loss: nan
agent1:                 episode reward: 0.8421,                 loss: 0.3413
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6605s / 331.6791 s
agent0:                 episode reward: -0.3126,                 loss: nan
agent1:                 episode reward: 0.3126,                 loss: 0.3464
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6527s / 332.3318 s
agent0:                 episode reward: -0.5730,                 loss: nan
agent1:                 episode reward: 0.5730,                 loss: 0.3458
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6555s / 332.9873 s
agent0:                 episode reward: -0.3417,                 loss: nan
agent1:                 episode reward: 0.3417,                 loss: 0.3438
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6561s / 333.6435 s
agent0:                 episode reward: -1.0297,                 loss: nan
agent1:                 episode reward: 1.0297,                 loss: 0.3456
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6481s / 334.2916 s
agent0:                 episode reward: -0.6137,                 loss: nan
agent1:                 episode reward: 0.6137,                 loss: 0.3480
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6518s / 334.9433 s
agent0:                 episode reward: -0.6681,                 loss: nan
agent1:                 episode reward: 0.6681,                 loss: 0.3438
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6538s / 335.5972 s
agent0:                 episode reward: -0.5542,                 loss: nan
agent1:                 episode reward: 0.5542,                 loss: 0.3471
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6502s / 336.2474 s
agent0:                 episode reward: -0.9038,                 loss: nan
agent1:                 episode reward: 0.9038,                 loss: 0.3440
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6554s / 336.9028 s
agent0:                 episode reward: -0.7538,                 loss: nan
agent1:                 episode reward: 0.7538,                 loss: 0.3457
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6519s / 337.5547 s
agent0:                 episode reward: -0.3710,                 loss: nan
agent1:                 episode reward: 0.3710,                 loss: 0.3463
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6553s / 338.2100 s
agent0:                 episode reward: -0.7154,                 loss: nan
agent1:                 episode reward: 0.7154,                 loss: 0.3471
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6616s / 338.8716 s
agent0:                 episode reward: -0.6955,                 loss: nan
agent1:                 episode reward: 0.6955,                 loss: 0.3459
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6510s / 339.5226 s
agent0:                 episode reward: -0.3669,                 loss: nan
agent1:                 episode reward: 0.3669,                 loss: 0.3446
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6705s / 340.1931 s
agent0:                 episode reward: -0.2448,                 loss: nan
agent1:                 episode reward: 0.2448,                 loss: 0.3438
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6626s / 340.8557 s
agent0:                 episode reward: -0.4996,                 loss: nan
agent1:                 episode reward: 0.4996,                 loss: 0.3474
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6594s / 341.5150 s
agent0:                 episode reward: -0.4524,                 loss: nan
agent1:                 episode reward: 0.4524,                 loss: 0.3471
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6645s / 342.1795 s
agent0:                 episode reward: -0.5595,                 loss: nan
agent1:                 episode reward: 0.5595,                 loss: 0.3439
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6588s / 342.8383 s
agent0:                 episode reward: -0.3135,                 loss: nan
agent1:                 episode reward: 0.3135,                 loss: 0.3435
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6568s / 343.4951 s
agent0:                 episode reward: -0.4564,                 loss: nan
agent1:                 episode reward: 0.4564,                 loss: 0.3476
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6584s / 344.1535 s
agent0:                 episode reward: -0.4132,                 loss: nan
agent1:                 episode reward: 0.4132,                 loss: 0.3469
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6535s / 344.8070 s
agent0:                 episode reward: -0.6406,                 loss: nan
agent1:                 episode reward: 0.6406,                 loss: 0.3460
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6578s / 345.4647 s
agent0:                 episode reward: -0.5850,                 loss: nan
agent1:                 episode reward: 0.5850,                 loss: 0.3451
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6616s / 346.1263 s
agent0:                 episode reward: -0.6170,                 loss: nan
agent1:                 episode reward: 0.6170,                 loss: 0.3467
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6731s / 346.7994 s
agent0:                 episode reward: -0.5325,                 loss: nan
agent1:                 episode reward: 0.5325,                 loss: 0.3463
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6591s / 347.4585 s
agent0:                 episode reward: -0.7042,                 loss: nan
agent1:                 episode reward: 0.7042,                 loss: 0.3441
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6606s / 348.1192 s
agent0:                 episode reward: -0.6179,                 loss: nan
agent1:                 episode reward: 0.6179,                 loss: 0.3438
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6637s / 348.7829 s
agent0:                 episode reward: -0.4467,                 loss: nan
agent1:                 episode reward: 0.4467,                 loss: 0.3449
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6567s / 349.4395 s
agent0:                 episode reward: -0.9782,                 loss: nan
agent1:                 episode reward: 0.9782,                 loss: 0.3474
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6754s / 350.1149 s
agent0:                 episode reward: -0.9090,                 loss: nan
agent1:                 episode reward: 0.9090,                 loss: 0.3426
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6642s / 350.7791 s
agent0:                 episode reward: -0.8394,                 loss: nan
agent1:                 episode reward: 0.8394,                 loss: 0.3452
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6542s / 351.4333 s
agent0:                 episode reward: -0.8712,                 loss: nan
agent1:                 episode reward: 0.8712,                 loss: 0.3483
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6544s / 352.0877 s
agent0:                 episode reward: -0.8877,                 loss: nan
agent1:                 episode reward: 0.8877,                 loss: 0.3509
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6554s / 352.7431 s
agent0:                 episode reward: -0.4835,                 loss: nan
agent1:                 episode reward: 0.4835,                 loss: 0.3555
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6619s / 353.4049 s
agent0:                 episode reward: -0.3804,                 loss: nan
agent1:                 episode reward: 0.3804,                 loss: 0.3540
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6614s / 354.0663 s
agent0:                 episode reward: -0.4561,                 loss: nan
agent1:                 episode reward: 0.4561,                 loss: 0.3535
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6585s / 354.7249 s
agent0:                 episode reward: -0.3998,                 loss: nan
agent1:                 episode reward: 0.3998,                 loss: 0.3539
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6531s / 355.3780 s
agent0:                 episode reward: -0.9435,                 loss: nan
agent1:                 episode reward: 0.9435,                 loss: 0.3548
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6650s / 356.0430 s
agent0:                 episode reward: -0.5422,                 loss: nan
agent1:                 episode reward: 0.5422,                 loss: 0.3528
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6546s / 356.6976 s
agent0:                 episode reward: -0.6477,                 loss: nan
agent1:                 episode reward: 0.6477,                 loss: 0.3553
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6633s / 357.3610 s
agent0:                 episode reward: -0.6367,                 loss: nan
agent1:                 episode reward: 0.6367,                 loss: 0.3561
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6728s / 358.0338 s
agent0:                 episode reward: -0.8822,                 loss: nan
agent1:                 episode reward: 0.8822,                 loss: 0.3528
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6666s / 358.7004 s
agent0:                 episode reward: -0.6083,                 loss: nan
agent1:                 episode reward: 0.6083,                 loss: 0.3546
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6712s / 359.3716 s
agent0:                 episode reward: -0.3336,                 loss: nan
agent1:                 episode reward: 0.3336,                 loss: 0.3515
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6776s / 360.0492 s
agent0:                 episode reward: -0.6717,                 loss: nan
agent1:                 episode reward: 0.6717,                 loss: 0.3513
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6757s / 360.7249 s
agent0:                 episode reward: -0.8608,                 loss: nan
agent1:                 episode reward: 0.8608,                 loss: 0.3527
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6797s / 361.4046 s
agent0:                 episode reward: -1.0021,                 loss: nan
agent1:                 episode reward: 1.0021,                 loss: 0.3550
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6708s / 362.0754 s
agent0:                 episode reward: -0.5725,                 loss: nan
agent1:                 episode reward: 0.5725,                 loss: 0.3553
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6745s / 362.7498 s
agent0:                 episode reward: -0.2638,                 loss: nan
agent1:                 episode reward: 0.2638,                 loss: 0.3518
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6712s / 363.4210 s
agent0:                 episode reward: -0.6308,                 loss: nan
agent1:                 episode reward: 0.6308,                 loss: 0.3369
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6689s / 364.0900 s
agent0:                 episode reward: -0.2831,                 loss: nan
agent1:                 episode reward: 0.2831,                 loss: 0.3321
Episode: 14061/30000 (46.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6577s / 364.7476 s
agent0:                 episode reward: -0.6027,                 loss: nan
agent1:                 episode reward: 0.6027,                 loss: 0.3352
Episode: 14081/30000 (46.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6664s / 365.4141 s
agent0:                 episode reward: -0.8891,                 loss: nan
agent1:                 episode reward: 0.8891,                 loss: 0.3378
Episode: 14101/30000 (47.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6624s / 366.0764 s
agent0:                 episode reward: -0.5565,                 loss: nan
agent1:                 episode reward: 0.5565,                 loss: 0.3342
Episode: 14121/30000 (47.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6681s / 366.7445 s
agent0:                 episode reward: -0.6763,                 loss: nan
agent1:                 episode reward: 0.6763,                 loss: 0.3320
Episode: 14141/30000 (47.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6661s / 367.4106 s
agent0:                 episode reward: -0.3439,                 loss: nan
agent1:                 episode reward: 0.3439,                 loss: 0.3325
Episode: 14161/30000 (47.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6673s / 368.0778 s
agent0:                 episode reward: -0.3772,                 loss: nan
agent1:                 episode reward: 0.3772,                 loss: 0.3351
Episode: 14181/30000 (47.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6715s / 368.7494 s
agent0:                 episode reward: -0.5744,                 loss: nan
agent1:                 episode reward: 0.5744,                 loss: 0.3337
Episode: 14201/30000 (47.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6625s / 369.4118 s
agent0:                 episode reward: -0.5048,                 loss: nan
agent1:                 episode reward: 0.5048,                 loss: 0.3357
Episode: 14221/30000 (47.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6616s / 370.0734 s
agent0:                 episode reward: -0.3506,                 loss: nan
agent1:                 episode reward: 0.3506,                 loss: 0.3329
Episode: 14241/30000 (47.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6718s / 370.7452 s
agent0:                 episode reward: -0.8854,                 loss: nan
agent1:                 episode reward: 0.8854,                 loss: 0.3311
Episode: 14261/30000 (47.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6692s / 371.4143 s
agent0:                 episode reward: -0.5933,                 loss: nan
agent1:                 episode reward: 0.5933,                 loss: 0.3333
Episode: 14281/30000 (47.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6805s / 372.0949 s
agent0:                 episode reward: -0.4337,                 loss: nan
agent1:                 episode reward: 0.4337,                 loss: 0.3312
Episode: 14301/30000 (47.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6753s / 372.7702 s
agent0:                 episode reward: -0.7042,                 loss: nan
agent1:                 episode reward: 0.7042,                 loss: 0.3350
Episode: 14321/30000 (47.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6683s / 373.4385 s
agent0:                 episode reward: -0.9857,                 loss: nan
agent1:                 episode reward: 0.9857,                 loss: 0.3320
Episode: 14341/30000 (47.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6823s / 374.1207 s
agent0:                 episode reward: -0.5711,                 loss: nan
agent1:                 episode reward: 0.5711,                 loss: 0.3404
Episode: 14361/30000 (47.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6791s / 374.7998 s
agent0:                 episode reward: -0.5050,                 loss: nan
agent1:                 episode reward: 0.5050,                 loss: 0.3538
Episode: 14381/30000 (47.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6724s / 375.4722 s
agent0:                 episode reward: -0.5006,                 loss: nan
agent1:                 episode reward: 0.5006,                 loss: 0.3581
Episode: 14401/30000 (48.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6734s / 376.1456 s
agent0:                 episode reward: -0.5004,                 loss: nan
agent1:                 episode reward: 0.5004,                 loss: 0.3550
Episode: 14421/30000 (48.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6811s / 376.8267 s
agent0:                 episode reward: -0.7857,                 loss: nan
agent1:                 episode reward: 0.7857,                 loss: 0.3563
Episode: 14441/30000 (48.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6776s / 377.5043 s
agent0:                 episode reward: -0.9438,                 loss: nan
agent1:                 episode reward: 0.9438,                 loss: 0.3549
Episode: 14461/30000 (48.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6899s / 378.1942 s
agent0:                 episode reward: -0.5552,                 loss: nan
agent1:                 episode reward: 0.5552,                 loss: 0.3537
Episode: 14481/30000 (48.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6792s / 378.8734 s
agent0:                 episode reward: -0.5700,                 loss: nan
agent1:                 episode reward: 0.5700,                 loss: 0.3563
Episode: 14501/30000 (48.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6797s / 379.5531 s
agent0:                 episode reward: -0.5440,                 loss: nan
agent1:                 episode reward: 0.5440,                 loss: 0.3516
Episode: 14521/30000 (48.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6773s / 380.2305 s
agent0:                 episode reward: -0.7796,                 loss: nan
agent1:                 episode reward: 0.7796,                 loss: 0.3568
Episode: 14541/30000 (48.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6746s / 380.9050 s
agent0:                 episode reward: -0.6388,                 loss: nan
agent1:                 episode reward: 0.6388,                 loss: 0.3553
Episode: 14561/30000 (48.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6822s / 381.5872 s
agent0:                 episode reward: -0.4174,                 loss: nan
agent1:                 episode reward: 0.4174,                 loss: 0.3538
Episode: 14581/30000 (48.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6759s / 382.2631 s
agent0:                 episode reward: -0.3632,                 loss: nan
agent1:                 episode reward: 0.3632,                 loss: 0.3527
Episode: 14601/30000 (48.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6790s / 382.9421 s
agent0:                 episode reward: -0.5134,                 loss: nan
agent1:                 episode reward: 0.5134,                 loss: 0.3561
Episode: 14621/30000 (48.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6918s / 383.6340 s
agent0:                 episode reward: -0.6921,                 loss: nan
agent1:                 episode reward: 0.6921,                 loss: 0.3551
Episode: 14641/30000 (48.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6774s / 384.3113 s
agent0:                 episode reward: -0.4098,                 loss: nan
agent1:                 episode reward: 0.4098,                 loss: 0.3589
Episode: 14661/30000 (48.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6821s / 384.9935 s
agent0:                 episode reward: -0.6257,                 loss: nan
agent1:                 episode reward: 0.6257,                 loss: 0.3571
Episode: 14681/30000 (48.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6780s / 385.6715 s
agent0:                 episode reward: -0.6282,                 loss: nan
agent1:                 episode reward: 0.6282,                 loss: 0.3548
Episode: 14701/30000 (49.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6858s / 386.3572 s
agent0:                 episode reward: -0.3570,                 loss: nan
agent1:                 episode reward: 0.3570,                 loss: 0.3512
Episode: 14721/30000 (49.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6829s / 387.0401 s
agent0:                 episode reward: -0.3528,                 loss: nan
agent1:                 episode reward: 0.3528,                 loss: 0.3530
Episode: 14741/30000 (49.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6779s / 387.7180 s
agent0:                 episode reward: -0.4939,                 loss: nan
agent1:                 episode reward: 0.4939,                 loss: 0.3519
Episode: 14761/30000 (49.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6793s / 388.3974 s
agent0:                 episode reward: -0.3375,                 loss: nan
agent1:                 episode reward: 0.3375,                 loss: 0.3514
Episode: 14781/30000 (49.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6788s / 389.0762 s
agent0:                 episode reward: -0.6583,                 loss: nan
agent1:                 episode reward: 0.6583,                 loss: 0.3533
Episode: 14801/30000 (49.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6810s / 389.7571 s
agent0:                 episode reward: -0.3084,                 loss: nan
agent1:                 episode reward: 0.3084,                 loss: 0.3495
Episode: 14821/30000 (49.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6869s / 390.4441 s
agent0:                 episode reward: -0.6161,                 loss: nan
agent1:                 episode reward: 0.6161,                 loss: 0.3514
Episode: 14841/30000 (49.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6765s / 391.1205 s
agent0:                 episode reward: -0.6721,                 loss: nan
agent1:                 episode reward: 0.6721,                 loss: 0.3502
Episode: 14861/30000 (49.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6909s / 391.8114 s
agent0:                 episode reward: -0.8136,                 loss: nan
agent1:                 episode reward: 0.8136,                 loss: 0.3521
Episode: 14881/30000 (49.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6769s / 392.4883 s
agent0:                 episode reward: -0.6626,                 loss: nan
agent1:                 episode reward: 0.6626,                 loss: 0.3480
Episode: 14901/30000 (49.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6761s / 393.1644 s
agent0:                 episode reward: -0.6398,                 loss: nan
agent1:                 episode reward: 0.6398,                 loss: 0.3514
Episode: 14921/30000 (49.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6681s / 393.8326 s
agent0:                 episode reward: -0.5818,                 loss: nan
agent1:                 episode reward: 0.5818,                 loss: 0.3512
Episode: 14941/30000 (49.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6642s / 394.4968 s
agent0:                 episode reward: -0.9155,                 loss: nan
agent1:                 episode reward: 0.9155,                 loss: 0.3537
Episode: 14961/30000 (49.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6713s / 395.1681 s
agent0:                 episode reward: -0.5618,                 loss: nan
agent1:                 episode reward: 0.5618,                 loss: 0.3520
Episode: 14981/30000 (49.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6922s / 395.8603 s
agent0:                 episode reward: -0.6939,                 loss: nan
agent1:                 episode reward: 0.6939,                 loss: 0.3524
Episode: 15001/30000 (50.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6765s / 396.5369 s
agent0:                 episode reward: -0.6635,                 loss: nan
agent1:                 episode reward: 0.6635,                 loss: 0.3532
Episode: 15021/30000 (50.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6937s / 397.2305 s
agent0:                 episode reward: -0.4744,                 loss: nan
agent1:                 episode reward: 0.4744,                 loss: 0.3293
Episode: 15041/30000 (50.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6868s / 397.9173 s
agent0:                 episode reward: -0.3661,                 loss: nan
agent1:                 episode reward: 0.3661,                 loss: 0.3246
Episode: 15061/30000 (50.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6866s / 398.6039 s
agent0:                 episode reward: -1.0825,                 loss: nan
agent1:                 episode reward: 1.0825,                 loss: 0.3276
Episode: 15081/30000 (50.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6807s / 399.2846 s
agent0:                 episode reward: -0.8655,                 loss: nan
agent1:                 episode reward: 0.8655,                 loss: 0.3243
Episode: 15101/30000 (50.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6799s / 399.9645 s
agent0:                 episode reward: -0.4280,                 loss: nan
agent1:                 episode reward: 0.4280,                 loss: 0.3274
Episode: 15121/30000 (50.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6737s / 400.6381 s
agent0:                 episode reward: -0.6428,                 loss: nan
agent1:                 episode reward: 0.6428,                 loss: 0.3266
Episode: 15141/30000 (50.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6781s / 401.3163 s
agent0:                 episode reward: -0.9027,                 loss: nan
agent1:                 episode reward: 0.9027,                 loss: 0.3289
Episode: 15161/30000 (50.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6791s / 401.9954 s
agent0:                 episode reward: -0.6678,                 loss: nan
agent1:                 episode reward: 0.6678,                 loss: 0.3277
Episode: 15181/30000 (50.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6829s / 402.6784 s
agent0:                 episode reward: -0.8371,                 loss: nan
agent1:                 episode reward: 0.8371,                 loss: 0.3255
Episode: 15201/30000 (50.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6803s / 403.3586 s
agent0:                 episode reward: -1.0279,                 loss: nan
agent1:                 episode reward: 1.0279,                 loss: 0.3255
Episode: 15221/30000 (50.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6810s / 404.0396 s
agent0:                 episode reward: -0.6966,                 loss: nan
agent1:                 episode reward: 0.6966,                 loss: 0.3269
Episode: 15241/30000 (50.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6916s / 404.7312 s
agent0:                 episode reward: -0.5242,                 loss: nan
agent1:                 episode reward: 0.5242,                 loss: 0.3257
Episode: 15261/30000 (50.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6817s / 405.4129 s
agent0:                 episode reward: -0.4850,                 loss: nan
agent1:                 episode reward: 0.4850,                 loss: 0.3272
Episode: 15281/30000 (50.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6851s / 406.0979 s
agent0:                 episode reward: -0.9537,                 loss: nan
agent1:                 episode reward: 0.9537,                 loss: 0.3270
Episode: 15301/30000 (51.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6823s / 406.7803 s
agent0:                 episode reward: -0.5113,                 loss: nan
agent1:                 episode reward: 0.5113,                 loss: 0.3274
Episode: 15321/30000 (51.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6764s / 407.4567 s
agent0:                 episode reward: -0.5281,                 loss: nan
agent1:                 episode reward: 0.5281,                 loss: 0.3283
Episode: 15341/30000 (51.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6840s / 408.1407 s
agent0:                 episode reward: -0.6404,                 loss: nan
agent1:                 episode reward: 0.6404,                 loss: 0.3339
Episode: 15361/30000 (51.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6926s / 408.8332 s
agent0:                 episode reward: -0.6277,                 loss: nan
agent1:                 episode reward: 0.6277,                 loss: 0.3506
Episode: 15381/30000 (51.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6781s / 409.5113 s
agent0:                 episode reward: -0.5777,                 loss: nan
agent1:                 episode reward: 0.5777,                 loss: 0.3488
Episode: 15401/30000 (51.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6771s / 410.1884 s
agent0:                 episode reward: -0.3166,                 loss: nan
agent1:                 episode reward: 0.3166,                 loss: 0.3497
Episode: 15421/30000 (51.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6869s / 410.8753 s
agent0:                 episode reward: -0.1057,                 loss: nan
agent1:                 episode reward: 0.1057,                 loss: 0.3522
Episode: 15441/30000 (51.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6794s / 411.5546 s
agent0:                 episode reward: -0.8741,                 loss: nan
agent1:                 episode reward: 0.8741,                 loss: 0.3519
Episode: 15461/30000 (51.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6840s / 412.2386 s
agent0:                 episode reward: -0.3838,                 loss: nan
agent1:                 episode reward: 0.3838,                 loss: 0.3504
Episode: 15481/30000 (51.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6826s / 412.9212 s
agent0:                 episode reward: -0.7975,                 loss: nan
agent1:                 episode reward: 0.7975,                 loss: 0.3516
Episode: 15501/30000 (51.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6825s / 413.6037 s
agent0:                 episode reward: -0.7507,                 loss: nan
agent1:                 episode reward: 0.7507,                 loss: 0.3505
Episode: 15521/30000 (51.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6830s / 414.2868 s
agent0:                 episode reward: -0.2924,                 loss: nan
agent1:                 episode reward: 0.2924,                 loss: 0.3519
Episode: 15541/30000 (51.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6882s / 414.9750 s
agent0:                 episode reward: -0.5685,                 loss: nan
agent1:                 episode reward: 0.5685,                 loss: 0.3513
Episode: 15561/30000 (51.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6792s / 415.6542 s
agent0:                 episode reward: -0.4067,                 loss: nan
agent1:                 episode reward: 0.4067,                 loss: 0.3498
Episode: 15581/30000 (51.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6843s / 416.3385 s
agent0:                 episode reward: -0.4526,                 loss: nan
agent1:                 episode reward: 0.4526,                 loss: 0.3464
Episode: 15601/30000 (52.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6848s / 417.0233 s
agent0:                 episode reward: -0.6872,                 loss: nan
agent1:                 episode reward: 0.6872,                 loss: 0.3513
Episode: 15621/30000 (52.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6875s / 417.7107 s
agent0:                 episode reward: -0.4768,                 loss: nan
agent1:                 episode reward: 0.4768,                 loss: 0.3530
Episode: 15641/30000 (52.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6949s / 418.4056 s
agent0:                 episode reward: -0.7180,                 loss: nan
agent1:                 episode reward: 0.7180,                 loss: 0.3507
Episode: 15661/30000 (52.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6832s / 419.0889 s
agent0:                 episode reward: -0.6734,                 loss: nan
agent1:                 episode reward: 0.6734,                 loss: 0.3497
Episode: 15681/30000 (52.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7013s / 419.7902 s
agent0:                 episode reward: -0.6205,                 loss: nan
agent1:                 episode reward: 0.6205,                 loss: 0.3449
Episode: 15701/30000 (52.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6801s / 420.4703 s
agent0:                 episode reward: -0.5553,                 loss: nan
agent1:                 episode reward: 0.5553,                 loss: 0.3480
Episode: 15721/30000 (52.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6902s / 421.1605 s
agent0:                 episode reward: -0.8032,                 loss: nan
agent1:                 episode reward: 0.8032,                 loss: 0.3472
Episode: 15741/30000 (52.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6841s / 421.8446 s
agent0:                 episode reward: -0.8199,                 loss: nan
agent1:                 episode reward: 0.8199,                 loss: 0.3466
Episode: 15761/30000 (52.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6860s / 422.5306 s
agent0:                 episode reward: -0.5190,                 loss: nan
agent1:                 episode reward: 0.5190,                 loss: 0.3445
Episode: 15781/30000 (52.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6903s / 423.2208 s
agent0:                 episode reward: -0.4476,                 loss: nan
agent1:                 episode reward: 0.4476,                 loss: 0.3483
Episode: 15801/30000 (52.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6794s / 423.9002 s
agent0:                 episode reward: -0.2855,                 loss: nan
agent1:                 episode reward: 0.2855,                 loss: 0.3453
Episode: 15821/30000 (52.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6775s / 424.5777 s
agent0:                 episode reward: -0.4154,                 loss: nan
agent1:                 episode reward: 0.4154,                 loss: 0.3472
Episode: 15841/30000 (52.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6857s / 425.2633 s
agent0:                 episode reward: -0.1495,                 loss: nan
agent1:                 episode reward: 0.1495,                 loss: 0.3453
Episode: 15861/30000 (52.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7001s / 425.9634 s
agent0:                 episode reward: -0.6653,                 loss: nan
agent1:                 episode reward: 0.6653,                 loss: 0.3464
Episode: 15881/30000 (52.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6844s / 426.6478 s
agent0:                 episode reward: -0.5372,                 loss: nan
agent1:                 episode reward: 0.5372,                 loss: 0.3483
Episode: 15901/30000 (53.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6876s / 427.3354 s
agent0:                 episode reward: -0.8518,                 loss: nan
agent1:                 episode reward: 0.8518,                 loss: 0.3455
Episode: 15921/30000 (53.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6810s / 428.0163 s
agent0:                 episode reward: -0.7295,                 loss: nan
agent1:                 episode reward: 0.7295,                 loss: 0.3485
Episode: 15941/30000 (53.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6848s / 428.7011 s
agent0:                 episode reward: -0.6268,                 loss: nan
agent1:                 episode reward: 0.6268,                 loss: 0.3492
Episode: 15961/30000 (53.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6819s / 429.3831 s
agent0:                 episode reward: -0.6691,                 loss: nan
agent1:                 episode reward: 0.6691,                 loss: 0.3457
Episode: 15981/30000 (53.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6853s / 430.0684 s
agent0:                 episode reward: -0.6788,                 loss: nan
agent1:                 episode reward: 0.6788,                 loss: 0.3465
Episode: 16001/30000 (53.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6924s / 430.7609 s
agent0:                 episode reward: -0.5895,                 loss: nan
agent1:                 episode reward: 0.5895,                 loss: 0.3481
Episode: 16021/30000 (53.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6951s / 431.4560 s
agent0:                 episode reward: -0.4427,                 loss: nan
agent1:                 episode reward: 0.4427,                 loss: 0.3344
Episode: 16041/30000 (53.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6804s / 432.1364 s
agent0:                 episode reward: -0.6042,                 loss: nan
agent1:                 episode reward: 0.6042,                 loss: 0.3383
Episode: 16061/30000 (53.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7045s / 432.8410 s
agent0:                 episode reward: -0.7921,                 loss: nan
agent1:                 episode reward: 0.7921,                 loss: 0.3365
Episode: 16081/30000 (53.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7007s / 433.5416 s
agent0:                 episode reward: -0.7150,                 loss: nan
agent1:                 episode reward: 0.7150,                 loss: 0.3389
Episode: 16101/30000 (53.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7017s / 434.2433 s
agent0:                 episode reward: -0.5563,                 loss: nan
agent1:                 episode reward: 0.5563,                 loss: 0.3368
Episode: 16121/30000 (53.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6934s / 434.9367 s
agent0:                 episode reward: -0.5709,                 loss: nan
agent1:                 episode reward: 0.5709,                 loss: 0.3373
Episode: 16141/30000 (53.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6881s / 435.6247 s
agent0:                 episode reward: -0.7722,                 loss: nan
agent1:                 episode reward: 0.7722,                 loss: 0.3389
Episode: 16161/30000 (53.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6947s / 436.3194 s
agent0:                 episode reward: -0.5423,                 loss: nan
agent1:                 episode reward: 0.5423,                 loss: 0.3373
Episode: 16181/30000 (53.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6949s / 437.0144 s
agent0:                 episode reward: -0.8655,                 loss: nan
agent1:                 episode reward: 0.8655,                 loss: 0.3372
Episode: 16201/30000 (54.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7030s / 437.7173 s
agent0:                 episode reward: -0.3530,                 loss: nan
agent1:                 episode reward: 0.3530,                 loss: 0.3358
Episode: 16221/30000 (54.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6967s / 438.4140 s
agent0:                 episode reward: -0.5519,                 loss: nan
agent1:                 episode reward: 0.5519,                 loss: 0.3352
Episode: 16241/30000 (54.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6944s / 439.1085 s
agent0:                 episode reward: -0.6074,                 loss: nan
agent1:                 episode reward: 0.6074,                 loss: 0.3381
Episode: 16261/30000 (54.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6957s / 439.8041 s
agent0:                 episode reward: -0.8259,                 loss: nan
agent1:                 episode reward: 0.8259,                 loss: 0.3397
Episode: 16281/30000 (54.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6856s / 440.4898 s
agent0:                 episode reward: -0.4820,                 loss: nan
agent1:                 episode reward: 0.4820,                 loss: 0.3389
Episode: 16301/30000 (54.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6819s / 441.1716 s
agent0:                 episode reward: -0.9129,                 loss: nan
agent1:                 episode reward: 0.9129,                 loss: 0.3377
Episode: 16321/30000 (54.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7105s / 441.8822 s
agent0:                 episode reward: -0.7037,                 loss: nan
agent1:                 episode reward: 0.7037,                 loss: 0.3386
Episode: 16341/30000 (54.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7182s / 442.6003 s
agent0:                 episode reward: -0.7442,                 loss: nan
agent1:                 episode reward: 0.7442,                 loss: 0.3424
Episode: 16361/30000 (54.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6945s / 443.2948 s
agent0:                 episode reward: -0.7966,                 loss: nan
agent1:                 episode reward: 0.7966,                 loss: 0.3505
Episode: 16381/30000 (54.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6961s / 443.9909 s
agent0:                 episode reward: -0.2901,                 loss: nan
agent1:                 episode reward: 0.2901,                 loss: 0.3510
Episode: 16401/30000 (54.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6948s / 444.6857 s
agent0:                 episode reward: -0.4186,                 loss: nan
agent1:                 episode reward: 0.4186,                 loss: 0.3531
Episode: 16421/30000 (54.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6935s / 445.3792 s
agent0:                 episode reward: -0.4410,                 loss: nan
agent1:                 episode reward: 0.4410,                 loss: 0.3537
Episode: 16441/30000 (54.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6958s / 446.0750 s
agent0:                 episode reward: -0.5041,                 loss: nan
agent1:                 episode reward: 0.5041,                 loss: 0.3529
Episode: 16461/30000 (54.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6945s / 446.7695 s
agent0:                 episode reward: -0.7330,                 loss: nan
agent1:                 episode reward: 0.7330,                 loss: 0.3501
Episode: 16481/30000 (54.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7032s / 447.4727 s
agent0:                 episode reward: -0.6961,                 loss: nan
agent1:                 episode reward: 0.6961,                 loss: 0.3503
Episode: 16501/30000 (55.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6998s / 448.1725 s
agent0:                 episode reward: -0.9133,                 loss: nan
agent1:                 episode reward: 0.9133,                 loss: 0.3511
Episode: 16521/30000 (55.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6983s / 448.8709 s
agent0:                 episode reward: -0.5704,                 loss: nan
agent1:                 episode reward: 0.5704,                 loss: 0.3535
Episode: 16541/30000 (55.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6902s / 449.5610 s
agent0:                 episode reward: -0.8506,                 loss: nan
agent1:                 episode reward: 0.8506,                 loss: 0.3510
Episode: 16561/30000 (55.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7038s / 450.2648 s
agent0:                 episode reward: -0.5337,                 loss: nan
agent1:                 episode reward: 0.5337,                 loss: 0.3502
Episode: 16581/30000 (55.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6959s / 450.9607 s
agent0:                 episode reward: -0.6079,                 loss: nan
agent1:                 episode reward: 0.6079,                 loss: 0.3524
Episode: 16601/30000 (55.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6999s / 451.6606 s
agent0:                 episode reward: -0.4887,                 loss: nan
agent1:                 episode reward: 0.4887,                 loss: 0.3534
Episode: 16621/30000 (55.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7015s / 452.3621 s
agent0:                 episode reward: -0.7213,                 loss: nan
agent1:                 episode reward: 0.7213,                 loss: 0.3530
Episode: 16641/30000 (55.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6959s / 453.0580 s
agent0:                 episode reward: -0.8081,                 loss: nan
agent1:                 episode reward: 0.8081,                 loss: 0.3538
Episode: 16661/30000 (55.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6981s / 453.7561 s
agent0:                 episode reward: -0.0802,                 loss: nan
agent1:                 episode reward: 0.0802,                 loss: 0.3529
Episode: 16681/30000 (55.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7037s / 454.4598 s
agent0:                 episode reward: -0.8593,                 loss: nan
agent1:                 episode reward: 0.8593,                 loss: 0.3444
Episode: 16701/30000 (55.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6992s / 455.1591 s
agent0:                 episode reward: -0.5812,                 loss: nan
agent1:                 episode reward: 0.5812,                 loss: 0.3438
Episode: 16721/30000 (55.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7057s / 455.8647 s
agent0:                 episode reward: -0.5432,                 loss: nan
agent1:                 episode reward: 0.5432,                 loss: 0.3420
Episode: 16741/30000 (55.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7024s / 456.5671 s
agent0:                 episode reward: -0.8851,                 loss: nan
agent1:                 episode reward: 0.8851,                 loss: 0.3425
Episode: 16761/30000 (55.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7054s / 457.2726 s
agent0:                 episode reward: -0.3668,                 loss: nan
agent1:                 episode reward: 0.3668,                 loss: 0.3428
Episode: 16781/30000 (55.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6966s / 457.9692 s
agent0:                 episode reward: -0.4767,                 loss: nan
agent1:                 episode reward: 0.4767,                 loss: 0.3398
Episode: 16801/30000 (56.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6992s / 458.6684 s
agent0:                 episode reward: -0.5736,                 loss: nan
agent1:                 episode reward: 0.5736,                 loss: 0.3420
Episode: 16821/30000 (56.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7064s / 459.3748 s
agent0:                 episode reward: -0.7765,                 loss: nan
agent1:                 episode reward: 0.7765,                 loss: 0.3427
Episode: 16841/30000 (56.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7126s / 460.0874 s
agent0:                 episode reward: -0.7362,                 loss: nan
agent1:                 episode reward: 0.7362,                 loss: 0.3415
Episode: 16861/30000 (56.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7001s / 460.7875 s
agent0:                 episode reward: -0.7563,                 loss: nan
agent1:                 episode reward: 0.7563,                 loss: 0.3377
Episode: 16881/30000 (56.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7060s / 461.4934 s
agent0:                 episode reward: -0.4616,                 loss: nan
agent1:                 episode reward: 0.4616,                 loss: 0.3419
Episode: 16901/30000 (56.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7034s / 462.1968 s
agent0:                 episode reward: -0.4486,                 loss: nan
agent1:                 episode reward: 0.4486,                 loss: 0.3449
Episode: 16921/30000 (56.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7164s / 462.9132 s
agent0:                 episode reward: -0.3527,                 loss: nan
agent1:                 episode reward: 0.3527,                 loss: 0.3444
Episode: 16941/30000 (56.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7052s / 463.6184 s
agent0:                 episode reward: -0.6417,                 loss: nan
agent1:                 episode reward: 0.6417,                 loss: 0.3414
Episode: 16961/30000 (56.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7129s / 464.3313 s
agent0:                 episode reward: -0.6043,                 loss: nan
agent1:                 episode reward: 0.6043,                 loss: 0.3378
Episode: 16981/30000 (56.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7051s / 465.0364 s
agent0:                 episode reward: -0.2341,                 loss: nan
agent1:                 episode reward: 0.2341,                 loss: 0.3438
Episode: 17001/30000 (56.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7092s / 465.7456 s
agent0:                 episode reward: -0.1963,                 loss: nan
agent1:                 episode reward: 0.1963,                 loss: 0.3432
Episode: 17021/30000 (56.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7067s / 466.4523 s
agent0:                 episode reward: -0.5400,                 loss: nan
agent1:                 episode reward: 0.5400,                 loss: 0.3445
Episode: 17041/30000 (56.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7206s / 467.1729 s
agent0:                 episode reward: -0.6029,                 loss: nan
agent1:                 episode reward: 0.6029,                 loss: 0.3436
Episode: 17061/30000 (56.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7085s / 467.8814 s
agent0:                 episode reward: -0.3869,                 loss: nan
agent1:                 episode reward: 0.3869,                 loss: 0.3481
Episode: 17081/30000 (56.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7199s / 468.6013 s
agent0:                 episode reward: -0.4214,                 loss: nan
agent1:                 episode reward: 0.4214,                 loss: 0.3428
Episode: 17101/30000 (57.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7087s / 469.3100 s
agent0:                 episode reward: -0.8131,                 loss: nan
agent1:                 episode reward: 0.8131,                 loss: 0.3460
Episode: 17121/30000 (57.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7152s / 470.0251 s
agent0:                 episode reward: -0.3980,                 loss: nan
agent1:                 episode reward: 0.3980,                 loss: 0.3477
Episode: 17141/30000 (57.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7069s / 470.7320 s
agent0:                 episode reward: -0.7112,                 loss: nan
agent1:                 episode reward: 0.7112,                 loss: 0.3415
Episode: 17161/30000 (57.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7042s / 471.4362 s
agent0:                 episode reward: -0.7318,                 loss: nan
agent1:                 episode reward: 0.7318,                 loss: 0.3432
Episode: 17181/30000 (57.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7003s / 472.1365 s
agent0:                 episode reward: -0.4983,                 loss: nan
agent1:                 episode reward: 0.4983,                 loss: 0.3423
Episode: 17201/30000 (57.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7155s / 472.8520 s
agent0:                 episode reward: -0.6443,                 loss: nan
agent1:                 episode reward: 0.6443,                 loss: 0.3430
Episode: 17221/30000 (57.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7142s / 473.5662 s
agent0:                 episode reward: -0.4549,                 loss: nan
agent1:                 episode reward: 0.4549,                 loss: 0.3449
Episode: 17241/30000 (57.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7063s / 474.2726 s
agent0:                 episode reward: -0.3906,                 loss: nan
agent1:                 episode reward: 0.3906,                 loss: 0.3449
Episode: 17261/30000 (57.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7174s / 474.9899 s
agent0:                 episode reward: -0.8092,                 loss: nan
agent1:                 episode reward: 0.8092,                 loss: 0.3461
Episode: 17281/30000 (57.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7026s / 475.6925 s
agent0:                 episode reward: -0.9185,                 loss: nan
agent1:                 episode reward: 0.9185,                 loss: 0.3440
Episode: 17301/30000 (57.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7099s / 476.4024 s
agent0:                 episode reward: -0.9327,                 loss: nan
agent1:                 episode reward: 0.9327,                 loss: 0.3428
Episode: 17321/30000 (57.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7049s / 477.1073 s
agent0:                 episode reward: -0.5861,                 loss: nan
agent1:                 episode reward: 0.5861,                 loss: 0.3426
Episode: 17341/30000 (57.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7142s / 477.8215 s
agent0:                 episode reward: -0.4089,                 loss: nan
agent1:                 episode reward: 0.4089,                 loss: 0.3441
Episode: 17361/30000 (57.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7126s / 478.5341 s
agent0:                 episode reward: -0.5318,                 loss: nan
agent1:                 episode reward: 0.5318,                 loss: 0.3485
Episode: 17381/30000 (57.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7117s / 479.2458 s
agent0:                 episode reward: -0.6439,                 loss: nan
agent1:                 episode reward: 0.6439,                 loss: 0.3461
Episode: 17401/30000 (58.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7122s / 479.9580 s
agent0:                 episode reward: -0.4816,                 loss: nan
agent1:                 episode reward: 0.4816,                 loss: 0.3460
Episode: 17421/30000 (58.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7109s / 480.6689 s
agent0:                 episode reward: -0.6342,                 loss: nan
agent1:                 episode reward: 0.6342,                 loss: 0.3468
Episode: 17441/30000 (58.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7066s / 481.3754 s
agent0:                 episode reward: -0.3787,                 loss: nan
agent1:                 episode reward: 0.3787,                 loss: 0.3448
Episode: 17461/30000 (58.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7060s / 482.0814 s
agent0:                 episode reward: -0.7671,                 loss: nan
agent1:                 episode reward: 0.7671,                 loss: 0.3493
Episode: 17481/30000 (58.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7087s / 482.7901 s
agent0:                 episode reward: -0.7945,                 loss: nan
agent1:                 episode reward: 0.7945,                 loss: 0.3435
Episode: 17501/30000 (58.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7093s / 483.4994 s
agent0:                 episode reward: -0.7598,                 loss: nan
agent1:                 episode reward: 0.7598,                 loss: 0.3462
Episode: 17521/30000 (58.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7097s / 484.2091 s
agent0:                 episode reward: -0.6549,                 loss: nan
agent1:                 episode reward: 0.6549,                 loss: 0.3451
Episode: 17541/30000 (58.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7160s / 484.9251 s
agent0:                 episode reward: -0.5178,                 loss: nan
agent1:                 episode reward: 0.5178,                 loss: 0.3478
Episode: 17561/30000 (58.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7145s / 485.6396 s
agent0:                 episode reward: -0.6350,                 loss: nan
agent1:                 episode reward: 0.6350,                 loss: 0.3482
Episode: 17581/30000 (58.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7133s / 486.3529 s
agent0:                 episode reward: -0.8974,                 loss: nan
agent1:                 episode reward: 0.8974,                 loss: 0.3463
Episode: 17601/30000 (58.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7261s / 487.0790 s
agent0:                 episode reward: -0.0212,                 loss: nan
agent1:                 episode reward: 0.0212,                 loss: 0.3471
Episode: 17621/30000 (58.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7226s / 487.8016 s
agent0:                 episode reward: -0.6639,                 loss: nan
agent1:                 episode reward: 0.6639,                 loss: 0.3434
Episode: 17641/30000 (58.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7165s / 488.5181 s
agent0:                 episode reward: -0.7804,                 loss: nan
agent1:                 episode reward: 0.7804,                 loss: 0.3451
Episode: 17661/30000 (58.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7163s / 489.2344 s
agent0:                 episode reward: -0.5277,                 loss: nan
agent1:                 episode reward: 0.5277,                 loss: 0.3444
Episode: 17681/30000 (58.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7121s / 489.9465 s
agent0:                 episode reward: -0.8766,                 loss: nan
agent1:                 episode reward: 0.8766,                 loss: 0.3518
Episode: 17701/30000 (59.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7167s / 490.6632 s
agent0:                 episode reward: -0.5082,                 loss: nan
agent1:                 episode reward: 0.5082,                 loss: 0.3463
Episode: 17721/30000 (59.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7166s / 491.3798 s
agent0:                 episode reward: -0.4903,                 loss: nan
agent1:                 episode reward: 0.4903,                 loss: 0.3468
Episode: 17741/30000 (59.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7136s / 492.0933 s
agent0:                 episode reward: 0.0718,                 loss: nan
agent1:                 episode reward: -0.0718,                 loss: 0.3496
Episode: 17761/30000 (59.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7197s / 492.8131 s
agent0:                 episode reward: -0.8345,                 loss: nan
agent1:                 episode reward: 0.8345,                 loss: 0.3482
Episode: 17781/30000 (59.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7225s / 493.5356 s
agent0:                 episode reward: -0.6341,                 loss: nan
agent1:                 episode reward: 0.6341,                 loss: 0.3468
Episode: 17801/30000 (59.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7259s / 494.2615 s
agent0:                 episode reward: -0.6158,                 loss: nan
agent1:                 episode reward: 0.6158,                 loss: 0.3467
Episode: 17821/30000 (59.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7217s / 494.9832 s
agent0:                 episode reward: -0.3660,                 loss: nan
agent1:                 episode reward: 0.3660,                 loss: 0.3461
Episode: 17841/30000 (59.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7138s / 495.6971 s
agent0:                 episode reward: -0.4062,                 loss: nan
agent1:                 episode reward: 0.4062,                 loss: 0.3478
Episode: 17861/30000 (59.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7160s / 496.4131 s
agent0:                 episode reward: -0.5336,                 loss: nan
agent1:                 episode reward: 0.5336,                 loss: 0.3501
Episode: 17881/30000 (59.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7229s / 497.1360 s
agent0:                 episode reward: -0.6311,                 loss: nan
agent1:                 episode reward: 0.6311,                 loss: 0.3464
Episode: 17901/30000 (59.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7192s / 497.8552 s
agent0:                 episode reward: -0.4917,                 loss: nan
agent1:                 episode reward: 0.4917,                 loss: 0.3487
Episode: 17921/30000 (59.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7203s / 498.5756 s
agent0:                 episode reward: -0.8183,                 loss: nan
agent1:                 episode reward: 0.8183,                 loss: 0.3497
Episode: 17941/30000 (59.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7216s / 499.2971 s
agent0:                 episode reward: -0.7037,                 loss: nan
agent1:                 episode reward: 0.7037,                 loss: 0.3503
Episode: 17961/30000 (59.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7273s / 500.0245 s
agent0:                 episode reward: -0.9301,                 loss: nan
agent1:                 episode reward: 0.9301,                 loss: 0.3478
Episode: 17981/30000 (59.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7224s / 500.7469 s
agent0:                 episode reward: -0.8153,                 loss: nan
agent1:                 episode reward: 0.8153,                 loss: 0.3505
Episode: 18001/30000 (60.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7312s / 501.4781 s
agent0:                 episode reward: -0.5116,                 loss: nan
agent1:                 episode reward: 0.5116,                 loss: 0.3475
Episode: 18021/30000 (60.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7240s / 502.2021 s
agent0:                 episode reward: -0.4236,                 loss: nan
agent1:                 episode reward: 0.4236,                 loss: 0.3348
Episode: 18041/30000 (60.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7231s / 502.9253 s
agent0:                 episode reward: -0.5820,                 loss: nan
agent1:                 episode reward: 0.5820,                 loss: 0.3275
Episode: 18061/30000 (60.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7305s / 503.6558 s
agent0:                 episode reward: -0.7429,                 loss: nan
agent1:                 episode reward: 0.7429,                 loss: 0.3309
Episode: 18081/30000 (60.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7259s / 504.3817 s
agent0:                 episode reward: -0.4438,                 loss: nan
agent1:                 episode reward: 0.4438,                 loss: 0.3316
Episode: 18101/30000 (60.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7325s / 505.1142 s
agent0:                 episode reward: -0.5738,                 loss: nan
agent1:                 episode reward: 0.5738,                 loss: 0.3302
Episode: 18121/30000 (60.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7255s / 505.8396 s
agent0:                 episode reward: -0.4035,                 loss: nan
agent1:                 episode reward: 0.4035,                 loss: 0.3337
Episode: 18141/30000 (60.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7282s / 506.5678 s
agent0:                 episode reward: -0.3905,                 loss: nan
agent1:                 episode reward: 0.3905,                 loss: 0.3308
Episode: 18161/30000 (60.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7232s / 507.2910 s
agent0:                 episode reward: -0.7698,                 loss: nan
agent1:                 episode reward: 0.7698,                 loss: 0.3300
Episode: 18181/30000 (60.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7330s / 508.0240 s
agent0:                 episode reward: -0.7536,                 loss: nan
agent1:                 episode reward: 0.7536,                 loss: 0.3279
Episode: 18201/30000 (60.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7314s / 508.7554 s
agent0:                 episode reward: -0.4578,                 loss: nan
agent1:                 episode reward: 0.4578,                 loss: 0.3300
Episode: 18221/30000 (60.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7351s / 509.4905 s
agent0:                 episode reward: -0.5244,                 loss: nan
agent1:                 episode reward: 0.5244,                 loss: 0.3291
Episode: 18241/30000 (60.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7244s / 510.2149 s
agent0:                 episode reward: -0.5115,                 loss: nan
agent1:                 episode reward: 0.5115,                 loss: 0.3315
Episode: 18261/30000 (60.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7304s / 510.9453 s
agent0:                 episode reward: -0.5030,                 loss: nan
agent1:                 episode reward: 0.5030,                 loss: 0.3311
Episode: 18281/30000 (60.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7261s / 511.6714 s
agent0:                 episode reward: -0.4915,                 loss: nan
agent1:                 episode reward: 0.4915,                 loss: 0.3288
Episode: 18301/30000 (61.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7248s / 512.3962 s
agent0:                 episode reward: -0.7341,                 loss: nan
agent1:                 episode reward: 0.7341,                 loss: 0.3278
Episode: 18321/30000 (61.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7262s / 513.1224 s
agent0:                 episode reward: -0.8786,                 loss: nan
agent1:                 episode reward: 0.8786,                 loss: 0.3338
Episode: 18341/30000 (61.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7276s / 513.8501 s
agent0:                 episode reward: -0.8928,                 loss: nan
agent1:                 episode reward: 0.8928,                 loss: 0.3433
Episode: 18361/30000 (61.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7219s / 514.5720 s
agent0:                 episode reward: -0.5739,                 loss: nan
agent1:                 episode reward: 0.5739,                 loss: 0.3594
Episode: 18381/30000 (61.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7233s / 515.2953 s
agent0:                 episode reward: -0.4991,                 loss: nan
agent1:                 episode reward: 0.4991,                 loss: 0.3621
Episode: 18401/30000 (61.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7178s / 516.0131 s
agent0:                 episode reward: -0.7415,                 loss: nan
agent1:                 episode reward: 0.7415,                 loss: 0.3608
Episode: 18421/30000 (61.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7537s / 516.7668 s
agent0:                 episode reward: -0.2763,                 loss: nan
agent1:                 episode reward: 0.2763,                 loss: 0.3603
Episode: 18441/30000 (61.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7187s / 517.4854 s
agent0:                 episode reward: -0.5081,                 loss: nan
agent1:                 episode reward: 0.5081,                 loss: 0.3612
Episode: 18461/30000 (61.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7390s / 518.2244 s
agent0:                 episode reward: -0.7507,                 loss: nan
agent1:                 episode reward: 0.7507,                 loss: 0.3612
Episode: 18481/30000 (61.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7261s / 518.9506 s
agent0:                 episode reward: -0.8133,                 loss: nan
agent1:                 episode reward: 0.8133,                 loss: 0.3608
Episode: 18501/30000 (61.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7262s / 519.6768 s
agent0:                 episode reward: -0.8662,                 loss: nan
agent1:                 episode reward: 0.8662,                 loss: 0.3585
Episode: 18521/30000 (61.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7297s / 520.4065 s
agent0:                 episode reward: -0.6942,                 loss: nan
agent1:                 episode reward: 0.6942,                 loss: 0.3600
Episode: 18541/30000 (61.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7124s / 521.1189 s
agent0:                 episode reward: -0.4750,                 loss: nan
agent1:                 episode reward: 0.4750,                 loss: 0.3605
Episode: 18561/30000 (61.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7139s / 521.8329 s
agent0:                 episode reward: -0.7699,                 loss: nan
agent1:                 episode reward: 0.7699,                 loss: 0.3608
Episode: 18581/30000 (61.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7201s / 522.5530 s
agent0:                 episode reward: -0.4850,                 loss: nan
agent1:                 episode reward: 0.4850,                 loss: 0.3612
Episode: 18601/30000 (62.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7288s / 523.2818 s
agent0:                 episode reward: -0.1322,                 loss: nan
agent1:                 episode reward: 0.1322,                 loss: 0.3580
Episode: 18621/30000 (62.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7200s / 524.0017 s
agent0:                 episode reward: -0.4863,                 loss: nan
agent1:                 episode reward: 0.4863,                 loss: 0.3622
Episode: 18641/30000 (62.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7278s / 524.7295 s
agent0:                 episode reward: -0.5779,                 loss: nan
agent1:                 episode reward: 0.5779,                 loss: 0.3584
Episode: 18661/30000 (62.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7273s / 525.4568 s
agent0:                 episode reward: -0.6293,                 loss: nan
agent1:                 episode reward: 0.6293,                 loss: 0.3604
Episode: 18681/30000 (62.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7242s / 526.1810 s
agent0:                 episode reward: -0.5424,                 loss: nan
agent1:                 episode reward: 0.5424,                 loss: 0.3490
Episode: 18701/30000 (62.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7157s / 526.8967 s
agent0:                 episode reward: -0.6923,                 loss: nan
agent1:                 episode reward: 0.6923,                 loss: 0.3390
Episode: 18721/30000 (62.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7324s / 527.6291 s
agent0:                 episode reward: -0.6753,                 loss: nan
agent1:                 episode reward: 0.6753,                 loss: 0.3413
Episode: 18741/30000 (62.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7325s / 528.3616 s
agent0:                 episode reward: -0.9684,                 loss: nan
agent1:                 episode reward: 0.9684,                 loss: 0.3444
Episode: 18761/30000 (62.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7209s / 529.0825 s
agent0:                 episode reward: -0.8672,                 loss: nan
agent1:                 episode reward: 0.8672,                 loss: 0.3383
Episode: 18781/30000 (62.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7299s / 529.8124 s
agent0:                 episode reward: -1.0280,                 loss: nan
agent1:                 episode reward: 1.0280,                 loss: 0.3397
Episode: 18801/30000 (62.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7239s / 530.5363 s
agent0:                 episode reward: -0.4187,                 loss: nan
agent1:                 episode reward: 0.4187,                 loss: 0.3397
Episode: 18821/30000 (62.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7275s / 531.2638 s
agent0:                 episode reward: -0.3876,                 loss: nan
agent1:                 episode reward: 0.3876,                 loss: 0.3412
Episode: 18841/30000 (62.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7309s / 531.9947 s
agent0:                 episode reward: -0.6021,                 loss: nan
agent1:                 episode reward: 0.6021,                 loss: 0.3423
Episode: 18861/30000 (62.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7287s / 532.7234 s
agent0:                 episode reward: -0.4451,                 loss: nan
agent1:                 episode reward: 0.4451,                 loss: 0.3418
Episode: 18881/30000 (62.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7187s / 533.4420 s
agent0:                 episode reward: -0.5215,                 loss: nan
agent1:                 episode reward: 0.5215,                 loss: 0.3444
Episode: 18901/30000 (63.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7392s / 534.1812 s
agent0:                 episode reward: -0.8516,                 loss: nan
agent1:                 episode reward: 0.8516,                 loss: 0.3407
Episode: 18921/30000 (63.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7376s / 534.9188 s
agent0:                 episode reward: -0.7106,                 loss: nan
agent1:                 episode reward: 0.7106,                 loss: 0.3421
Episode: 18941/30000 (63.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7318s / 535.6506 s
agent0:                 episode reward: -0.8244,                 loss: nan
agent1:                 episode reward: 0.8244,                 loss: 0.3404
Episode: 18961/30000 (63.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7367s / 536.3873 s
agent0:                 episode reward: -0.7098,                 loss: nan
agent1:                 episode reward: 0.7098,                 loss: 0.3430
Episode: 18981/30000 (63.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7379s / 537.1251 s
agent0:                 episode reward: -0.8422,                 loss: nan
agent1:                 episode reward: 0.8422,                 loss: 0.3415
Episode: 19001/30000 (63.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7343s / 537.8594 s
agent0:                 episode reward: -0.5949,                 loss: nan
agent1:                 episode reward: 0.5949,                 loss: 0.3434
Episode: 19021/30000 (63.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7341s / 538.5935 s
agent0:                 episode reward: -0.8112,                 loss: nan
agent1:                 episode reward: 0.8112,                 loss: 0.3343
Episode: 19041/30000 (63.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7206s / 539.3142 s
agent0:                 episode reward: -0.4403,                 loss: nan
agent1:                 episode reward: 0.4403,                 loss: 0.3302
Episode: 19061/30000 (63.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7345s / 540.0486 s
agent0:                 episode reward: -0.6863,                 loss: nan
agent1:                 episode reward: 0.6863,                 loss: 0.3303
Episode: 19081/30000 (63.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7329s / 540.7816 s
agent0:                 episode reward: -1.1133,                 loss: nan
agent1:                 episode reward: 1.1133,                 loss: 0.3288
Episode: 19101/30000 (63.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7215s / 541.5030 s
agent0:                 episode reward: -0.7337,                 loss: nan
agent1:                 episode reward: 0.7337,                 loss: 0.3282
Episode: 19121/30000 (63.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7404s / 542.2434 s
agent0:                 episode reward: -0.5237,                 loss: nan
agent1:                 episode reward: 0.5237,                 loss: 0.3301
Episode: 19141/30000 (63.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7349s / 542.9782 s
agent0:                 episode reward: -0.5980,                 loss: nan
agent1:                 episode reward: 0.5980,                 loss: 0.3323
Episode: 19161/30000 (63.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7234s / 543.7017 s
agent0:                 episode reward: -0.4537,                 loss: nan
agent1:                 episode reward: 0.4537,                 loss: 0.3287
Episode: 19181/30000 (63.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7399s / 544.4415 s
agent0:                 episode reward: -0.7000,                 loss: nan
agent1:                 episode reward: 0.7000,                 loss: 0.3272
Episode: 19201/30000 (64.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7423s / 545.1838 s
agent0:                 episode reward: -0.6032,                 loss: nan
agent1:                 episode reward: 0.6032,                 loss: 0.3312
Episode: 19221/30000 (64.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7352s / 545.9189 s
agent0:                 episode reward: -0.5002,                 loss: nan
agent1:                 episode reward: 0.5002,                 loss: 0.3289
Episode: 19241/30000 (64.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7323s / 546.6512 s
agent0:                 episode reward: -0.7000,                 loss: nan
agent1:                 episode reward: 0.7000,                 loss: 0.3342
Episode: 19261/30000 (64.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7549s / 547.4061 s
agent0:                 episode reward: -0.5454,                 loss: nan
agent1:                 episode reward: 0.5454,                 loss: 0.3308
Episode: 19281/30000 (64.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7399s / 548.1460 s
agent0:                 episode reward: -0.7764,                 loss: nan
agent1:                 episode reward: 0.7764,                 loss: 0.3324
Episode: 19301/30000 (64.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7406s / 548.8866 s
agent0:                 episode reward: -0.4493,                 loss: nan
agent1:                 episode reward: 0.4493,                 loss: 0.3279
Episode: 19321/30000 (64.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7322s / 549.6188 s
agent0:                 episode reward: -0.5262,                 loss: nan
agent1:                 episode reward: 0.5262,                 loss: 0.3269
Episode: 19341/30000 (64.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7488s / 550.3677 s
agent0:                 episode reward: -0.2018,                 loss: nan
agent1:                 episode reward: 0.2018,                 loss: 0.3444
Episode: 19361/30000 (64.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7419s / 551.1095 s
agent0:                 episode reward: -0.4942,                 loss: nan
agent1:                 episode reward: 0.4942,                 loss: 0.3597
Episode: 19381/30000 (64.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7468s / 551.8564 s
agent0:                 episode reward: -0.6221,                 loss: nan
agent1:                 episode reward: 0.6221,                 loss: 0.3554
Episode: 19401/30000 (64.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7469s / 552.6033 s
agent0:                 episode reward: -0.9396,                 loss: nan
agent1:                 episode reward: 0.9396,                 loss: 0.3584
Episode: 19421/30000 (64.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7387s / 553.3420 s
agent0:                 episode reward: -0.6194,                 loss: nan
agent1:                 episode reward: 0.6194,                 loss: 0.3594
Episode: 19441/30000 (64.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7306s / 554.0725 s
agent0:                 episode reward: -0.5965,                 loss: nan
agent1:                 episode reward: 0.5965,                 loss: 0.3614
Episode: 19461/30000 (64.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7451s / 554.8176 s
agent0:                 episode reward: -0.7971,                 loss: nan
agent1:                 episode reward: 0.7971,                 loss: 0.3580
Episode: 19481/30000 (64.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7397s / 555.5573 s
agent0:                 episode reward: -0.5310,                 loss: nan
agent1:                 episode reward: 0.5310,                 loss: 0.3598
Episode: 19501/30000 (65.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7495s / 556.3068 s
agent0:                 episode reward: -0.5850,                 loss: nan
agent1:                 episode reward: 0.5850,                 loss: 0.3592
Episode: 19521/30000 (65.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7455s / 557.0523 s
agent0:                 episode reward: -0.5652,                 loss: nan
agent1:                 episode reward: 0.5652,                 loss: 0.3589
Episode: 19541/30000 (65.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7488s / 557.8011 s
agent0:                 episode reward: -0.5478,                 loss: nan
agent1:                 episode reward: 0.5478,                 loss: 0.3586
Episode: 19561/30000 (65.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7439s / 558.5449 s
agent0:                 episode reward: -0.4185,                 loss: nan
agent1:                 episode reward: 0.4185,                 loss: 0.3605
Episode: 19581/30000 (65.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7361s / 559.2811 s
agent0:                 episode reward: -0.7235,                 loss: nan
agent1:                 episode reward: 0.7235,                 loss: 0.3589
Episode: 19601/30000 (65.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7397s / 560.0207 s
agent0:                 episode reward: -0.3030,                 loss: nan
agent1:                 episode reward: 0.3030,                 loss: 0.3546
Episode: 19621/30000 (65.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7444s / 560.7651 s
agent0:                 episode reward: -0.8222,                 loss: nan
agent1:                 episode reward: 0.8222,                 loss: 0.3625
Episode: 19641/30000 (65.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7341s / 561.4992 s
agent0:                 episode reward: -0.3184,                 loss: nan
agent1:                 episode reward: 0.3184,                 loss: 0.3575
Episode: 19661/30000 (65.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7487s / 562.2479 s
agent0:                 episode reward: -0.6151,                 loss: nan
agent1:                 episode reward: 0.6151,                 loss: 0.3596
Episode: 19681/30000 (65.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7444s / 562.9923 s
agent0:                 episode reward: -0.2659,                 loss: nan
agent1:                 episode reward: 0.2659,                 loss: 0.3447
Episode: 19701/30000 (65.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7468s / 563.7390 s
agent0:                 episode reward: -0.3757,                 loss: nan
agent1:                 episode reward: 0.3757,                 loss: 0.3403
Episode: 19721/30000 (65.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7615s / 564.5005 s
agent0:                 episode reward: -0.5041,                 loss: nan
agent1:                 episode reward: 0.5041,                 loss: 0.3393
Episode: 19741/30000 (65.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7364s / 565.2370 s
agent0:                 episode reward: -0.4423,                 loss: nan
agent1:                 episode reward: 0.4423,                 loss: 0.3367
Episode: 19761/30000 (65.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7544s / 565.9914 s
agent0:                 episode reward: -0.7156,                 loss: nan
agent1:                 episode reward: 0.7156,                 loss: 0.3349
Episode: 19781/30000 (65.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7545s / 566.7459 s
agent0:                 episode reward: -0.8649,                 loss: nan
agent1:                 episode reward: 0.8649,                 loss: 0.3357
Episode: 19801/30000 (66.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7492s / 567.4951 s
agent0:                 episode reward: -0.9492,                 loss: nan
agent1:                 episode reward: 0.9492,                 loss: 0.3375
Episode: 19821/30000 (66.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7445s / 568.2396 s
agent0:                 episode reward: -0.6733,                 loss: nan
agent1:                 episode reward: 0.6733,                 loss: 0.3367
Episode: 19841/30000 (66.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7386s / 568.9782 s
agent0:                 episode reward: -0.7784,                 loss: nan
agent1:                 episode reward: 0.7784,                 loss: 0.3365
Episode: 19861/30000 (66.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7483s / 569.7265 s
agent0:                 episode reward: -0.5507,                 loss: nan
agent1:                 episode reward: 0.5507,                 loss: 0.3377
Episode: 19881/30000 (66.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7472s / 570.4737 s
agent0:                 episode reward: -0.3147,                 loss: nan
agent1:                 episode reward: 0.3147,                 loss: 0.3405
Episode: 19901/30000 (66.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7483s / 571.2219 s
agent0:                 episode reward: -0.6284,                 loss: nan
agent1:                 episode reward: 0.6284,                 loss: 0.3376
Episode: 19921/30000 (66.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7517s / 571.9737 s
agent0:                 episode reward: -0.6914,                 loss: nan
agent1:                 episode reward: 0.6914,                 loss: 0.3394
Episode: 19941/30000 (66.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7628s / 572.7364 s
agent0:                 episode reward: -0.5806,                 loss: nan
agent1:                 episode reward: 0.5806,                 loss: 0.3369
Episode: 19961/30000 (66.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7488s / 573.4852 s
agent0:                 episode reward: -0.4113,                 loss: nan
agent1:                 episode reward: 0.4113,                 loss: 0.3403
Episode: 19981/30000 (66.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7470s / 574.2322 s
agent0:                 episode reward: -0.6126,                 loss: nan
agent1:                 episode reward: 0.6126,                 loss: 0.3383
Episode: 20001/30000 (66.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7476s / 574.9798 s
agent0:                 episode reward: -0.7065,                 loss: nan
agent1:                 episode reward: 0.7065,                 loss: 0.3386
Episode: 20021/30000 (66.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7579s / 575.7377 s
agent0:                 episode reward: -0.5882,                 loss: nan
agent1:                 episode reward: 0.5882,                 loss: 0.3450
Episode: 20041/30000 (66.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7566s / 576.4943 s
agent0:                 episode reward: -0.8501,                 loss: nan
agent1:                 episode reward: 0.8501,                 loss: 0.3450
Episode: 20061/30000 (66.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7470s / 577.2413 s
agent0:                 episode reward: -1.0653,                 loss: nan
agent1:                 episode reward: 1.0653,                 loss: 0.3476
Episode: 20081/30000 (66.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7533s / 577.9946 s
agent0:                 episode reward: -0.7096,                 loss: nan
agent1:                 episode reward: 0.7096,                 loss: 0.3436
Episode: 20101/30000 (67.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7464s / 578.7410 s
agent0:                 episode reward: -1.0510,                 loss: nan
agent1:                 episode reward: 1.0510,                 loss: 0.3483
Episode: 20121/30000 (67.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7563s / 579.4973 s
agent0:                 episode reward: -0.6985,                 loss: nan
agent1:                 episode reward: 0.6985,                 loss: 0.3443
Episode: 20141/30000 (67.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7710s / 580.2683 s
agent0:                 episode reward: -0.3532,                 loss: nan
agent1:                 episode reward: 0.3532,                 loss: 0.3461
Episode: 20161/30000 (67.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7457s / 581.0140 s
agent0:                 episode reward: -0.4779,                 loss: nan
agent1:                 episode reward: 0.4779,                 loss: 0.3498
Episode: 20181/30000 (67.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7603s / 581.7743 s
agent0:                 episode reward: -0.8547,                 loss: nan
agent1:                 episode reward: 0.8547,                 loss: 0.3469
Episode: 20201/30000 (67.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7535s / 582.5278 s
agent0:                 episode reward: -0.3581,                 loss: nan
agent1:                 episode reward: 0.3581,                 loss: 0.3487
Episode: 20221/30000 (67.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7625s / 583.2904 s
agent0:                 episode reward: -0.5928,                 loss: nan
agent1:                 episode reward: 0.5928,                 loss: 0.3424
Episode: 20241/30000 (67.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7490s / 584.0394 s
agent0:                 episode reward: -0.7184,                 loss: nan
agent1:                 episode reward: 0.7184,                 loss: 0.3458
Episode: 20261/30000 (67.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7543s / 584.7938 s
agent0:                 episode reward: -0.4851,                 loss: nan
agent1:                 episode reward: 0.4851,                 loss: 0.3478
Episode: 20281/30000 (67.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7594s / 585.5531 s
agent0:                 episode reward: -0.4735,                 loss: nan
agent1:                 episode reward: 0.4735,                 loss: 0.3437
Episode: 20301/30000 (67.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7637s / 586.3168 s
agent0:                 episode reward: -0.6903,                 loss: nan
agent1:                 episode reward: 0.6903,                 loss: 0.3461
Episode: 20321/30000 (67.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7530s / 587.0698 s
agent0:                 episode reward: -0.6004,                 loss: nan
agent1:                 episode reward: 0.6004,                 loss: 0.3472
Episode: 20341/30000 (67.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7606s / 587.8303 s
agent0:                 episode reward: -0.4101,                 loss: nan
agent1:                 episode reward: 0.4101,                 loss: 0.3523
Episode: 20361/30000 (67.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7566s / 588.5869 s
agent0:                 episode reward: -0.6611,                 loss: nan
agent1:                 episode reward: 0.6611,                 loss: 0.3585
Episode: 20381/30000 (67.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7586s / 589.3455 s
agent0:                 episode reward: -0.8244,                 loss: nan
agent1:                 episode reward: 0.8244,                 loss: 0.3568
Episode: 20401/30000 (68.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7658s / 590.1113 s
agent0:                 episode reward: -0.5432,                 loss: nan
agent1:                 episode reward: 0.5432,                 loss: 0.3578
Episode: 20421/30000 (68.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7674s / 590.8787 s
agent0:                 episode reward: -0.4724,                 loss: nan
agent1:                 episode reward: 0.4724,                 loss: 0.3567
Episode: 20441/30000 (68.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7680s / 591.6467 s
agent0:                 episode reward: -0.6410,                 loss: nan
agent1:                 episode reward: 0.6410,                 loss: 0.3532
Episode: 20461/30000 (68.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7803s / 592.4270 s
agent0:                 episode reward: -0.6910,                 loss: nan
agent1:                 episode reward: 0.6910,                 loss: 0.3581
Episode: 20481/30000 (68.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7673s / 593.1943 s
agent0:                 episode reward: -0.5819,                 loss: nan
agent1:                 episode reward: 0.5819,                 loss: 0.3573
Episode: 20501/30000 (68.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7609s / 593.9552 s
agent0:                 episode reward: -0.7814,                 loss: nan
agent1:                 episode reward: 0.7814,                 loss: 0.3567
Episode: 20521/30000 (68.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7669s / 594.7221 s
agent0:                 episode reward: -0.4527,                 loss: nan
agent1:                 episode reward: 0.4527,                 loss: 0.3554
Episode: 20541/30000 (68.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7552s / 595.4773 s
agent0:                 episode reward: -0.3983,                 loss: nan
agent1:                 episode reward: 0.3983,                 loss: 0.3567
Episode: 20561/30000 (68.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7644s / 596.2417 s
agent0:                 episode reward: -0.8123,                 loss: nan
agent1:                 episode reward: 0.8123,                 loss: 0.3565
Episode: 20581/30000 (68.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7573s / 596.9990 s
agent0:                 episode reward: -0.6209,                 loss: nan
agent1:                 episode reward: 0.6209,                 loss: 0.3561
Episode: 20601/30000 (68.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7539s / 597.7529 s
agent0:                 episode reward: -0.5573,                 loss: nan
agent1:                 episode reward: 0.5573,                 loss: 0.3599
Episode: 20621/30000 (68.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7584s / 598.5113 s
agent0:                 episode reward: -0.7904,                 loss: nan
agent1:                 episode reward: 0.7904,                 loss: 0.3568
Episode: 20641/30000 (68.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7517s / 599.2630 s
agent0:                 episode reward: -0.2179,                 loss: nan
agent1:                 episode reward: 0.2179,                 loss: 0.3587
Episode: 20661/30000 (68.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7649s / 600.0279 s
agent0:                 episode reward: -0.8719,                 loss: nan
agent1:                 episode reward: 0.8719,                 loss: 0.3556
Episode: 20681/30000 (68.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7662s / 600.7941 s
agent0:                 episode reward: -0.5671,                 loss: nan
agent1:                 episode reward: 0.5671,                 loss: 0.3502
Episode: 20701/30000 (69.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7778s / 601.5719 s
agent0:                 episode reward: -0.5619,                 loss: nan
agent1:                 episode reward: 0.5619,                 loss: 0.3415
Episode: 20721/30000 (69.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7550s / 602.3269 s
agent0:                 episode reward: -0.7816,                 loss: nan
agent1:                 episode reward: 0.7816,                 loss: 0.3412
Episode: 20741/30000 (69.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7640s / 603.0909 s
agent0:                 episode reward: -0.7728,                 loss: nan
agent1:                 episode reward: 0.7728,                 loss: 0.3416
Episode: 20761/30000 (69.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7739s / 603.8647 s
agent0:                 episode reward: -0.5363,                 loss: nan
agent1:                 episode reward: 0.5363,                 loss: 0.3405
Episode: 20781/30000 (69.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7736s / 604.6384 s
agent0:                 episode reward: -0.5255,                 loss: nan
agent1:                 episode reward: 0.5255,                 loss: 0.3392
Episode: 20801/30000 (69.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7689s / 605.4073 s
agent0:                 episode reward: -0.3921,                 loss: nan
agent1:                 episode reward: 0.3921,                 loss: 0.3408
Episode: 20821/30000 (69.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7570s / 606.1643 s
agent0:                 episode reward: -0.2751,                 loss: nan
agent1:                 episode reward: 0.2751,                 loss: 0.3410
Episode: 20841/30000 (69.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7629s / 606.9272 s
agent0:                 episode reward: -0.6002,                 loss: nan
agent1:                 episode reward: 0.6002,                 loss: 0.3413
Episode: 20861/30000 (69.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7652s / 607.6924 s
agent0:                 episode reward: -0.3718,                 loss: nan
agent1:                 episode reward: 0.3718,                 loss: 0.3405
Episode: 20881/30000 (69.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7669s / 608.4593 s
agent0:                 episode reward: -1.0701,                 loss: nan
agent1:                 episode reward: 1.0701,                 loss: 0.3407
Episode: 20901/30000 (69.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7787s / 609.2380 s
agent0:                 episode reward: -0.3185,                 loss: nan
agent1:                 episode reward: 0.3185,                 loss: 0.3387
Episode: 20921/30000 (69.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7646s / 610.0026 s
agent0:                 episode reward: -0.3955,                 loss: nan
agent1:                 episode reward: 0.3955,                 loss: 0.3391
Episode: 20941/30000 (69.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7609s / 610.7635 s
agent0:                 episode reward: -0.6950,                 loss: nan
agent1:                 episode reward: 0.6950,                 loss: 0.3422
Episode: 20961/30000 (69.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7601s / 611.5236 s
agent0:                 episode reward: -0.5397,                 loss: nan
agent1:                 episode reward: 0.5397,                 loss: 0.3390
Episode: 20981/30000 (69.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7672s / 612.2908 s
agent0:                 episode reward: -0.7055,                 loss: nan
agent1:                 episode reward: 0.7055,                 loss: 0.3412
Episode: 21001/30000 (70.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7521s / 613.0430 s
agent0:                 episode reward: -0.7017,                 loss: nan
agent1:                 episode reward: 0.7017,                 loss: 0.3395
Episode: 21021/30000 (70.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7565s / 613.7995 s
agent0:                 episode reward: -0.5552,                 loss: nan
agent1:                 episode reward: 0.5552,                 loss: 0.3450
Episode: 21041/30000 (70.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7721s / 614.5715 s
agent0:                 episode reward: -0.7552,                 loss: nan
agent1:                 episode reward: 0.7552,                 loss: 0.3488
Episode: 21061/30000 (70.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7649s / 615.3364 s
agent0:                 episode reward: -0.2399,                 loss: nan
agent1:                 episode reward: 0.2399,                 loss: 0.3463
Episode: 21081/30000 (70.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7644s / 616.1008 s
agent0:                 episode reward: -0.2827,                 loss: nan
agent1:                 episode reward: 0.2827,                 loss: 0.3484
Episode: 21101/30000 (70.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7653s / 616.8661 s
agent0:                 episode reward: -0.8901,                 loss: nan
agent1:                 episode reward: 0.8901,                 loss: 0.3466
Episode: 21121/30000 (70.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7629s / 617.6290 s
agent0:                 episode reward: -0.6975,                 loss: nan
agent1:                 episode reward: 0.6975,                 loss: 0.3452
Episode: 21141/30000 (70.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7674s / 618.3964 s
agent0:                 episode reward: -0.9518,                 loss: nan
agent1:                 episode reward: 0.9518,                 loss: 0.3450
Episode: 21161/30000 (70.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7780s / 619.1744 s
agent0:                 episode reward: -0.2763,                 loss: nan
agent1:                 episode reward: 0.2763,                 loss: 0.3465
Episode: 21181/30000 (70.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7577s / 619.9321 s
agent0:                 episode reward: -0.8319,                 loss: nan
agent1:                 episode reward: 0.8319,                 loss: 0.3456
Episode: 21201/30000 (70.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7702s / 620.7023 s
agent0:                 episode reward: -0.3267,                 loss: nan
agent1:                 episode reward: 0.3267,                 loss: 0.3478
Episode: 21221/30000 (70.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7761s / 621.4784 s
agent0:                 episode reward: -0.5606,                 loss: nan
agent1:                 episode reward: 0.5606,                 loss: 0.3490
Episode: 21241/30000 (70.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7658s / 622.2442 s
agent0:                 episode reward: -0.4544,                 loss: nan
agent1:                 episode reward: 0.4544,                 loss: 0.3482
Episode: 21261/30000 (70.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7736s / 623.0178 s
agent0:                 episode reward: -0.6230,                 loss: nan
agent1:                 episode reward: 0.6230,                 loss: 0.3467
Episode: 21281/30000 (70.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7629s / 623.7807 s
agent0:                 episode reward: -0.7615,                 loss: nan
agent1:                 episode reward: 0.7615,                 loss: 0.3475
Episode: 21301/30000 (71.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7663s / 624.5470 s
agent0:                 episode reward: -0.6005,                 loss: nan
agent1:                 episode reward: 0.6005,                 loss: 0.3468
Episode: 21321/30000 (71.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7823s / 625.3293 s
agent0:                 episode reward: -0.6329,                 loss: nan
agent1:                 episode reward: 0.6329,                 loss: 0.3492
Episode: 21341/30000 (71.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8092s / 626.1385 s
agent0:                 episode reward: -0.3788,                 loss: nan
agent1:                 episode reward: 0.3788,                 loss: 0.3492
Episode: 21361/30000 (71.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7719s / 626.9105 s
agent0:                 episode reward: -0.4865,                 loss: nan
agent1:                 episode reward: 0.4865,                 loss: 0.3559
Episode: 21381/30000 (71.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7781s / 627.6886 s
agent0:                 episode reward: -0.4984,                 loss: nan
agent1:                 episode reward: 0.4984,                 loss: 0.3546
Episode: 21401/30000 (71.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7628s / 628.4514 s
agent0:                 episode reward: -0.8592,                 loss: nan
agent1:                 episode reward: 0.8592,                 loss: 0.3522
Episode: 21421/30000 (71.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7781s / 629.2295 s
agent0:                 episode reward: -0.7395,                 loss: nan
agent1:                 episode reward: 0.7395,                 loss: 0.3508
Episode: 21441/30000 (71.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7631s / 629.9926 s
agent0:                 episode reward: -0.6284,                 loss: nan
agent1:                 episode reward: 0.6284,                 loss: 0.3538
Episode: 21461/30000 (71.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7837s / 630.7763 s
agent0:                 episode reward: -0.4510,                 loss: nan
agent1:                 episode reward: 0.4510,                 loss: 0.3528
Episode: 21481/30000 (71.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7818s / 631.5581 s
agent0:                 episode reward: -0.6447,                 loss: nan
agent1:                 episode reward: 0.6447,                 loss: 0.3535
Episode: 21501/30000 (71.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7762s / 632.3343 s
agent0:                 episode reward: -0.5024,                 loss: nan
agent1:                 episode reward: 0.5024,                 loss: 0.3541
Episode: 21521/30000 (71.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7855s / 633.1198 s
agent0:                 episode reward: -0.8559,                 loss: nan
agent1:                 episode reward: 0.8559,                 loss: 0.3557
Episode: 21541/30000 (71.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7813s / 633.9011 s
agent0:                 episode reward: -0.5081,                 loss: nan
agent1:                 episode reward: 0.5081,                 loss: 0.3508
Episode: 21561/30000 (71.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7771s / 634.6782 s
agent0:                 episode reward: -0.5336,                 loss: nan
agent1:                 episode reward: 0.5336,                 loss: 0.3554
Episode: 21581/30000 (71.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7893s / 635.4675 s
agent0:                 episode reward: -0.4598,                 loss: nan
agent1:                 episode reward: 0.4598,                 loss: 0.3526
Episode: 21601/30000 (72.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7878s / 636.2554 s
agent0:                 episode reward: -0.2326,                 loss: nan
agent1:                 episode reward: 0.2326,                 loss: 0.3504
Episode: 21621/30000 (72.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7830s / 637.0384 s
agent0:                 episode reward: -0.3379,                 loss: nan
agent1:                 episode reward: 0.3379,                 loss: 0.3518
Episode: 21641/30000 (72.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7817s / 637.8201 s
agent0:                 episode reward: -0.4822,                 loss: nan
agent1:                 episode reward: 0.4822,                 loss: 0.3508
Episode: 21661/30000 (72.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7837s / 638.6038 s
agent0:                 episode reward: -0.7577,                 loss: nan
agent1:                 episode reward: 0.7577,                 loss: 0.3515
Episode: 21681/30000 (72.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7890s / 639.3928 s
agent0:                 episode reward: -1.0530,                 loss: nan
agent1:                 episode reward: 1.0530,                 loss: 0.3445
Episode: 21701/30000 (72.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7936s / 640.1865 s
agent0:                 episode reward: -0.8253,                 loss: nan
agent1:                 episode reward: 0.8253,                 loss: 0.3363
Episode: 21721/30000 (72.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7877s / 640.9742 s
agent0:                 episode reward: -0.7406,                 loss: nan
agent1:                 episode reward: 0.7406,                 loss: 0.3384
Episode: 21741/30000 (72.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7774s / 641.7516 s
agent0:                 episode reward: -0.6223,                 loss: nan
agent1:                 episode reward: 0.6223,                 loss: 0.3353
Episode: 21761/30000 (72.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7874s / 642.5390 s
agent0:                 episode reward: -0.5290,                 loss: nan
agent1:                 episode reward: 0.5290,                 loss: 0.3359
Episode: 21781/30000 (72.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7962s / 643.3352 s
agent0:                 episode reward: -0.7057,                 loss: nan
agent1:                 episode reward: 0.7057,                 loss: 0.3378
Episode: 21801/30000 (72.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7752s / 644.1104 s
agent0:                 episode reward: -0.7066,                 loss: nan
agent1:                 episode reward: 0.7066,                 loss: 0.3362
Episode: 21821/30000 (72.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7934s / 644.9039 s
agent0:                 episode reward: -0.5052,                 loss: nan
agent1:                 episode reward: 0.5052,                 loss: 0.3352
Episode: 21841/30000 (72.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7790s / 645.6828 s
agent0:                 episode reward: -0.5635,                 loss: nan
agent1:                 episode reward: 0.5635,                 loss: 0.3389
Episode: 21861/30000 (72.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7791s / 646.4619 s
agent0:                 episode reward: -0.7617,                 loss: nan
agent1:                 episode reward: 0.7617,                 loss: 0.3337
Episode: 21881/30000 (72.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7739s / 647.2358 s
agent0:                 episode reward: -0.5540,                 loss: nan
agent1:                 episode reward: 0.5540,                 loss: 0.3377
Episode: 21901/30000 (73.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7808s / 648.0166 s
agent0:                 episode reward: -0.8583,                 loss: nan
agent1:                 episode reward: 0.8583,                 loss: 0.3374
Episode: 21921/30000 (73.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7801s / 648.7967 s
agent0:                 episode reward: -0.4787,                 loss: nan
agent1:                 episode reward: 0.4787,                 loss: 0.3373
Episode: 21941/30000 (73.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7846s / 649.5813 s
agent0:                 episode reward: -0.4710,                 loss: nan
agent1:                 episode reward: 0.4710,                 loss: 0.3340
Episode: 21961/30000 (73.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7920s / 650.3733 s
agent0:                 episode reward: -0.3090,                 loss: nan
agent1:                 episode reward: 0.3090,                 loss: 0.3391
Episode: 21981/30000 (73.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7956s / 651.1689 s
agent0:                 episode reward: -0.4817,                 loss: nan
agent1:                 episode reward: 0.4817,                 loss: 0.3333
Episode: 22001/30000 (73.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8015s / 651.9704 s
agent0:                 episode reward: -0.7358,                 loss: nan
agent1:                 episode reward: 0.7358,                 loss: 0.3378
Episode: 22021/30000 (73.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7802s / 652.7505 s
agent0:                 episode reward: -0.5593,                 loss: nan
agent1:                 episode reward: 0.5593,                 loss: 0.3492
Episode: 22041/30000 (73.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7844s / 653.5349 s
agent0:                 episode reward: -0.7371,                 loss: nan
agent1:                 episode reward: 0.7371,                 loss: 0.3440
Episode: 22061/30000 (73.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7869s / 654.3217 s
agent0:                 episode reward: -0.3360,                 loss: nan
agent1:                 episode reward: 0.3360,                 loss: 0.3462
Episode: 22081/30000 (73.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7948s / 655.1165 s
agent0:                 episode reward: -0.4143,                 loss: nan
agent1:                 episode reward: 0.4143,                 loss: 0.3458
Episode: 22101/30000 (73.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7848s / 655.9013 s
agent0:                 episode reward: -0.6654,                 loss: nan
agent1:                 episode reward: 0.6654,                 loss: 0.3457
Episode: 22121/30000 (73.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7830s / 656.6844 s
agent0:                 episode reward: -0.6352,                 loss: nan
agent1:                 episode reward: 0.6352,                 loss: 0.3477
Episode: 22141/30000 (73.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8099s / 657.4943 s
agent0:                 episode reward: -0.7436,                 loss: nan
agent1:                 episode reward: 0.7436,                 loss: 0.3471
Episode: 22161/30000 (73.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7926s / 658.2868 s
agent0:                 episode reward: -0.8432,                 loss: nan
agent1:                 episode reward: 0.8432,                 loss: 0.3452
Episode: 22181/30000 (73.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7864s / 659.0732 s
agent0:                 episode reward: -1.1915,                 loss: nan
agent1:                 episode reward: 1.1915,                 loss: 0.3459
Episode: 22201/30000 (74.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7891s / 659.8624 s
agent0:                 episode reward: -0.9029,                 loss: nan
agent1:                 episode reward: 0.9029,                 loss: 0.3438
Episode: 22221/30000 (74.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7836s / 660.6459 s
agent0:                 episode reward: -0.6580,                 loss: nan
agent1:                 episode reward: 0.6580,                 loss: 0.3447
Episode: 22241/30000 (74.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7882s / 661.4341 s
agent0:                 episode reward: -0.6590,                 loss: nan
agent1:                 episode reward: 0.6590,                 loss: 0.3457
Episode: 22261/30000 (74.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7866s / 662.2207 s
agent0:                 episode reward: -0.6543,                 loss: nan
agent1:                 episode reward: 0.6543,                 loss: 0.3459
Episode: 22281/30000 (74.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7889s / 663.0096 s
agent0:                 episode reward: -0.5620,                 loss: nan
agent1:                 episode reward: 0.5620,                 loss: 0.3432
Episode: 22301/30000 (74.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7885s / 663.7981 s
agent0:                 episode reward: -1.0078,                 loss: nan
agent1:                 episode reward: 1.0078,                 loss: 0.3457
Episode: 22321/30000 (74.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8098s / 664.6080 s
agent0:                 episode reward: -0.7263,                 loss: nan
agent1:                 episode reward: 0.7263,                 loss: 0.3445
Episode: 22341/30000 (74.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8134s / 665.4214 s
agent0:                 episode reward: -0.5292,                 loss: nan
agent1:                 episode reward: 0.5292,                 loss: 0.3532
Episode: 22361/30000 (74.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7772s / 666.1986 s
agent0:                 episode reward: -0.6287,                 loss: nan
agent1:                 episode reward: 0.6287,                 loss: 0.3628
Episode: 22381/30000 (74.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7907s / 666.9893 s
agent0:                 episode reward: -0.6521,                 loss: nan
agent1:                 episode reward: 0.6521,                 loss: 0.3610
Episode: 22401/30000 (74.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7832s / 667.7725 s
agent0:                 episode reward: -0.4795,                 loss: nan
agent1:                 episode reward: 0.4795,                 loss: 0.3598
Episode: 22421/30000 (74.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7847s / 668.5572 s
agent0:                 episode reward: -0.5295,                 loss: nan
agent1:                 episode reward: 0.5295,                 loss: 0.3612
Episode: 22441/30000 (74.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7906s / 669.3478 s
agent0:                 episode reward: -0.3538,                 loss: nan
agent1:                 episode reward: 0.3538,                 loss: 0.3603
Episode: 22461/30000 (74.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8066s / 670.1544 s
agent0:                 episode reward: -0.8810,                 loss: nan
agent1:                 episode reward: 0.8810,                 loss: 0.3618
Episode: 22481/30000 (74.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7949s / 670.9492 s
agent0:                 episode reward: -0.6588,                 loss: nan
agent1:                 episode reward: 0.6588,                 loss: 0.3606
Episode: 22501/30000 (75.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7903s / 671.7396 s
agent0:                 episode reward: -0.4341,                 loss: nan
agent1:                 episode reward: 0.4341,                 loss: 0.3625
Episode: 22521/30000 (75.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7790s / 672.5186 s
agent0:                 episode reward: -0.7228,                 loss: nan
agent1:                 episode reward: 0.7228,                 loss: 0.3624
Episode: 22541/30000 (75.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8039s / 673.3225 s
agent0:                 episode reward: -0.9256,                 loss: nan
agent1:                 episode reward: 0.9256,                 loss: 0.3604
Episode: 22561/30000 (75.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7982s / 674.1207 s
agent0:                 episode reward: -0.7483,                 loss: nan
agent1:                 episode reward: 0.7483,                 loss: 0.3624
Episode: 22581/30000 (75.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7945s / 674.9152 s
agent0:                 episode reward: -0.7308,                 loss: nan
agent1:                 episode reward: 0.7308,                 loss: 0.3601
Episode: 22601/30000 (75.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7910s / 675.7062 s
agent0:                 episode reward: -0.7317,                 loss: nan
agent1:                 episode reward: 0.7317,                 loss: 0.3623
Episode: 22621/30000 (75.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8038s / 676.5100 s
agent0:                 episode reward: -0.7170,                 loss: nan
agent1:                 episode reward: 0.7170,                 loss: 0.3642
Episode: 22641/30000 (75.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7902s / 677.3002 s
agent0:                 episode reward: -0.3497,                 loss: nan
agent1:                 episode reward: 0.3497,                 loss: 0.3621
Episode: 22661/30000 (75.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7923s / 678.0924 s
agent0:                 episode reward: -0.7587,                 loss: nan
agent1:                 episode reward: 0.7587,                 loss: 0.3618
Episode: 22681/30000 (75.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8000s / 678.8924 s
agent0:                 episode reward: -0.4393,                 loss: nan
agent1:                 episode reward: 0.4393,                 loss: 0.3439
Episode: 22701/30000 (75.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7952s / 679.6876 s
agent0:                 episode reward: -0.6674,                 loss: nan
agent1:                 episode reward: 0.6674,                 loss: 0.3301
Episode: 22721/30000 (75.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8195s / 680.5071 s
agent0:                 episode reward: -0.6599,                 loss: nan
agent1:                 episode reward: 0.6599,                 loss: 0.3273
Episode: 22741/30000 (75.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8262s / 681.3333 s
agent0:                 episode reward: -0.4183,                 loss: nan
agent1:                 episode reward: 0.4183,                 loss: 0.3317
Episode: 22761/30000 (75.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8314s / 682.1647 s
agent0:                 episode reward: -0.5189,                 loss: nan
agent1:                 episode reward: 0.5189,                 loss: 0.3326
Episode: 22781/30000 (75.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8018s / 682.9665 s
agent0:                 episode reward: -0.8701,                 loss: nan
agent1:                 episode reward: 0.8701,                 loss: 0.3298
Episode: 22801/30000 (76.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8033s / 683.7698 s
agent0:                 episode reward: -0.7437,                 loss: nan
agent1:                 episode reward: 0.7437,                 loss: 0.3289
Episode: 22821/30000 (76.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8063s / 684.5761 s
agent0:                 episode reward: -0.6752,                 loss: nan
agent1:                 episode reward: 0.6752,                 loss: 0.3318
Episode: 22841/30000 (76.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7973s / 685.3734 s
agent0:                 episode reward: -0.6135,                 loss: nan
agent1:                 episode reward: 0.6135,                 loss: 0.3288
Episode: 22861/30000 (76.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8050s / 686.1784 s
agent0:                 episode reward: -0.2890,                 loss: nan
agent1:                 episode reward: 0.2890,                 loss: 0.3319
Episode: 22881/30000 (76.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8164s / 686.9948 s
agent0:                 episode reward: -0.4090,                 loss: nan
agent1:                 episode reward: 0.4090,                 loss: 0.3320
Episode: 22901/30000 (76.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8066s / 687.8015 s
agent0:                 episode reward: -0.9090,                 loss: nan
agent1:                 episode reward: 0.9090,                 loss: 0.3300
Episode: 22921/30000 (76.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7985s / 688.6000 s
agent0:                 episode reward: -0.7668,                 loss: nan
agent1:                 episode reward: 0.7668,                 loss: 0.3333
Episode: 22941/30000 (76.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8049s / 689.4049 s
agent0:                 episode reward: -0.8560,                 loss: nan
agent1:                 episode reward: 0.8560,                 loss: 0.3309
Episode: 22961/30000 (76.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8086s / 690.2135 s
agent0:                 episode reward: -0.8569,                 loss: nan
agent1:                 episode reward: 0.8569,                 loss: 0.3272
Episode: 22981/30000 (76.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7934s / 691.0069 s
agent0:                 episode reward: -0.5791,                 loss: nan
agent1:                 episode reward: 0.5791,                 loss: 0.3290
Episode: 23001/30000 (76.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8023s / 691.8092 s
agent0:                 episode reward: -0.3626,                 loss: nan
agent1:                 episode reward: 0.3626,                 loss: 0.3349
Episode: 23021/30000 (76.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7952s / 692.6043 s
agent0:                 episode reward: -0.6593,                 loss: nan
agent1:                 episode reward: 0.6593,                 loss: 0.3521
Episode: 23041/30000 (76.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7995s / 693.4039 s
agent0:                 episode reward: -0.9842,                 loss: nan
agent1:                 episode reward: 0.9842,                 loss: 0.3499
Episode: 23061/30000 (76.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8047s / 694.2086 s
agent0:                 episode reward: -0.3889,                 loss: nan
agent1:                 episode reward: 0.3889,                 loss: 0.3481
Episode: 23081/30000 (76.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8015s / 695.0101 s
agent0:                 episode reward: -0.4359,                 loss: nan
agent1:                 episode reward: 0.4359,                 loss: 0.3532
Episode: 23101/30000 (77.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7951s / 695.8052 s
agent0:                 episode reward: -0.3457,                 loss: nan
agent1:                 episode reward: 0.3457,                 loss: 0.3486
Episode: 23121/30000 (77.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8191s / 696.6243 s
agent0:                 episode reward: -0.6597,                 loss: nan
agent1:                 episode reward: 0.6597,                 loss: 0.3495
Episode: 23141/30000 (77.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7935s / 697.4178 s
agent0:                 episode reward: -0.7020,                 loss: nan
agent1:                 episode reward: 0.7020,                 loss: 0.3520
Episode: 23161/30000 (77.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8143s / 698.2322 s
agent0:                 episode reward: -0.4359,                 loss: nan
agent1:                 episode reward: 0.4359,                 loss: 0.3477
Episode: 23181/30000 (77.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8193s / 699.0515 s
agent0:                 episode reward: -0.9042,                 loss: nan
agent1:                 episode reward: 0.9042,                 loss: 0.3531
Episode: 23201/30000 (77.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8016s / 699.8531 s
agent0:                 episode reward: -0.1432,                 loss: nan
agent1:                 episode reward: 0.1432,                 loss: 0.3507
Episode: 23221/30000 (77.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8222s / 700.6753 s
agent0:                 episode reward: -0.6761,                 loss: nan
agent1:                 episode reward: 0.6761,                 loss: 0.3502
Episode: 23241/30000 (77.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8162s / 701.4915 s
agent0:                 episode reward: -0.8860,                 loss: nan
agent1:                 episode reward: 0.8860,                 loss: 0.3506
Episode: 23261/30000 (77.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8071s / 702.2985 s
agent0:                 episode reward: -0.6762,                 loss: nan
agent1:                 episode reward: 0.6762,                 loss: 0.3477
Episode: 23281/30000 (77.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8163s / 703.1148 s
agent0:                 episode reward: -0.7047,                 loss: nan
agent1:                 episode reward: 0.7047,                 loss: 0.3512
Episode: 23301/30000 (77.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7959s / 703.9108 s
agent0:                 episode reward: -0.7685,                 loss: nan
agent1:                 episode reward: 0.7685,                 loss: 0.3512
Episode: 23321/30000 (77.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7955s / 704.7063 s
agent0:                 episode reward: -0.2911,                 loss: nan
agent1:                 episode reward: 0.2911,                 loss: 0.3507
Episode: 23341/30000 (77.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8075s / 705.5137 s
agent0:                 episode reward: -0.3636,                 loss: nan
agent1:                 episode reward: 0.3636,                 loss: 0.3532
Episode: 23361/30000 (77.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8276s / 706.3414 s
agent0:                 episode reward: -0.4504,                 loss: nan
agent1:                 episode reward: 0.4504,                 loss: 0.3578
Episode: 23381/30000 (77.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7998s / 707.1412 s
agent0:                 episode reward: -0.4629,                 loss: nan
agent1:                 episode reward: 0.4629,                 loss: 0.3567
Episode: 23401/30000 (78.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8076s / 707.9487 s
agent0:                 episode reward: -0.4533,                 loss: nan
agent1:                 episode reward: 0.4533,                 loss: 0.3539
Episode: 23421/30000 (78.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8086s / 708.7573 s
agent0:                 episode reward: -0.4709,                 loss: nan
agent1:                 episode reward: 0.4709,                 loss: 0.3574
Episode: 23441/30000 (78.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8156s / 709.5729 s
agent0:                 episode reward: -0.4455,                 loss: nan
agent1:                 episode reward: 0.4455,                 loss: 0.3597
Episode: 23461/30000 (78.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8242s / 710.3971 s
agent0:                 episode reward: -0.5508,                 loss: nan
agent1:                 episode reward: 0.5508,                 loss: 0.3567
Episode: 23481/30000 (78.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8087s / 711.2058 s
agent0:                 episode reward: -0.5172,                 loss: nan
agent1:                 episode reward: 0.5172,                 loss: 0.3592
Episode: 23501/30000 (78.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8190s / 712.0248 s
agent0:                 episode reward: -0.4377,                 loss: nan
agent1:                 episode reward: 0.4377,                 loss: 0.3596
Episode: 23521/30000 (78.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8102s / 712.8350 s
agent0:                 episode reward: -0.8369,                 loss: nan
agent1:                 episode reward: 0.8369,                 loss: 0.3551
Episode: 23541/30000 (78.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.7997s / 713.6347 s
agent0:                 episode reward: -0.7411,                 loss: nan
agent1:                 episode reward: 0.7411,                 loss: 0.3566
Episode: 23561/30000 (78.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8116s / 714.4463 s
agent0:                 episode reward: -0.6534,                 loss: nan
agent1:                 episode reward: 0.6534,                 loss: 0.3589
Episode: 23581/30000 (78.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8091s / 715.2554 s
agent0:                 episode reward: -0.3396,                 loss: nan
agent1:                 episode reward: 0.3396,                 loss: 0.3588
Episode: 23601/30000 (78.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8117s / 716.0671 s
agent0:                 episode reward: -0.8970,                 loss: nan
agent1:                 episode reward: 0.8970,                 loss: 0.3568
Episode: 23621/30000 (78.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8074s / 716.8745 s
agent0:                 episode reward: -0.5424,                 loss: nan
agent1:                 episode reward: 0.5424,                 loss: 0.3571
Episode: 23641/30000 (78.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8190s / 717.6936 s
agent0:                 episode reward: -0.7335,                 loss: nan
agent1:                 episode reward: 0.7335,                 loss: 0.3568
Episode: 23661/30000 (78.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8163s / 718.5099 s
agent0:                 episode reward: -0.9357,                 loss: nan
agent1:                 episode reward: 0.9357,                 loss: 0.3568
Episode: 23681/30000 (78.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8153s / 719.3251 s
agent0:                 episode reward: -0.6569,                 loss: nan
agent1:                 episode reward: 0.6569,                 loss: 0.3428
Episode: 23701/30000 (79.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8097s / 720.1348 s
agent0:                 episode reward: -0.5657,                 loss: nan
agent1:                 episode reward: 0.5657,                 loss: 0.3305
Episode: 23721/30000 (79.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8318s / 720.9666 s
agent0:                 episode reward: -0.6953,                 loss: nan
agent1:                 episode reward: 0.6953,                 loss: 0.3341
Episode: 23741/30000 (79.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8190s / 721.7856 s
agent0:                 episode reward: -0.5128,                 loss: nan
agent1:                 episode reward: 0.5128,                 loss: 0.3335
Episode: 23761/30000 (79.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8148s / 722.6004 s
agent0:                 episode reward: -0.7513,                 loss: nan
agent1:                 episode reward: 0.7513,                 loss: 0.3323
Episode: 23781/30000 (79.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8241s / 723.4245 s
agent0:                 episode reward: -0.5417,                 loss: nan
agent1:                 episode reward: 0.5417,                 loss: 0.3367
Episode: 23801/30000 (79.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8013s / 724.2259 s
agent0:                 episode reward: -0.5436,                 loss: nan
agent1:                 episode reward: 0.5436,                 loss: 0.3313
Episode: 23821/30000 (79.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8196s / 725.0455 s
agent0:                 episode reward: -0.1368,                 loss: nan
agent1:                 episode reward: 0.1368,                 loss: 0.3346
Episode: 23841/30000 (79.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8288s / 725.8743 s
agent0:                 episode reward: -0.7432,                 loss: nan
agent1:                 episode reward: 0.7432,                 loss: 0.3342
Episode: 23861/30000 (79.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8436s / 726.7179 s
agent0:                 episode reward: -0.4231,                 loss: nan
agent1:                 episode reward: 0.4231,                 loss: 0.3341
Episode: 23881/30000 (79.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8205s / 727.5384 s
agent0:                 episode reward: -0.8598,                 loss: nan
agent1:                 episode reward: 0.8598,                 loss: 0.3301
Episode: 23901/30000 (79.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8173s / 728.3557 s
agent0:                 episode reward: -0.4956,                 loss: nan
agent1:                 episode reward: 0.4956,                 loss: 0.3341
Episode: 23921/30000 (79.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8353s / 729.1910 s
agent0:                 episode reward: -0.9477,                 loss: nan
agent1:                 episode reward: 0.9477,                 loss: 0.3335
Episode: 23941/30000 (79.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8207s / 730.0117 s
agent0:                 episode reward: -0.6111,                 loss: nan
agent1:                 episode reward: 0.6111,                 loss: 0.3335
Episode: 23961/30000 (79.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8289s / 730.8406 s
agent0:                 episode reward: -0.4815,                 loss: nan
agent1:                 episode reward: 0.4815,                 loss: 0.3318
Episode: 23981/30000 (79.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8324s / 731.6730 s
agent0:                 episode reward: -0.7728,                 loss: nan
agent1:                 episode reward: 0.7728,                 loss: 0.3319
Episode: 24001/30000 (80.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8168s / 732.4898 s
agent0:                 episode reward: -0.5372,                 loss: nan
agent1:                 episode reward: 0.5372,                 loss: 0.3340
Episode: 24021/30000 (80.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8192s / 733.3090 s
agent0:                 episode reward: -0.6228,                 loss: nan
agent1:                 episode reward: 0.6228,                 loss: 0.3508
Episode: 24041/30000 (80.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8265s / 734.1355 s
agent0:                 episode reward: -0.5229,                 loss: nan
agent1:                 episode reward: 0.5229,                 loss: 0.3487
Episode: 24061/30000 (80.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8310s / 734.9665 s
agent0:                 episode reward: -0.3823,                 loss: nan
agent1:                 episode reward: 0.3823,                 loss: 0.3509
Episode: 24081/30000 (80.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8159s / 735.7824 s
agent0:                 episode reward: -0.3148,                 loss: nan
agent1:                 episode reward: 0.3148,                 loss: 0.3486
Episode: 24101/30000 (80.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8169s / 736.5994 s
agent0:                 episode reward: -0.4679,                 loss: nan
agent1:                 episode reward: 0.4679,                 loss: 0.3491
Episode: 24121/30000 (80.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8274s / 737.4268 s
agent0:                 episode reward: -0.7321,                 loss: nan
agent1:                 episode reward: 0.7321,                 loss: 0.3496
Episode: 24141/30000 (80.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8349s / 738.2617 s
agent0:                 episode reward: -0.5384,                 loss: nan
agent1:                 episode reward: 0.5384,                 loss: 0.3487
Episode: 24161/30000 (80.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8339s / 739.0956 s
agent0:                 episode reward: -0.6145,                 loss: nan
agent1:                 episode reward: 0.6145,                 loss: 0.3477
Episode: 24181/30000 (80.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8314s / 739.9270 s
agent0:                 episode reward: -0.7666,                 loss: nan
agent1:                 episode reward: 0.7666,                 loss: 0.3487
Episode: 24201/30000 (80.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8390s / 740.7660 s
agent0:                 episode reward: -0.7201,                 loss: nan
agent1:                 episode reward: 0.7201,                 loss: 0.3454
Episode: 24221/30000 (80.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8248s / 741.5908 s
agent0:                 episode reward: -0.3498,                 loss: nan
agent1:                 episode reward: 0.3498,                 loss: 0.3509
Episode: 24241/30000 (80.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8296s / 742.4204 s
agent0:                 episode reward: -0.6038,                 loss: nan
agent1:                 episode reward: 0.6038,                 loss: 0.3482
Episode: 24261/30000 (80.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8496s / 743.2699 s
agent0:                 episode reward: -0.5868,                 loss: nan
agent1:                 episode reward: 0.5868,                 loss: 0.3491
Episode: 24281/30000 (80.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8293s / 744.0992 s
agent0:                 episode reward: -0.6488,                 loss: nan
agent1:                 episode reward: 0.6488,                 loss: 0.3513
Episode: 24301/30000 (81.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8284s / 744.9276 s
agent0:                 episode reward: -0.4775,                 loss: nan
agent1:                 episode reward: 0.4775,                 loss: 0.3475
Episode: 24321/30000 (81.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8517s / 745.7793 s
agent0:                 episode reward: -0.5614,                 loss: nan
agent1:                 episode reward: 0.5614,                 loss: 0.3466
Episode: 24341/30000 (81.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8320s / 746.6113 s
agent0:                 episode reward: -0.6367,                 loss: nan
agent1:                 episode reward: 0.6367,                 loss: 0.3546
Episode: 24361/30000 (81.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8369s / 747.4482 s
agent0:                 episode reward: -0.2571,                 loss: nan
agent1:                 episode reward: 0.2571,                 loss: 0.3544
Episode: 24381/30000 (81.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8440s / 748.2922 s
agent0:                 episode reward: -0.6798,                 loss: nan
agent1:                 episode reward: 0.6798,                 loss: 0.3566
Episode: 24401/30000 (81.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8260s / 749.1182 s
agent0:                 episode reward: -0.7001,                 loss: nan
agent1:                 episode reward: 0.7001,                 loss: 0.3580
Episode: 24421/30000 (81.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8426s / 749.9608 s
agent0:                 episode reward: -0.7075,                 loss: nan
agent1:                 episode reward: 0.7075,                 loss: 0.3542
Episode: 24441/30000 (81.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8362s / 750.7970 s
agent0:                 episode reward: -0.4734,                 loss: nan
agent1:                 episode reward: 0.4734,                 loss: 0.3553
Episode: 24461/30000 (81.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8278s / 751.6247 s
agent0:                 episode reward: -0.9161,                 loss: nan
agent1:                 episode reward: 0.9161,                 loss: 0.3574
Episode: 24481/30000 (81.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8346s / 752.4593 s
agent0:                 episode reward: -0.5284,                 loss: nan
agent1:                 episode reward: 0.5284,                 loss: 0.3545
Episode: 24501/30000 (81.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8367s / 753.2960 s
agent0:                 episode reward: -0.5571,                 loss: nan
agent1:                 episode reward: 0.5571,                 loss: 0.3571
Episode: 24521/30000 (81.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8399s / 754.1360 s
agent0:                 episode reward: -0.6598,                 loss: nan
agent1:                 episode reward: 0.6598,                 loss: 0.3560
Episode: 24541/30000 (81.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8322s / 754.9682 s
agent0:                 episode reward: -0.1575,                 loss: nan
agent1:                 episode reward: 0.1575,                 loss: 0.3532
Episode: 24561/30000 (81.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8282s / 755.7964 s
agent0:                 episode reward: -0.1718,                 loss: nan
agent1:                 episode reward: 0.1718,                 loss: 0.3552
Episode: 24581/30000 (81.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8551s / 756.6515 s
agent0:                 episode reward: -0.8553,                 loss: nan
agent1:                 episode reward: 0.8553,                 loss: 0.3534
Episode: 24601/30000 (82.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8491s / 757.5006 s
agent0:                 episode reward: -0.4786,                 loss: nan
agent1:                 episode reward: 0.4786,                 loss: 0.3572
Episode: 24621/30000 (82.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8361s / 758.3368 s
agent0:                 episode reward: -0.5649,                 loss: nan
agent1:                 episode reward: 0.5649,                 loss: 0.3557
Episode: 24641/30000 (82.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8580s / 759.1947 s
agent0:                 episode reward: -0.6369,                 loss: nan
agent1:                 episode reward: 0.6369,                 loss: 0.3533
Episode: 24661/30000 (82.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8464s / 760.0411 s
agent0:                 episode reward: -0.7341,                 loss: nan
agent1:                 episode reward: 0.7341,                 loss: 0.3528
Episode: 24681/30000 (82.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8448s / 760.8860 s
agent0:                 episode reward: -0.6335,                 loss: nan
agent1:                 episode reward: 0.6335,                 loss: 0.3415
Episode: 24701/30000 (82.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8532s / 761.7391 s
agent0:                 episode reward: -0.8410,                 loss: nan
agent1:                 episode reward: 0.8410,                 loss: 0.3295
Episode: 24721/30000 (82.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8494s / 762.5885 s
agent0:                 episode reward: -0.9155,                 loss: nan
agent1:                 episode reward: 0.9155,                 loss: 0.3258
Episode: 24741/30000 (82.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8442s / 763.4327 s
agent0:                 episode reward: -0.6273,                 loss: nan
agent1:                 episode reward: 0.6273,                 loss: 0.3282
Episode: 24761/30000 (82.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8394s / 764.2721 s
agent0:                 episode reward: -0.6021,                 loss: nan
agent1:                 episode reward: 0.6021,                 loss: 0.3264
Episode: 24781/30000 (82.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8542s / 765.1264 s
agent0:                 episode reward: -0.7992,                 loss: nan
agent1:                 episode reward: 0.7992,                 loss: 0.3313
Episode: 24801/30000 (82.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8461s / 765.9725 s
agent0:                 episode reward: -0.7180,                 loss: nan
agent1:                 episode reward: 0.7180,                 loss: 0.3280
Episode: 24821/30000 (82.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8413s / 766.8138 s
agent0:                 episode reward: -0.5820,                 loss: nan
agent1:                 episode reward: 0.5820,                 loss: 0.3285
Episode: 24841/30000 (82.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8562s / 767.6700 s
agent0:                 episode reward: -0.5897,                 loss: nan
agent1:                 episode reward: 0.5897,                 loss: 0.3279
Episode: 24861/30000 (82.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8357s / 768.5057 s
agent0:                 episode reward: -0.5516,                 loss: nan
agent1:                 episode reward: 0.5516,                 loss: 0.3286
Episode: 24881/30000 (82.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8516s / 769.3573 s
agent0:                 episode reward: -0.3583,                 loss: nan
agent1:                 episode reward: 0.3583,                 loss: 0.3267
Episode: 24901/30000 (83.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8494s / 770.2067 s
agent0:                 episode reward: -0.6615,                 loss: nan
agent1:                 episode reward: 0.6615,                 loss: 0.3295
Episode: 24921/30000 (83.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8454s / 771.0522 s
agent0:                 episode reward: -0.1523,                 loss: nan
agent1:                 episode reward: 0.1523,                 loss: 0.3275
Episode: 24941/30000 (83.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8433s / 771.8955 s
agent0:                 episode reward: -0.5665,                 loss: nan
agent1:                 episode reward: 0.5665,                 loss: 0.3288
Episode: 24961/30000 (83.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8433s / 772.7388 s
agent0:                 episode reward: -0.4246,                 loss: nan
agent1:                 episode reward: 0.4246,                 loss: 0.3303
Episode: 24981/30000 (83.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8435s / 773.5822 s
agent0:                 episode reward: -0.7688,                 loss: nan
agent1:                 episode reward: 0.7688,                 loss: 0.3294
Episode: 25001/30000 (83.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8331s / 774.4154 s
agent0:                 episode reward: -0.5561,                 loss: nan
agent1:                 episode reward: 0.5561,                 loss: 0.3319
Episode: 25021/30000 (83.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8436s / 775.2590 s
agent0:                 episode reward: -0.8060,                 loss: nan
agent1:                 episode reward: 0.8060,                 loss: 0.3581
Episode: 25041/30000 (83.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8513s / 776.1103 s
agent0:                 episode reward: -0.5131,                 loss: nan
agent1:                 episode reward: 0.5131,                 loss: 0.3526
Episode: 25061/30000 (83.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8571s / 776.9674 s
agent0:                 episode reward: -0.9291,                 loss: nan
agent1:                 episode reward: 0.9291,                 loss: 0.3557
Episode: 25081/30000 (83.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8531s / 777.8205 s
agent0:                 episode reward: -0.6328,                 loss: nan
agent1:                 episode reward: 0.6328,                 loss: 0.3571
Episode: 25101/30000 (83.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8340s / 778.6545 s
agent0:                 episode reward: -0.4642,                 loss: nan
agent1:                 episode reward: 0.4642,                 loss: 0.3563
Episode: 25121/30000 (83.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8407s / 779.4953 s
agent0:                 episode reward: -0.3674,                 loss: nan
agent1:                 episode reward: 0.3674,                 loss: 0.3581
Episode: 25141/30000 (83.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8541s / 780.3493 s
agent0:                 episode reward: -0.1680,                 loss: nan
agent1:                 episode reward: 0.1680,                 loss: 0.3568
Episode: 25161/30000 (83.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8635s / 781.2128 s
agent0:                 episode reward: -0.2273,                 loss: nan
agent1:                 episode reward: 0.2273,                 loss: 0.3574
Episode: 25181/30000 (83.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8501s / 782.0629 s
agent0:                 episode reward: -0.8979,                 loss: nan
agent1:                 episode reward: 0.8979,                 loss: 0.3563
Episode: 25201/30000 (84.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8561s / 782.9190 s
agent0:                 episode reward: -0.6966,                 loss: nan
agent1:                 episode reward: 0.6966,                 loss: 0.3551
Episode: 25221/30000 (84.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8632s / 783.7822 s
agent0:                 episode reward: -0.2724,                 loss: nan
agent1:                 episode reward: 0.2724,                 loss: 0.3579
Episode: 25241/30000 (84.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8451s / 784.6273 s
agent0:                 episode reward: -0.2411,                 loss: nan
agent1:                 episode reward: 0.2411,                 loss: 0.3584
Episode: 25261/30000 (84.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8567s / 785.4840 s
agent0:                 episode reward: -0.6127,                 loss: nan
agent1:                 episode reward: 0.6127,                 loss: 0.3565
Episode: 25281/30000 (84.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8447s / 786.3287 s
agent0:                 episode reward: -0.3355,                 loss: nan
agent1:                 episode reward: 0.3355,                 loss: 0.3575
Episode: 25301/30000 (84.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8781s / 787.2068 s
agent0:                 episode reward: -0.9530,                 loss: nan
agent1:                 episode reward: 0.9530,                 loss: 0.3580
Episode: 25321/30000 (84.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8648s / 788.0716 s
agent0:                 episode reward: -0.3700,                 loss: nan
agent1:                 episode reward: 0.3700,                 loss: 0.3561
Episode: 25341/30000 (84.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8624s / 788.9340 s
agent0:                 episode reward: -0.4836,                 loss: nan
agent1:                 episode reward: 0.4836,                 loss: 0.3575
Episode: 25361/30000 (84.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8530s / 789.7870 s
agent0:                 episode reward: -0.6245,                 loss: nan
agent1:                 episode reward: 0.6245,                 loss: 0.3470
Episode: 25381/30000 (84.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8468s / 790.6338 s
agent0:                 episode reward: -0.3257,                 loss: nan
agent1:                 episode reward: 0.3257,                 loss: 0.3509
Episode: 25401/30000 (84.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8627s / 791.4965 s
agent0:                 episode reward: -0.6790,                 loss: nan
agent1:                 episode reward: 0.6790,                 loss: 0.3508
Episode: 25421/30000 (84.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8509s / 792.3474 s
agent0:                 episode reward: -0.5582,                 loss: nan
agent1:                 episode reward: 0.5582,                 loss: 0.3534
Episode: 25441/30000 (84.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8575s / 793.2049 s
agent0:                 episode reward: -0.7672,                 loss: nan
agent1:                 episode reward: 0.7672,                 loss: 0.3492
Episode: 25461/30000 (84.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8642s / 794.0691 s
agent0:                 episode reward: -0.4641,                 loss: nan
agent1:                 episode reward: 0.4641,                 loss: 0.3500
Episode: 25481/30000 (84.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8525s / 794.9215 s
agent0:                 episode reward: -0.7316,                 loss: nan
agent1:                 episode reward: 0.7316,                 loss: 0.3499
Episode: 25501/30000 (85.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8488s / 795.7704 s
agent0:                 episode reward: -0.5001,                 loss: nan
agent1:                 episode reward: 0.5001,                 loss: 0.3517
Episode: 25521/30000 (85.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8554s / 796.6258 s
agent0:                 episode reward: -1.1830,                 loss: nan
agent1:                 episode reward: 1.1830,                 loss: 0.3497
Episode: 25541/30000 (85.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8574s / 797.4832 s
agent0:                 episode reward: -0.3110,                 loss: nan
agent1:                 episode reward: 0.3110,                 loss: 0.3526
Episode: 25561/30000 (85.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8565s / 798.3396 s
agent0:                 episode reward: -0.6766,                 loss: nan
agent1:                 episode reward: 0.6766,                 loss: 0.3494
Episode: 25581/30000 (85.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8573s / 799.1969 s
agent0:                 episode reward: -0.6967,                 loss: nan
agent1:                 episode reward: 0.6967,                 loss: 0.3519
Episode: 25601/30000 (85.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8718s / 800.0687 s
agent0:                 episode reward: -0.4261,                 loss: nan
agent1:                 episode reward: 0.4261,                 loss: 0.3494
Episode: 25621/30000 (85.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8737s / 800.9424 s
agent0:                 episode reward: -1.0506,                 loss: nan
agent1:                 episode reward: 1.0506,                 loss: 0.3483
Episode: 25641/30000 (85.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8694s / 801.8118 s
agent0:                 episode reward: -0.2628,                 loss: nan
agent1:                 episode reward: 0.2628,                 loss: 0.3499
Episode: 25661/30000 (85.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8543s / 802.6661 s
agent0:                 episode reward: -0.5573,                 loss: nan
agent1:                 episode reward: 0.5573,                 loss: 0.3516
Episode: 25681/30000 (85.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8498s / 803.5159 s
agent0:                 episode reward: -0.5764,                 loss: nan
agent1:                 episode reward: 0.5764,                 loss: 0.3356
Episode: 25701/30000 (85.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8523s / 804.3683 s
agent0:                 episode reward: -0.3711,                 loss: nan
agent1:                 episode reward: 0.3711,                 loss: 0.3249
Episode: 25721/30000 (85.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8697s / 805.2379 s
agent0:                 episode reward: -0.3657,                 loss: nan
agent1:                 episode reward: 0.3657,                 loss: 0.3225
Episode: 25741/30000 (85.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8600s / 806.0979 s
agent0:                 episode reward: -0.6661,                 loss: nan
agent1:                 episode reward: 0.6661,                 loss: 0.3265
Episode: 25761/30000 (85.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8618s / 806.9598 s
agent0:                 episode reward: -0.4001,                 loss: nan
agent1:                 episode reward: 0.4001,                 loss: 0.3231
Episode: 25781/30000 (85.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8682s / 807.8279 s
agent0:                 episode reward: -0.7316,                 loss: nan
agent1:                 episode reward: 0.7316,                 loss: 0.3233
Episode: 25801/30000 (86.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8754s / 808.7033 s
agent0:                 episode reward: -0.5448,                 loss: nan
agent1:                 episode reward: 0.5448,                 loss: 0.3206
Episode: 25821/30000 (86.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8548s / 809.5582 s
agent0:                 episode reward: -0.7501,                 loss: nan
agent1:                 episode reward: 0.7501,                 loss: 0.3225
Episode: 25841/30000 (86.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8696s / 810.4278 s
agent0:                 episode reward: -0.5014,                 loss: nan
agent1:                 episode reward: 0.5014,                 loss: 0.3222
Episode: 25861/30000 (86.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8702s / 811.2980 s
agent0:                 episode reward: -0.5597,                 loss: nan
agent1:                 episode reward: 0.5597,                 loss: 0.3224
Episode: 25881/30000 (86.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8642s / 812.1622 s
agent0:                 episode reward: -0.5443,                 loss: nan
agent1:                 episode reward: 0.5443,                 loss: 0.3222
Episode: 25901/30000 (86.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8699s / 813.0321 s
agent0:                 episode reward: -0.3193,                 loss: nan
agent1:                 episode reward: 0.3193,                 loss: 0.3211
Episode: 25921/30000 (86.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8719s / 813.9040 s
agent0:                 episode reward: -0.6777,                 loss: nan
agent1:                 episode reward: 0.6777,                 loss: 0.3231
Episode: 25941/30000 (86.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8641s / 814.7681 s
agent0:                 episode reward: -0.6065,                 loss: nan
agent1:                 episode reward: 0.6065,                 loss: 0.3218
Episode: 25961/30000 (86.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8641s / 815.6322 s
agent0:                 episode reward: -0.7189,                 loss: nan
agent1:                 episode reward: 0.7189,                 loss: 0.3210
Episode: 25981/30000 (86.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8631s / 816.4953 s
agent0:                 episode reward: -0.5273,                 loss: nan
agent1:                 episode reward: 0.5273,                 loss: 0.3227
Episode: 26001/30000 (86.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8627s / 817.3581 s
agent0:                 episode reward: -0.0374,                 loss: nan
agent1:                 episode reward: 0.0374,                 loss: 0.3251
Episode: 26021/30000 (86.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8658s / 818.2239 s
agent0:                 episode reward: -0.4613,                 loss: nan
agent1:                 episode reward: 0.4613,                 loss: 0.3694
Episode: 26041/30000 (86.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8711s / 819.0950 s
agent0:                 episode reward: -0.8476,                 loss: nan
agent1:                 episode reward: 0.8476,                 loss: 0.3634
Episode: 26061/30000 (86.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8582s / 819.9532 s
agent0:                 episode reward: -0.5707,                 loss: nan
agent1:                 episode reward: 0.5707,                 loss: 0.3628
Episode: 26081/30000 (86.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8749s / 820.8281 s
agent0:                 episode reward: -0.7411,                 loss: nan
agent1:                 episode reward: 0.7411,                 loss: 0.3640
Episode: 26101/30000 (87.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8529s / 821.6810 s
agent0:                 episode reward: -0.6033,                 loss: nan
agent1:                 episode reward: 0.6033,                 loss: 0.3654
Episode: 26121/30000 (87.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8759s / 822.5569 s
agent0:                 episode reward: -0.4772,                 loss: nan
agent1:                 episode reward: 0.4772,                 loss: 0.3652
Episode: 26141/30000 (87.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8806s / 823.4375 s
agent0:                 episode reward: -0.6874,                 loss: nan
agent1:                 episode reward: 0.6874,                 loss: 0.3613
Episode: 26161/30000 (87.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8684s / 824.3059 s
agent0:                 episode reward: -0.5691,                 loss: nan
agent1:                 episode reward: 0.5691,                 loss: 0.3635
Episode: 26181/30000 (87.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8634s / 825.1693 s
agent0:                 episode reward: -0.6147,                 loss: nan
agent1:                 episode reward: 0.6147,                 loss: 0.3628
Episode: 26201/30000 (87.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8792s / 826.0485 s
agent0:                 episode reward: -0.3612,                 loss: nan
agent1:                 episode reward: 0.3612,                 loss: 0.3614
Episode: 26221/30000 (87.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8574s / 826.9059 s
agent0:                 episode reward: -0.6592,                 loss: nan
agent1:                 episode reward: 0.6592,                 loss: 0.3621
Episode: 26241/30000 (87.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8727s / 827.7786 s
agent0:                 episode reward: -0.3482,                 loss: nan
agent1:                 episode reward: 0.3482,                 loss: 0.3634
Episode: 26261/30000 (87.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8854s / 828.6639 s
agent0:                 episode reward: -0.5566,                 loss: nan
agent1:                 episode reward: 0.5566,                 loss: 0.3624
Episode: 26281/30000 (87.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8976s / 829.5616 s
agent0:                 episode reward: -0.5899,                 loss: nan
agent1:                 episode reward: 0.5899,                 loss: 0.3621
Episode: 26301/30000 (87.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8660s / 830.4276 s
agent0:                 episode reward: -0.5643,                 loss: nan
agent1:                 episode reward: 0.5643,                 loss: 0.3632
Episode: 26321/30000 (87.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8635s / 831.2911 s
agent0:                 episode reward: -0.7582,                 loss: nan
agent1:                 episode reward: 0.7582,                 loss: 0.3643
Episode: 26341/30000 (87.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8673s / 832.1584 s
agent0:                 episode reward: -0.6626,                 loss: nan
agent1:                 episode reward: 0.6626,                 loss: 0.3598
Episode: 26361/30000 (87.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8736s / 833.0320 s
agent0:                 episode reward: -0.8407,                 loss: nan
agent1:                 episode reward: 0.8407,                 loss: 0.3434
Episode: 26381/30000 (87.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8652s / 833.8973 s
agent0:                 episode reward: -0.5960,                 loss: nan
agent1:                 episode reward: 0.5960,                 loss: 0.3446
Episode: 26401/30000 (88.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8830s / 834.7803 s
agent0:                 episode reward: -0.6649,                 loss: nan
agent1:                 episode reward: 0.6649,                 loss: 0.3451
Episode: 26421/30000 (88.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8840s / 835.6643 s
agent0:                 episode reward: -0.6210,                 loss: nan
agent1:                 episode reward: 0.6210,                 loss: 0.3409
Episode: 26441/30000 (88.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8833s / 836.5476 s
agent0:                 episode reward: -0.8652,                 loss: nan
agent1:                 episode reward: 0.8652,                 loss: 0.3433
Episode: 26461/30000 (88.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8855s / 837.4331 s
agent0:                 episode reward: -0.7691,                 loss: nan
agent1:                 episode reward: 0.7691,                 loss: 0.3443
Episode: 26481/30000 (88.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8911s / 838.3242 s
agent0:                 episode reward: -0.5763,                 loss: nan
agent1:                 episode reward: 0.5763,                 loss: 0.3428
Episode: 26501/30000 (88.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8973s / 839.2216 s
agent0:                 episode reward: -0.1064,                 loss: nan
agent1:                 episode reward: 0.1064,                 loss: 0.3461
Episode: 26521/30000 (88.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8790s / 840.1006 s
agent0:                 episode reward: -0.3815,                 loss: nan
agent1:                 episode reward: 0.3815,                 loss: 0.3440
Episode: 26541/30000 (88.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8742s / 840.9747 s
agent0:                 episode reward: -0.3583,                 loss: nan
agent1:                 episode reward: 0.3583,                 loss: 0.3394
Episode: 26561/30000 (88.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8781s / 841.8529 s
agent0:                 episode reward: -0.3007,                 loss: nan
agent1:                 episode reward: 0.3007,                 loss: 0.3429
Episode: 26581/30000 (88.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8686s / 842.7215 s
agent0:                 episode reward: -0.2082,                 loss: nan
agent1:                 episode reward: 0.2082,                 loss: 0.3451
Episode: 26601/30000 (88.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8826s / 843.6040 s
agent0:                 episode reward: -0.4886,                 loss: nan
agent1:                 episode reward: 0.4886,                 loss: 0.3428
Episode: 26621/30000 (88.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8843s / 844.4884 s
agent0:                 episode reward: -0.4966,                 loss: nan
agent1:                 episode reward: 0.4966,                 loss: 0.3459
Episode: 26641/30000 (88.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9022s / 845.3906 s
agent0:                 episode reward: -0.8263,                 loss: nan
agent1:                 episode reward: 0.8263,                 loss: 0.3424
Episode: 26661/30000 (88.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8779s / 846.2684 s
agent0:                 episode reward: -0.9766,                 loss: nan
agent1:                 episode reward: 0.9766,                 loss: 0.3442
Episode: 26681/30000 (88.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8740s / 847.1425 s
agent0:                 episode reward: -0.6913,                 loss: nan
agent1:                 episode reward: 0.6913,                 loss: 0.3435
Episode: 26701/30000 (89.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8891s / 848.0315 s
agent0:                 episode reward: -0.6481,                 loss: nan
agent1:                 episode reward: 0.6481,                 loss: 0.3382
Episode: 26721/30000 (89.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8794s / 848.9110 s
agent0:                 episode reward: -0.4526,                 loss: nan
agent1:                 episode reward: 0.4526,                 loss: 0.3408
Episode: 26741/30000 (89.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8743s / 849.7853 s
agent0:                 episode reward: -0.6801,                 loss: nan
agent1:                 episode reward: 0.6801,                 loss: 0.3351
Episode: 26761/30000 (89.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8759s / 850.6612 s
agent0:                 episode reward: -0.7747,                 loss: nan
agent1:                 episode reward: 0.7747,                 loss: 0.3372
Episode: 26781/30000 (89.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8920s / 851.5532 s
agent0:                 episode reward: -0.5740,                 loss: nan
agent1:                 episode reward: 0.5740,                 loss: 0.3367
Episode: 26801/30000 (89.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8891s / 852.4423 s
agent0:                 episode reward: -0.8333,                 loss: nan
agent1:                 episode reward: 0.8333,                 loss: 0.3393
Episode: 26821/30000 (89.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8907s / 853.3329 s
agent0:                 episode reward: -0.7810,                 loss: nan
agent1:                 episode reward: 0.7810,                 loss: 0.3372
Episode: 26841/30000 (89.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8914s / 854.2243 s
agent0:                 episode reward: -0.5787,                 loss: nan
agent1:                 episode reward: 0.5787,                 loss: 0.3375
Episode: 26861/30000 (89.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8816s / 855.1059 s
agent0:                 episode reward: -0.6086,                 loss: nan
agent1:                 episode reward: 0.6086,                 loss: 0.3394
Episode: 26881/30000 (89.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8888s / 855.9947 s
agent0:                 episode reward: -1.1556,                 loss: nan
agent1:                 episode reward: 1.1556,                 loss: 0.3387
Episode: 26901/30000 (89.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8792s / 856.8739 s
agent0:                 episode reward: -0.0629,                 loss: nan
agent1:                 episode reward: 0.0629,                 loss: 0.3378
Episode: 26921/30000 (89.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8840s / 857.7579 s
agent0:                 episode reward: -0.5176,                 loss: nan
agent1:                 episode reward: 0.5176,                 loss: 0.3386
Episode: 26941/30000 (89.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8932s / 858.6511 s
agent0:                 episode reward: -0.5134,                 loss: nan
agent1:                 episode reward: 0.5134,                 loss: 0.3386
Episode: 26961/30000 (89.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8785s / 859.5296 s
agent0:                 episode reward: -0.4685,                 loss: nan
agent1:                 episode reward: 0.4685,                 loss: 0.3394
Episode: 26981/30000 (89.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8711s / 860.4006 s
agent0:                 episode reward: -1.0295,                 loss: nan
agent1:                 episode reward: 1.0295,                 loss: 0.3398
Episode: 27001/30000 (90.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8979s / 861.2985 s
agent0:                 episode reward: -0.4722,                 loss: nan
agent1:                 episode reward: 0.4722,                 loss: 0.3377
Episode: 27021/30000 (90.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8872s / 862.1857 s
agent0:                 episode reward: -0.4182,                 loss: nan
agent1:                 episode reward: 0.4182,                 loss: 0.3637
Episode: 27041/30000 (90.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9013s / 863.0870 s
agent0:                 episode reward: -0.2064,                 loss: nan
agent1:                 episode reward: 0.2064,                 loss: 0.3621
Episode: 27061/30000 (90.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8728s / 863.9599 s
agent0:                 episode reward: -0.5263,                 loss: nan
agent1:                 episode reward: 0.5263,                 loss: 0.3629
Episode: 27081/30000 (90.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8765s / 864.8364 s
agent0:                 episode reward: -0.7503,                 loss: nan
agent1:                 episode reward: 0.7503,                 loss: 0.3587
Episode: 27101/30000 (90.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8852s / 865.7215 s
agent0:                 episode reward: -0.6860,                 loss: nan
agent1:                 episode reward: 0.6860,                 loss: 0.3599
Episode: 27121/30000 (90.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8942s / 866.6157 s
agent0:                 episode reward: -0.6970,                 loss: nan
agent1:                 episode reward: 0.6970,                 loss: 0.3621
Episode: 27141/30000 (90.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8881s / 867.5037 s
agent0:                 episode reward: -0.5471,                 loss: nan
agent1:                 episode reward: 0.5471,                 loss: 0.3595
Episode: 27161/30000 (90.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8967s / 868.4004 s
agent0:                 episode reward: -0.9366,                 loss: nan
agent1:                 episode reward: 0.9366,                 loss: 0.3600
Episode: 27181/30000 (90.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9181s / 869.3185 s
agent0:                 episode reward: -0.6793,                 loss: nan
agent1:                 episode reward: 0.6793,                 loss: 0.3629
Episode: 27201/30000 (90.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8920s / 870.2105 s
agent0:                 episode reward: -0.8127,                 loss: nan
agent1:                 episode reward: 0.8127,                 loss: 0.3596
Episode: 27221/30000 (90.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8863s / 871.0968 s
agent0:                 episode reward: -0.6588,                 loss: nan
agent1:                 episode reward: 0.6588,                 loss: 0.3611
Episode: 27241/30000 (90.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8966s / 871.9933 s
agent0:                 episode reward: -0.4868,                 loss: nan
agent1:                 episode reward: 0.4868,                 loss: 0.3602
Episode: 27261/30000 (90.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8961s / 872.8894 s
agent0:                 episode reward: -0.6496,                 loss: nan
agent1:                 episode reward: 0.6496,                 loss: 0.3601
Episode: 27281/30000 (90.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8908s / 873.7802 s
agent0:                 episode reward: -0.5599,                 loss: nan
agent1:                 episode reward: 0.5599,                 loss: 0.3603
Episode: 27301/30000 (91.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8930s / 874.6732 s
agent0:                 episode reward: -0.6609,                 loss: nan
agent1:                 episode reward: 0.6609,                 loss: 0.3606
Episode: 27321/30000 (91.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9019s / 875.5751 s
agent0:                 episode reward: -0.4284,                 loss: nan
agent1:                 episode reward: 0.4284,                 loss: 0.3599
Episode: 27341/30000 (91.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8878s / 876.4629 s
agent0:                 episode reward: -0.4750,                 loss: nan
agent1:                 episode reward: 0.4750,                 loss: 0.3562
Episode: 27361/30000 (91.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8958s / 877.3587 s
agent0:                 episode reward: -0.5822,                 loss: nan
agent1:                 episode reward: 0.5822,                 loss: 0.3420
Episode: 27381/30000 (91.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8819s / 878.2406 s
agent0:                 episode reward: -0.5814,                 loss: nan
agent1:                 episode reward: 0.5814,                 loss: 0.3413
Episode: 27401/30000 (91.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8909s / 879.1315 s
agent0:                 episode reward: -0.6955,                 loss: nan
agent1:                 episode reward: 0.6955,                 loss: 0.3384
Episode: 27421/30000 (91.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8955s / 880.0270 s
agent0:                 episode reward: -0.5515,                 loss: nan
agent1:                 episode reward: 0.5515,                 loss: 0.3406
Episode: 27441/30000 (91.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8894s / 880.9164 s
agent0:                 episode reward: -0.6958,                 loss: nan
agent1:                 episode reward: 0.6958,                 loss: 0.3407
Episode: 27461/30000 (91.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9025s / 881.8189 s
agent0:                 episode reward: -0.5628,                 loss: nan
agent1:                 episode reward: 0.5628,                 loss: 0.3405
Episode: 27481/30000 (91.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8914s / 882.7103 s
agent0:                 episode reward: -0.4364,                 loss: nan
agent1:                 episode reward: 0.4364,                 loss: 0.3404
Episode: 27501/30000 (91.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8967s / 883.6070 s
agent0:                 episode reward: -0.3865,                 loss: nan
agent1:                 episode reward: 0.3865,                 loss: 0.3416
Episode: 27521/30000 (91.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8917s / 884.4987 s
agent0:                 episode reward: -0.4083,                 loss: nan
agent1:                 episode reward: 0.4083,                 loss: 0.3422
Episode: 27541/30000 (91.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9121s / 885.4108 s
agent0:                 episode reward: -0.5019,                 loss: nan
agent1:                 episode reward: 0.5019,                 loss: 0.3389
Episode: 27561/30000 (91.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8987s / 886.3096 s
agent0:                 episode reward: -0.5334,                 loss: nan
agent1:                 episode reward: 0.5334,                 loss: 0.3428
Episode: 27581/30000 (91.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8954s / 887.2049 s
agent0:                 episode reward: -0.4850,                 loss: nan
agent1:                 episode reward: 0.4850,                 loss: 0.3447
Episode: 27601/30000 (92.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9208s / 888.1257 s
agent0:                 episode reward: -0.9373,                 loss: nan
agent1:                 episode reward: 0.9373,                 loss: 0.3461
Episode: 27621/30000 (92.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9042s / 889.0299 s
agent0:                 episode reward: -0.4874,                 loss: nan
agent1:                 episode reward: 0.4874,                 loss: 0.3425
Episode: 27641/30000 (92.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9093s / 889.9391 s
agent0:                 episode reward: -0.4703,                 loss: nan
agent1:                 episode reward: 0.4703,                 loss: 0.3423
Episode: 27661/30000 (92.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9180s / 890.8572 s
agent0:                 episode reward: -0.2393,                 loss: nan
agent1:                 episode reward: 0.2393,                 loss: 0.3424
Episode: 27681/30000 (92.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8949s / 891.7521 s
agent0:                 episode reward: -0.6120,                 loss: nan
agent1:                 episode reward: 0.6120,                 loss: 0.3422
Episode: 27701/30000 (92.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9225s / 892.6746 s
agent0:                 episode reward: -0.9253,                 loss: nan
agent1:                 episode reward: 0.9253,                 loss: 0.3376
Episode: 27721/30000 (92.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8980s / 893.5727 s
agent0:                 episode reward: -0.5505,                 loss: nan
agent1:                 episode reward: 0.5505,                 loss: 0.3406
Episode: 27741/30000 (92.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9208s / 894.4935 s
agent0:                 episode reward: -0.5505,                 loss: nan
agent1:                 episode reward: 0.5505,                 loss: 0.3413
Episode: 27761/30000 (92.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9194s / 895.4129 s
agent0:                 episode reward: -0.7699,                 loss: nan
agent1:                 episode reward: 0.7699,                 loss: 0.3388
Episode: 27781/30000 (92.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9065s / 896.3194 s
agent0:                 episode reward: -0.8690,                 loss: nan
agent1:                 episode reward: 0.8690,                 loss: 0.3399
Episode: 27801/30000 (92.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8929s / 897.2123 s
agent0:                 episode reward: -0.5426,                 loss: nan
agent1:                 episode reward: 0.5426,                 loss: 0.3391
Episode: 27821/30000 (92.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9038s / 898.1161 s
agent0:                 episode reward: -0.7067,                 loss: nan
agent1:                 episode reward: 0.7067,                 loss: 0.3404
Episode: 27841/30000 (92.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9153s / 899.0314 s
agent0:                 episode reward: -1.0432,                 loss: nan
agent1:                 episode reward: 1.0432,                 loss: 0.3416
Episode: 27861/30000 (92.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9080s / 899.9393 s
agent0:                 episode reward: -0.2940,                 loss: nan
agent1:                 episode reward: 0.2940,                 loss: 0.3391
Episode: 27881/30000 (92.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9129s / 900.8522 s
agent0:                 episode reward: -0.9952,                 loss: nan
agent1:                 episode reward: 0.9952,                 loss: 0.3404
Episode: 27901/30000 (93.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9019s / 901.7541 s
agent0:                 episode reward: -0.8376,                 loss: nan
agent1:                 episode reward: 0.8376,                 loss: 0.3419
Episode: 27921/30000 (93.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9106s / 902.6647 s
agent0:                 episode reward: -0.5147,                 loss: nan
agent1:                 episode reward: 0.5147,                 loss: 0.3440
Episode: 27941/30000 (93.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9045s / 903.5692 s
agent0:                 episode reward: -0.7591,                 loss: nan
agent1:                 episode reward: 0.7591,                 loss: 0.3367
Episode: 27961/30000 (93.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9173s / 904.4865 s
agent0:                 episode reward: -0.4479,                 loss: nan
agent1:                 episode reward: 0.4479,                 loss: 0.3374
Episode: 27981/30000 (93.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9089s / 905.3953 s
agent0:                 episode reward: -0.8570,                 loss: nan
agent1:                 episode reward: 0.8570,                 loss: 0.3425
Episode: 28001/30000 (93.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8965s / 906.2919 s
agent0:                 episode reward: -0.3875,                 loss: nan
agent1:                 episode reward: 0.3875,                 loss: 0.3414
Episode: 28021/30000 (93.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9003s / 907.1922 s
agent0:                 episode reward: -0.8854,                 loss: nan
agent1:                 episode reward: 0.8854,                 loss: 0.3614
Episode: 28041/30000 (93.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9013s / 908.0935 s
agent0:                 episode reward: -0.6675,                 loss: nan
agent1:                 episode reward: 0.6675,                 loss: 0.3593
Episode: 28061/30000 (93.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9018s / 908.9953 s
agent0:                 episode reward: -0.2742,                 loss: nan
agent1:                 episode reward: 0.2742,                 loss: 0.3596
Episode: 28081/30000 (93.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9023s / 909.8976 s
agent0:                 episode reward: -0.3925,                 loss: nan
agent1:                 episode reward: 0.3925,                 loss: 0.3596
Episode: 28101/30000 (93.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9152s / 910.8128 s
agent0:                 episode reward: -0.9964,                 loss: nan
agent1:                 episode reward: 0.9964,                 loss: 0.3607
Episode: 28121/30000 (93.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8959s / 911.7087 s
agent0:                 episode reward: -0.5020,                 loss: nan
agent1:                 episode reward: 0.5020,                 loss: 0.3590
Episode: 28141/30000 (93.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9041s / 912.6128 s
agent0:                 episode reward: -0.8753,                 loss: nan
agent1:                 episode reward: 0.8753,                 loss: 0.3607
Episode: 28161/30000 (93.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9098s / 913.5226 s
agent0:                 episode reward: -0.8617,                 loss: nan
agent1:                 episode reward: 0.8617,                 loss: 0.3610
Episode: 28181/30000 (93.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9307s / 914.4532 s
agent0:                 episode reward: -0.8218,                 loss: nan
agent1:                 episode reward: 0.8218,                 loss: 0.3570
Episode: 28201/30000 (94.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9072s / 915.3604 s
agent0:                 episode reward: -0.7181,                 loss: nan
agent1:                 episode reward: 0.7181,                 loss: 0.3570
Episode: 28221/30000 (94.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9177s / 916.2782 s
agent0:                 episode reward: -0.5705,                 loss: nan
agent1:                 episode reward: 0.5705,                 loss: 0.3568
Episode: 28241/30000 (94.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9258s / 917.2040 s
agent0:                 episode reward: -0.4871,                 loss: nan
agent1:                 episode reward: 0.4871,                 loss: 0.3620
Episode: 28261/30000 (94.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9086s / 918.1126 s
agent0:                 episode reward: -0.3781,                 loss: nan
agent1:                 episode reward: 0.3781,                 loss: 0.3579
Episode: 28281/30000 (94.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9017s / 919.0143 s
agent0:                 episode reward: -0.7848,                 loss: nan
agent1:                 episode reward: 0.7848,                 loss: 0.3596
Episode: 28301/30000 (94.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9322s / 919.9465 s
agent0:                 episode reward: -0.6040,                 loss: nan
agent1:                 episode reward: 0.6040,                 loss: 0.3610
Episode: 28321/30000 (94.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9107s / 920.8572 s
agent0:                 episode reward: -0.6596,                 loss: nan
agent1:                 episode reward: 0.6596,                 loss: 0.3591
Episode: 28341/30000 (94.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9142s / 921.7714 s
agent0:                 episode reward: -0.8219,                 loss: nan
agent1:                 episode reward: 0.8219,                 loss: 0.3548
Episode: 28361/30000 (94.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9424s / 922.7138 s
agent0:                 episode reward: -0.8277,                 loss: nan
agent1:                 episode reward: 0.8277,                 loss: 0.3343
Episode: 28381/30000 (94.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9154s / 923.6293 s
agent0:                 episode reward: -0.4290,                 loss: nan
agent1:                 episode reward: 0.4290,                 loss: 0.3317
Episode: 28401/30000 (94.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.8929s / 924.5221 s
agent0:                 episode reward: -0.8833,                 loss: nan
agent1:                 episode reward: 0.8833,                 loss: 0.3330
Episode: 28421/30000 (94.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9153s / 925.4375 s
agent0:                 episode reward: -0.6585,                 loss: nan
agent1:                 episode reward: 0.6585,                 loss: 0.3331
Episode: 28441/30000 (94.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9195s / 926.3569 s
agent0:                 episode reward: -0.4607,                 loss: nan
agent1:                 episode reward: 0.4607,                 loss: 0.3350
Episode: 28461/30000 (94.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9281s / 927.2850 s
agent0:                 episode reward: -0.6378,                 loss: nan
agent1:                 episode reward: 0.6378,                 loss: 0.3373
Episode: 28481/30000 (94.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9180s / 928.2030 s
agent0:                 episode reward: -0.4347,                 loss: nan
agent1:                 episode reward: 0.4347,                 loss: 0.3321
Episode: 28501/30000 (95.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9183s / 929.1213 s
agent0:                 episode reward: -0.5354,                 loss: nan
agent1:                 episode reward: 0.5354,                 loss: 0.3357
Episode: 28521/30000 (95.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9186s / 930.0399 s
agent0:                 episode reward: -0.7015,                 loss: nan
agent1:                 episode reward: 0.7015,                 loss: 0.3317
Episode: 28541/30000 (95.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9200s / 930.9599 s
agent0:                 episode reward: -0.5552,                 loss: nan
agent1:                 episode reward: 0.5552,                 loss: 0.3341
Episode: 28561/30000 (95.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9182s / 931.8781 s
agent0:                 episode reward: -0.9794,                 loss: nan
agent1:                 episode reward: 0.9794,                 loss: 0.3345
Episode: 28581/30000 (95.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9392s / 932.8172 s
agent0:                 episode reward: -0.9144,                 loss: nan
agent1:                 episode reward: 0.9144,                 loss: 0.3321
Episode: 28601/30000 (95.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9175s / 933.7347 s
agent0:                 episode reward: -0.6225,                 loss: nan
agent1:                 episode reward: 0.6225,                 loss: 0.3305
Episode: 28621/30000 (95.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9223s / 934.6570 s
agent0:                 episode reward: -0.3605,                 loss: nan
agent1:                 episode reward: 0.3605,                 loss: 0.3350
Episode: 28641/30000 (95.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9197s / 935.5767 s
agent0:                 episode reward: -0.5876,                 loss: nan
agent1:                 episode reward: 0.5876,                 loss: 0.3350
Episode: 28661/30000 (95.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9163s / 936.4931 s
agent0:                 episode reward: -0.7588,                 loss: nan
agent1:                 episode reward: 0.7588,                 loss: 0.3334
Episode: 28681/30000 (95.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9383s / 937.4314 s
agent0:                 episode reward: -0.7762,                 loss: nan
agent1:                 episode reward: 0.7762,                 loss: 0.3426
Episode: 28701/30000 (95.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9136s / 938.3450 s
agent0:                 episode reward: -0.9193,                 loss: nan
agent1:                 episode reward: 0.9193,                 loss: 0.3441
Episode: 28721/30000 (95.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9225s / 939.2675 s
agent0:                 episode reward: -0.7071,                 loss: nan
agent1:                 episode reward: 0.7071,                 loss: 0.3430
Episode: 28741/30000 (95.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9244s / 940.1919 s
agent0:                 episode reward: -0.6715,                 loss: nan
agent1:                 episode reward: 0.6715,                 loss: 0.3418
Episode: 28761/30000 (95.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9244s / 941.1163 s
agent0:                 episode reward: -0.3594,                 loss: nan
agent1:                 episode reward: 0.3594,                 loss: 0.3398
Episode: 28781/30000 (95.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9289s / 942.0452 s
agent0:                 episode reward: -0.8688,                 loss: nan
agent1:                 episode reward: 0.8688,                 loss: 0.3418
Episode: 28801/30000 (96.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9210s / 942.9662 s
agent0:                 episode reward: -0.3701,                 loss: nan
agent1:                 episode reward: 0.3701,                 loss: 0.3409
Episode: 28821/30000 (96.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9224s / 943.8887 s
agent0:                 episode reward: -0.6353,                 loss: nan
agent1:                 episode reward: 0.6353,                 loss: 0.3406
Episode: 28841/30000 (96.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9272s / 944.8158 s
agent0:                 episode reward: -0.7909,                 loss: nan
agent1:                 episode reward: 0.7909,                 loss: 0.3384
Episode: 28861/30000 (96.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9130s / 945.7288 s
agent0:                 episode reward: -0.6575,                 loss: nan
agent1:                 episode reward: 0.6575,                 loss: 0.3420
Episode: 28881/30000 (96.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9209s / 946.6497 s
agent0:                 episode reward: -0.7328,                 loss: nan
agent1:                 episode reward: 0.7328,                 loss: 0.3374
Episode: 28901/30000 (96.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9253s / 947.5750 s
agent0:                 episode reward: -0.2355,                 loss: nan
agent1:                 episode reward: 0.2355,                 loss: 0.3424
Episode: 28921/30000 (96.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9400s / 948.5150 s
agent0:                 episode reward: -0.3350,                 loss: nan
agent1:                 episode reward: 0.3350,                 loss: 0.3416
Episode: 28941/30000 (96.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9227s / 949.4377 s
agent0:                 episode reward: -0.6771,                 loss: nan
agent1:                 episode reward: 0.6771,                 loss: 0.3389
Episode: 28961/30000 (96.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9341s / 950.3718 s
agent0:                 episode reward: -0.5474,                 loss: nan
agent1:                 episode reward: 0.5474,                 loss: 0.3375
Episode: 28981/30000 (96.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9461s / 951.3179 s
agent0:                 episode reward: -0.5124,                 loss: nan
agent1:                 episode reward: 0.5124,                 loss: 0.3400
Episode: 29001/30000 (96.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9338s / 952.2517 s
agent0:                 episode reward: -0.5142,                 loss: nan
agent1:                 episode reward: 0.5142,                 loss: 0.3446
Episode: 29021/30000 (96.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9284s / 953.1801 s
agent0:                 episode reward: -0.6111,                 loss: nan
agent1:                 episode reward: 0.6111,                 loss: 0.3627
Episode: 29041/30000 (96.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9295s / 954.1097 s
agent0:                 episode reward: -0.7820,                 loss: nan
agent1:                 episode reward: 0.7820,                 loss: 0.3515
Episode: 29061/30000 (96.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9326s / 955.0422 s
agent0:                 episode reward: -0.7441,                 loss: nan
agent1:                 episode reward: 0.7441,                 loss: 0.3555
Episode: 29081/30000 (96.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9232s / 955.9654 s
agent0:                 episode reward: -0.4827,                 loss: nan
agent1:                 episode reward: 0.4827,                 loss: 0.3545
Episode: 29101/30000 (97.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9251s / 956.8905 s
agent0:                 episode reward: -0.6270,                 loss: nan
agent1:                 episode reward: 0.6270,                 loss: 0.3548
Episode: 29121/30000 (97.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9411s / 957.8316 s
agent0:                 episode reward: -0.9215,                 loss: nan
agent1:                 episode reward: 0.9215,                 loss: 0.3549
Episode: 29141/30000 (97.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9398s / 958.7714 s
agent0:                 episode reward: -0.5225,                 loss: nan
agent1:                 episode reward: 0.5225,                 loss: 0.3555
Episode: 29161/30000 (97.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9459s / 959.7174 s
agent0:                 episode reward: -0.4345,                 loss: nan
agent1:                 episode reward: 0.4345,                 loss: 0.3573
Episode: 29181/30000 (97.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9539s / 960.6713 s
agent0:                 episode reward: -0.4046,                 loss: nan
agent1:                 episode reward: 0.4046,                 loss: 0.3568
Episode: 29201/30000 (97.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9355s / 961.6067 s
agent0:                 episode reward: -0.7392,                 loss: nan
agent1:                 episode reward: 0.7392,                 loss: 0.3543
Episode: 29221/30000 (97.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9621s / 962.5689 s
agent0:                 episode reward: -0.8222,                 loss: nan
agent1:                 episode reward: 0.8222,                 loss: 0.3572
Episode: 29241/30000 (97.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9504s / 963.5193 s
agent0:                 episode reward: -0.7128,                 loss: nan
agent1:                 episode reward: 0.7128,                 loss: 0.3544
Episode: 29261/30000 (97.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9282s / 964.4475 s
agent0:                 episode reward: -0.5548,                 loss: nan
agent1:                 episode reward: 0.5548,                 loss: 0.3531
Episode: 29281/30000 (97.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9383s / 965.3858 s
agent0:                 episode reward: -0.4905,                 loss: nan
agent1:                 episode reward: 0.4905,                 loss: 0.3580
Episode: 29301/30000 (97.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9400s / 966.3258 s
agent0:                 episode reward: -0.2282,                 loss: nan
agent1:                 episode reward: 0.2282,                 loss: 0.3526
Episode: 29321/30000 (97.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9355s / 967.2613 s
agent0:                 episode reward: -0.7113,                 loss: nan
agent1:                 episode reward: 0.7113,                 loss: 0.3548
Episode: 29341/30000 (97.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9304s / 968.1917 s
agent0:                 episode reward: -0.4491,                 loss: nan
agent1:                 episode reward: 0.4491,                 loss: 0.3522
Episode: 29361/30000 (97.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9467s / 969.1384 s
agent0:                 episode reward: -0.9677,                 loss: nan
agent1:                 episode reward: 0.9677,                 loss: 0.3286
Episode: 29381/30000 (97.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9262s / 970.0646 s
agent0:                 episode reward: -0.7003,                 loss: nan
agent1:                 episode reward: 0.7003,                 loss: 0.3228
Episode: 29401/30000 (98.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9381s / 971.0026 s
agent0:                 episode reward: -0.7783,                 loss: nan
agent1:                 episode reward: 0.7783,                 loss: 0.3232
Episode: 29421/30000 (98.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9373s / 971.9399 s
agent0:                 episode reward: -0.3368,                 loss: nan
agent1:                 episode reward: 0.3368,                 loss: 0.3235
Episode: 29441/30000 (98.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9428s / 972.8827 s
agent0:                 episode reward: -0.8174,                 loss: nan
agent1:                 episode reward: 0.8174,                 loss: 0.3238
Episode: 29461/30000 (98.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9340s / 973.8167 s
agent0:                 episode reward: -0.7246,                 loss: nan
agent1:                 episode reward: 0.7246,                 loss: 0.3245
Episode: 29481/30000 (98.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9518s / 974.7685 s
agent0:                 episode reward: -0.3082,                 loss: nan
agent1:                 episode reward: 0.3082,                 loss: 0.3259
Episode: 29501/30000 (98.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9539s / 975.7224 s
agent0:                 episode reward: -0.7368,                 loss: nan
agent1:                 episode reward: 0.7368,                 loss: 0.3251
Episode: 29521/30000 (98.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9334s / 976.6558 s
agent0:                 episode reward: -0.4203,                 loss: nan
agent1:                 episode reward: 0.4203,                 loss: 0.3255
Episode: 29541/30000 (98.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9459s / 977.6017 s
agent0:                 episode reward: -0.6044,                 loss: nan
agent1:                 episode reward: 0.6044,                 loss: 0.3218
Episode: 29561/30000 (98.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9326s / 978.5342 s
agent0:                 episode reward: -0.5443,                 loss: nan
agent1:                 episode reward: 0.5443,                 loss: 0.3274
Episode: 29581/30000 (98.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9362s / 979.4704 s
agent0:                 episode reward: -0.7433,                 loss: nan
agent1:                 episode reward: 0.7433,                 loss: 0.3253
Episode: 29601/30000 (98.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9473s / 980.4178 s
agent0:                 episode reward: -0.7532,                 loss: nan
agent1:                 episode reward: 0.7532,                 loss: 0.3238
Episode: 29621/30000 (98.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9449s / 981.3627 s
agent0:                 episode reward: -0.5517,                 loss: nan
agent1:                 episode reward: 0.5517,                 loss: 0.3231/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 29641/30000 (98.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9737s / 982.3364 s
agent0:                 episode reward: -0.7463,                 loss: nan
agent1:                 episode reward: 0.7463,                 loss: 0.3245
Episode: 29661/30000 (98.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9641s / 983.3005 s
agent0:                 episode reward: -0.5517,                 loss: nan
agent1:                 episode reward: 0.5517,                 loss: 0.3247
Episode: 29681/30000 (98.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9392s / 984.2397 s
agent0:                 episode reward: -0.2930,                 loss: nan
agent1:                 episode reward: 0.2930,                 loss: 0.3424
Episode: 29701/30000 (99.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9469s / 985.1866 s
agent0:                 episode reward: -0.7988,                 loss: nan
agent1:                 episode reward: 0.7988,                 loss: 0.3487
Episode: 29721/30000 (99.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9450s / 986.1317 s
agent0:                 episode reward: -0.3129,                 loss: nan
agent1:                 episode reward: 0.3129,                 loss: 0.3490
Episode: 29741/30000 (99.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9669s / 987.0985 s
agent0:                 episode reward: -0.3949,                 loss: nan
agent1:                 episode reward: 0.3949,                 loss: 0.3461
Episode: 29761/30000 (99.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9510s / 988.0495 s
agent0:                 episode reward: -0.5957,                 loss: nan
agent1:                 episode reward: 0.5957,                 loss: 0.3489
Episode: 29781/30000 (99.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9540s / 989.0035 s
agent0:                 episode reward: -0.4420,                 loss: nan
agent1:                 episode reward: 0.4420,                 loss: 0.3480
Episode: 29801/30000 (99.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9552s / 989.9587 s
agent0:                 episode reward: -0.5534,                 loss: nan
agent1:                 episode reward: 0.5534,                 loss: 0.3479
Episode: 29821/30000 (99.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9587s / 990.9174 s
agent0:                 episode reward: -0.7163,                 loss: nan
agent1:                 episode reward: 0.7163,                 loss: 0.3476
Episode: 29841/30000 (99.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9464s / 991.8638 s
agent0:                 episode reward: -0.2242,                 loss: nan
agent1:                 episode reward: 0.2242,                 loss: 0.3466
Episode: 29861/30000 (99.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9513s / 992.8152 s
agent0:                 episode reward: -0.6964,                 loss: nan
agent1:                 episode reward: 0.6964,                 loss: 0.3494
Episode: 29881/30000 (99.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9378s / 993.7530 s
agent0:                 episode reward: -0.8674,                 loss: nan
agent1:                 episode reward: 0.8674,                 loss: 0.3501
Episode: 29901/30000 (99.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9634s / 994.7163 s
agent0:                 episode reward: -0.8948,                 loss: nan
agent1:                 episode reward: 0.8948,                 loss: 0.3487
Episode: 29921/30000 (99.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9391s / 995.6554 s
agent0:                 episode reward: -0.5807,                 loss: nan
agent1:                 episode reward: 0.5807,                 loss: 0.3478
Episode: 29941/30000 (99.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9355s / 996.5909 s
agent0:                 episode reward: -0.6031,                 loss: nan
agent1:                 episode reward: 0.6031,                 loss: 0.3511
Episode: 29961/30000 (99.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9138s / 997.5047 s
agent0:                 episode reward: -0.9200,                 loss: nan
agent1:                 episode reward: 0.9200,                 loss: 0.3476
Episode: 29981/30000 (99.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.9176s / 998.4223 s
agent0:                 episode reward: -0.6042,                 loss: nan
agent1:                 episode reward: 0.6042,                 loss: 0.3474
