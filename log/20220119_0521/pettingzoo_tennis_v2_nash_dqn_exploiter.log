pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
tennis_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'exploiter_update_itr': 3}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220119_0521/pettingzoo_tennis_v2_nash_dqn_exploiter. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0521/pettingzoo_tennis_v2_nash_dqn_exploiter.
Episode: 1/10000 (0.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 294.9157s / 294.9157 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0183
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0191
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 6447.6,                last time consumption/overall running time: 7470.5543s / 7765.4701 s
env0_first_0:                 episode reward: 16.2500,                 loss: 0.0164
env0_second_0:                 episode reward: -16.2500,                 loss: 0.0161
env1_first_0:                 episode reward: 16.4500,                 loss: nan
env1_second_0:                 episode reward: -16.4500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 4319.25,                last time consumption/overall running time: 5342.8373s / 13108.3074 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.0161
env0_second_0:                 episode reward: 8.4500,                 loss: 0.0151
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 2714.95,                last time consumption/overall running time: 3365.0834s / 16473.3908 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.0079
env0_second_0:                 episode reward: 11.2500,                 loss: 0.0060
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 1965.8,                last time consumption/overall running time: 2429.3328s / 18902.7236 s
env0_first_0:                 episode reward: -18.7000,                 loss: 0.0060
env0_second_0:                 episode reward: 18.7000,                 loss: 0.0046
env1_first_0:                 episode reward: -16.6000,                 loss: nan
env1_second_0:                 episode reward: 16.6000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 1897.55,                last time consumption/overall running time: 2343.7241s / 21246.4477 s
env0_first_0:                 episode reward: -20.5000,                 loss: 0.0063
env0_second_0:                 episode reward: 20.5000,                 loss: 0.0051
env1_first_0:                 episode reward: -19.1000,                 loss: nan
env1_second_0:                 episode reward: 19.1000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 1893.9,                last time consumption/overall running time: 2355.4313s / 23601.8790 s
env0_first_0:                 episode reward: -18.5000,                 loss: 0.0086
env0_second_0:                 episode reward: 18.5000,                 loss: 0.0070
env1_first_0:                 episode reward: -17.9500,                 loss: nan
env1_second_0:                 episode reward: 17.9500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 1688.75,                last time consumption/overall running time: 2107.6390s / 25709.5180 s
env0_first_0:                 episode reward: -21.4500,                 loss: 0.0096
env0_second_0:                 episode reward: 21.4500,                 loss: 0.0089
env1_first_0:                 episode reward: -22.6000,                 loss: nan
env1_second_0:                 episode reward: 22.6000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 1559.95,                last time consumption/overall running time: 1935.1001s / 27644.6181 s
env0_first_0:                 episode reward: -22.0000,                 loss: 0.0104
env0_second_0:                 episode reward: 22.0000,                 loss: 0.0100
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 1557.85,                last time consumption/overall running time: 1935.8696s / 29580.4876 s
env0_first_0:                 episode reward: -22.7500,                 loss: 0.0100
env0_second_0:                 episode reward: 22.7500,                 loss: 0.0092
env1_first_0:                 episode reward: -23.8000,                 loss: nan
env1_second_0:                 episode reward: 23.8000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 1629.6,                last time consumption/overall running time: 2035.8774s / 31616.3650 s
env0_first_0:                 episode reward: -20.6500,                 loss: 0.0096
env0_second_0:                 episode reward: 20.6500,                 loss: 0.0096
env1_first_0:                 episode reward: -21.8500,                 loss: nan
env1_second_0:                 episode reward: 21.8500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 1657.2,                last time consumption/overall running time: 2070.6903s / 33687.0553 s
env0_first_0:                 episode reward: -19.7500,                 loss: 0.0099
env0_second_0:                 episode reward: 19.7500,                 loss: 0.0097
env1_first_0:                 episode reward: -21.3500,                 loss: nan
env1_second_0:                 episode reward: 21.3500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 1679.9,                last time consumption/overall running time: 2102.2103s / 35789.2657 s
env0_first_0:                 episode reward: -21.7500,                 loss: 0.0083
env0_second_0:                 episode reward: 21.7500,                 loss: 0.0088
env1_first_0:                 episode reward: -22.0000,                 loss: nan
env1_second_0:                 episode reward: 22.0000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 1584.65,                last time consumption/overall running time: 2022.1491s / 37811.4148 s
env0_first_0:                 episode reward: -22.6500,                 loss: 0.0074
env0_second_0:                 episode reward: 22.6500,                 loss: 0.0074
env1_first_0:                 episode reward: -22.6500,                 loss: nan
env1_second_0:                 episode reward: 22.6500,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 1566.15,                last time consumption/overall running time: 2290.0740s / 40101.4888 s
env0_first_0:                 episode reward: -20.1500,                 loss: 0.0073
env0_second_0:                 episode reward: 20.1500,                 loss: 0.0070
env1_first_0:                 episode reward: -21.7500,                 loss: nan
env1_second_0:                 episode reward: 21.7500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 1569.85,                last time consumption/overall running time: 2311.6472s / 42413.1359 s
env0_first_0:                 episode reward: -21.7500,                 loss: 0.0065
env0_second_0:                 episode reward: 21.7500,                 loss: 0.0073
env1_first_0:                 episode reward: -22.6000,                 loss: nan
env1_second_0:                 episode reward: 22.6000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 1460.5,                last time consumption/overall running time: 2148.3270s / 44561.4629 s
env0_first_0:                 episode reward: -24.3500,                 loss: 0.0057
env0_second_0:                 episode reward: 24.3500,                 loss: 0.0064
env1_first_0:                 episode reward: -23.8000,                 loss: nan
env1_second_0:                 episode reward: 23.8000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 1500.55,                last time consumption/overall running time: 2223.4883s / 46784.9512 s
env0_first_0:                 episode reward: -24.5500,                 loss: 0.0053
env0_second_0:                 episode reward: 24.5500,                 loss: 0.0049
env1_first_0:                 episode reward: -26.1500,                 loss: nan
env1_second_0:                 episode reward: 26.1500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 1569.25,                last time consumption/overall running time: 2323.9148s / 49108.8660 s
env0_first_0:                 episode reward: -24.3000,                 loss: 0.0059
env0_second_0:                 episode reward: 24.3000,                 loss: 0.0059
env1_first_0:                 episode reward: -25.2500,                 loss: nan
env1_second_0:                 episode reward: 25.2500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 1494.1,                last time consumption/overall running time: 2215.6603s / 51324.5264 s
env0_first_0:                 episode reward: -25.6500,                 loss: 0.0063
env0_second_0:                 episode reward: 25.6500,                 loss: 0.0066
env1_first_0:                 episode reward: -25.6500,                 loss: nan
env1_second_0:                 episode reward: 25.6500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 1524.25,                last time consumption/overall running time: 2264.3804s / 53588.9067 s
env0_first_0:                 episode reward: -23.4000,                 loss: 0.0061
env0_second_0:                 episode reward: 23.4000,                 loss: 0.0069
env1_first_0:                 episode reward: -24.9000,                 loss: nan
env1_second_0:                 episode reward: 24.9000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 1664.25,                last time consumption/overall running time: 2463.1008s / 56052.0075 s
env0_first_0:                 episode reward: -24.1500,                 loss: 0.0068
env0_second_0:                 episode reward: 24.1500,                 loss: 0.0080
env1_first_0:                 episode reward: -22.4500,                 loss: nan
env1_second_0:                 episode reward: 22.4500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 1613.95,                last time consumption/overall running time: 2382.5780s / 58434.5855 s
env0_first_0:                 episode reward: -25.8500,                 loss: 0.0078
env0_second_0:                 episode reward: 25.8500,                 loss: 0.0081
env1_first_0:                 episode reward: -24.5000,                 loss: nan
env1_second_0:                 episode reward: 24.5000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 1540.4,                last time consumption/overall running time: 2259.9303s / 60694.5158 s
env0_first_0:                 episode reward: -27.1000,                 loss: 0.0072
env0_second_0:                 episode reward: 27.1000,                 loss: 0.0083
env1_first_0:                 episode reward: -26.7000,                 loss: nan
env1_second_0:                 episode reward: 26.7000,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 1502.1,                last time consumption/overall running time: 2199.2007s / 62893.7165 s
env0_first_0:                 episode reward: -26.5500,                 loss: 0.0070
env0_second_0:                 episode reward: 26.5500,                 loss: 0.0080
env1_first_0:                 episode reward: -26.6500,                 loss: nan
env1_second_0:                 episode reward: 26.6500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 1560.55,                last time consumption/overall running time: 2281.3019s / 65175.0184 s
env0_first_0:                 episode reward: -26.6000,                 loss: 0.0077
env0_second_0:                 episode reward: 26.6000,                 loss: 0.0079
env1_first_0:                 episode reward: -25.8500,                 loss: nan
env1_second_0:                 episode reward: 25.8500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 1577.85,                last time consumption/overall running time: 2319.8800s / 67494.8985 s
env0_first_0:                 episode reward: -24.7500,                 loss: 0.0079
env0_second_0:                 episode reward: 24.7500,                 loss: 0.0081
env1_first_0:                 episode reward: -24.3000,                 loss: nan
env1_second_0:                 episode reward: 24.3000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 1562.35,                last time consumption/overall running time: 2301.7169s / 69796.6154 s
env0_first_0:                 episode reward: -25.1500,                 loss: 0.0074
env0_second_0:                 episode reward: 25.1500,                 loss: 0.0076
env1_first_0:                 episode reward: -24.9500,                 loss: nan
env1_second_0:                 episode reward: 24.9500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 1527.9,                last time consumption/overall running time: 2243.4123s / 72040.0277 s
env0_first_0:                 episode reward: -26.1000,                 loss: 0.0073
env0_second_0:                 episode reward: 26.1000,                 loss: 0.0075
env1_first_0:                 episode reward: -25.7000,                 loss: nan
env1_second_0:                 episode reward: 25.7000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 1614.3,                last time consumption/overall running time: 2367.2159s / 74407.2436 s
env0_first_0:                 episode reward: -25.6000,                 loss: 0.0073
env0_second_0:                 episode reward: 25.6000,                 loss: 0.0074
env1_first_0:                 episode reward: -26.3500,                 loss: nan
env1_second_0:                 episode reward: 26.3500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 1530.1,                last time consumption/overall running time: 2243.6396s / 76650.8832 s
env0_first_0:                 episode reward: -24.0500,                 loss: 0.0077
env0_second_0:                 episode reward: 24.0500,                 loss: 0.0069
env1_first_0:                 episode reward: -25.2000,                 loss: nan
env1_second_0:                 episode reward: 25.2000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 1549.75,                last time consumption/overall running time: 2280.3117s / 78931.1949 s
env0_first_0:                 episode reward: -26.0500,                 loss: 0.0073
env0_second_0:                 episode reward: 26.0500,                 loss: 0.0063
env1_first_0:                 episode reward: -25.9500,                 loss: nan
env1_second_0:                 episode reward: 25.9500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 1515.4,                last time consumption/overall running time: 2223.6516s / 81154.8465 s
env0_first_0:                 episode reward: -25.6000,                 loss: 0.0074
env0_second_0:                 episode reward: 25.6000,                 loss: 0.0064
env1_first_0:                 episode reward: -23.1000,                 loss: nan
env1_second_0:                 episode reward: 23.1000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 1519.55,                last time consumption/overall running time: 2238.3058s / 83393.1522 s
env0_first_0:                 episode reward: -26.4000,                 loss: 0.0073
env0_second_0:                 episode reward: 26.4000,                 loss: 0.0059
env1_first_0:                 episode reward: -24.3500,                 loss: nan
env1_second_0:                 episode reward: 24.3500,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 1521.25,                last time consumption/overall running time: 2233.4600s / 85626.6122 s
env0_first_0:                 episode reward: -25.1000,                 loss: 0.0073
env0_second_0:                 episode reward: 25.1000,                 loss: 0.0066
env1_first_0:                 episode reward: -24.0500,                 loss: nan
env1_second_0:                 episode reward: 24.0500,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 1662.7,                last time consumption/overall running time: 2452.6169s / 88079.2291 s
env0_first_0:                 episode reward: -24.3500,                 loss: 0.0078
env0_second_0:                 episode reward: 24.3500,                 loss: 0.0070
env1_first_0:                 episode reward: -24.3000,                 loss: nan
env1_second_0:                 episode reward: 24.3000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 1715.55,                last time consumption/overall running time: 2527.2900s / 90606.5191 s
env0_first_0:                 episode reward: -23.8500,                 loss: 0.0090
env0_second_0:                 episode reward: 23.8500,                 loss: 0.0085
env1_first_0:                 episode reward: -23.9500,                 loss: nan
env1_second_0:                 episode reward: 23.9500,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 1549.2,                last time consumption/overall running time: 2278.8996s / 92885.4186 s
env0_first_0:                 episode reward: -24.0500,                 loss: 0.0087
env0_second_0:                 episode reward: 24.0500,                 loss: 0.0072
env1_first_0:                 episode reward: -25.1000,                 loss: nan
env1_second_0:                 episode reward: 25.1000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 1516.05,                last time consumption/overall running time: 2248.4991s / 95133.9177 s
env0_first_0:                 episode reward: -26.4000,                 loss: 0.0079
env0_second_0:                 episode reward: 26.4000,                 loss: 0.0072
env1_first_0:                 episode reward: -26.3000,                 loss: nan
env1_second_0:                 episode reward: 26.3000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 1488.85,                last time consumption/overall running time: 2185.2189s / 97319.1366 s
env0_first_0:                 episode reward: -25.8000,                 loss: 0.0066
env0_second_0:                 episode reward: 25.8000,                 loss: 0.0065
env1_first_0:                 episode reward: -26.8500,                 loss: nan
env1_second_0:                 episode reward: 26.8500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 1470.6,                last time consumption/overall running time: 2136.2063s / 99455.3430 s
env0_first_0:                 episode reward: -24.9500,                 loss: 0.0064
env0_second_0:                 episode reward: 24.9500,                 loss: 0.0062
env1_first_0:                 episode reward: -25.4500,                 loss: nan
env1_second_0:                 episode reward: 25.4500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 1478.0,                last time consumption/overall running time: 2120.4187s / 101575.7617 s
env0_first_0:                 episode reward: -23.3500,                 loss: 0.0060
env0_second_0:                 episode reward: 23.3500,                 loss: 0.0064
env1_first_0:                 episode reward: -24.5500,                 loss: nan
env1_second_0:                 episode reward: 24.5500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 1469.5,                last time consumption/overall running time: 2131.4859s / 103707.2476 s
env0_first_0:                 episode reward: -24.8000,                 loss: 0.0056
env0_second_0:                 episode reward: 24.8000,                 loss: 0.0055
env1_first_0:                 episode reward: -24.8000,                 loss: nan
env1_second_0:                 episode reward: 24.8000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 1527.35,                last time consumption/overall running time: 2197.2442s / 105904.4918 s
env0_first_0:                 episode reward: -27.6500,                 loss: 0.0060
env0_second_0:                 episode reward: 27.6500,                 loss: 0.0055
env1_first_0:                 episode reward: -25.7000,                 loss: nan
env1_second_0:                 episode reward: 25.7000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 1534.9,                last time consumption/overall running time: 2211.1800s / 108115.6717 s
env0_first_0:                 episode reward: -27.6000,                 loss: 0.0063
env0_second_0:                 episode reward: 27.6000,                 loss: 0.0067
env1_first_0:                 episode reward: -27.6000,                 loss: nan
env1_second_0:                 episode reward: 27.6000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 1513.5,                last time consumption/overall running time: 2194.1467s / 110309.8184 s
env0_first_0:                 episode reward: -27.8500,                 loss: 0.0064
env0_second_0:                 episode reward: 27.8500,                 loss: 0.0064
env1_first_0:                 episode reward: -26.3000,                 loss: nan
env1_second_0:                 episode reward: 26.3000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 1576.45,                last time consumption/overall running time: 2279.2121s / 112589.0306 s
env0_first_0:                 episode reward: -26.8500,                 loss: 0.0065
env0_second_0:                 episode reward: 26.8500,                 loss: 0.0060
env1_first_0:                 episode reward: -26.9000,                 loss: nan
env1_second_0:                 episode reward: 26.9000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 1933.9,                last time consumption/overall running time: 2808.6963s / 115397.7269 s
env0_first_0:                 episode reward: -22.4000,                 loss: 0.0076
env0_second_0:                 episode reward: 22.4000,                 loss: 0.0084
env1_first_0:                 episode reward: -22.2000,                 loss: nan
env1_second_0:                 episode reward: 22.2000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 1805.45,                last time consumption/overall running time: 2610.2365s / 118007.9633 s
env0_first_0:                 episode reward: -22.1500,                 loss: 0.0069
env0_second_0:                 episode reward: 22.1500,                 loss: 0.0072
env1_first_0:                 episode reward: -23.6000,                 loss: nan
env1_second_0:                 episode reward: 23.6000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 1557.0,                last time consumption/overall running time: 2251.2305s / 120259.1938 s
env0_first_0:                 episode reward: -23.4000,                 loss: 0.0060
env0_second_0:                 episode reward: 23.4000,                 loss: 0.0070
env1_first_0:                 episode reward: -24.1000,                 loss: nan
env1_second_0:                 episode reward: 24.1000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 1654.5,                last time consumption/overall running time: 2390.0309s / 122649.2247 s
env0_first_0:                 episode reward: -25.1000,                 loss: 0.0063
env0_second_0:                 episode reward: 25.1000,                 loss: 0.0070
env1_first_0:                 episode reward: -26.5000,                 loss: nan
env1_second_0:                 episode reward: 26.5000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 1544.45,                last time consumption/overall running time: 2232.6863s / 124881.9110 s
env0_first_0:                 episode reward: -27.4000,                 loss: 0.0071
env0_second_0:                 episode reward: 27.4000,                 loss: 0.0073
env1_first_0:                 episode reward: -26.3000,                 loss: nan
env1_second_0:                 episode reward: 26.3000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 1552.5,                last time consumption/overall running time: 2235.0194s / 127116.9305 s
env0_first_0:                 episode reward: -26.0000,                 loss: 0.0062
env0_second_0:                 episode reward: 26.0000,                 loss: 0.0064
env1_first_0:                 episode reward: -25.6500,                 loss: nan
env1_second_0:                 episode reward: 25.6500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 1577.25,                last time consumption/overall running time: 2288.3205s / 129405.2510 s
env0_first_0:                 episode reward: -24.7500,                 loss: 0.0058
env0_second_0:                 episode reward: 24.7500,                 loss: 0.0071
env1_first_0:                 episode reward: -26.7000,                 loss: nan
env1_second_0:                 episode reward: 26.7000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 1569.3,                last time consumption/overall running time: 2266.5003s / 131671.7512 s
env0_first_0:                 episode reward: -25.0500,                 loss: 0.0062
env0_second_0:                 episode reward: 25.0500,                 loss: 0.0065
env1_first_0:                 episode reward: -24.7500,                 loss: nan
env1_second_0:                 episode reward: 24.7500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 1569.75,                last time consumption/overall running time: 2255.5042s / 133927.2554 s
env0_first_0:                 episode reward: -26.6000,                 loss: 0.0058
env0_second_0:                 episode reward: 26.6000,                 loss: 0.0066
env1_first_0:                 episode reward: -25.1000,                 loss: nan
env1_second_0:                 episode reward: 25.1000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 1528.45,                last time consumption/overall running time: 2212.7745s / 136140.0299 s
env0_first_0:                 episode reward: -27.7000,                 loss: 0.0074
env0_second_0:                 episode reward: 27.7000,                 loss: 0.0062
env1_first_0:                 episode reward: -26.9500,                 loss: nan
env1_second_0:                 episode reward: 26.9500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 1521.45,                last time consumption/overall running time: 2203.0800s / 138343.1099 s
env0_first_0:                 episode reward: -26.8500,                 loss: 0.0061
env0_second_0:                 episode reward: 26.8500,                 loss: 0.0059
env1_first_0:                 episode reward: -28.2000,                 loss: nan
env1_second_0:                 episode reward: 28.2000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 1540.75,                last time consumption/overall running time: 2205.5120s / 140548.6219 s
env0_first_0:                 episode reward: -27.8000,                 loss: 0.0061
env0_second_0:                 episode reward: 27.8000,                 loss: 0.0058
env1_first_0:                 episode reward: -27.6000,                 loss: nan
env1_second_0:                 episode reward: 27.6000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 1559.8,                last time consumption/overall running time: 2250.8251s / 142799.4470 s
env0_first_0:                 episode reward: -26.3000,                 loss: 0.0058
env0_second_0:                 episode reward: 26.3000,                 loss: 0.0055
env1_first_0:                 episode reward: -27.6000,                 loss: nan
env1_second_0:                 episode reward: 27.6000,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 1631.05,                last time consumption/overall running time: 2353.4536s / 145152.9006 s
env0_first_0:                 episode reward: -26.7000,                 loss: 0.0060
env0_second_0:                 episode reward: 26.7000,                 loss: 0.0063
env1_first_0:                 episode reward: -25.6500,                 loss: nan
env1_second_0:                 episode reward: 25.6500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 1549.15,                last time consumption/overall running time: 2189.5736s / 147342.4742 s
env0_first_0:                 episode reward: -26.9500,                 loss: 0.0069
env0_second_0:                 episode reward: 26.9500,                 loss: 0.0072
env1_first_0:                 episode reward: -25.1000,                 loss: nan
env1_second_0:                 episode reward: 25.1000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 1509.95,                last time consumption/overall running time: 2122.7807s / 149465.2549 s
env0_first_0:                 episode reward: -26.5000,                 loss: 0.0059
env0_second_0:                 episode reward: 26.5000,                 loss: 0.0059
env1_first_0:                 episode reward: -25.9000,                 loss: nan
env1_second_0:                 episode reward: 25.9000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 1477.25,                last time consumption/overall running time: 2066.5510s / 151531.8059 s
env0_first_0:                 episode reward: -25.2000,                 loss: 0.0053
env0_second_0:                 episode reward: 25.2000,                 loss: 0.0054
env1_first_0:                 episode reward: -28.0000,                 loss: nan
env1_second_0:                 episode reward: 28.0000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 1564.8,                last time consumption/overall running time: 2183.0695s / 153714.8754 s
env0_first_0:                 episode reward: -27.4500,                 loss: 0.0058
env0_second_0:                 episode reward: 27.4500,                 loss: 0.0060
env1_first_0:                 episode reward: -26.8000,                 loss: nan
env1_second_0:                 episode reward: 26.8000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 1559.5,                last time consumption/overall running time: 2163.0624s / 155877.9379 s
env0_first_0:                 episode reward: -26.4000,                 loss: 0.0064
env0_second_0:                 episode reward: 26.4000,                 loss: 0.0065
env1_first_0:                 episode reward: -25.9500,                 loss: nan
env1_second_0:                 episode reward: 25.9500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 1604.6,                last time consumption/overall running time: 2229.2288s / 158107.1667 s
env0_first_0:                 episode reward: -25.7500,                 loss: 0.0065
env0_second_0:                 episode reward: 25.7500,                 loss: 0.0071
env1_first_0:                 episode reward: -25.2500,                 loss: nan
env1_second_0:                 episode reward: 25.2500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 1558.05,                last time consumption/overall running time: 2171.7024s / 160278.8691 s
env0_first_0:                 episode reward: -26.4000,                 loss: 0.0065
env0_second_0:                 episode reward: 26.4000,                 loss: 0.0064
env1_first_0:                 episode reward: -26.9000,                 loss: nan
env1_second_0:                 episode reward: 26.9000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 1538.6,                last time consumption/overall running time: 2145.0687s / 162423.9378 s
env0_first_0:                 episode reward: -25.1000,                 loss: 0.0060
env0_second_0:                 episode reward: 25.1000,                 loss: 0.0064
env1_first_0:                 episode reward: -26.1500,                 loss: nan
env1_second_0:                 episode reward: 26.1500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 1577.55,                last time consumption/overall running time: 2183.0094s / 164606.9471 s
env0_first_0:                 episode reward: -25.7000,                 loss: 0.0063
env0_second_0:                 episode reward: 25.7000,                 loss: 0.0071
env1_first_0:                 episode reward: -24.8000,                 loss: nan
env1_second_0:                 episode reward: 24.8000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 1712.4,                last time consumption/overall running time: 2361.9860s / 166968.9331 s
env0_first_0:                 episode reward: -27.3000,                 loss: 0.0071
env0_second_0:                 episode reward: 27.3000,                 loss: 0.0075
env1_first_0:                 episode reward: -25.5500,                 loss: nan
env1_second_0:                 episode reward: 25.5500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 1749.6,                last time consumption/overall running time: 2404.6888s / 169373.6220 s
env0_first_0:                 episode reward: -26.5000,                 loss: 0.0071
env0_second_0:                 episode reward: 26.5000,                 loss: 0.0074
env1_first_0:                 episode reward: -25.5500,                 loss: nan
env1_second_0:                 episode reward: 25.5500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 1685.1,                last time consumption/overall running time: 2300.5360s / 171674.1580 s
env0_first_0:                 episode reward: -25.5500,                 loss: 0.0067
env0_second_0:                 episode reward: 25.5500,                 loss: 0.0071
env1_first_0:                 episode reward: -26.4500,                 loss: nan
env1_second_0:                 episode reward: 26.4500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 1697.9,                last time consumption/overall running time: 2332.9395s / 174007.0974 s
env0_first_0:                 episode reward: -25.9000,                 loss: 0.0063
env0_second_0:                 episode reward: 25.9000,                 loss: 0.0067
env1_first_0:                 episode reward: -26.2500,                 loss: nan
env1_second_0:                 episode reward: 26.2500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 1767.45,                last time consumption/overall running time: 2423.9349s / 176431.0324 s
env0_first_0:                 episode reward: -26.5000,                 loss: 0.0062
env0_second_0:                 episode reward: 26.5000,                 loss: 0.0066
env1_first_0:                 episode reward: -25.7500,                 loss: nan
env1_second_0:                 episode reward: 25.7500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 1702.3,                last time consumption/overall running time: 2350.5497s / 178781.5821 s
env0_first_0:                 episode reward: -22.9500,                 loss: 0.0059
env0_second_0:                 episode reward: 22.9500,                 loss: 0.0067
env1_first_0:                 episode reward: -24.1000,                 loss: nan
env1_second_0:                 episode reward: 24.1000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 1612.25,                last time consumption/overall running time: 2270.1575s / 181051.7395 s
env0_first_0:                 episode reward: -24.5000,                 loss: 0.0054
env0_second_0:                 episode reward: 24.5000,                 loss: 0.0051
env1_first_0:                 episode reward: -23.2500,                 loss: nan
env1_second_0:                 episode reward: 23.2500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 1636.85,                last time consumption/overall running time: 2299.7228s / 183351.4623 s
env0_first_0:                 episode reward: -25.2000,                 loss: 0.0052
env0_second_0:                 episode reward: 25.2000,                 loss: 0.0053
env1_first_0:                 episode reward: -25.3500,                 loss: nan
env1_second_0:                 episode reward: 25.3500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 1765.75,                last time consumption/overall running time: 2486.1751s / 185837.6374 s
env0_first_0:                 episode reward: -23.1500,                 loss: 0.0055
env0_second_0:                 episode reward: 23.1500,                 loss: 0.0060
env1_first_0:                 episode reward: -24.6000,                 loss: nan
env1_second_0:                 episode reward: 24.6000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 1683.45,                last time consumption/overall running time: 2358.4110s / 188196.0484 s
env0_first_0:                 episode reward: -24.1000,                 loss: 0.0058
env0_second_0:                 episode reward: 24.1000,                 loss: 0.0064
env1_first_0:                 episode reward: -25.5000,                 loss: nan
env1_second_0:                 episode reward: 25.5000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 1820.95,                last time consumption/overall running time: 2552.4708s / 190748.5192 s
env0_first_0:                 episode reward: -24.2000,                 loss: 0.0063
env0_second_0:                 episode reward: 24.2000,                 loss: 0.0070
env1_first_0:                 episode reward: -24.9500,                 loss: nan
env1_second_0:                 episode reward: 24.9500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 1781.45,                last time consumption/overall running time: 2459.8270s / 193208.3462 s
env0_first_0:                 episode reward: -27.3000,                 loss: 0.0068
env0_second_0:                 episode reward: 27.3000,                 loss: 0.0071
env1_first_0:                 episode reward: -25.7000,                 loss: nan
env1_second_0:                 episode reward: 25.7000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 1766.9,                last time consumption/overall running time: 2424.3576s / 195632.7039 s
env0_first_0:                 episode reward: -24.7500,                 loss: 0.0070
env0_second_0:                 episode reward: 24.7500,                 loss: 0.0070
env1_first_0:                 episode reward: -24.1000,                 loss: nan
env1_second_0:                 episode reward: 24.1000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 1847.85,                last time consumption/overall running time: 2509.9373s / 198142.6412 s
env0_first_0:                 episode reward: -23.5000,                 loss: 0.0060
env0_second_0:                 episode reward: 23.5000,                 loss: 0.0065
env1_first_0:                 episode reward: -22.9000,                 loss: nan
env1_second_0:                 episode reward: 22.9000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 1814.2,                last time consumption/overall running time: 2442.3884s / 200585.0295 s
env0_first_0:                 episode reward: -23.0500,                 loss: 0.0063
env0_second_0:                 episode reward: 23.0500,                 loss: 0.0061
env1_first_0:                 episode reward: -24.5000,                 loss: nan
env1_second_0:                 episode reward: 24.5000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 1741.15,                last time consumption/overall running time: 2278.2472s / 202863.2768 s
env0_first_0:                 episode reward: -23.4500,                 loss: 0.0058
env0_second_0:                 episode reward: 23.4500,                 loss: 0.0057
env1_first_0:                 episode reward: -23.6000,                 loss: nan
env1_second_0:                 episode reward: 23.6000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 1940.0,                last time consumption/overall running time: 2484.4362s / 205347.7130 s
env0_first_0:                 episode reward: -24.0000,                 loss: 0.0058
env0_second_0:                 episode reward: 24.0000,                 loss: 0.0061
env1_first_0:                 episode reward: -24.7500,                 loss: nan
env1_second_0:                 episode reward: 24.7500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 1920.5,                last time consumption/overall running time: 2455.4705s / 207803.1834 s
env0_first_0:                 episode reward: -21.6000,                 loss: 0.0063
env0_second_0:                 episode reward: 21.6000,                 loss: 0.0068
env1_first_0:                 episode reward: -19.3000,                 loss: nan
env1_second_0:                 episode reward: 19.3000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 2074.2,                last time consumption/overall running time: 2643.6941s / 210446.8776 s
env0_first_0:                 episode reward: -22.1500,                 loss: 0.0064
env0_second_0:                 episode reward: 22.1500,                 loss: 0.0081
env1_first_0:                 episode reward: -22.4000,                 loss: nan
env1_second_0:                 episode reward: 22.4000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 1947.1,                last time consumption/overall running time: 2481.0382s / 212927.9158 s
env0_first_0:                 episode reward: -23.3000,                 loss: 0.0056
env0_second_0:                 episode reward: 23.3000,                 loss: 0.0068
env1_first_0:                 episode reward: -21.3000,                 loss: nan
env1_second_0:                 episode reward: 21.3000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 1890.95,                last time consumption/overall running time: 2414.8677s / 215342.7835 s
env0_first_0:                 episode reward: -23.9500,                 loss: 0.0051
env0_second_0:                 episode reward: 23.9500,                 loss: 0.0058
env1_first_0:                 episode reward: -23.8000,                 loss: nan
env1_second_0:                 episode reward: 23.8000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 1757.75,                last time consumption/overall running time: 2221.6077s / 217564.3912 s
env0_first_0:                 episode reward: -22.5000,                 loss: 0.0053
env0_second_0:                 episode reward: 22.5000,                 loss: 0.0055
env1_first_0:                 episode reward: -24.5000,                 loss: nan
env1_second_0:                 episode reward: 24.5000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 1847.35,                last time consumption/overall running time: 2301.5846s / 219865.9757 s
env0_first_0:                 episode reward: -21.0000,                 loss: 0.0053
env0_second_0:                 episode reward: 21.0000,                 loss: 0.0052
env1_first_0:                 episode reward: -23.0500,                 loss: nan
env1_second_0:                 episode reward: 23.0500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 1893.3,                last time consumption/overall running time: 2364.3162s / 222230.2919 s
env0_first_0:                 episode reward: -21.7500,                 loss: 0.0053
env0_second_0:                 episode reward: 21.7500,                 loss: 0.0054
env1_first_0:                 episode reward: -22.7000,                 loss: nan
env1_second_0:                 episode reward: 22.7000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 2242.2,                last time consumption/overall running time: 2793.3154s / 225023.6073 s
env0_first_0:                 episode reward: -20.1000,                 loss: 0.0057
env0_second_0:                 episode reward: 20.1000,                 loss: 0.0059
env1_first_0:                 episode reward: -21.3000,                 loss: nan
env1_second_0:                 episode reward: 21.3000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 2626.3,                last time consumption/overall running time: 3260.3254s / 228283.9327 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.0057
env0_second_0:                 episode reward: 12.2000,                 loss: 0.0069
env1_first_0:                 episode reward: -12.9000,                 loss: nan
env1_second_0:                 episode reward: 12.9000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 2563.6,                last time consumption/overall running time: 3134.1371s / 231418.0698 s
env0_first_0:                 episode reward: -15.5000,                 loss: 0.0080
env0_second_0:                 episode reward: 15.5000,                 loss: 0.0095
env1_first_0:                 episode reward: -17.1000,                 loss: nan
env1_second_0:                 episode reward: 17.1000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 3164.1,                last time consumption/overall running time: 3872.4902s / 235290.5600 s
env0_first_0:                 episode reward: 14.3500,                 loss: 0.0107
env0_second_0:                 episode reward: -14.3500,                 loss: 0.0108
env1_first_0:                 episode reward: 5.4500,                 loss: nan
env1_second_0:                 episode reward: -5.4500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 2429.95,                last time consumption/overall running time: 2970.5481s / 238261.1081 s
env0_first_0:                 episode reward: -15.9500,                 loss: 0.0096
env0_second_0:                 episode reward: 15.9500,                 loss: 0.0104
env1_first_0:                 episode reward: -18.7000,                 loss: nan
env1_second_0:                 episode reward: 18.7000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 2219.8,                last time consumption/overall running time: 2717.8089s / 240978.9170 s
env0_first_0:                 episode reward: -21.0500,                 loss: 0.0069
env0_second_0:                 episode reward: 21.0500,                 loss: 0.0068
env1_first_0:                 episode reward: -23.0000,                 loss: nan
env1_second_0:                 episode reward: 23.0000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 2283.0,                last time consumption/overall running time: 2819.9316s / 243798.8486 s
env0_first_0:                 episode reward: -21.5000,                 loss: 0.0056
env0_second_0:                 episode reward: 21.5000,                 loss: 0.0058
env1_first_0:                 episode reward: -20.2500,                 loss: nan
env1_second_0:                 episode reward: 20.2500,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 2206.15,                last time consumption/overall running time: 2714.4581s / 246513.3067 s
env0_first_0:                 episode reward: -21.8000,                 loss: 0.0056
env0_second_0:                 episode reward: 21.8000,                 loss: 0.0055
env1_first_0:                 episode reward: -20.5000,                 loss: nan
env1_second_0:                 episode reward: 20.5000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 2224.95,                last time consumption/overall running time: 2737.2065s / 249250.5132 s
env0_first_0:                 episode reward: -23.4500,                 loss: 0.0047
env0_second_0:                 episode reward: 23.4500,                 loss: 0.0048
env1_first_0:                 episode reward: -22.0500,                 loss: nan
env1_second_0:                 episode reward: 22.0500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 2392.05,                last time consumption/overall running time: 2940.8032s / 252191.3164 s
env0_first_0:                 episode reward: -22.0500,                 loss: 0.0050
env0_second_0:                 episode reward: 22.0500,                 loss: 0.0053
env1_first_0:                 episode reward: -21.2000,                 loss: nan
env1_second_0:                 episode reward: 21.2000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 2144.6,                last time consumption/overall running time: 2605.7967s / 254797.1131 s
env0_first_0:                 episode reward: -23.9000,                 loss: 0.0052
env0_second_0:                 episode reward: 23.9000,                 loss: 0.0062
env1_first_0:                 episode reward: -21.0500,                 loss: nan
env1_second_0:                 episode reward: 21.0500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 2015.5,                last time consumption/overall running time: 2443.0747s / 257240.1878 s
env0_first_0:                 episode reward: -22.4500,                 loss: 0.0046
env0_second_0:                 episode reward: 22.4500,                 loss: 0.0057
env1_first_0:                 episode reward: -19.8000,                 loss: nan
env1_second_0:                 episode reward: 19.8000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 2334.1,                last time consumption/overall running time: 2790.5996s / 260030.7874 s
env0_first_0:                 episode reward: -21.4500,                 loss: 0.0054
env0_second_0:                 episode reward: 21.4500,                 loss: 0.0060
env1_first_0:                 episode reward: -22.6000,                 loss: nan
env1_second_0:                 episode reward: 22.6000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 2347.3,                last time consumption/overall running time: 2800.7395s / 262831.5269 s
env0_first_0:                 episode reward: -22.9500,                 loss: 0.0056
env0_second_0:                 episode reward: 22.9500,                 loss: 0.0068
env1_first_0:                 episode reward: -22.8500,                 loss: nan
env1_second_0:                 episode reward: 22.8500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 2166.4,                last time consumption/overall running time: 2597.2668s / 265428.7937 s
env0_first_0:                 episode reward: -22.3500,                 loss: 0.0056
env0_second_0:                 episode reward: 22.3500,                 loss: 0.0061
env1_first_0:                 episode reward: -24.0000,                 loss: nan
env1_second_0:                 episode reward: 24.0000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 2268.25,                last time consumption/overall running time: 2706.4463s / 268135.2401 s
env0_first_0:                 episode reward: -22.8500,                 loss: 0.0061
env0_second_0:                 episode reward: 22.8500,                 loss: 0.0063
env1_first_0:                 episode reward: -20.1500,                 loss: nan
env1_second_0:                 episode reward: 20.1500,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 2479.0,                last time consumption/overall running time: 2960.2757s / 271095.5158 s
env0_first_0:                 episode reward: -19.1500,                 loss: 0.0060
env0_second_0:                 episode reward: 19.1500,                 loss: 0.0065
env1_first_0:                 episode reward: -19.7000,                 loss: nan
env1_second_0:                 episode reward: 19.7000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 2042.85,                last time consumption/overall running time: 2440.6465s / 273536.1623 s
env0_first_0:                 episode reward: -22.3500,                 loss: 0.0053
env0_second_0:                 episode reward: 22.3500,                 loss: 0.0053
env1_first_0:                 episode reward: -24.0500,                 loss: nan
env1_second_0:                 episode reward: 24.0500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 2259.85,                last time consumption/overall running time: 2694.5569s / 276230.7191 s
env0_first_0:                 episode reward: -22.1500,                 loss: 0.0056
env0_second_0:                 episode reward: 22.1500,                 loss: 0.0053
env1_first_0:                 episode reward: -23.5000,                 loss: nan
env1_second_0:                 episode reward: 23.5000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 2714.05,                last time consumption/overall running time: 3227.2832s / 279458.0023 s
env0_first_0:                 episode reward: -21.5500,                 loss: 0.0058
env0_second_0:                 episode reward: 21.5500,                 loss: 0.0059
env1_first_0:                 episode reward: -22.0500,                 loss: nan
env1_second_0:                 episode reward: 22.0500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 2424.6,                last time consumption/overall running time: 2872.8984s / 282330.9007 s
env0_first_0:                 episode reward: -21.4000,                 loss: 0.0062
env0_second_0:                 episode reward: 21.4000,                 loss: 0.0060
env1_first_0:                 episode reward: -19.3500,                 loss: nan
env1_second_0:                 episode reward: 19.3500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 2404.5,                last time consumption/overall running time: 2844.5830s / 285175.4837 s
env0_first_0:                 episode reward: -20.0500,                 loss: 0.0065
env0_second_0:                 episode reward: 20.0500,                 loss: 0.0057
env1_first_0:                 episode reward: -19.5500,                 loss: nan
env1_second_0:                 episode reward: 19.5500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 2678.15,                last time consumption/overall running time: 3176.6013s / 288352.0850 s
env0_first_0:                 episode reward: -18.4000,                 loss: 0.0068
env0_second_0:                 episode reward: 18.4000,                 loss: 0.0077
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 2324.45,                last time consumption/overall running time: 2728.3631s / 291080.4481 s
env0_first_0:                 episode reward: -19.3000,                 loss: 0.0052
env0_second_0:                 episode reward: 19.3000,                 loss: 0.0064
env1_first_0:                 episode reward: -18.8000,                 loss: nan
env1_second_0:                 episode reward: 18.8000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 2487.2,                last time consumption/overall running time: 2871.8445s / 293952.2926 s
env0_first_0:                 episode reward: -19.1000,                 loss: 0.0053
env0_second_0:                 episode reward: 19.1000,                 loss: 0.0062
env1_first_0:                 episode reward: -21.7500,                 loss: nan
env1_second_0:                 episode reward: 21.7500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 2553.85,                last time consumption/overall running time: 2944.2991s / 296896.5917 s
env0_first_0:                 episode reward: -21.4500,                 loss: 0.0053
env0_second_0:                 episode reward: 21.4500,                 loss: 0.0063
env1_first_0:                 episode reward: -23.6000,                 loss: nan
env1_second_0:                 episode reward: 23.6000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 2132.1,                last time consumption/overall running time: 2473.9161s / 299370.5078 s
env0_first_0:                 episode reward: -20.8000,                 loss: 0.0049
env0_second_0:                 episode reward: 20.8000,                 loss: 0.0056
env1_first_0:                 episode reward: -21.2500,                 loss: nan
env1_second_0:                 episode reward: 21.2500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 2404.05,                last time consumption/overall running time: 2873.1385s / 302243.6463 s
env0_first_0:                 episode reward: -20.2000,                 loss: 0.0050
env0_second_0:                 episode reward: 20.2000,                 loss: 0.0055
env1_first_0:                 episode reward: -22.7500,                 loss: nan
env1_second_0:                 episode reward: 22.7500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 2624.2,                last time consumption/overall running time: 3106.0766s / 305349.7228 s
env0_first_0:                 episode reward: -17.6000,                 loss: 0.0053
env0_second_0:                 episode reward: 17.6000,                 loss: 0.0057
env1_first_0:                 episode reward: -16.2000,                 loss: nan
env1_second_0:                 episode reward: 16.2000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 2765.5,                last time consumption/overall running time: 3103.3911s / 308453.1139 s
env0_first_0:                 episode reward: -19.3500,                 loss: 0.0053
env0_second_0:                 episode reward: 19.3500,                 loss: 0.0071
env1_first_0:                 episode reward: -19.5500,                 loss: nan
env1_second_0:                 episode reward: 19.5500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 2528.2,                last time consumption/overall running time: 2959.3167s / 311412.4306 s
env0_first_0:                 episode reward: -22.4000,                 loss: 0.0060
env0_second_0:                 episode reward: 22.4000,                 loss: 0.0063
env1_first_0:                 episode reward: -19.8500,                 loss: nan
env1_second_0:                 episode reward: 19.8500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 3089.65,                last time consumption/overall running time: 3467.3875s / 314879.8181 s
env0_first_0:                 episode reward: -22.3500,                 loss: 0.0062
env0_second_0:                 episode reward: 22.3500,                 loss: 0.0068
env1_first_0:                 episode reward: -19.8000,                 loss: nan
env1_second_0:                 episode reward: 19.8000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 2530.5,                last time consumption/overall running time: 2774.1659s / 317653.9840 s
env0_first_0:                 episode reward: -23.1500,                 loss: 0.0066
env0_second_0:                 episode reward: 23.1500,                 loss: 0.0074
env1_first_0:                 episode reward: -20.9500,                 loss: nan
env1_second_0:                 episode reward: 20.9500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 1958.85,                last time consumption/overall running time: 2129.9087s / 319783.8927 s
env0_first_0:                 episode reward: -22.4000,                 loss: 0.0057
env0_second_0:                 episode reward: 22.4000,                 loss: 0.0063
env1_first_0:                 episode reward: -20.0500,                 loss: nan
env1_second_0:                 episode reward: 20.0500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 2096.15,                last time consumption/overall running time: 2279.0696s / 322062.9623 s
env0_first_0:                 episode reward: -17.2500,                 loss: 0.0054
env0_second_0:                 episode reward: 17.2500,                 loss: 0.0053
env1_first_0:                 episode reward: -18.4000,                 loss: nan
env1_second_0:                 episode reward: 18.4000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 2587.9,                last time consumption/overall running time: 2781.3704s / 324844.3326 s
env0_first_0:                 episode reward: -24.5000,                 loss: 0.0063
env0_second_0:                 episode reward: 24.5000,                 loss: 0.0066
env1_first_0:                 episode reward: -24.0500,                 loss: nan
env1_second_0:                 episode reward: 24.0500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 2816.4,                last time consumption/overall running time: 3033.3884s / 327877.7210 s
env0_first_0:                 episode reward: -24.4000,                 loss: 0.0061
env0_second_0:                 episode reward: 24.4000,                 loss: 0.0069
env1_first_0:                 episode reward: -24.4000,                 loss: nan
env1_second_0:                 episode reward: 24.4000,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 2533.95,                last time consumption/overall running time: 2733.9501s / 330611.6712 s
env0_first_0:                 episode reward: -23.2000,                 loss: 0.0066
env0_second_0:                 episode reward: 23.2000,                 loss: 0.0070
env1_first_0:                 episode reward: -24.2500,                 loss: nan
env1_second_0:                 episode reward: 24.2500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 2313.05,                last time consumption/overall running time: 2471.7269s / 333083.3980 s
env0_first_0:                 episode reward: -23.5500,                 loss: 0.0051
env0_second_0:                 episode reward: 23.5500,                 loss: 0.0058
env1_first_0:                 episode reward: -20.6000,                 loss: nan
env1_second_0:                 episode reward: 20.6000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 2405.35,                last time consumption/overall running time: 2553.4736s / 335636.8716 s
env0_first_0:                 episode reward: -21.9000,                 loss: 0.0048
env0_second_0:                 episode reward: 21.9000,                 loss: 0.0052
env1_first_0:                 episode reward: -21.2500,                 loss: nan
env1_second_0:                 episode reward: 21.2500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 2470.95,                last time consumption/overall running time: 2620.4446s / 338257.3161 s
env0_first_0:                 episode reward: -21.6500,                 loss: 0.0056
env0_second_0:                 episode reward: 21.6500,                 loss: 0.0058
env1_first_0:                 episode reward: -21.7000,                 loss: nan
env1_second_0:                 episode reward: 21.7000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 2648.4,                last time consumption/overall running time: 2800.4375s / 341057.7536 s
env0_first_0:                 episode reward: -18.7500,                 loss: 0.0063
env0_second_0:                 episode reward: 18.7500,                 loss: 0.0075
env1_first_0:                 episode reward: -21.2500,                 loss: nan
env1_second_0:                 episode reward: 21.2500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 3707.15,                last time consumption/overall running time: 3922.4077s / 344980.1613 s
env0_first_0:                 episode reward: -14.3000,                 loss: 0.0069
env0_second_0:                 episode reward: 14.3000,                 loss: 0.0074
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 3185.25,                last time consumption/overall running time: 3347.9771s / 348328.1384 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.0097
env0_second_0:                 episode reward: 13.0500,                 loss: 0.0099
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 2129.75,                last time consumption/overall running time: 2245.1101s / 350573.2485 s
env0_first_0:                 episode reward: -21.1000,                 loss: 0.0050
env0_second_0:                 episode reward: 21.1000,                 loss: 0.0057
env1_first_0:                 episode reward: -22.2500,                 loss: nan
env1_second_0:                 episode reward: 22.2500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 2078.5,                last time consumption/overall running time: 2171.9116s / 352745.1601 s
env0_first_0:                 episode reward: -23.3000,                 loss: 0.0049
env0_second_0:                 episode reward: 23.3000,                 loss: 0.0051
env1_first_0:                 episode reward: -21.7500,                 loss: nan
env1_second_0:                 episode reward: 21.7500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 2584.3,                last time consumption/overall running time: 2683.7321s / 355428.8922 s
env0_first_0:                 episode reward: -22.4000,                 loss: 0.0056
env0_second_0:                 episode reward: 22.4000,                 loss: 0.0064
env1_first_0:                 episode reward: -21.1500,                 loss: nan
env1_second_0:                 episode reward: 21.1500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 2758.5,                last time consumption/overall running time: 2870.9282s / 358299.8204 s
env0_first_0:                 episode reward: -20.5500,                 loss: 0.0059
env0_second_0:                 episode reward: 20.5500,                 loss: 0.0069
env1_first_0:                 episode reward: -20.2500,                 loss: nan
env1_second_0:                 episode reward: 20.2500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 3083.25,                last time consumption/overall running time: 3209.1315s / 361508.9519 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0064
env0_second_0:                 episode reward: 3.8000,                 loss: 0.0074
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 3227.8,                last time consumption/overall running time: 3355.1368s / 364864.0887 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0112
env0_second_0:                 episode reward: 4.4500,                 loss: 0.0125
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 2171.2,                last time consumption/overall running time: 2239.9733s / 367104.0620 s
env0_first_0:                 episode reward: -22.1000,                 loss: 0.0049
env0_second_0:                 episode reward: 22.1000,                 loss: 0.0069
env1_first_0:                 episode reward: -21.3500,                 loss: nan
env1_second_0:                 episode reward: 21.3500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 2842.7,                last time consumption/overall running time: 2917.3296s / 370021.3916 s
env0_first_0:                 episode reward: -19.1000,                 loss: 0.0054
env0_second_0:                 episode reward: 19.1000,                 loss: 0.0056
env1_first_0:                 episode reward: -20.5500,                 loss: nan
env1_second_0:                 episode reward: 20.5500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 2573.4,                last time consumption/overall running time: 2630.5730s / 372651.9645 s
env0_first_0:                 episode reward: -24.2500,                 loss: 0.0067
env0_second_0:                 episode reward: 24.2500,                 loss: 0.0063
env1_first_0:                 episode reward: -24.3000,                 loss: nan
env1_second_0:                 episode reward: 24.3000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 3073.0,                last time consumption/overall running time: 3104.0346s / 375755.9992 s
env0_first_0:                 episode reward: -24.4000,                 loss: 0.0068
env0_second_0:                 episode reward: 24.4000,                 loss: 0.0068
env1_first_0:                 episode reward: -21.1000,                 loss: nan
env1_second_0:                 episode reward: 21.1000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 2515.25,                last time consumption/overall running time: 2515.8456s / 378271.8448 s
env0_first_0:                 episode reward: -20.5500,                 loss: 0.0064
env0_second_0:                 episode reward: 20.5500,                 loss: 0.0069
env1_first_0:                 episode reward: -21.2500,                 loss: nan
env1_second_0:                 episode reward: 21.2500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 3123.35,                last time consumption/overall running time: 3146.1460s / 381417.9908 s
env0_first_0:                 episode reward: -20.5500,                 loss: 0.0060
env0_second_0:                 episode reward: 20.5500,                 loss: 0.0065
env1_first_0:                 episode reward: -20.7500,                 loss: nan
env1_second_0:                 episode reward: 20.7500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 2976.65,                last time consumption/overall running time: 2977.8216s / 384395.8124 s
env0_first_0:                 episode reward: -18.9500,                 loss: 0.0067
env0_second_0:                 episode reward: 18.9500,                 loss: 0.0069
env1_first_0:                 episode reward: -17.9000,                 loss: nan
env1_second_0:                 episode reward: 17.9000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 2760.3,                last time consumption/overall running time: 3024.4246s / 387420.2370 s
env0_first_0:                 episode reward: -18.3500,                 loss: 0.0069
env0_second_0:                 episode reward: 18.3500,                 loss: 0.0071
env1_first_0:                 episode reward: -15.6000,                 loss: nan
env1_second_0:                 episode reward: 15.6000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 3057.2,                last time consumption/overall running time: 3508.7757s / 390929.0127 s
env0_first_0:                 episode reward: -15.5000,                 loss: 0.0070
env0_second_0:                 episode reward: 15.5000,                 loss: 0.0075
env1_first_0:                 episode reward: -19.0500,                 loss: nan
env1_second_0:                 episode reward: 19.0500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 3172.15,                last time consumption/overall running time: 3611.8371s / 394540.8498 s
env0_first_0:                 episode reward: -19.2500,                 loss: 0.0063
env0_second_0:                 episode reward: 19.2500,                 loss: 0.0070
env1_first_0:                 episode reward: -21.5500,                 loss: nan
env1_second_0:                 episode reward: 21.5500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 3728.95,                last time consumption/overall running time: 4218.8582s / 398759.7080 s
env0_first_0:                 episode reward: -18.4000,                 loss: 0.0057
env0_second_0:                 episode reward: 18.4000,                 loss: 0.0063
env1_first_0:                 episode reward: -19.1500,                 loss: nan
env1_second_0:                 episode reward: 19.1500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 2990.65,                last time consumption/overall running time: 3364.0478s / 402123.7558 s
env0_first_0:                 episode reward: -20.6000,                 loss: 0.0060
env0_second_0:                 episode reward: 20.6000,                 loss: 0.0070
env1_first_0:                 episode reward: -17.9500,                 loss: nan
env1_second_0:                 episode reward: 17.9500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 3337.2,                last time consumption/overall running time: 3749.1660s / 405872.9218 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.0062
env0_second_0:                 episode reward: 14.8500,                 loss: 0.0073
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 3285.45,                last time consumption/overall running time: 3675.4057s / 409548.3275 s
env0_first_0:                 episode reward: -16.8500,                 loss: 0.0056
env0_second_0:                 episode reward: 16.8500,                 loss: 0.0066
env1_first_0:                 episode reward: -16.5500,                 loss: nan
env1_second_0:                 episode reward: 16.5500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 2526.85,                last time consumption/overall running time: 2798.8051s / 412347.1326 s
env0_first_0:                 episode reward: -18.0500,                 loss: 0.0054
env0_second_0:                 episode reward: 18.0500,                 loss: 0.0065
env1_first_0:                 episode reward: -21.0500,                 loss: nan
env1_second_0:                 episode reward: 21.0500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 2647.4,                last time consumption/overall running time: 2939.8114s / 415286.9440 s
env0_first_0:                 episode reward: -18.5500,                 loss: 0.0055
env0_second_0:                 episode reward: 18.5500,                 loss: 0.0066
env1_first_0:                 episode reward: -19.4000,                 loss: nan
env1_second_0:                 episode reward: 19.4000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 2622.3,                last time consumption/overall running time: 2916.1428s / 418203.0868 s
env0_first_0:                 episode reward: -19.4000,                 loss: 0.0054
env0_second_0:                 episode reward: 19.4000,                 loss: 0.0063
env1_first_0:                 episode reward: -20.0500,                 loss: nan
env1_second_0:                 episode reward: 20.0500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 3089.4,                last time consumption/overall running time: 3427.4925s / 421630.5793 s
env0_first_0:                 episode reward: -20.3500,                 loss: 0.0060
env0_second_0:                 episode reward: 20.3500,                 loss: 0.0063
env1_first_0:                 episode reward: -19.3500,                 loss: nan
env1_second_0:                 episode reward: 19.3500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 2719.45,                last time consumption/overall running time: 2986.1016s / 424616.6809 s
env0_first_0:                 episode reward: -23.0000,                 loss: 0.0055
env0_second_0:                 episode reward: 23.0000,                 loss: 0.0076
env1_first_0:                 episode reward: -20.4000,                 loss: nan
env1_second_0:                 episode reward: 20.4000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 3305.85,                last time consumption/overall running time: 3612.0248s / 428228.7057 s
env0_first_0:                 episode reward: -24.0500,                 loss: 0.0068
env0_second_0:                 episode reward: 24.0500,                 loss: 0.0073
env1_first_0:                 episode reward: -20.8000,                 loss: nan
env1_second_0:                 episode reward: 20.8000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 2970.5,                last time consumption/overall running time: 3253.2028s / 431481.9085 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.0068
env0_second_0:                 episode reward: 15.2500,                 loss: 0.0070
env1_first_0:                 episode reward: -21.1000,                 loss: nan
env1_second_0:                 episode reward: 21.1000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 3232.6,                last time consumption/overall running time: 3542.5454s / 435024.4539 s
env0_first_0:                 episode reward: -22.7000,                 loss: 0.0069
env0_second_0:                 episode reward: 22.7000,                 loss: 0.0067
env1_first_0:                 episode reward: -20.8000,                 loss: nan
env1_second_0:                 episode reward: 20.8000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 3258.15,                last time consumption/overall running time: 3548.5048s / 438572.9586 s
env0_first_0:                 episode reward: -20.2000,                 loss: 0.0061
env0_second_0:                 episode reward: 20.2000,                 loss: 0.0063
env1_first_0:                 episode reward: -21.2000,                 loss: nan
env1_second_0:                 episode reward: 21.2000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 3554.7,                last time consumption/overall running time: 3876.5495s / 442449.5081 s
env0_first_0:                 episode reward: -22.6500,                 loss: 0.0067
env0_second_0:                 episode reward: 22.6500,                 loss: 0.0068
env1_first_0:                 episode reward: -18.5500,                 loss: nan
env1_second_0:                 episode reward: 18.5500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 3286.75,                last time consumption/overall running time: 3571.6706s / 446021.1787 s
env0_first_0:                 episode reward: -20.8000,                 loss: 0.0070
env0_second_0:                 episode reward: 20.8000,                 loss: 0.0065
env1_first_0:                 episode reward: -22.3500,                 loss: nan
env1_second_0:                 episode reward: 22.3500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 3426.85,                last time consumption/overall running time: 3602.7433s / 449623.9221 s
env0_first_0:                 episode reward: -22.6500,                 loss: 0.0075
env0_second_0:                 episode reward: 22.6500,                 loss: 0.0069
env1_first_0:                 episode reward: -23.4000,                 loss: nan
env1_second_0:                 episode reward: 23.4000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 3317.6,                last time consumption/overall running time: 3425.4412s / 453049.3632 s
env0_first_0:                 episode reward: -22.2000,                 loss: 0.0073
env0_second_0:                 episode reward: 22.2000,                 loss: 0.0075
env1_first_0:                 episode reward: -15.1000,                 loss: nan
env1_second_0:                 episode reward: 15.1000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 3168.2,                last time consumption/overall running time: 3214.4408s / 456263.8040 s
env0_first_0:                 episode reward: -24.3000,                 loss: 0.0070
env0_second_0:                 episode reward: 24.3000,                 loss: 0.0070
env1_first_0:                 episode reward: -22.5500,                 loss: nan
env1_second_0:                 episode reward: 22.5500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 3139.7,                last time consumption/overall running time: 3104.6762s / 459368.4803 s
env0_first_0:                 episode reward: -23.0500,                 loss: 0.0056
env0_second_0:                 episode reward: 23.0500,                 loss: 0.0061
env1_first_0:                 episode reward: -22.4000,                 loss: nan
env1_second_0:                 episode reward: 22.4000,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 3587.05,                last time consumption/overall running time: 3549.2121s / 462917.6924 s
env0_first_0:                 episode reward: -22.2000,                 loss: 0.0062
env0_second_0:                 episode reward: 22.2000,                 loss: 0.0063
env1_first_0:                 episode reward: -21.7500,                 loss: nan
env1_second_0:                 episode reward: 21.7500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 2611.05,                last time consumption/overall running time: 2577.4202s / 465495.1126 s
env0_first_0:                 episode reward: -20.7500,                 loss: 0.0060
env0_second_0:                 episode reward: 20.7500,                 loss: 0.0067
env1_first_0:                 episode reward: -22.5000,                 loss: nan
env1_second_0:                 episode reward: 22.5000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 2358.8,                last time consumption/overall running time: 2500.1592s / 467995.2718 s
env0_first_0:                 episode reward: -17.2000,                 loss: 0.0053
env0_second_0:                 episode reward: 17.2000,                 loss: 0.0061
env1_first_0:                 episode reward: -23.4500,                 loss: nan
env1_second_0:                 episode reward: 23.4500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 2712.75,                last time consumption/overall running time: 3069.1998s / 471064.4715 s
env0_first_0:                 episode reward: -22.1500,                 loss: 0.0058
env0_second_0:                 episode reward: 22.1500,                 loss: 0.0064
env1_first_0:                 episode reward: -19.0000,                 loss: nan
env1_second_0:                 episode reward: 19.0000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 3287.55,                last time consumption/overall running time: 3720.4681s / 474784.9397 s
env0_first_0:                 episode reward: -22.8500,                 loss: 0.0071
env0_second_0:                 episode reward: 22.8500,                 loss: 0.0072
env1_first_0:                 episode reward: -23.0500,                 loss: nan
env1_second_0:                 episode reward: 23.0500,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 2852.75,                last time consumption/overall running time: 3226.5703s / 478011.5099 s
env0_first_0:                 episode reward: -19.8000,                 loss: 0.0072
env0_second_0:                 episode reward: 19.8000,                 loss: 0.0077
env1_first_0:                 episode reward: -17.8000,                 loss: nan
env1_second_0:                 episode reward: 17.8000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 3066.7,                last time consumption/overall running time: 3424.5187s / 481436.0286 s
env0_first_0:                 episode reward: -18.3000,                 loss: 0.0068
env0_second_0:                 episode reward: 18.3000,                 loss: 0.0068
env1_first_0:                 episode reward: -20.8000,                 loss: nan
env1_second_0:                 episode reward: 20.8000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 3039.7,                last time consumption/overall running time: 3373.8514s / 484809.8800 s
env0_first_0:                 episode reward: -21.1500,                 loss: 0.0056
env0_second_0:                 episode reward: 21.1500,                 loss: 0.0058
env1_first_0:                 episode reward: -21.4500,                 loss: nan
env1_second_0:                 episode reward: 21.4500,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 2415.6,                last time consumption/overall running time: 2676.4461s / 487486.3261 s
env0_first_0:                 episode reward: -21.7500,                 loss: 0.0055
env0_second_0:                 episode reward: 21.7500,                 loss: 0.0062
env1_first_0:                 episode reward: -21.0500,                 loss: nan
env1_second_0:                 episode reward: 21.0500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 3070.95,                last time consumption/overall running time: 3426.5519s / 490912.8780 s
env0_first_0:                 episode reward: -20.4000,                 loss: 0.0055
env0_second_0:                 episode reward: 20.4000,                 loss: 0.0067
env1_first_0:                 episode reward: -18.4500,                 loss: nan
env1_second_0:                 episode reward: 18.4500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 3104.2,                last time consumption/overall running time: 3459.3875s / 494372.2655 s
env0_first_0:                 episode reward: -20.7500,                 loss: 0.0060
env0_second_0:                 episode reward: 20.7500,                 loss: 0.0069
env1_first_0:                 episode reward: -20.2000,                 loss: nan
env1_second_0:                 episode reward: 20.2000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 3354.95,                last time consumption/overall running time: 3733.1722s / 498105.4377 s
env0_first_0:                 episode reward: -21.0000,                 loss: 0.0055
env0_second_0:                 episode reward: 21.0000,                 loss: 0.0064
env1_first_0:                 episode reward: -20.2000,                 loss: nan
env1_second_0:                 episode reward: 20.2000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 2941.55,                last time consumption/overall running time: 3271.3694s / 501376.8071 s
env0_first_0:                 episode reward: -19.0500,                 loss: 0.0053
env0_second_0:                 episode reward: 19.0500,                 loss: 0.0062
env1_first_0:                 episode reward: -21.0500,                 loss: nan
env1_second_0:                 episode reward: 21.0500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 2700.95,                last time consumption/overall running time: 3009.7644s / 504386.5715 s
env0_first_0:                 episode reward: -17.8500,                 loss: 0.0053
env0_second_0:                 episode reward: 17.8500,                 loss: 0.0061
env1_first_0:                 episode reward: -19.5500,                 loss: nan
env1_second_0:                 episode reward: 19.5500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 2881.3,                last time consumption/overall running time: 3206.6492s / 507593.2207 s
env0_first_0:                 episode reward: -22.3000,                 loss: 0.0055
env0_second_0:                 episode reward: 22.3000,                 loss: 0.0062
env1_first_0:                 episode reward: -20.4500,                 loss: nan
env1_second_0:                 episode reward: 20.4500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 3010.75,                last time consumption/overall running time: 4059.3128s / 511652.5335 s
env0_first_0:                 episode reward: -21.9500,                 loss: 0.0061
env0_second_0:                 episode reward: 21.9500,                 loss: 0.0067
env1_first_0:                 episode reward: -18.8500,                 loss: nan
env1_second_0:                 episode reward: 18.8500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 3215.75,                last time consumption/overall running time: 4833.8011s / 516486.3346 s
env0_first_0:                 episode reward: -21.7000,                 loss: 0.0066
env0_second_0:                 episode reward: 21.7000,                 loss: 0.0072
env1_first_0:                 episode reward: -21.9500,                 loss: nan
env1_second_0:                 episode reward: 21.9500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 3170.7,                last time consumption/overall running time: 4736.6655s / 521223.0001 s
env0_first_0:                 episode reward: -24.6500,                 loss: 0.0078
env0_second_0:                 episode reward: 24.6500,                 loss: 0.0081
env1_first_0:                 episode reward: -25.0500,                 loss: nan
env1_second_0:                 episode reward: 25.0500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 3677.7,                last time consumption/overall running time: 5405.6594s / 526628.6596 s
env0_first_0:                 episode reward: -16.0000,                 loss: 0.0079
env0_second_0:                 episode reward: 16.0000,                 loss: 0.0084
env1_first_0:                 episode reward: -16.7000,                 loss: nan
env1_second_0:                 episode reward: 16.7000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 2726.95,                last time consumption/overall running time: 3991.7535s / 530620.4131 s
env0_first_0:                 episode reward: -18.3500,                 loss: 0.0067
env0_second_0:                 episode reward: 18.3500,                 loss: 0.0068
env1_first_0:                 episode reward: -20.8500,                 loss: nan
env1_second_0:                 episode reward: 20.8500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 3063.95,                last time consumption/overall running time: 4484.0666s / 535104.4797 s
env0_first_0:                 episode reward: -20.7500,                 loss: 0.0067
env0_second_0:                 episode reward: 20.7500,                 loss: 0.0069
env1_first_0:                 episode reward: -21.2000,                 loss: nan
env1_second_0:                 episode reward: 21.2000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 2742.8,                last time consumption/overall running time: 3999.8167s / 539104.2964 s
env0_first_0:                 episode reward: -21.5000,                 loss: 0.0067
env0_second_0:                 episode reward: 21.5000,                 loss: 0.0071
env1_first_0:                 episode reward: -20.2500,                 loss: nan
env1_second_0:                 episode reward: 20.2500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 2769.15,                last time consumption/overall running time: 4006.5676s / 543110.8640 s
env0_first_0:                 episode reward: -15.8000,                 loss: 0.0066
env0_second_0:                 episode reward: 15.8000,                 loss: 0.0067
env1_first_0:                 episode reward: -20.6500,                 loss: nan
env1_second_0:                 episode reward: 20.6500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 3303.4,                last time consumption/overall running time: 4731.7192s / 547842.5832 s
env0_first_0:                 episode reward: -22.7000,                 loss: 0.0075
env0_second_0:                 episode reward: 22.7000,                 loss: 0.0073
env1_first_0:                 episode reward: -17.4000,                 loss: nan
env1_second_0:                 episode reward: 17.4000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 3171.1,                last time consumption/overall running time: 4517.8861s / 552360.4693 s
env0_first_0:                 episode reward: -18.3000,                 loss: 0.0069
env0_second_0:                 episode reward: 18.3000,                 loss: 0.0069
env1_first_0:                 episode reward: -19.8500,                 loss: nan
env1_second_0:                 episode reward: 19.8500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 3428.75,                last time consumption/overall running time: 4898.8477s / 557259.3170 s
env0_first_0:                 episode reward: -18.2500,                 loss: 0.0065
env0_second_0:                 episode reward: 18.2500,                 loss: 0.0066
env1_first_0:                 episode reward: -22.8500,                 loss: nan
env1_second_0:                 episode reward: 22.8500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 3710.05,                last time consumption/overall running time: 5207.4418s / 562466.7588 s
env0_first_0:                 episode reward: -21.1000,                 loss: 0.0071
env0_second_0:                 episode reward: 21.1000,                 loss: 0.0071
env1_first_0:                 episode reward: -16.2500,                 loss: nan
env1_second_0:                 episode reward: 16.2500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 2790.3,                last time consumption/overall running time: 3817.0596s / 566283.8184 s
env0_first_0:                 episode reward: -21.7500,                 loss: 0.0064
env0_second_0:                 episode reward: 21.7500,                 loss: 0.0068
env1_first_0:                 episode reward: -22.6500,                 loss: nan
env1_second_0:                 episode reward: 22.6500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 3032.0,                last time consumption/overall running time: 4145.6593s / 570429.4777 s
env0_first_0:                 episode reward: -19.7500,                 loss: 0.0077
env0_second_0:                 episode reward: 19.7500,                 loss: 0.0074
env1_first_0:                 episode reward: -19.1000,                 loss: nan
env1_second_0:                 episode reward: 19.1000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 2954.8,                last time consumption/overall running time: 4076.5957s / 574506.0734 s
env0_first_0:                 episode reward: -18.9000,                 loss: 0.0072
env0_second_0:                 episode reward: 18.9000,                 loss: 0.0071
env1_first_0:                 episode reward: -20.2000,                 loss: nan
env1_second_0:                 episode reward: 20.2000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 3002.45,                last time consumption/overall running time: 4091.2656s / 578597.3390 s
env0_first_0:                 episode reward: -22.1500,                 loss: 0.0059
env0_second_0:                 episode reward: 22.1500,                 loss: 0.0065
env1_first_0:                 episode reward: -19.7500,                 loss: nan
env1_second_0:                 episode reward: 19.7500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 3395.35,                last time consumption/overall running time: 4584.5385s / 583181.8774 s
env0_first_0:                 episode reward: -19.9500,                 loss: 0.0067
env0_second_0:                 episode reward: 19.9500,                 loss: 0.0062
env1_first_0:                 episode reward: -19.7500,                 loss: nan
env1_second_0:                 episode reward: 19.7500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 3295.2,                last time consumption/overall running time: 4309.6451s / 587491.5225 s
env0_first_0:                 episode reward: -20.1500,                 loss: 0.0069
env0_second_0:                 episode reward: 20.1500,                 loss: 0.0061
env1_first_0:                 episode reward: -21.3000,                 loss: nan
env1_second_0:                 episode reward: 21.3000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 3436.85,                last time consumption/overall running time: 4459.8218s / 591951.3443 s
env0_first_0:                 episode reward: -21.0500,                 loss: 0.0060
env0_second_0:                 episode reward: 21.0500,                 loss: 0.0059
env1_first_0:                 episode reward: -21.4000,                 loss: nan
env1_second_0:                 episode reward: 21.4000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 3453.1,                last time consumption/overall running time: 4461.6535s / 596412.9978 s
env0_first_0:                 episode reward: -17.8000,                 loss: 0.0065
env0_second_0:                 episode reward: 17.8000,                 loss: 0.0067
env1_first_0:                 episode reward: -22.9500,                 loss: nan
env1_second_0:                 episode reward: 22.9500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 3263.95,                last time consumption/overall running time: 4209.4945s / 600622.4923 s
env0_first_0:                 episode reward: -21.3500,                 loss: 0.0063
env0_second_0:                 episode reward: 21.3500,                 loss: 0.0067
env1_first_0:                 episode reward: -21.7500,                 loss: nan
env1_second_0:                 episode reward: 21.7500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 3036.9,                last time consumption/overall running time: 3922.7961s / 604545.2884 s
env0_first_0:                 episode reward: -16.0500,                 loss: 0.0063
env0_second_0:                 episode reward: 16.0500,                 loss: 0.0073
env1_first_0:                 episode reward: -18.6000,                 loss: nan
env1_second_0:                 episode reward: 18.6000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 2896.55,                last time consumption/overall running time: 3705.8452s / 608251.1336 s
env0_first_0:                 episode reward: -14.4500,                 loss: 0.0064
env0_second_0:                 episode reward: 14.4500,                 loss: 0.0079
env1_first_0:                 episode reward: -19.1000,                 loss: nan
env1_second_0:                 episode reward: 19.1000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 3647.45,                last time consumption/overall running time: 4617.6648s / 612868.7984 s
env0_first_0:                 episode reward: -18.1500,                 loss: 0.0055
env0_second_0:                 episode reward: 18.1500,                 loss: 0.0070
env1_first_0:                 episode reward: -21.4500,                 loss: nan
env1_second_0:                 episode reward: 21.4500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 2363.4,                last time consumption/overall running time: 2990.4113s / 615859.2097 s
env0_first_0:                 episode reward: -21.9500,                 loss: 0.0056
env0_second_0:                 episode reward: 21.9500,                 loss: 0.0065
env1_first_0:                 episode reward: -22.6000,                 loss: nan
env1_second_0:                 episode reward: 22.6000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 2525.65,                last time consumption/overall running time: 3151.4741s / 619010.6838 s
env0_first_0:                 episode reward: -21.1000,                 loss: 0.0056
env0_second_0:                 episode reward: 21.1000,                 loss: 0.0065
env1_first_0:                 episode reward: -22.6000,                 loss: nan
env1_second_0:                 episode reward: 22.6000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 2596.7,                last time consumption/overall running time: 3253.9928s / 622264.6766 s
env0_first_0:                 episode reward: -25.9000,                 loss: 0.0053
env0_second_0:                 episode reward: 25.9000,                 loss: 0.0064
env1_first_0:                 episode reward: -25.2500,                 loss: nan
env1_second_0:                 episode reward: 25.2500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 2748.85,                last time consumption/overall running time: 3365.9064s / 625630.5830 s
env0_first_0:                 episode reward: -22.6000,                 loss: 0.0053
env0_second_0:                 episode reward: 22.6000,                 loss: 0.0065
env1_first_0:                 episode reward: -21.8500,                 loss: nan
env1_second_0:                 episode reward: 21.8500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 3169.1,                last time consumption/overall running time: 3886.5596s / 629517.1426 s
env0_first_0:                 episode reward: -20.2500,                 loss: 0.0056
env0_second_0:                 episode reward: 20.2500,                 loss: 0.0067
env1_first_0:                 episode reward: -21.5000,                 loss: nan
env1_second_0:                 episode reward: 21.5000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 3704.6,                last time consumption/overall running time: 4401.0427s / 633918.1852 s
env0_first_0:                 episode reward: -17.8500,                 loss: 0.0068
env0_second_0:                 episode reward: 17.8500,                 loss: 0.0072
env1_first_0:                 episode reward: -19.6500,                 loss: nan
env1_second_0:                 episode reward: 19.6500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 3465.2,                last time consumption/overall running time: 4037.9437s / 637956.1290 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.0083
env0_second_0:                 episode reward: 13.0000,                 loss: 0.0086
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 3146.65,                last time consumption/overall running time: 3654.1987s / 641610.3277 s
env0_first_0:                 episode reward: -23.9000,                 loss: 0.0060
env0_second_0:                 episode reward: 23.9000,                 loss: 0.0067
env1_first_0:                 episode reward: -24.0500,                 loss: nan
env1_second_0:                 episode reward: 24.0500,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 2860.3,                last time consumption/overall running time: 3270.0168s / 644880.3445 s
env0_first_0:                 episode reward: -24.2000,                 loss: 0.0058
env0_second_0:                 episode reward: 24.2000,                 loss: 0.0065
env1_first_0:                 episode reward: -23.9000,                 loss: nan
env1_second_0:                 episode reward: 23.9000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 2885.1,                last time consumption/overall running time: 3204.5463s / 648084.8908 s
env0_first_0:                 episode reward: -21.2500,                 loss: 0.0060
env0_second_0:                 episode reward: 21.2500,                 loss: 0.0062
env1_first_0:                 episode reward: -21.7500,                 loss: nan
env1_second_0:                 episode reward: 21.7500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 2736.5,                last time consumption/overall running time: 2989.0591s / 651073.9499 s
env0_first_0:                 episode reward: -20.5000,                 loss: 0.0059
env0_second_0:                 episode reward: 20.5000,                 loss: 0.0055
env1_first_0:                 episode reward: -20.5000,                 loss: nan
env1_second_0:                 episode reward: 20.5000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 3041.85,                last time consumption/overall running time: 3336.1002s / 654410.0501 s
env0_first_0:                 episode reward: -16.7500,                 loss: 0.0054
env0_second_0:                 episode reward: 16.7500,                 loss: 0.0054
env1_first_0:                 episode reward: -19.5000,                 loss: nan
env1_second_0:                 episode reward: 19.5000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 2602.05,                last time consumption/overall running time: 2836.1950s / 657246.2451 s
env0_first_0:                 episode reward: -20.7500,                 loss: 0.0056
env0_second_0:                 episode reward: 20.7500,                 loss: 0.0060
env1_first_0:                 episode reward: -24.2500,                 loss: nan
env1_second_0:                 episode reward: 24.2500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 2931.7,                last time consumption/overall running time: 3189.9702s / 660436.2153 s
env0_first_0:                 episode reward: -20.8500,                 loss: 0.0065
env0_second_0:                 episode reward: 20.8500,                 loss: 0.0066
env1_first_0:                 episode reward: -23.0000,                 loss: nan
env1_second_0:                 episode reward: 23.0000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 3013.35,                last time consumption/overall running time: 3267.2729s / 663703.4882 s
env0_first_0:                 episode reward: -22.7500,                 loss: 0.0066
env0_second_0:                 episode reward: 22.7500,                 loss: 0.0065
env1_first_0:                 episode reward: -23.8500,                 loss: nan
env1_second_0:                 episode reward: 23.8500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 3590.5,                last time consumption/overall running time: 3900.8954s / 667604.3836 s
env0_first_0:                 episode reward: -21.7500,                 loss: 0.0064
env0_second_0:                 episode reward: 21.7500,                 loss: 0.0066
env1_first_0:                 episode reward: -21.2500,                 loss: nan
env1_second_0:                 episode reward: 21.2500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 3091.35,                last time consumption/overall running time: 3348.9262s / 670953.3099 s
env0_first_0:                 episode reward: -20.6000,                 loss: 0.0062
env0_second_0:                 episode reward: 20.6000,                 loss: 0.0060
env1_first_0:                 episode reward: -20.8500,                 loss: nan
env1_second_0:                 episode reward: 20.8500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 3283.25,                last time consumption/overall running time: 3508.7456s / 674462.0554 s
env0_first_0:                 episode reward: -19.6500,                 loss: 0.0064
env0_second_0:                 episode reward: 19.6500,                 loss: 0.0059
env1_first_0:                 episode reward: -19.3500,                 loss: nan
env1_second_0:                 episode reward: 19.3500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 2982.6,                last time consumption/overall running time: 3132.8518s / 677594.9072 s
env0_first_0:                 episode reward: -22.0000,                 loss: 0.0065
env0_second_0:                 episode reward: 22.0000,                 loss: 0.0059
env1_first_0:                 episode reward: -24.6500,                 loss: nan
env1_second_0:                 episode reward: 24.6500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 3002.5,                last time consumption/overall running time: 3108.5509s / 680703.4581 s
env0_first_0:                 episode reward: -20.2000,                 loss: 0.0057
env0_second_0:                 episode reward: 20.2000,                 loss: 0.0055
env1_first_0:                 episode reward: -20.0000,                 loss: nan
env1_second_0:                 episode reward: 20.0000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 2805.65,                last time consumption/overall running time: 2889.8904s / 683593.3485 s
env0_first_0:                 episode reward: -20.6500,                 loss: 0.0053
env0_second_0:                 episode reward: 20.6500,                 loss: 0.0051
env1_first_0:                 episode reward: -21.2500,                 loss: nan
env1_second_0:                 episode reward: 21.2500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 2874.05,                last time consumption/overall running time: 2909.7109s / 686503.0594 s
env0_first_0:                 episode reward: -21.0500,                 loss: 0.0059
env0_second_0:                 episode reward: 21.0500,                 loss: 0.0057
env1_first_0:                 episode reward: -21.1500,                 loss: nan
env1_second_0:                 episode reward: 21.1500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 2999.35,                last time consumption/overall running time: 3012.4199s / 689515.4793 s
env0_first_0:                 episode reward: -20.6000,                 loss: 0.0067
env0_second_0:                 episode reward: 20.6000,                 loss: 0.0062
env1_first_0:                 episode reward: -19.9500,                 loss: nan
env1_second_0:                 episode reward: 19.9500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 3281.5,                last time consumption/overall running time: 3293.3886s / 692808.8679 s
env0_first_0:                 episode reward: -21.4000,                 loss: 0.0070
env0_second_0:                 episode reward: 21.4000,                 loss: 0.0064
env1_first_0:                 episode reward: -21.7500,                 loss: nan
env1_second_0:                 episode reward: 21.7500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 3964.8,                last time consumption/overall running time: 3996.3771s / 696805.2450 s
env0_first_0:                 episode reward: -22.7500,                 loss: 0.0064
env0_second_0:                 episode reward: 22.7500,                 loss: 0.0061
env1_first_0:                 episode reward: -18.4000,                 loss: nan
env1_second_0:                 episode reward: 18.4000,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 3076.2,                last time consumption/overall running time: 3085.5131s / 699890.7581 s
env0_first_0:                 episode reward: -19.0500,                 loss: 0.0060
env0_second_0:                 episode reward: 19.0500,                 loss: 0.0064
env1_first_0:                 episode reward: -21.5500,                 loss: nan
env1_second_0:                 episode reward: 21.5500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 3860.15,                last time consumption/overall running time: 3836.5602s / 703727.3182 s
env0_first_0:                 episode reward: -19.6500,                 loss: 0.0061
env0_second_0:                 episode reward: 19.6500,                 loss: 0.0059
env1_first_0:                 episode reward: -19.1000,                 loss: nan
env1_second_0:                 episode reward: 19.1000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 4366.2,                last time consumption/overall running time: 4284.5736s / 708011.8918 s
env0_first_0:                 episode reward: -20.3500,                 loss: 0.0069
env0_second_0:                 episode reward: 20.3500,                 loss: 0.0065
env1_first_0:                 episode reward: -25.4000,                 loss: nan
env1_second_0:                 episode reward: 25.4000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 3627.7,                last time consumption/overall running time: 3551.0586s / 711562.9505 s
env0_first_0:                 episode reward: -22.6000,                 loss: 0.0062
env0_second_0:                 episode reward: 22.6000,                 loss: 0.0063
env1_first_0:                 episode reward: -23.1000,                 loss: nan
env1_second_0:                 episode reward: 23.1000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 3316.45,                last time consumption/overall running time: 3224.2779s / 714787.2283 s
env0_first_0:                 episode reward: -22.9500,                 loss: 0.0062
env0_second_0:                 episode reward: 22.9500,                 loss: 0.0063
env1_first_0:                 episode reward: -18.6000,                 loss: nan
env1_second_0:                 episode reward: 18.6000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 2962.5,                last time consumption/overall running time: 2864.2013s / 717651.4297 s
env0_first_0:                 episode reward: -21.7500,                 loss: 0.0056
env0_second_0:                 episode reward: 21.7500,                 loss: 0.0054
env1_first_0:                 episode reward: -20.7000,                 loss: nan
env1_second_0:                 episode reward: 20.7000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 3339.55,                last time consumption/overall running time: 3183.3441s / 720834.7738 s
env0_first_0:                 episode reward: -20.4500,                 loss: 0.0064
env0_second_0:                 episode reward: 20.4500,                 loss: 0.0061
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 3051.9,                last time consumption/overall running time: 2894.2108s / 723728.9846 s
env0_first_0:                 episode reward: -19.7500,                 loss: 0.0059
env0_second_0:                 episode reward: 19.7500,                 loss: 0.0059
env1_first_0:                 episode reward: -18.7000,                 loss: nan
env1_second_0:                 episode reward: 18.7000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 3049.55,                last time consumption/overall running time: 2851.8453s / 726580.8299 s
env0_first_0:                 episode reward: -18.7000,                 loss: 0.0060
env0_second_0:                 episode reward: 18.7000,                 loss: 0.0062
env1_first_0:                 episode reward: -18.4000,                 loss: nan
env1_second_0:                 episode reward: 18.4000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 3770.7,                last time consumption/overall running time: 3520.3501s / 730101.1800 s
env0_first_0:                 episode reward: -20.8500,                 loss: 0.0064
env0_second_0:                 episode reward: 20.8500,                 loss: 0.0063
env1_first_0:                 episode reward: -20.4500,                 loss: nan
env1_second_0:                 episode reward: 20.4500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 2780.1,                last time consumption/overall running time: 2662.3424s / 732763.5223 s
env0_first_0:                 episode reward: -22.7000,                 loss: 0.0068
env0_second_0:                 episode reward: 22.7000,                 loss: 0.0060
env1_first_0:                 episode reward: -21.8500,                 loss: nan
env1_second_0:                 episode reward: 21.8500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 3065.6,                last time consumption/overall running time: 2936.8437s / 735700.3660 s
env0_first_0:                 episode reward: -21.3500,                 loss: 0.0061
env0_second_0:                 episode reward: 21.3500,                 loss: 0.0061
env1_first_0:                 episode reward: -22.3500,                 loss: nan
env1_second_0:                 episode reward: 22.3500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 3453.3,                last time consumption/overall running time: 3282.5340s / 738982.9000 s
env0_first_0:                 episode reward: -23.3500,                 loss: 0.0070
env0_second_0:                 episode reward: 23.3500,                 loss: 0.0067
env1_first_0:                 episode reward: -22.7000,                 loss: nan
env1_second_0:                 episode reward: 22.7000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 3634.65,                last time consumption/overall running time: 3434.0223s / 742416.9224 s
env0_first_0:                 episode reward: -21.7000,                 loss: 0.0064
env0_second_0:                 episode reward: 21.7000,                 loss: 0.0062
env1_first_0:                 episode reward: -19.8000,                 loss: nan
env1_second_0:                 episode reward: 19.8000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 3091.2,                last time consumption/overall running time: 2841.8225s / 745258.7448 s
env0_first_0:                 episode reward: -23.7000,                 loss: 0.0063
env0_second_0:                 episode reward: 23.7000,                 loss: 0.0060
env1_first_0:                 episode reward: -20.5000,                 loss: nan
env1_second_0:                 episode reward: 20.5000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 3082.75,                last time consumption/overall running time: 2841.2354s / 748099.9802 s
env0_first_0:                 episode reward: -22.7500,                 loss: 0.0061
env0_second_0:                 episode reward: 22.7500,                 loss: 0.0061
env1_first_0:                 episode reward: -23.5500,                 loss: nan
env1_second_0:                 episode reward: 23.5500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 3445.15,                last time consumption/overall running time: 3154.2989s / 751254.2791 s
env0_first_0:                 episode reward: -21.4500,                 loss: 0.0056
env0_second_0:                 episode reward: 21.4500,                 loss: 0.0055
env1_first_0:                 episode reward: -21.2000,                 loss: nan
env1_second_0:                 episode reward: 21.2000,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 3468.9,                last time consumption/overall running time: 3133.3322s / 754387.6113 s
env0_first_0:                 episode reward: -16.5000,                 loss: 0.0057
env0_second_0:                 episode reward: 16.5000,                 loss: 0.0063
env1_first_0:                 episode reward: -21.1500,                 loss: nan
env1_second_0:                 episode reward: 21.1500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 3138.25,                last time consumption/overall running time: 2893.8769s / 757281.4882 s
env0_first_0:                 episode reward: -20.7000,                 loss: 0.0065
env0_second_0:                 episode reward: 20.7000,                 loss: 0.0062
env1_first_0:                 episode reward: -16.9000,                 loss: nan
env1_second_0:                 episode reward: 16.9000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 2876.5,                last time consumption/overall running time: 2661.5023s / 759942.9905 s
env0_first_0:                 episode reward: -21.4000,                 loss: 0.0057
env0_second_0:                 episode reward: 21.4000,                 loss: 0.0059
env1_first_0:                 episode reward: -23.3000,                 loss: nan
env1_second_0:                 episode reward: 23.3000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 3445.8,                last time consumption/overall running time: 3181.7494s / 763124.7399 s
env0_first_0:                 episode reward: -18.7500,                 loss: 0.0051
env0_second_0:                 episode reward: 18.7500,                 loss: 0.0054
env1_first_0:                 episode reward: -20.8500,                 loss: nan
env1_second_0:                 episode reward: 20.8500,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 3244.65,                last time consumption/overall running time: 2861.4289s / 765986.1687 s
env0_first_0:                 episode reward: -21.4000,                 loss: 0.0058
env0_second_0:                 episode reward: 21.4000,                 loss: 0.0068
env1_first_0:                 episode reward: -20.1000,                 loss: nan
env1_second_0:                 episode reward: 20.1000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 4135.15,                last time consumption/overall running time: 3625.2029s / 769611.3716 s
env0_first_0:                 episode reward: -18.6000,                 loss: 0.0055
env0_second_0:                 episode reward: 18.6000,                 loss: 0.0057
env1_first_0:                 episode reward: -19.4500,                 loss: nan
env1_second_0:                 episode reward: 19.4500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 4296.9,                last time consumption/overall running time: 3835.0674s / 773446.4390 s
env0_first_0:                 episode reward: -22.9000,                 loss: 0.0061
env0_second_0:                 episode reward: 22.9000,                 loss: 0.0062
env1_first_0:                 episode reward: -21.5000,                 loss: nan
env1_second_0:                 episode reward: 21.5000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 3538.7,                last time consumption/overall running time: 3205.2738s / 776651.7129 s
env0_first_0:                 episode reward: -19.2000,                 loss: 0.0063
env0_second_0:                 episode reward: 19.2000,                 loss: 0.0062
env1_first_0:                 episode reward: -15.8000,                 loss: nan
env1_second_0:                 episode reward: 15.8000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 3303.35,                last time consumption/overall running time: 2957.2038s / 779608.9166 s
env0_first_0:                 episode reward: -23.7500,                 loss: 0.0065
env0_second_0:                 episode reward: 23.7500,                 loss: 0.0065
env1_first_0:                 episode reward: -23.9500,                 loss: nan
env1_second_0:                 episode reward: 23.9500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 3134.5,                last time consumption/overall running time: 2809.3439s / 782418.2605 s
env0_first_0:                 episode reward: -20.8500,                 loss: 0.0059
env0_second_0:                 episode reward: 20.8500,                 loss: 0.0062
env1_first_0:                 episode reward: -22.0500,                 loss: nan
env1_second_0:                 episode reward: 22.0500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 3570.8,                last time consumption/overall running time: 3175.9350s / 785594.1955 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.0091
env0_second_0:                 episode reward: 7.8500,                 loss: 0.0090
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 3875.9,                last time consumption/overall running time: 3440.2318s / 789034.4274 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.0093
env0_second_0:                 episode reward: 12.2000,                 loss: 0.0087
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 3198.65,                last time consumption/overall running time: 2820.0118s / 791854.4391 s
env0_first_0:                 episode reward: -16.7000,                 loss: 0.0071
env0_second_0:                 episode reward: 16.7000,                 loss: 0.0070
env1_first_0:                 episode reward: -18.7500,                 loss: nan
env1_second_0:                 episode reward: 18.7500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 3133.55,                last time consumption/overall running time: 2776.8113s / 794631.2504 s
env0_first_0:                 episode reward: -17.8000,                 loss: 0.0065
env0_second_0:                 episode reward: 17.8000,                 loss: 0.0065
env1_first_0:                 episode reward: -17.4000,                 loss: nan
env1_second_0:                 episode reward: 17.4000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 3434.85,                last time consumption/overall running time: 3027.8131s / 797659.0634 s
env0_first_0:                 episode reward: -22.1500,                 loss: 0.0068
env0_second_0:                 episode reward: 22.1500,                 loss: 0.0069
env1_first_0:                 episode reward: -19.3000,                 loss: nan
env1_second_0:                 episode reward: 19.3000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 3318.55,                last time consumption/overall running time: 2915.2052s / 800574.2686 s
env0_first_0:                 episode reward: -21.3500,                 loss: 0.0066
env0_second_0:                 episode reward: 21.3500,                 loss: 0.0061
env1_first_0:                 episode reward: -22.8500,                 loss: nan
env1_second_0:                 episode reward: 22.8500,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 3537.1,                last time consumption/overall running time: 3077.6562s / 803651.9249 s
env0_first_0:                 episode reward: -21.5500,                 loss: 0.0062
env0_second_0:                 episode reward: 21.5500,                 loss: 0.0063
env1_first_0:                 episode reward: -20.2500,                 loss: nan
env1_second_0:                 episode reward: 20.2500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 3620.35,                last time consumption/overall running time: 3155.5947s / 806807.5195 s
env0_first_0:                 episode reward: -21.1000,                 loss: 0.0063
env0_second_0:                 episode reward: 21.1000,                 loss: 0.0063
env1_first_0:                 episode reward: -20.8000,                 loss: nan
env1_second_0:                 episode reward: 20.8000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 3533.85,                last time consumption/overall running time: 3055.4539s / 809862.9734 s
env0_first_0:                 episode reward: -23.3500,                 loss: 0.0062
env0_second_0:                 episode reward: 23.3500,                 loss: 0.0060
env1_first_0:                 episode reward: -21.9000,                 loss: nan
env1_second_0:                 episode reward: 21.9000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 3877.05,                last time consumption/overall running time: 3360.8219s / 813223.7953 s
env0_first_0:                 episode reward: -18.4000,                 loss: 0.0062
env0_second_0:                 episode reward: 18.4000,                 loss: 0.0060
env1_first_0:                 episode reward: -24.5500,                 loss: nan
env1_second_0:                 episode reward: 24.5500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 3476.45,                last time consumption/overall running time: 3028.8074s / 816252.6027 s
env0_first_0:                 episode reward: -22.3000,                 loss: 0.0070
env0_second_0:                 episode reward: 22.3000,                 loss: 0.0062
env1_first_0:                 episode reward: -19.0000,                 loss: nan
env1_second_0:                 episode reward: 19.0000,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 3326.8,                last time consumption/overall running time: 2868.2248s / 819120.8276 s
env0_first_0:                 episode reward: -22.5000,                 loss: 0.0062
env0_second_0:                 episode reward: 22.5000,                 loss: 0.0058
env1_first_0:                 episode reward: -24.5000,                 loss: nan
env1_second_0:                 episode reward: 24.5000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 4309.9,                last time consumption/overall running time: 3724.4021s / 822845.2297 s
env0_first_0:                 episode reward: -15.4500,                 loss: 0.0065
env0_second_0:                 episode reward: 15.4500,                 loss: 0.0065
env1_first_0:                 episode reward: -19.9500,                 loss: nan
env1_second_0:                 episode reward: 19.9500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 4269.85,                last time consumption/overall running time: 3686.3135s / 826531.5432 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0084
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0085
env1_first_0:                 episode reward: 4.1500,                 loss: nan
env1_second_0:                 episode reward: -4.1500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 3320.0,                last time consumption/overall running time: 2867.6472s / 829399.1903 s
env0_first_0:                 episode reward: -18.6000,                 loss: 0.0080
env0_second_0:                 episode reward: 18.6000,                 loss: 0.0086
env1_first_0:                 episode reward: -16.8500,                 loss: nan
env1_second_0:                 episode reward: 16.8500,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 3201.65,                last time consumption/overall running time: 2824.8894s / 832224.0798 s
env0_first_0:                 episode reward: -22.0500,                 loss: 0.0058
env0_second_0:                 episode reward: 22.0500,                 loss: 0.0064
env1_first_0:                 episode reward: -18.7000,                 loss: nan
env1_second_0:                 episode reward: 18.7000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 2882.6,                last time consumption/overall running time: 2485.7462s / 834709.8259 s
env0_first_0:                 episode reward: -21.2500,                 loss: 0.0053
env0_second_0:                 episode reward: 21.2500,                 loss: 0.0058
env1_first_0:                 episode reward: -23.3000,                 loss: nan
env1_second_0:                 episode reward: 23.3000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 3452.0,                last time consumption/overall running time: 2976.5847s / 837686.4107 s
env0_first_0:                 episode reward: -21.3000,                 loss: 0.0063
env0_second_0:                 episode reward: 21.3000,                 loss: 0.0065
env1_first_0:                 episode reward: -21.3000,                 loss: nan
env1_second_0:                 episode reward: 21.3000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 3303.8,                last time consumption/overall running time: 2844.6018s / 840531.0125 s
env0_first_0:                 episode reward: -20.6500,                 loss: 0.0062
env0_second_0:                 episode reward: 20.6500,                 loss: 0.0062
env1_first_0:                 episode reward: -19.3000,                 loss: nan
env1_second_0:                 episode reward: 19.3000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 3168.0,                last time consumption/overall running time: 2715.9987s / 843247.0111 s
env0_first_0:                 episode reward: -18.9000,                 loss: 0.0064
env0_second_0:                 episode reward: 18.9000,                 loss: 0.0062
env1_first_0:                 episode reward: -19.1500,                 loss: nan
env1_second_0:                 episode reward: 19.1500,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 3184.25,                last time consumption/overall running time: 2743.0612s / 845990.0723 s
env0_first_0:                 episode reward: -23.3000,                 loss: 0.0066
env0_second_0:                 episode reward: 23.3000,                 loss: 0.0064
env1_first_0:                 episode reward: -21.1000,                 loss: nan
env1_second_0:                 episode reward: 21.1000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 3414.05,                last time consumption/overall running time: 2947.5670s / 848937.6393 s
env0_first_0:                 episode reward: -19.3000,                 loss: 0.0064
env0_second_0:                 episode reward: 19.3000,                 loss: 0.0060
env1_first_0:                 episode reward: -17.7000,                 loss: nan
env1_second_0:                 episode reward: 17.7000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 3936.7,                last time consumption/overall running time: 3408.2846s / 852345.9238 s
env0_first_0:                 episode reward: -16.6000,                 loss: 0.0067
env0_second_0:                 episode reward: 16.6000,                 loss: 0.0070
env1_first_0:                 episode reward: -17.8000,                 loss: nan
env1_second_0:                 episode reward: 17.8000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 3134.75,                last time consumption/overall running time: 2710.3393s / 855056.2631 s
env0_first_0:                 episode reward: -20.1500,                 loss: 0.0066
env0_second_0:                 episode reward: 20.1500,                 loss: 0.0068
env1_first_0:                 episode reward: -19.5000,                 loss: nan
env1_second_0:                 episode reward: 19.5000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 2955.3,                last time consumption/overall running time: 2553.3486s / 857609.6117 s
env0_first_0:                 episode reward: -18.1500,                 loss: 0.0063
env0_second_0:                 episode reward: 18.1500,                 loss: 0.0064
env1_first_0:                 episode reward: -18.4000,                 loss: nan
env1_second_0:                 episode reward: 18.4000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 3382.35,                last time consumption/overall running time: 2915.6260s / 860525.2377 s
env0_first_0:                 episode reward: -17.7500,                 loss: 0.0064
env0_second_0:                 episode reward: 17.7500,                 loss: 0.0063
env1_first_0:                 episode reward: -18.2500,                 loss: nan
env1_second_0:                 episode reward: 18.2500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 3886.5,                last time consumption/overall running time: 3356.5167s / 863881.7544 s
env0_first_0:                 episode reward: -17.7500,                 loss: 0.0073
env0_second_0:                 episode reward: 17.7500,                 loss: 0.0072
env1_first_0:                 episode reward: -19.9500,                 loss: nan
env1_second_0:                 episode reward: 19.9500,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 2702.0,                last time consumption/overall running time: 2322.7241s / 866204.4785 s
env0_first_0:                 episode reward: -18.9500,                 loss: 0.0063
env0_second_0:                 episode reward: 18.9500,                 loss: 0.0063
env1_first_0:                 episode reward: -20.2000,                 loss: nan
env1_second_0:                 episode reward: 20.2000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 3391.05,                last time consumption/overall running time: 2936.8700s / 869141.3484 s
env0_first_0:                 episode reward: -21.0500,                 loss: 0.0062
env0_second_0:                 episode reward: 21.0500,                 loss: 0.0063
env1_first_0:                 episode reward: -21.8500,                 loss: nan
env1_second_0:                 episode reward: 21.8500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 3282.4,                last time consumption/overall running time: 2845.6932s / 871987.0417 s
env0_first_0:                 episode reward: -23.4500,                 loss: 0.0067
env0_second_0:                 episode reward: 23.4500,                 loss: 0.0065
env1_first_0:                 episode reward: -23.4000,                 loss: nan
env1_second_0:                 episode reward: 23.4000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 3423.4,                last time consumption/overall running time: 2944.3073s / 874931.3489 s
env0_first_0:                 episode reward: -20.5500,                 loss: 0.0058
env0_second_0:                 episode reward: 20.5500,                 loss: 0.0057
env1_first_0:                 episode reward: -21.3500,                 loss: nan
env1_second_0:                 episode reward: 21.3500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 2854.05,                last time consumption/overall running time: 2473.6081s / 877404.9571 s
env0_first_0:                 episode reward: -19.2000,                 loss: 0.0052
env0_second_0:                 episode reward: 19.2000,                 loss: 0.0057
env1_first_0:                 episode reward: -17.8500,                 loss: nan
env1_second_0:                 episode reward: 17.8500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 3000.2,                last time consumption/overall running time: 2585.4448s / 879990.4018 s
env0_first_0:                 episode reward: -17.9500,                 loss: 0.0051
env0_second_0:                 episode reward: 17.9500,                 loss: 0.0057
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 3308.0,                last time consumption/overall running time: 2814.9680s / 882805.3698 s
env0_first_0:                 episode reward: -17.6000,                 loss: 0.0061
env0_second_0:                 episode reward: 17.6000,                 loss: 0.0064
env1_first_0:                 episode reward: -19.8000,                 loss: nan
env1_second_0:                 episode reward: 19.8000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 3038.9,                last time consumption/overall running time: 2598.9234s / 885404.2932 s
env0_first_0:                 episode reward: -19.0500,                 loss: 0.0061
env0_second_0:                 episode reward: 19.0500,                 loss: 0.0061
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 2948.6,                last time consumption/overall running time: 2523.1312s / 887927.4245 s
env0_first_0:                 episode reward: -20.2500,                 loss: 0.0062
env0_second_0:                 episode reward: 20.2500,                 loss: 0.0063
env1_first_0:                 episode reward: -20.9000,                 loss: nan
env1_second_0:                 episode reward: 20.9000,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 2749.45,                last time consumption/overall running time: 2338.9933s / 890266.4178 s
env0_first_0:                 episode reward: -20.8000,                 loss: 0.0067
env0_second_0:                 episode reward: 20.8000,                 loss: 0.0067
env1_first_0:                 episode reward: -20.9000,                 loss: nan
env1_second_0:                 episode reward: 20.9000,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 2728.0,                last time consumption/overall running time: 2320.2138s / 892586.6316 s
env0_first_0:                 episode reward: -19.3000,                 loss: 0.0056
env0_second_0:                 episode reward: 19.3000,                 loss: 0.0063
env1_first_0:                 episode reward: -20.6000,                 loss: nan
env1_second_0:                 episode reward: 20.6000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 3558.4,                last time consumption/overall running time: 3028.7735s / 895615.4051 s
env0_first_0:                 episode reward: -22.1500,                 loss: 0.0063
env0_second_0:                 episode reward: 22.1500,                 loss: 0.0070
env1_first_0:                 episode reward: -20.3000,                 loss: nan
env1_second_0:                 episode reward: 20.3000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 3835.95,                last time consumption/overall running time: 3259.1866s / 898874.5917 s
env0_first_0:                 episode reward: -18.4000,                 loss: 0.0057
env0_second_0:                 episode reward: 18.4000,                 loss: 0.0060
env1_first_0:                 episode reward: -21.9000,                 loss: nan
env1_second_0:                 episode reward: 21.9000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 3013.75,                last time consumption/overall running time: 2549.3177s / 901423.9094 s
env0_first_0:                 episode reward: -19.4000,                 loss: 0.0062
env0_second_0:                 episode reward: 19.4000,                 loss: 0.0065
env1_first_0:                 episode reward: -17.5000,                 loss: nan
env1_second_0:                 episode reward: 17.5000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 3348.15,                last time consumption/overall running time: 2829.6285s / 904253.5379 s
env0_first_0:                 episode reward: -21.3000,                 loss: 0.0059
env0_second_0:                 episode reward: 21.3000,                 loss: 0.0067
env1_first_0:                 episode reward: -20.9500,                 loss: nan
env1_second_0:                 episode reward: 20.9500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 3043.5,                last time consumption/overall running time: 2578.6148s / 906832.1527 s
env0_first_0:                 episode reward: -22.2500,                 loss: 0.0057
env0_second_0:                 episode reward: 22.2500,                 loss: 0.0062
env1_first_0:                 episode reward: -22.1500,                 loss: nan
env1_second_0:                 episode reward: 22.1500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 3128.0,                last time consumption/overall running time: 2641.9446s / 909474.0973 s
env0_first_0:                 episode reward: -21.8500,                 loss: 0.0056
env0_second_0:                 episode reward: 21.8500,                 loss: 0.0059
env1_first_0:                 episode reward: -22.8500,                 loss: nan
env1_second_0:                 episode reward: 22.8500,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 3607.05,                last time consumption/overall running time: 3045.2084s / 912519.3057 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0061
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0062
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 3287.1,                last time consumption/overall running time: 2767.0666s / 915286.3723 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0091
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0089
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 3850.75,                last time consumption/overall running time: 3232.6316s / 918519.0039 s
env0_first_0:                 episode reward: -13.9000,                 loss: 0.0064
env0_second_0:                 episode reward: 13.9000,                 loss: 0.0062
env1_first_0:                 episode reward: -16.2000,                 loss: nan
env1_second_0:                 episode reward: 16.2000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 3511.95,                last time consumption/overall running time: 2949.8459s / 921468.8498 s
env0_first_0:                 episode reward: -20.7000,                 loss: 0.0063
env0_second_0:                 episode reward: 20.7000,                 loss: 0.0066
env1_first_0:                 episode reward: -22.9000,                 loss: nan
env1_second_0:                 episode reward: 22.9000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 3467.1,                last time consumption/overall running time: 2904.9018s / 924373.7516 s
env0_first_0:                 episode reward: -16.1500,                 loss: 0.0052
env0_second_0:                 episode reward: 16.1500,                 loss: 0.0053
env1_first_0:                 episode reward: -19.5000,                 loss: nan
env1_second_0:                 episode reward: 19.5000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 4664.4,                last time consumption/overall running time: 3922.6609s / 928296.4126 s
env0_first_0:                 episode reward: -9.5500,                 loss: 0.0058
env0_second_0:                 episode reward: 9.5500,                 loss: 0.0057
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 3330.9,                last time consumption/overall running time: 2808.2321s / 931104.6447 s
env0_first_0:                 episode reward: -19.4000,                 loss: 0.0070
env0_second_0:                 episode reward: 19.4000,                 loss: 0.0072
env1_first_0:                 episode reward: -17.8000,                 loss: nan
env1_second_0:                 episode reward: 17.8000,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 3701.2,                last time consumption/overall running time: 3124.7893s / 934229.4340 s
env0_first_0:                 episode reward: -20.0500,                 loss: 0.0052
env0_second_0:                 episode reward: 20.0500,                 loss: 0.0050
env1_first_0:                 episode reward: -19.5000,                 loss: nan
env1_second_0:                 episode reward: 19.5000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 3242.6,                last time consumption/overall running time: 2734.5160s / 936963.9499 s
env0_first_0:                 episode reward: -21.7500,                 loss: 0.0053
env0_second_0:                 episode reward: 21.7500,                 loss: 0.0054
env1_first_0:                 episode reward: -19.5000,                 loss: nan
env1_second_0:                 episode reward: 19.5000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 3643.65,                last time consumption/overall running time: 3066.0878s / 940030.0377 s
env0_first_0:                 episode reward: -18.4500,                 loss: 0.0056
env0_second_0:                 episode reward: 18.4500,                 loss: 0.0053
env1_first_0:                 episode reward: -20.1000,                 loss: nan
env1_second_0:                 episode reward: 20.1000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 3297.35,                last time consumption/overall running time: 2769.6595s / 942799.6972 s
env0_first_0:                 episode reward: -18.5500,                 loss: 0.0058
env0_second_0:                 episode reward: 18.5500,                 loss: 0.0058
env1_first_0:                 episode reward: -19.3500,                 loss: nan
env1_second_0:                 episode reward: 19.3500,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 3435.55,                last time consumption/overall running time: 2889.1590s / 945688.8563 s
env0_first_0:                 episode reward: -17.5500,                 loss: 0.0061
env0_second_0:                 episode reward: 17.5500,                 loss: 0.0059
env1_first_0:                 episode reward: -16.6000,                 loss: nan
env1_second_0:                 episode reward: 16.6000,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 4147.65,                last time consumption/overall running time: 3500.0769s / 949188.9331 s
env0_first_0:                 episode reward: -15.6500,                 loss: 0.0057
env0_second_0:                 episode reward: 15.6500,                 loss: 0.0060
env1_first_0:                 episode reward: -21.0500,                 loss: nan
env1_second_0:                 episode reward: 21.0500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 3720.55,                last time consumption/overall running time: 3134.2154s / 952323.1486 s
env0_first_0:                 episode reward: -15.3500,                 loss: 0.0070
env0_second_0:                 episode reward: 15.3500,                 loss: 0.0066
env1_first_0:                 episode reward: -17.4500,                 loss: nan
env1_second_0:                 episode reward: 17.4500,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 3306.95,                last time consumption/overall running time: 2784.5005s / 955107.6491 s
env0_first_0:                 episode reward: -20.7000,                 loss: 0.0055
env0_second_0:                 episode reward: 20.7000,                 loss: 0.0055
env1_first_0:                 episode reward: -18.5000,                 loss: nan
env1_second_0:                 episode reward: 18.5000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 3585.65,                last time consumption/overall running time: 3000.5402s / 958108.1893 s
env0_first_0:                 episode reward: -20.4500,                 loss: 0.0056
env0_second_0:                 episode reward: 20.4500,                 loss: 0.0051
env1_first_0:                 episode reward: -18.0500,                 loss: nan
env1_second_0:                 episode reward: 18.0500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 3188.2,                last time consumption/overall running time: 2673.0176s / 960781.2068 s
env0_first_0:                 episode reward: -19.9500,                 loss: 0.0054
env0_second_0:                 episode reward: 19.9500,                 loss: 0.0056
env1_first_0:                 episode reward: -17.5000,                 loss: nan
env1_second_0:                 episode reward: 17.5000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 3309.6,                last time consumption/overall running time: 2768.9034s / 963550.1102 s
env0_first_0:                 episode reward: -20.3500,                 loss: 0.0053
env0_second_0:                 episode reward: 20.3500,                 loss: 0.0058
env1_first_0:                 episode reward: -18.5500,                 loss: nan
env1_second_0:                 episode reward: 18.5500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 3539.3,                last time consumption/overall running time: 2962.3086s / 966512.4189 s
env0_first_0:                 episode reward: -17.9000,                 loss: 0.0059
env0_second_0:                 episode reward: 17.9000,                 loss: 0.0063
env1_first_0:                 episode reward: -19.7500,                 loss: nan
env1_second_0:                 episode reward: 19.7500,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 4336.15,                last time consumption/overall running time: 3638.8812s / 970151.3001 s
env0_first_0:                 episode reward: -21.5500,                 loss: 0.0063
env0_second_0:                 episode reward: 21.5500,                 loss: 0.0064
env1_first_0:                 episode reward: -19.9000,                 loss: nan
env1_second_0:                 episode reward: 19.9000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 3980.5,                last time consumption/overall running time: 3320.6506s / 973471.9507 s
env0_first_0:                 episode reward: -19.0000,                 loss: 0.0063
env0_second_0:                 episode reward: 19.0000,                 loss: 0.0061
env1_first_0:                 episode reward: -21.1500,                 loss: nan
env1_second_0:                 episode reward: 21.1500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 3987.95,                last time consumption/overall running time: 3348.0393s / 976819.9899 s
env0_first_0:                 episode reward: -18.8500,                 loss: 0.0061
env0_second_0:                 episode reward: 18.8500,                 loss: 0.0060
env1_first_0:                 episode reward: -20.6000,                 loss: nan
env1_second_0:                 episode reward: 20.6000,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 3364.3,                last time consumption/overall running time: 2838.6365s / 979658.6265 s
env0_first_0:                 episode reward: -20.4500,                 loss: 0.0059
env0_second_0:                 episode reward: 20.4500,                 loss: 0.0057
env1_first_0:                 episode reward: -22.4000,                 loss: nan
env1_second_0:                 episode reward: 22.4000,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 3087.8,                last time consumption/overall running time: 2578.1938s / 982236.8202 s
env0_first_0:                 episode reward: -19.6000,                 loss: 0.0050
env0_second_0:                 episode reward: 19.6000,                 loss: 0.0049
env1_first_0:                 episode reward: -18.3000,                 loss: nan
env1_second_0:                 episode reward: 18.3000,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 3551.6,                last time consumption/overall running time: 2969.8042s / 985206.6244 s
env0_first_0:                 episode reward: -21.8000,                 loss: 0.0059
env0_second_0:                 episode reward: 21.8000,                 loss: 0.0059
env1_first_0:                 episode reward: -18.4000,                 loss: nan
env1_second_0:                 episode reward: 18.4000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 3401.9,                last time consumption/overall running time: 2846.7991s / 988053.4235 s
env0_first_0:                 episode reward: -21.3000,                 loss: 0.0059
env0_second_0:                 episode reward: 21.3000,                 loss: 0.0056
env1_first_0:                 episode reward: -21.7500,                 loss: nan
env1_second_0:                 episode reward: 21.7500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 3375.45,                last time consumption/overall running time: 2838.9861s / 990892.4095 s
env0_first_0:                 episode reward: -20.9500,                 loss: 0.0057
env0_second_0:                 episode reward: 20.9500,                 loss: 0.0055
env1_first_0:                 episode reward: -22.7500,                 loss: nan
env1_second_0:                 episode reward: 22.7500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 3045.35,                last time consumption/overall running time: 2551.2284s / 993443.6379 s
env0_first_0:                 episode reward: -21.9000,                 loss: 0.0053
env0_second_0:                 episode reward: 21.9000,                 loss: 0.0054
env1_first_0:                 episode reward: -22.5000,                 loss: nan
env1_second_0:                 episode reward: 22.5000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 3083.5,                last time consumption/overall running time: 2580.6934s / 996024.3313 s
env0_first_0:                 episode reward: -22.2500,                 loss: 0.0055
env0_second_0:                 episode reward: 22.2500,                 loss: 0.0056
env1_first_0:                 episode reward: -23.5500,                 loss: nan
env1_second_0:                 episode reward: 23.5500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 3415.7,                last time consumption/overall running time: 2850.6701s / 998875.0013 s
env0_first_0:                 episode reward: -20.9500,                 loss: 0.0059
env0_second_0:                 episode reward: 20.9500,                 loss: 0.0055
env1_first_0:                 episode reward: -21.6500,                 loss: nan
env1_second_0:                 episode reward: 21.6500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 3063.65,                last time consumption/overall running time: 2531.5418s / 1001406.5432 s
env0_first_0:                 episode reward: -20.0000,                 loss: 0.0056
env0_second_0:                 episode reward: 20.0000,                 loss: 0.0055
env1_first_0:                 episode reward: -20.9500,                 loss: nan
env1_second_0:                 episode reward: 20.9500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 3000.8,                last time consumption/overall running time: 2491.2726s / 1003897.8157 s
env0_first_0:                 episode reward: -19.4000,                 loss: 0.0059
env0_second_0:                 episode reward: 19.4000,                 loss: 0.0059
env1_first_0:                 episode reward: -20.0000,                 loss: nan
env1_second_0:                 episode reward: 20.0000,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 3044.65,                last time consumption/overall running time: 2542.7052s / 1006440.5210 s
env0_first_0:                 episode reward: -21.4500,                 loss: 0.0052
env0_second_0:                 episode reward: 21.4500,                 loss: 0.0051
env1_first_0:                 episode reward: -20.3000,                 loss: nan
env1_second_0:                 episode reward: 20.3000,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 3310.75,                last time consumption/overall running time: 2745.8508s / 1009186.3718 s
env0_first_0:                 episode reward: -18.7500,                 loss: 0.0059
env0_second_0:                 episode reward: 18.7500,                 loss: 0.0052
env1_first_0:                 episode reward: -18.6500,                 loss: nan
env1_second_0:                 episode reward: 18.6500,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 3543.8,                last time consumption/overall running time: 2956.5819s / 1012142.9537 s
env0_first_0:                 episode reward: -18.2000,                 loss: 0.0061
env0_second_0:                 episode reward: 18.2000,                 loss: 0.0056
env1_first_0:                 episode reward: -18.8000,                 loss: nan
env1_second_0:                 episode reward: 18.8000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 2794.55,                last time consumption/overall running time: 2406.9011s / 1014549.8548 s
env0_first_0:                 episode reward: -19.1000,                 loss: 0.0056
env0_second_0:                 episode reward: 19.1000,                 loss: 0.0060
env1_first_0:                 episode reward: -21.1000,                 loss: nan
env1_second_0:                 episode reward: 21.1000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 2989.4,                last time consumption/overall running time: 2512.0607s / 1017061.9155 s
env0_first_0:                 episode reward: -21.0000,                 loss: 0.0055
env0_second_0:                 episode reward: 21.0000,                 loss: 0.0058
env1_first_0:                 episode reward: -23.4000,                 loss: nan
env1_second_0:                 episode reward: 23.4000,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 3027.9,                last time consumption/overall running time: 2528.8479s / 1019590.7633 s
env0_first_0:                 episode reward: -19.5500,                 loss: 0.0061
env0_second_0:                 episode reward: 19.5500,                 loss: 0.0061
env1_first_0:                 episode reward: -20.9500,                 loss: nan
env1_second_0:                 episode reward: 20.9500,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 3465.65,                last time consumption/overall running time: 2924.5836s / 1022515.3469 s
env0_first_0:                 episode reward: -20.0500,                 loss: 0.0063
env0_second_0:                 episode reward: 20.0500,                 loss: 0.0066
env1_first_0:                 episode reward: -23.8000,                 loss: nan
env1_second_0:                 episode reward: 23.8000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 3601.85,                last time consumption/overall running time: 3074.0625s / 1025589.4094 s
env0_first_0:                 episode reward: -14.1500,                 loss: 0.0064
env0_second_0:                 episode reward: 14.1500,                 loss: 0.0064
env1_first_0:                 episode reward: -17.3000,                 loss: nan
env1_second_0:                 episode reward: 17.3000,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 3731.9,                last time consumption/overall running time: 3143.7394s / 1028733.1488 s
env0_first_0:                 episode reward: -19.7500,                 loss: 0.0052
env0_second_0:                 episode reward: 19.7500,                 loss: 0.0052
env1_first_0:                 episode reward: -20.8000,                 loss: nan
env1_second_0:                 episode reward: 20.8000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 3725.65,                last time consumption/overall running time: 3120.9077s / 1031854.0565 s
env0_first_0:                 episode reward: -18.8000,                 loss: 0.0058
env0_second_0:                 episode reward: 18.8000,                 loss: 0.0060
env1_first_0:                 episode reward: -18.0500,                 loss: nan
env1_second_0:                 episode reward: 18.0500,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 3417.9,                last time consumption/overall running time: 2855.0871s / 1034709.1436 s
env0_first_0:                 episode reward: -20.5500,                 loss: 0.0058
env0_second_0:                 episode reward: 20.5500,                 loss: 0.0055
env1_first_0:                 episode reward: -19.1000,                 loss: nan
env1_second_0:                 episode reward: 19.1000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 3816.8,                last time consumption/overall running time: 3213.3164s / 1037922.4600 s
env0_first_0:                 episode reward: -19.2500,                 loss: 0.0048
env0_second_0:                 episode reward: 19.2500,                 loss: 0.0048
env1_first_0:                 episode reward: -20.5000,                 loss: nan
env1_second_0:                 episode reward: 20.5000,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 3037.35,                last time consumption/overall running time: 2555.0897s / 1040477.5497 s
env0_first_0:                 episode reward: -19.6500,                 loss: 0.0049
env0_second_0:                 episode reward: 19.6500,                 loss: 0.0051
env1_first_0:                 episode reward: -17.7500,                 loss: nan
env1_second_0:                 episode reward: 17.7500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 2891.9,                last time consumption/overall running time: 2414.5046s / 1042892.0543 s
env0_first_0:                 episode reward: -21.9000,                 loss: 0.0049
env0_second_0:                 episode reward: 21.9000,                 loss: 0.0048
env1_first_0:                 episode reward: -20.4500,                 loss: nan
env1_second_0:                 episode reward: 20.4500,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 3430.0,                last time consumption/overall running time: 2879.2515s / 1045771.3058 s
env0_first_0:                 episode reward: -21.0500,                 loss: 0.0050
env0_second_0:                 episode reward: 21.0500,                 loss: 0.0050
env1_first_0:                 episode reward: -20.4500,                 loss: nan
env1_second_0:                 episode reward: 20.4500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 3295.1,                last time consumption/overall running time: 2749.0073s / 1048520.3131 s
env0_first_0:                 episode reward: -21.3500,                 loss: 0.0053
env0_second_0:                 episode reward: 21.3500,                 loss: 0.0052
env1_first_0:                 episode reward: -19.5500,                 loss: nan
env1_second_0:                 episode reward: 19.5500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 3673.85,                last time consumption/overall running time: 3074.8619s / 1051595.1749 s
env0_first_0:                 episode reward: -22.2500,                 loss: 0.0051
env0_second_0:                 episode reward: 22.2500,                 loss: 0.0053
env1_first_0:                 episode reward: -21.3500,                 loss: nan
env1_second_0:                 episode reward: 21.3500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 3053.2,                last time consumption/overall running time: 2529.1698s / 1054124.3448 s
env0_first_0:                 episode reward: -21.6500,                 loss: 0.0052
env0_second_0:                 episode reward: 21.6500,                 loss: 0.0059
env1_first_0:                 episode reward: -20.3000,                 loss: nan
env1_second_0:                 episode reward: 20.3000,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 2802.65,                last time consumption/overall running time: 2340.6986s / 1056465.0433 s
env0_first_0:                 episode reward: -18.0500,                 loss: 0.0048
env0_second_0:                 episode reward: 18.0500,                 loss: 0.0051
env1_first_0:                 episode reward: -17.0500,                 loss: nan
env1_second_0:                 episode reward: 17.0500,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 3116.7,                last time consumption/overall running time: 2591.9799s / 1059057.0232 s
env0_first_0:                 episode reward: -19.6500,                 loss: 0.0052
env0_second_0:                 episode reward: 19.6500,                 loss: 0.0053
env1_first_0:                 episode reward: -21.3000,                 loss: nan
env1_second_0:                 episode reward: 21.3000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 3404.05,                last time consumption/overall running time: 2828.8014s / 1061885.8246 s
env0_first_0:                 episode reward: -21.8500,                 loss: 0.0056
env0_second_0:                 episode reward: 21.8500,                 loss: 0.0057
env1_first_0:                 episode reward: -23.4500,                 loss: nan
env1_second_0:                 episode reward: 23.4500,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 3231.95,                last time consumption/overall running time: 2677.3919s / 1064563.2165 s
env0_first_0:                 episode reward: -22.0000,                 loss: 0.0058
env0_second_0:                 episode reward: 22.0000,                 loss: 0.0062
env1_first_0:                 episode reward: -20.9500,                 loss: nan
env1_second_0:                 episode reward: 20.9500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 3099.7,                last time consumption/overall running time: 2574.0155s / 1067137.2320 s
env0_first_0:                 episode reward: -22.3500,                 loss: 0.0053
env0_second_0:                 episode reward: 22.3500,                 loss: 0.0057
env1_first_0:                 episode reward: -23.5500,                 loss: nan
env1_second_0:                 episode reward: 23.5500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 3201.45,                last time consumption/overall running time: 2634.3353s / 1069771.5672 s
env0_first_0:                 episode reward: -20.2000,                 loss: 0.0049
env0_second_0:                 episode reward: 20.2000,                 loss: 0.0055
env1_first_0:                 episode reward: -20.6000,                 loss: nan
env1_second_0:                 episode reward: 20.6000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 2858.6,                last time consumption/overall running time: 2367.8813s / 1072139.4485 s
env0_first_0:                 episode reward: -20.7000,                 loss: 0.0050
env0_second_0:                 episode reward: 20.7000,                 loss: 0.0055
env1_first_0:                 episode reward: -18.5500,                 loss: nan
env1_second_0:                 episode reward: 18.5500,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 2650.1,                last time consumption/overall running time: 2203.4211s / 1074342.8697 s
env0_first_0:                 episode reward: -20.6000,                 loss: 0.0051
env0_second_0:                 episode reward: 20.6000,                 loss: 0.0052
env1_first_0:                 episode reward: -20.3000,                 loss: nan
env1_second_0:                 episode reward: 20.3000,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 3090.2,                last time consumption/overall running time: 2571.4749s / 1076914.3446 s
env0_first_0:                 episode reward: -18.0500,                 loss: 0.0049
env0_second_0:                 episode reward: 18.0500,                 loss: 0.0046
env1_first_0:                 episode reward: -19.1500,                 loss: nan
env1_second_0:                 episode reward: 19.1500,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 3106.2,                last time consumption/overall running time: 2579.0796s / 1079493.4242 s
env0_first_0:                 episode reward: -19.9500,                 loss: 0.0046
env0_second_0:                 episode reward: 19.9500,                 loss: 0.0047
env1_first_0:                 episode reward: -20.5500,                 loss: nan
env1_second_0:                 episode reward: 20.5500,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 3116.6,                last time consumption/overall running time: 2584.7839s / 1082078.2081 s
env0_first_0:                 episode reward: -21.9000,                 loss: 0.0054
env0_second_0:                 episode reward: 21.9000,                 loss: 0.0055
env1_first_0:                 episode reward: -20.7500,                 loss: nan
env1_second_0:                 episode reward: 20.7500,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 3734.7,                last time consumption/overall running time: 3085.9923s / 1085164.2004 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.0073
env0_second_0:                 episode reward: 8.6000,                 loss: 0.0074
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 3361.0,                last time consumption/overall running time: 2778.5036s / 1087942.7040 s
env0_first_0:                 episode reward: -20.8000,                 loss: 0.0054
env0_second_0:                 episode reward: 20.8000,                 loss: 0.0055
env1_first_0:                 episode reward: -18.4500,                 loss: nan
env1_second_0:                 episode reward: 18.4500,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 3334.3,                last time consumption/overall running time: 2761.5737s / 1090704.2777 s
env0_first_0:                 episode reward: -21.0000,                 loss: 0.0050
env0_second_0:                 episode reward: 21.0000,                 loss: 0.0050
env1_first_0:                 episode reward: -21.8000,                 loss: nan
env1_second_0:                 episode reward: 21.8000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 3593.45,                last time consumption/overall running time: 2975.8615s / 1093680.1392 s
env0_first_0:                 episode reward: -18.7500,                 loss: 0.0050
env0_second_0:                 episode reward: 18.7500,                 loss: 0.0056
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 3267.0,                last time consumption/overall running time: 2699.3800s / 1096379.5192 s
env0_first_0:                 episode reward: -22.3000,                 loss: 0.0049
env0_second_0:                 episode reward: 22.3000,                 loss: 0.0053
env1_first_0:                 episode reward: -20.0000,                 loss: nan
env1_second_0:                 episode reward: 20.0000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 3272.95,                last time consumption/overall running time: 2695.0455s / 1099074.5647 s
env0_first_0:                 episode reward: -18.5500,                 loss: 0.0048
env0_second_0:                 episode reward: 18.5500,                 loss: 0.0054
env1_first_0:                 episode reward: -18.1000,                 loss: nan
env1_second_0:                 episode reward: 18.1000,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 3925.45,                last time consumption/overall running time: 3249.2943s / 1102323.8590 s
env0_first_0:                 episode reward: -17.7000,                 loss: 0.0058
env0_second_0:                 episode reward: 17.7000,                 loss: 0.0059
env1_first_0:                 episode reward: -14.5000,                 loss: nan
env1_second_0:                 episode reward: 14.5000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 3110.05,                last time consumption/overall running time: 2584.9012s / 1104908.7601 s
env0_first_0:                 episode reward: -21.3500,                 loss: 0.0062
env0_second_0:                 episode reward: 21.3500,                 loss: 0.0066
env1_first_0:                 episode reward: -15.7000,                 loss: nan
env1_second_0:                 episode reward: 15.7000,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 2731.65,                last time consumption/overall running time: 2261.1576s / 1107169.9177 s
env0_first_0:                 episode reward: -20.7500,                 loss: 0.0051
env0_second_0:                 episode reward: 20.7500,                 loss: 0.0055
env1_first_0:                 episode reward: -19.9500,                 loss: nan
env1_second_0:                 episode reward: 19.9500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 3112.05,                last time consumption/overall running time: 2568.4963s / 1109738.4140 s
env0_first_0:                 episode reward: -21.2500,                 loss: 0.0050
env0_second_0:                 episode reward: 21.2500,                 loss: 0.0052
env1_first_0:                 episode reward: -19.4500,                 loss: nan
env1_second_0:                 episode reward: 19.4500,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 3116.95,                last time consumption/overall running time: 2574.8309s / 1112313.2449 s
env0_first_0:                 episode reward: -23.1500,                 loss: 0.0054
env0_second_0:                 episode reward: 23.1500,                 loss: 0.0053
env1_first_0:                 episode reward: -22.6500,                 loss: nan
env1_second_0:                 episode reward: 22.6500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 3172.0,                last time consumption/overall running time: 2604.5909s / 1114917.8358 s
env0_first_0:                 episode reward: -20.0000,                 loss: 0.0057
env0_second_0:                 episode reward: 20.0000,                 loss: 0.0052
env1_first_0:                 episode reward: -19.3000,                 loss: nan
env1_second_0:                 episode reward: 19.3000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 3345.35,                last time consumption/overall running time: 2760.9759s / 1117678.8117 s
env0_first_0:                 episode reward: -19.2000,                 loss: 0.0052
env0_second_0:                 episode reward: 19.2000,                 loss: 0.0051
env1_first_0:                 episode reward: -21.4500,                 loss: nan
env1_second_0:                 episode reward: 21.4500,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 3162.05,                last time consumption/overall running time: 2593.1832s / 1120271.9949 s
env0_first_0:                 episode reward: -22.1500,                 loss: 0.0055
env0_second_0:                 episode reward: 22.1500,                 loss: 0.0049
env1_first_0:                 episode reward: -21.9500,                 loss: nan
env1_second_0:                 episode reward: 21.9500,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 3927.8,                last time consumption/overall running time: 3223.6396s / 1123495.6345 s
env0_first_0:                 episode reward: -19.2500,                 loss: 0.0062
env0_second_0:                 episode reward: 19.2500,                 loss: 0.0062
env1_first_0:                 episode reward: -17.6000,                 loss: nan
env1_second_0:                 episode reward: 17.6000,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 3311.75,                last time consumption/overall running time: 2728.0008s / 1126223.6354 s
env0_first_0:                 episode reward: -19.5500,                 loss: 0.0059
env0_second_0:                 episode reward: 19.5500,                 loss: 0.0058
env1_first_0:                 episode reward: -17.1000,                 loss: nan
env1_second_0:                 episode reward: 17.1000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 4126.1,                last time consumption/overall running time: 3402.6074s / 1129626.2427 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.0066
env0_second_0:                 episode reward: 8.4000,                 loss: 0.0064
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 4005.6,                last time consumption/overall running time: 3303.1157s / 1132929.3584 s
env0_first_0:                 episode reward: -21.4500,                 loss: 0.0068
env0_second_0:                 episode reward: 21.4500,                 loss: 0.0067
env1_first_0:                 episode reward: -15.9500,                 loss: nan
env1_second_0:                 episode reward: 15.9500,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 3772.2,                last time consumption/overall running time: 3100.4587s / 1136029.8171 s
env0_first_0:                 episode reward: -5.8000,                 loss: 0.0077
env0_second_0:                 episode reward: 5.8000,                 loss: 0.0079
env1_first_0:                 episode reward: -7.9000,                 loss: nan
env1_second_0:                 episode reward: 7.9000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 3477.75,                last time consumption/overall running time: 2842.7739s / 1138872.5910 s
env0_first_0:                 episode reward: -22.1000,                 loss: 0.0054
env0_second_0:                 episode reward: 22.1000,                 loss: 0.0059
env1_first_0:                 episode reward: -22.0000,                 loss: nan
env1_second_0:                 episode reward: 22.0000,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 3381.75,                last time consumption/overall running time: 2775.6056s / 1141648.1966 s
env0_first_0:                 episode reward: -21.7500,                 loss: 0.0055
env0_second_0:                 episode reward: 21.7500,                 loss: 0.0055
env1_first_0:                 episode reward: -19.7000,                 loss: nan
env1_second_0:                 episode reward: 19.7000,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 2924.15,                last time consumption/overall running time: 2414.8587s / 1144063.0552 s
env0_first_0:                 episode reward: -21.7000,                 loss: 0.0051
env0_second_0:                 episode reward: 21.7000,                 loss: 0.0054
env1_first_0:                 episode reward: -22.7000,                 loss: nan
env1_second_0:                 episode reward: 22.7000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 3326.85,                last time consumption/overall running time: 2728.3542s / 1146791.4094 s
env0_first_0:                 episode reward: -19.8500,                 loss: 0.0047
env0_second_0:                 episode reward: 19.8500,                 loss: 0.0050
env1_first_0:                 episode reward: -22.4000,                 loss: nan
env1_second_0:                 episode reward: 22.4000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 3050.2,                last time consumption/overall running time: 2522.8388s / 1149314.2482 s
env0_first_0:                 episode reward: -20.7000,                 loss: 0.0054
env0_second_0:                 episode reward: 20.7000,                 loss: 0.0055
env1_first_0:                 episode reward: -21.5000,                 loss: nan
env1_second_0:                 episode reward: 21.5000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 3994.55,                last time consumption/overall running time: 3286.4999s / 1152600.7482 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.0062
env0_second_0:                 episode reward: 6.6500,                 loss: 0.0062
env1_first_0:                 episode reward: -13.9000,                 loss: nan
env1_second_0:                 episode reward: 13.9000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 3462.0,                last time consumption/overall running time: 2843.5296s / 1155444.2778 s
env0_first_0:                 episode reward: -19.4500,                 loss: 0.0062
env0_second_0:                 episode reward: 19.4500,                 loss: 0.0065
env1_first_0:                 episode reward: -20.2500,                 loss: nan
env1_second_0:                 episode reward: 20.2500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 4252.65,                last time consumption/overall running time: 3524.0934s / 1158968.3711 s
env0_first_0:                 episode reward: -10.7500,                 loss: 0.0067
env0_second_0:                 episode reward: 10.7500,                 loss: 0.0067
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 4142.85,                last time consumption/overall running time: 3407.9206s / 1162376.2917 s
env0_first_0:                 episode reward: -18.1500,                 loss: 0.0053
env0_second_0:                 episode reward: 18.1500,                 loss: 0.0052
env1_first_0:                 episode reward: -20.3000,                 loss: nan
env1_second_0:                 episode reward: 20.3000,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 3217.9,                last time consumption/overall running time: 2652.5542s / 1165028.8459 s
env0_first_0:                 episode reward: -20.0500,                 loss: 0.0052
env0_second_0:                 episode reward: 20.0500,                 loss: 0.0052
env1_first_0:                 episode reward: -19.3500,                 loss: nan
env1_second_0:                 episode reward: 19.3500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 3178.35,                last time consumption/overall running time: 2606.3408s / 1167635.1867 s
env0_first_0:                 episode reward: -21.3000,                 loss: 0.0048
env0_second_0:                 episode reward: 21.3000,                 loss: 0.0053
env1_first_0:                 episode reward: -20.2000,                 loss: nan
env1_second_0:                 episode reward: 20.2000,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 3491.2,                last time consumption/overall running time: 2861.7823s / 1170496.9690 s
env0_first_0:                 episode reward: -18.5000,                 loss: 0.0049
env0_second_0:                 episode reward: 18.5000,                 loss: 0.0050
env1_first_0:                 episode reward: -19.5500,                 loss: nan
env1_second_0:                 episode reward: 19.5500,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 3755.15,                last time consumption/overall running time: 3082.1119s / 1173579.0809 s
env0_first_0:                 episode reward: -15.3500,                 loss: 0.0053
env0_second_0:                 episode reward: 15.3500,                 loss: 0.0053
env1_first_0:                 episode reward: -17.2500,                 loss: nan
env1_second_0:                 episode reward: 17.2500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 2804.65,                last time consumption/overall running time: 2294.6268s / 1175873.7078 s
env0_first_0:                 episode reward: -19.9500,                 loss: 0.0045
env0_second_0:                 episode reward: 19.9500,                 loss: 0.0044
env1_first_0:                 episode reward: -21.6500,                 loss: nan
env1_second_0:                 episode reward: 21.6500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 3545.05,                last time consumption/overall running time: 2899.6412s / 1178773.3490 s
env0_first_0:                 episode reward: -21.7500,                 loss: 0.0045
env0_second_0:                 episode reward: 21.7500,                 loss: 0.0045
env1_first_0:                 episode reward: -17.4500,                 loss: nan
env1_second_0:                 episode reward: 17.4500,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 3340.75,                last time consumption/overall running time: 2737.5098s / 1181510.8588 s
env0_first_0:                 episode reward: -19.4500,                 loss: 0.0052
env0_second_0:                 episode reward: 19.4500,                 loss: 0.0051
env1_first_0:                 episode reward: -20.9500,                 loss: nan
env1_second_0:                 episode reward: 20.9500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 3527.85,                last time consumption/overall running time: 2883.8565s / 1184394.7153 s
env0_first_0:                 episode reward: -22.4000,                 loss: 0.0049
env0_second_0:                 episode reward: 22.4000,                 loss: 0.0053
env1_first_0:                 episode reward: -21.5500,                 loss: nan
env1_second_0:                 episode reward: 21.5500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 3707.4,                last time consumption/overall running time: 3043.5227s / 1187438.2379 s
env0_first_0:                 episode reward: -21.5000,                 loss: 0.0050
env0_second_0:                 episode reward: 21.5000,                 loss: 0.0054
env1_first_0:                 episode reward: -22.5500,                 loss: nan
env1_second_0:                 episode reward: 22.5500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 3332.3,                last time consumption/overall running time: 2747.2805s / 1190185.5185 s
env0_first_0:                 episode reward: -21.1000,                 loss: 0.0042
env0_second_0:                 episode reward: 21.1000,                 loss: 0.0046
env1_first_0:                 episode reward: -20.6000,                 loss: nan
env1_second_0:                 episode reward: 20.6000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 2664.55,                last time consumption/overall running time: 2199.5940s / 1192385.1125 s
env0_first_0:                 episode reward: -22.8000,                 loss: 0.0046
env0_second_0:                 episode reward: 22.8000,                 loss: 0.0049
env1_first_0:                 episode reward: -21.9000,                 loss: nan
env1_second_0:                 episode reward: 21.9000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 2636.25,                last time consumption/overall running time: 2171.4668s / 1194556.5793 s
env0_first_0:                 episode reward: -18.6500,                 loss: 0.0047
env0_second_0:                 episode reward: 18.6500,                 loss: 0.0047
env1_first_0:                 episode reward: -19.7500,                 loss: nan
env1_second_0:                 episode reward: 19.7500,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 3311.85,                last time consumption/overall running time: 2734.9935s / 1197291.5729 s
env0_first_0:                 episode reward: -21.8500,                 loss: 0.0047
env0_second_0:                 episode reward: 21.8500,                 loss: 0.0052
env1_first_0:                 episode reward: -20.6500,                 loss: nan
env1_second_0:                 episode reward: 20.6500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 3514.9,                last time consumption/overall running time: 2857.8573s / 1200149.4301 s
env0_first_0:                 episode reward: -20.2000,                 loss: 0.0051
env0_second_0:                 episode reward: 20.2000,                 loss: 0.0051
env1_first_0:                 episode reward: -20.2500,                 loss: nan
env1_second_0:                 episode reward: 20.2500,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 2785.0,                last time consumption/overall running time: 2279.4226s / 1202428.8527 s
env0_first_0:                 episode reward: -22.7500,                 loss: 0.0051
env0_second_0:                 episode reward: 22.7500,                 loss: 0.0051
env1_first_0:                 episode reward: -20.5500,                 loss: nan
env1_second_0:                 episode reward: 20.5500,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 3347.9,                last time consumption/overall running time: 2741.2614s / 1205170.1142 s
env0_first_0:                 episode reward: -23.4000,                 loss: 0.0048
env0_second_0:                 episode reward: 23.4000,                 loss: 0.0047
env1_first_0:                 episode reward: -23.0500,                 loss: nan
env1_second_0:                 episode reward: 23.0500,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 3570.15,                last time consumption/overall running time: 2942.4593s / 1208112.5735 s
env0_first_0:                 episode reward: -22.5500,                 loss: 0.0055
env0_second_0:                 episode reward: 22.5500,                 loss: 0.0057
env1_first_0:                 episode reward: -23.3500,                 loss: nan
env1_second_0:                 episode reward: 23.3500,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 3028.8,                last time consumption/overall running time: 2470.9160s / 1210583.4895 s
env0_first_0:                 episode reward: -20.1500,                 loss: 0.0051
env0_second_0:                 episode reward: 20.1500,                 loss: 0.0053
env1_first_0:                 episode reward: -21.0500,                 loss: nan
env1_second_0:                 episode reward: 21.0500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 2823.45,                last time consumption/overall running time: 2304.7843s / 1212888.2738 s
env0_first_0:                 episode reward: -20.9000,                 loss: 0.0046
env0_second_0:                 episode reward: 20.9000,                 loss: 0.0053
env1_first_0:                 episode reward: -19.0500,                 loss: nan
env1_second_0:                 episode reward: 19.0500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 2940.95,                last time consumption/overall running time: 2420.1667s / 1215308.4404 s
env0_first_0:                 episode reward: -20.9000,                 loss: 0.0046
env0_second_0:                 episode reward: 20.9000,                 loss: 0.0048
env1_first_0:                 episode reward: -19.7000,                 loss: nan
env1_second_0:                 episode reward: 19.7000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 4173.65,                last time consumption/overall running time: 3426.9732s / 1218735.4136 s
env0_first_0:                 episode reward: -19.8500,                 loss: 0.0051
env0_second_0:                 episode reward: 19.8500,                 loss: 0.0049
env1_first_0:                 episode reward: -18.7000,                 loss: nan
env1_second_0:                 episode reward: 18.7000,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 2920.65,                last time consumption/overall running time: 2395.4170s / 1221130.8306 s
env0_first_0:                 episode reward: -19.8000,                 loss: 0.0050
env0_second_0:                 episode reward: 19.8000,                 loss: 0.0048
env1_first_0:                 episode reward: -22.2000,                 loss: nan
env1_second_0:                 episode reward: 22.2000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 3016.3,                last time consumption/overall running time: 2472.4083s / 1223603.2389 s
env0_first_0:                 episode reward: -20.4500,                 loss: 0.0043
env0_second_0:                 episode reward: 20.4500,                 loss: 0.0046
env1_first_0:                 episode reward: -18.7500,                 loss: nan
env1_second_0:                 episode reward: 18.7500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 3472.2,                last time consumption/overall running time: 2855.0288s / 1226458.2677 s
env0_first_0:                 episode reward: -18.2000,                 loss: 0.0057
env0_second_0:                 episode reward: 18.2000,                 loss: 0.0057
env1_first_0:                 episode reward: -19.6500,                 loss: nan
env1_second_0:                 episode reward: 19.6500,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 3510.4,                last time consumption/overall running time: 2877.1046s / 1229335.3723 s
env0_first_0:                 episode reward: -19.0500,                 loss: 0.0052
env0_second_0:                 episode reward: 19.0500,                 loss: 0.0055
env1_first_0:                 episode reward: -20.4000,                 loss: nan
env1_second_0:                 episode reward: 20.4000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 3416.1,                last time consumption/overall running time: 2803.1963s / 1232138.5686 s
env0_first_0:                 episode reward: -16.7000,                 loss: 0.0058
env0_second_0:                 episode reward: 16.7000,                 loss: 0.0061
env1_first_0:                 episode reward: -20.5500,                 loss: nan
env1_second_0:                 episode reward: 20.5500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 3266.35,                last time consumption/overall running time: 2692.8829s / 1234831.4516 s
env0_first_0:                 episode reward: -21.4000,                 loss: 0.0053
env0_second_0:                 episode reward: 21.4000,                 loss: 0.0058
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 3524.75,                last time consumption/overall running time: 2890.3908s / 1237721.8423 s
env0_first_0:                 episode reward: -19.5500,                 loss: 0.0052
env0_second_0:                 episode reward: 19.5500,                 loss: 0.0052
env1_first_0:                 episode reward: -16.8000,                 loss: nan
env1_second_0:                 episode reward: 16.8000,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 3367.1,                last time consumption/overall running time: 2833.6118s / 1240555.4541 s
env0_first_0:                 episode reward: -20.0500,                 loss: 0.0052
env0_second_0:                 episode reward: 20.0500,                 loss: 0.0053
env1_first_0:                 episode reward: -23.2500,                 loss: nan
env1_second_0:                 episode reward: 23.2500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 3097.65,                last time consumption/overall running time: 2519.8604s / 1243075.3145 s
env0_first_0:                 episode reward: -22.4500,                 loss: 0.0048
env0_second_0:                 episode reward: 22.4500,                 loss: 0.0052
env1_first_0:                 episode reward: -21.9000,                 loss: nan
env1_second_0:                 episode reward: 21.9000,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 3301.85,                last time consumption/overall running time: 2694.1585s / 1245769.4730 s
env0_first_0:                 episode reward: -23.5000,                 loss: 0.0050
env0_second_0:                 episode reward: 23.5000,                 loss: 0.0054
env1_first_0:                 episode reward: -22.2000,                 loss: nan
env1_second_0:                 episode reward: 22.2000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 4093.1,                last time consumption/overall running time: 3425.2225s / 1249194.6955 s
env0_first_0:                 episode reward: -6.9500,                 loss: 0.0056
env0_second_0:                 episode reward: 6.9500,                 loss: 0.0054
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 4690.55,                last time consumption/overall running time: 3939.5015s / 1253134.1970 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.0089
env0_second_0:                 episode reward: -2.1000,                 loss: 0.0092
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 3529.65,                last time consumption/overall running time: 2985.5805s / 1256119.7775 s
env0_first_0:                 episode reward: -20.6500,                 loss: 0.0055
env0_second_0:                 episode reward: 20.6500,                 loss: 0.0054
env1_first_0:                 episode reward: -22.0000,                 loss: nan
env1_second_0:                 episode reward: 22.0000,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 3315.7,                last time consumption/overall running time: 2790.4489s / 1258910.2263 s
env0_first_0:                 episode reward: -18.5000,                 loss: 0.0056
env0_second_0:                 episode reward: 18.5000,                 loss: 0.0056
env1_first_0:                 episode reward: -18.2500,                 loss: nan
env1_second_0:                 episode reward: 18.2500,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 3384.9,                last time consumption/overall running time: 2807.3014s / 1261717.5277 s
env0_first_0:                 episode reward: -20.5000,                 loss: 0.0051
env0_second_0:                 episode reward: 20.5000,                 loss: 0.0050
env1_first_0:                 episode reward: -21.7500,                 loss: nan
env1_second_0:                 episode reward: 21.7500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 3334.6,                last time consumption/overall running time: 2747.1515s / 1264464.6792 s
env0_first_0:                 episode reward: -21.2000,                 loss: 0.0046
env0_second_0:                 episode reward: 21.2000,                 loss: 0.0048
env1_first_0:                 episode reward: -19.9000,                 loss: nan
env1_second_0:                 episode reward: 19.9000,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 3506.55,                last time consumption/overall running time: 2889.8831s / 1267354.5624 s
env0_first_0:                 episode reward: -14.9000,                 loss: 0.0051
env0_second_0:                 episode reward: 14.9000,                 loss: 0.0052
env1_first_0:                 episode reward: -20.5500,                 loss: nan
env1_second_0:                 episode reward: 20.5500,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 3440.5,                last time consumption/overall running time: 2836.8584s / 1270191.4208 s
env0_first_0:                 episode reward: -20.0500,                 loss: 0.0048
env0_second_0:                 episode reward: 20.0500,                 loss: 0.0047
env1_first_0:                 episode reward: -18.9000,                 loss: nan
env1_second_0:                 episode reward: 18.9000,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 3406.3,                last time consumption/overall running time: 2807.6776s / 1272999.0984 s
env0_first_0:                 episode reward: -20.0500,                 loss: 0.0046
env0_second_0:                 episode reward: 20.0500,                 loss: 0.0046
env1_first_0:                 episode reward: -18.1000,                 loss: nan
env1_second_0:                 episode reward: 18.1000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 3487.65,                last time consumption/overall running time: 3002.7380s / 1276001.8364 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.0067
env0_second_0:                 episode reward: 12.9500,                 loss: 0.0067
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 3125.95,                last time consumption/overall running time: 2568.6827s / 1278570.5191 s
env0_first_0:                 episode reward: -23.5000,                 loss: 0.0049
env0_second_0:                 episode reward: 23.5000,                 loss: 0.0054
env1_first_0:                 episode reward: -21.8000,                 loss: nan
env1_second_0:                 episode reward: 21.8000,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 3287.5,                last time consumption/overall running time: 2701.7564s / 1281272.2754 s
env0_first_0:                 episode reward: -19.6000,                 loss: 0.0050
env0_second_0:                 episode reward: 19.6000,                 loss: 0.0054
env1_first_0:                 episode reward: -20.9000,                 loss: nan
env1_second_0:                 episode reward: 20.9000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 3556.2,                last time consumption/overall running time: 2959.8163s / 1284232.0918 s
env0_first_0:                 episode reward: -22.3000,                 loss: 0.0058
env0_second_0:                 episode reward: 22.3000,                 loss: 0.0056
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 3494.15,                last time consumption/overall running time: 2966.4920s / 1287198.5837 s
env0_first_0:                 episode reward: -23.1500,                 loss: 0.0057
env0_second_0:                 episode reward: 23.1500,                 loss: 0.0055
env1_first_0:                 episode reward: -20.3500,                 loss: nan
env1_second_0:                 episode reward: 20.3500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 3341.55,                last time consumption/overall running time: 2812.1082s / 1290010.6919 s
env0_first_0:                 episode reward: -21.3500,                 loss: 0.0055
env0_second_0:                 episode reward: 21.3500,                 loss: 0.0053
env1_first_0:                 episode reward: -18.2500,                 loss: nan
env1_second_0:                 episode reward: 18.2500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 3253.25,                last time consumption/overall running time: 2739.1654s / 1292749.8573 s
env0_first_0:                 episode reward: -23.9500,                 loss: 0.0053
env0_second_0:                 episode reward: 23.9500,                 loss: 0.0053
env1_first_0:                 episode reward: -22.4000,                 loss: nan
env1_second_0:                 episode reward: 22.4000,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 3153.75,                last time consumption/overall running time: 2582.9373s / 1295332.7947 s
env0_first_0:                 episode reward: -20.6000,                 loss: 0.0056
env0_second_0:                 episode reward: 20.6000,                 loss: 0.0058
env1_first_0:                 episode reward: -24.2000,                 loss: nan
env1_second_0:                 episode reward: 24.2000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 3162.25,                last time consumption/overall running time: 2571.1568s / 1297903.9515 s
env0_first_0:                 episode reward: -20.4500,                 loss: 0.0053
env0_second_0:                 episode reward: 20.4500,                 loss: 0.0056
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 3111.75,                last time consumption/overall running time: 2541.8953s / 1300445.8468 s
env0_first_0:                 episode reward: -23.9500,                 loss: 0.0057
env0_second_0:                 episode reward: 23.9500,                 loss: 0.0057
env1_first_0:                 episode reward: -23.5000,                 loss: nan
env1_second_0:                 episode reward: 23.5000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 2978.25,                last time consumption/overall running time: 2416.2837s / 1302862.1305 s
env0_first_0:                 episode reward: -21.7000,                 loss: 0.0055
env0_second_0:                 episode reward: 21.7000,                 loss: 0.0054
env1_first_0:                 episode reward: -22.9000,                 loss: nan
env1_second_0:                 episode reward: 22.9000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 3534.25,                last time consumption/overall running time: 2878.3666s / 1305740.4971 s
env0_first_0:                 episode reward: -20.0500,                 loss: 0.0054
env0_second_0:                 episode reward: 20.0500,                 loss: 0.0054
env1_first_0:                 episode reward: -18.4500,                 loss: nan
env1_second_0:                 episode reward: 18.4500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 3658.95,                last time consumption/overall running time: 2960.9726s / 1308701.4696 s
env0_first_0:                 episode reward: -21.8000,                 loss: 0.0049
env0_second_0:                 episode reward: 21.8000,                 loss: 0.0051
env1_first_0:                 episode reward: -22.9000,                 loss: nan
env1_second_0:                 episode reward: 22.9000,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 3026.9,                last time consumption/overall running time: 2507.7861s / 1311209.2557 s
env0_first_0:                 episode reward: -23.7000,                 loss: 0.0054
env0_second_0:                 episode reward: 23.7000,                 loss: 0.0054
env1_first_0:                 episode reward: -23.7500,                 loss: nan
env1_second_0:                 episode reward: 23.7500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 3054.9,                last time consumption/overall running time: 2513.0255s / 1313722.2812 s
env0_first_0:                 episode reward: -21.0000,                 loss: 0.0050
env0_second_0:                 episode reward: 21.0000,                 loss: 0.0056
env1_first_0:                 episode reward: -21.3500,                 loss: nan
env1_second_0:                 episode reward: 21.3500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 3380.2,                last time consumption/overall running time: 2750.5514s / 1316472.8326 s
env0_first_0:                 episode reward: -20.5500,                 loss: 0.0049
env0_second_0:                 episode reward: 20.5500,                 loss: 0.0048
env1_first_0:                 episode reward: -22.3000,                 loss: nan
env1_second_0:                 episode reward: 22.3000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 3616.85,                last time consumption/overall running time: 2961.8634s / 1319434.6960 s
env0_first_0:                 episode reward: -16.0000,                 loss: 0.0050
env0_second_0:                 episode reward: 16.0000,                 loss: 0.0051
env1_first_0:                 episode reward: -18.0000,                 loss: nan
env1_second_0:                 episode reward: 18.0000,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 3548.95,                last time consumption/overall running time: 2912.6304s / 1322347.3264 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.0091
env0_second_0:                 episode reward: 11.7000,                 loss: 0.0090
env1_first_0:                 episode reward: -3.7000,                 loss: nan
env1_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 3678.85,                last time consumption/overall running time: 2976.7297s / 1325324.0562 s
env0_first_0:                 episode reward: -22.7500,                 loss: 0.0055
env0_second_0:                 episode reward: 22.7500,                 loss: 0.0055
env1_first_0:                 episode reward: -22.4000,                 loss: nan
env1_second_0:                 episode reward: 22.4000,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 3732.6,                last time consumption/overall running time: 3046.4103s / 1328370.4665 s
env0_first_0:                 episode reward: -20.9000,                 loss: 0.0053
env0_second_0:                 episode reward: 20.9000,                 loss: 0.0053
env1_first_0:                 episode reward: -21.9000,                 loss: nan
env1_second_0:                 episode reward: 21.9000,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 3577.5,                last time consumption/overall running time: 2924.0040s / 1331294.4705 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.0058
env0_second_0:                 episode reward: 12.2000,                 loss: 0.0062
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 3205.85,                last time consumption/overall running time: 2640.2934s / 1333934.7639 s
env0_first_0:                 episode reward: -21.0000,                 loss: 0.0057
env0_second_0:                 episode reward: 21.0000,                 loss: 0.0061
env1_first_0:                 episode reward: -20.4500,                 loss: nan
env1_second_0:                 episode reward: 20.4500,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 3808.55,                last time consumption/overall running time: 3183.1636s / 1337117.9276 s
env0_first_0:                 episode reward: -21.9000,                 loss: 0.0049
env0_second_0:                 episode reward: 21.9000,                 loss: 0.0051
env1_first_0:                 episode reward: -19.7500,                 loss: nan
env1_second_0:                 episode reward: 19.7500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 3645.65,                last time consumption/overall running time: 3033.0207s / 1340150.9483 s
env0_first_0:                 episode reward: -21.2500,                 loss: 0.0056
env0_second_0:                 episode reward: 21.2500,                 loss: 0.0052
env1_first_0:                 episode reward: -21.6500,                 loss: nan
env1_second_0:                 episode reward: 21.6500,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 3170.6,                last time consumption/overall running time: 2568.2341s / 1342719.1824 s
env0_first_0:                 episode reward: -18.0500,                 loss: 0.0049
env0_second_0:                 episode reward: 18.0500,                 loss: 0.0048
env1_first_0:                 episode reward: -23.2000,                 loss: nan
env1_second_0:                 episode reward: 23.2000,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 3013.5,                last time consumption/overall running time: 2460.1471s / 1345179.3294 s
env0_first_0:                 episode reward: -20.5000,                 loss: 0.0052
env0_second_0:                 episode reward: 20.5000,                 loss: 0.0052
env1_first_0:                 episode reward: -20.1000,                 loss: nan
env1_second_0:                 episode reward: 20.1000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 3230.5,                last time consumption/overall running time: 2621.4540s / 1347800.7834 s
env0_first_0:                 episode reward: -16.9000,                 loss: 0.0055
env0_second_0:                 episode reward: 16.9000,                 loss: 0.0060
env1_first_0:                 episode reward: -21.2500,                 loss: nan
env1_second_0:                 episode reward: 21.2500,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 4476.0,                last time consumption/overall running time: 3631.0668s / 1351431.8502 s
env0_first_0:                 episode reward: -24.0000,                 loss: 0.0053
env0_second_0:                 episode reward: 24.0000,                 loss: 0.0056
env1_first_0:                 episode reward: -21.6500,                 loss: nan
env1_second_0:                 episode reward: 21.6500,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 4433.4,                last time consumption/overall running time: 3604.1067s / 1355035.9569 s
env0_first_0:                 episode reward: -19.1000,                 loss: 0.0055
env0_second_0:                 episode reward: 19.1000,                 loss: 0.0053
env1_first_0:                 episode reward: -19.9000,                 loss: nan
env1_second_0:                 episode reward: 19.9000,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 3804.1,                last time consumption/overall running time: 3077.4522s / 1358113.4091 s
env0_first_0:                 episode reward: -17.0000,                 loss: 0.0048
env0_second_0:                 episode reward: 17.0000,                 loss: 0.0046
env1_first_0:                 episode reward: -19.7500,                 loss: nan
env1_second_0:                 episode reward: 19.7500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 3777.05,                last time consumption/overall running time: 3025.2049s / 1361138.6140 s
env0_first_0:                 episode reward: -17.4500,                 loss: 0.0054
env0_second_0:                 episode reward: 17.4500,                 loss: 0.0049
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 3765.5,                last time consumption/overall running time: 3021.1942s / 1364159.8083 s
env0_first_0:                 episode reward: -15.8500,                 loss: 0.0050
env0_second_0:                 episode reward: 15.8500,                 loss: 0.0053
env1_first_0:                 episode reward: -17.0500,                 loss: nan
env1_second_0:                 episode reward: 17.0500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 4071.7,                last time consumption/overall running time: 3283.2017s / 1367443.0100 s
env0_first_0:                 episode reward: -17.2500,                 loss: 0.0062
env0_second_0:                 episode reward: 17.2500,                 loss: 0.0065
env1_first_0:                 episode reward: -17.9500,                 loss: nan
env1_second_0:                 episode reward: 17.9500,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 4138.35,                last time consumption/overall running time: 3324.9795s / 1370767.9895 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.0051
env0_second_0:                 episode reward: 15.2000,                 loss: 0.0054
env1_first_0:                 episode reward: -17.8500,                 loss: nan
env1_second_0:                 episode reward: 17.8500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 3372.75,                last time consumption/overall running time: 2740.1119s / 1373508.1014 s
env0_first_0:                 episode reward: -23.7000,                 loss: 0.0061
env0_second_0:                 episode reward: 23.7000,                 loss: 0.0058
env1_first_0:                 episode reward: -19.5000,                 loss: nan
env1_second_0:                 episode reward: 19.5000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 3110.85,                last time consumption/overall running time: 2527.9942s / 1376036.0956 s
env0_first_0:                 episode reward: -21.5000,                 loss: 0.0049
env0_second_0:                 episode reward: 21.5000,                 loss: 0.0043
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 3477.65,                last time consumption/overall running time: 2797.0135s / 1378833.1091 s
env0_first_0:                 episode reward: -21.2500,                 loss: 0.0048
env0_second_0:                 episode reward: 21.2500,                 loss: 0.0046
env1_first_0:                 episode reward: -18.5000,                 loss: nan
env1_second_0:                 episode reward: 18.5000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 3020.95,                last time consumption/overall running time: 2452.5872s / 1381285.6962 s
env0_first_0:                 episode reward: -20.5500,                 loss: 0.0048
env0_second_0:                 episode reward: 20.5500,                 loss: 0.0049
env1_first_0:                 episode reward: -23.0000,                 loss: nan
env1_second_0:                 episode reward: 23.0000,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 3365.9,                last time consumption/overall running time: 2725.8619s / 1384011.5581 s
env0_first_0:                 episode reward: -21.5500,                 loss: 0.0049
env0_second_0:                 episode reward: 21.5500,                 loss: 0.0048
env1_first_0:                 episode reward: -20.9500,                 loss: nan
env1_second_0:                 episode reward: 20.9500,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 3732.3,                last time consumption/overall running time: 3018.6244s / 1387030.1826 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.0069
env0_second_0:                 episode reward: 13.8000,                 loss: 0.0067
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 3548.5,                last time consumption/overall running time: 2875.0936s / 1389905.2761 s
env0_first_0:                 episode reward: -21.4500,                 loss: 0.0051
env0_second_0:                 episode reward: 21.4500,                 loss: 0.0049
env1_first_0:                 episode reward: -21.5500,                 loss: nan
env1_second_0:                 episode reward: 21.5500,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 3636.55,                last time consumption/overall running time: 2959.4796s / 1392864.7557 s
env0_first_0:                 episode reward: -21.1000,                 loss: 0.0053
env0_second_0:                 episode reward: 21.1000,                 loss: 0.0051
env1_first_0:                 episode reward: -22.2500,                 loss: nan
env1_second_0:                 episode reward: 22.2500,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 3669.2,                last time consumption/overall running time: 2987.0961s / 1395851.8518 s
env0_first_0:                 episode reward: -21.2000,                 loss: 0.0053
env0_second_0:                 episode reward: 21.2000,                 loss: 0.0058
env1_first_0:                 episode reward: -20.6000,                 loss: nan
env1_second_0:                 episode reward: 20.6000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 3347.35,                last time consumption/overall running time: 2797.2542s / 1398649.1060 s
env0_first_0:                 episode reward: -23.3500,                 loss: 0.0055
env0_second_0:                 episode reward: 23.3500,                 loss: 0.0059
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 3383.9,                last time consumption/overall running time: 2749.3769s / 1401398.4829 s
env0_first_0:                 episode reward: -20.1000,                 loss: 0.0054
env0_second_0:                 episode reward: 20.1000,                 loss: 0.0058
env1_first_0:                 episode reward: -19.8000,                 loss: nan
env1_second_0:                 episode reward: 19.8000,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 3842.45,                last time consumption/overall running time: 3146.6434s / 1404545.1264 s
env0_first_0:                 episode reward: -20.2500,                 loss: 0.0053
env0_second_0:                 episode reward: 20.2500,                 loss: 0.0056
env1_first_0:                 episode reward: -19.7000,                 loss: nan
env1_second_0:                 episode reward: 19.7000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 2954.75,                last time consumption/overall running time: 2406.8504s / 1406951.9768 s
env0_first_0:                 episode reward: -16.8500,                 loss: 0.0051
env0_second_0:                 episode reward: 16.8500,                 loss: 0.0053
env1_first_0:                 episode reward: -17.7500,                 loss: nan
env1_second_0:                 episode reward: 17.7500,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 4097.15,                last time consumption/overall running time: 3362.6391s / 1410314.6159 s
env0_first_0:                 episode reward: -19.7500,                 loss: 0.0050
env0_second_0:                 episode reward: 19.7500,                 loss: 0.0049
env1_first_0:                 episode reward: -20.6000,                 loss: nan
env1_second_0:                 episode reward: 20.6000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 3543.3,                last time consumption/overall running time: 2943.3984s / 1413258.0143 s
env0_first_0:                 episode reward: -17.5000,                 loss: 0.0050
env0_second_0:                 episode reward: 17.5000,                 loss: 0.0049
env1_first_0:                 episode reward: -19.1500,                 loss: nan
env1_second_0:                 episode reward: 19.1500,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 4934.05,                last time consumption/overall running time: 4038.5181s / 1417296.5323 s
env0_first_0:                 episode reward: -22.5000,                 loss: 0.0053
env0_second_0:                 episode reward: 22.5000,                 loss: 0.0050
env1_first_0:                 episode reward: -23.6000,                 loss: nan
env1_second_0:                 episode reward: 23.6000,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 4108.95,                last time consumption/overall running time: 3323.3348s / 1420619.8672 s
env0_first_0:                 episode reward: -23.6000,                 loss: 0.0053
env0_second_0:                 episode reward: 23.6000,                 loss: 0.0053
env1_first_0:                 episode reward: -23.7500,                 loss: nan
env1_second_0:                 episode reward: 23.7500,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 4433.15,                last time consumption/overall running time: 3639.9447s / 1424259.8119 sLoad tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
/home/zihan/research/MARS/mars/rl/agents/nash_dqn_exploiter.py:174: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  action = torch.LongTensor(action).to(self.device)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env0_first_0:                 episode reward: -18.7000,                 loss: 0.0053
env0_second_0:                 episode reward: 18.7000,                 loss: 0.0052
env1_first_0:                 episode reward: -17.8500,                 loss: nan
env1_second_0:                 episode reward: 17.8500,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 4626.6,                last time consumption/overall running time: 3797.3919s / 1428057.2038 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0067
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0065
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 3914.65,                last time consumption/overall running time: 3365.0073s / 1431422.2111 s
env0_first_0:                 episode reward: -22.4500,                 loss: 0.0061
env0_second_0:                 episode reward: 22.4500,                 loss: 0.0061
env1_first_0:                 episode reward: -22.8000,                 loss: nan
env1_second_0:                 episode reward: 22.8000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 4101.15,                last time consumption/overall running time: 3364.8439s / 1434787.0550 s
env0_first_0:                 episode reward: -21.9000,                 loss: 0.0045
env0_second_0:                 episode reward: 21.9000,                 loss: 0.0047
env1_first_0:                 episode reward: -19.8500,                 loss: nan
env1_second_0:                 episode reward: 19.8500,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 3879.05,                last time consumption/overall running time: 3148.4890s / 1437935.5440 s
env0_first_0:                 episode reward: -19.8000,                 loss: 0.0042
env0_second_0:                 episode reward: 19.8000,                 loss: 0.0044
env1_first_0:                 episode reward: -18.0000,                 loss: nan
env1_second_0:                 episode reward: 18.0000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 3712.0,                last time consumption/overall running time: 3067.4176s / 1441002.9616 s
env0_first_0:                 episode reward: -18.8000,                 loss: 0.0045
env0_second_0:                 episode reward: 18.8000,                 loss: 0.0050
env1_first_0:                 episode reward: -17.4000,                 loss: nan
env1_second_0:                 episode reward: 17.4000,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 3546.5,                last time consumption/overall running time: 2918.8618s / 1443921.8234 s
env0_first_0:                 episode reward: -17.1000,                 loss: 0.0049
env0_second_0:                 episode reward: 17.1000,                 loss: 0.0053
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 3749.05,                last time consumption/overall running time: 3049.3129s / 1446971.1363 s
env0_first_0:                 episode reward: -16.6500,                 loss: 0.0048
env0_second_0:                 episode reward: 16.6500,                 loss: 0.0049
env1_first_0:                 episode reward: -20.4500,                 loss: nan
env1_second_0:                 episode reward: 20.4500,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 3522.5,                last time consumption/overall running time: 2924.6149s / 1449895.7512 s
env0_first_0:                 episode reward: -19.1000,                 loss: 0.0049
env0_second_0:                 episode reward: 19.1000,                 loss: 0.0047
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 3493.95,                last time consumption/overall running time: 2971.9558s / 1452867.7069 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.0057
env0_second_0:                 episode reward: 12.2000,                 loss: 0.0058
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 3394.5,                last time consumption/overall running time: 2824.3608s / 1455692.0678 s
env0_first_0:                 episode reward: -21.0500,                 loss: 0.0043
env0_second_0:                 episode reward: 21.0500,                 loss: 0.0047
env1_first_0:                 episode reward: -20.6500,                 loss: nan
env1_second_0:                 episode reward: 20.6500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 3871.05,                last time consumption/overall running time: 3096.0801s / 1458788.1479 s
env0_first_0:                 episode reward: -20.1000,                 loss: 0.0055
env0_second_0:                 episode reward: 20.1000,                 loss: 0.0057
env1_first_0:                 episode reward: -23.6500,                 loss: nan
env1_second_0:                 episode reward: 23.6500,                 loss: nan
