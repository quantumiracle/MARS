pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
random seed: 91
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f182a3f5110>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [array([0.223, 0.081, 0.081, ..., 0.   , 0.   , 0.   ]) array([0.073, 0.014, 0.056, ..., 0.   , 0.   , 0.   ])]
Load checkpoints (policy family):  [list(['83', '5753', '6419', '9691', '12712', '16446', '20191', '20772', '24729', '28587', '35631', '38431', '38946', '39041', '39808', '40118', '40412', '41100', '41478', '41778', '41983', '42076', '42433', '42768', '43151', '43229', '43949', '44117', '44258', '44846', '45166', '45962', '46596', '46667', '47327', '47599', '47724', '48094', '48455', '48649', '48828', '49089', '49310', '49568', '49947', '50154', '50323', '50446', '51000', '52183', '52933', '53029', '53373', '54083', '54247', '54577', '54813', '55333', '55871', '55920', '55984', '56212', '56500', '56609', '56849', '57129', '57305', '57555', '59346', '59648', '59764', '60207', '60423', '61244', '61420', '61592', '61837', '62162', '62663', '62787', '63152', '63581', '64655', '65225', '65678', '65977', '66229', '66493', '66823', '67596', '67842', '68192', '68377', '68658', '68870', '69079', '69130', '70683', '70945', '71028', '71872', '72171', '72330', '73029', '73234', '73651', '74310', '74673', '75564', '75872', '76617', '77360', '77698', '78278', '78468', '78608', '78725', '78831', '78946', '79127', '79375', '80113', '80412', '80964', '81822', '82081', '82591', '82743', '83276', '83457', '83821', '84289', '84705', '85190', '85520', '86114', '86276', '86458', '86795', '87082', '87322', '87419', '87647', '88120', '89504', '89866', '90025', '90883', '91498', '91752', '93315', '93611', '94495', '95458', '95705', '95803', '96469', '97114', '97170', '98252', '98869', '99486'])
 list(['121', '6342', '6627', '9768', '12785', '16467', '20231', '20802', '24751', '28619', '35652', '38452', '38973', '39078', '39831', '40164', '40433', '41156', '41501', '41819', '42011', '42097', '42458', '42797', '43176', '43250', '44010', '44146', '44297', '44888', '45313', '45997', '46620', '46694', '47431', '47654', '47771', '48131', '48485', '48670', '48949', '49156', '49349', '49679', '49974', '50175', '50367', '50477', '51025', '52237', '52954', '53079', '53449', '54148', '54273', '54643', '54841', '55369', '55895', '55950', '56022', '56241', '56546', '56722', '56881', '57157', '57352', '57708', '59367', '59703', '59852', '60231', '60531', '61274', '61444', '61613', '61885', '62188', '62700', '62816', '63249', '63724', '64717', '65246', '65752', '66003', '66266', '66518', '66855', '67649', '67880', '68289', '68425', '68783', '68960', '69100', '69268', '70743', '70983', '71060', '71894', '72207', '72417', '73050', '73299', '73719', '74432', '74706', '75649', '75983', '76641', '77384', '77739', '78307', '78490', '78693', '78767', '78877', '78967', '79225', '79437', '80135', '80505', '81139', '81856', '82144', '82612', '82779', '83426', '83515', '83845', '84367', '84741', '85211', '85586', '86171', '86300', '86517', '86857', '87103', '87356', '87440', '87695', '88141', '89586', '89887', '90046', '90922', '91623', '91860', '93350', '93827', '94522', '95483', '95772', '95848', '96494', '97135', '97248', '98304', '98894'])]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'update_itr': 1}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'cpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220116204408/epi_100000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nxdo2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220116204408_exploit_100000/mdp_arbitrary_mdp_nxdo2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220116204408_exploit_100000/mdp_arbitrary_mdp_nxdo2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.3364s / 1.3364 s
agent0:                 episode reward: -1.6958,                 loss: nan
agent1:                 episode reward: 1.6958,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3782s / 1.7146 s
agent0:                 episode reward: -0.1702,                 loss: nan
agent1:                 episode reward: 0.1702,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4506s / 2.1651 s
agent0:                 episode reward: -0.2973,                 loss: nan
agent1:                 episode reward: 0.2973,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3798s / 2.5449 s
agent0:                 episode reward: 0.1981,                 loss: nan
agent1:                 episode reward: -0.1981,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0780s / 2.6229 s
agent0:                 episode reward: -0.2053,                 loss: nan
agent1:                 episode reward: 0.2053,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0839s / 2.7068 s
agent0:                 episode reward: -0.0053,                 loss: nan
agent1:                 episode reward: 0.0053,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2146s / 2.9214 s
agent0:                 episode reward: -0.0456,                 loss: nan
agent1:                 episode reward: 0.0456,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4452s / 3.3666 s
agent0:                 episode reward: 0.0104,                 loss: nan
agent1:                 episode reward: -0.0104,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3944s / 3.7610 s
agent0:                 episode reward: 0.0118,                 loss: nan
agent1:                 episode reward: -0.0118,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.4392s / 4.2002 s
agent0:                 episode reward: 0.7763,                 loss: nan
agent1:                 episode reward: -0.7763,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6158s / 4.8160 s
agent0:                 episode reward: -0.1258,                 loss: nan
agent1:                 episode reward: 0.1258,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 41.2566s / 46.0726 s
agent0:                 episode reward: -0.1778,                 loss: nan
agent1:                 episode reward: 0.1778,                 loss: 0.2028
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 101.7419s / 147.8146 s
agent0:                 episode reward: 0.2117,                 loss: nan
agent1:                 episode reward: -0.2117,                 loss: 0.1811
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 97.8385s / 245.6531 s
agent0:                 episode reward: 0.1278,                 loss: nan
agent1:                 episode reward: -0.1278,                 loss: 0.1662
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 94.9347s / 340.5877 s
agent0:                 episode reward: 0.3436,                 loss: nan
agent1:                 episode reward: -0.3436,                 loss: 0.1603
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 95.7066s / 436.2944 s
agent0:                 episode reward: 0.1229,                 loss: nan
agent1:                 episode reward: -0.1229,                 loss: 0.1602
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 99.0614s / 535.3558 s
agent0:                 episode reward: 0.3948,                 loss: nan
agent1:                 episode reward: -0.3948,                 loss: 0.1593
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 100.6371s / 635.9929 s
agent0:                 episode reward: 0.0205,                 loss: nan
agent1:                 episode reward: -0.0205,                 loss: 0.1582
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 99.7329s / 735.7258 s
agent0:                 episode reward: 0.1984,                 loss: nan
agent1:                 episode reward: -0.1984,                 loss: 0.1573
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 101.3056s / 837.0314 s
agent0:                 episode reward: 0.2493,                 loss: nan
agent1:                 episode reward: -0.2493,                 loss: 0.1533
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 99.9123s / 936.9437 s
agent0:                 episode reward: 0.5271,                 loss: nan
agent1:                 episode reward: -0.5271,                 loss: 0.1532
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 102.1192s / 1039.0629 s
agent0:                 episode reward: 0.0461,                 loss: nan
agent1:                 episode reward: -0.0461,                 loss: 0.1516
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 97.7451s / 1136.8080 s
agent0:                 episode reward: -0.1816,                 loss: nan
agent1:                 episode reward: 0.1816,                 loss: 0.1509
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 100.2249s / 1237.0329 s
agent0:                 episode reward: -0.1435,                 loss: nan
agent1:                 episode reward: 0.1435,                 loss: 0.1514
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 92.3163s / 1329.3492 s
agent0:                 episode reward: -0.0912,                 loss: nan
agent1:                 episode reward: 0.0912,                 loss: 0.1510
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 98.2383s / 1427.5875 s
agent0:                 episode reward: -0.3675,                 loss: nan
agent1:                 episode reward: 0.3675,                 loss: 0.1496
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 97.1210s / 1524.7085 s
agent0:                 episode reward: 0.0298,                 loss: nan
agent1:                 episode reward: -0.0298,                 loss: 0.1487
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 100.6764s / 1625.3848 s
agent0:                 episode reward: 0.3763,                 loss: nan
agent1:                 episode reward: -0.3763,                 loss: 0.1488
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 101.4683s / 1726.8532 s
agent0:                 episode reward: -0.1778,                 loss: nan
agent1:                 episode reward: 0.1778,                 loss: 0.1626
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 99.8099s / 1826.6630 s
agent0:                 episode reward: 0.4970,                 loss: nan
agent1:                 episode reward: -0.4970,                 loss: 0.1566
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 95.5612s / 1922.2242 s
agent0:                 episode reward: -0.2428,                 loss: nan
agent1:                 episode reward: 0.2428,                 loss: 0.1570
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 99.1095s / 2021.3337 s
agent0:                 episode reward: -0.2394,                 loss: nan
agent1:                 episode reward: 0.2394,                 loss: 0.1564
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 98.8400s / 2120.1737 s
agent0:                 episode reward: 0.0904,                 loss: nan
agent1:                 episode reward: -0.0904,                 loss: 0.1575
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 98.2826s / 2218.4563 s
agent0:                 episode reward: 0.1020,                 loss: nan
agent1:                 episode reward: -0.1020,                 loss: 0.1571
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 99.1404s / 2317.5967 s
agent0:                 episode reward: 0.2806,                 loss: nan
agent1:                 episode reward: -0.2806,                 loss: 0.1562
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 95.8113s / 2413.4080 s
agent0:                 episode reward: -0.2958,                 loss: nan
agent1:                 episode reward: 0.2958,                 loss: 0.1553
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 99.5769s / 2512.9849 s
agent0:                 episode reward: -0.2514,                 loss: nan
agent1:                 episode reward: 0.2514,                 loss: 0.1546
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 99.7373s / 2612.7221 s
agent0:                 episode reward: 0.0234,                 loss: nan
agent1:                 episode reward: -0.0234,                 loss: 0.1551
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 97.1498s / 2709.8719 s
agent0:                 episode reward: 0.3021,                 loss: nan
agent1:                 episode reward: -0.3021,                 loss: 0.1548
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 125.1451s / 2835.0170 s
agent0:                 episode reward: 0.0735,                 loss: nan
agent1:                 episode reward: -0.0735,                 loss: 0.1548
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7593s / 2972.7763 s
agent0:                 episode reward: 0.2739,                 loss: nan
agent1:                 episode reward: -0.2739,                 loss: 0.1549
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.3621s / 3114.1384 s
agent0:                 episode reward: -0.4212,                 loss: nan
agent1:                 episode reward: 0.4212,                 loss: 0.1525
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1361s / 3249.2745 s
agent0:                 episode reward: -0.1879,                 loss: nan
agent1:                 episode reward: 0.1879,                 loss: 0.1531
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1808s / 3385.4553 s
agent0:                 episode reward: 0.3112,                 loss: nan
agent1:                 episode reward: -0.3112,                 loss: 0.1537
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5531s / 3523.0084 s
agent0:                 episode reward: -0.4369,                 loss: nan
agent1:                 episode reward: 0.4369,                 loss: 0.1515
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9352s / 3658.9437 s
agent0:                 episode reward: 0.0854,                 loss: nan
agent1:                 episode reward: -0.0854,                 loss: 0.1498
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.2068s / 3791.1504 s
agent0:                 episode reward: 0.1829,                 loss: nan
agent1:                 episode reward: -0.1829,                 loss: 0.1502
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7847s / 3928.9351 s
agent0:                 episode reward: 0.1208,                 loss: nan
agent1:                 episode reward: -0.1208,                 loss: 0.1499
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7715s / 4065.7066 s
agent0:                 episode reward: -0.3286,                 loss: nan
agent1:                 episode reward: 0.3286,                 loss: 0.1483
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.7817s / 4204.4883 s
agent0:                 episode reward: -0.2086,                 loss: nan
agent1:                 episode reward: 0.2086,                 loss: 0.1484
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7537s / 4341.2420 s
agent0:                 episode reward: 0.0526,                 loss: nan
agent1:                 episode reward: -0.0526,                 loss: 0.1490
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6559s / 4479.8980 s
agent0:                 episode reward: -0.4409,                 loss: nan
agent1:                 episode reward: 0.4409,                 loss: 0.1490
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5734s / 4613.4713 s
agent0:                 episode reward: -0.1441,                 loss: nan
agent1:                 episode reward: 0.1441,                 loss: 0.1483
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.1570s / 4756.6283 s
agent0:                 episode reward: 0.3206,                 loss: nan
agent1:                 episode reward: -0.3206,                 loss: 0.1485
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.6789s / 4896.3072 s
agent0:                 episode reward: -0.0450,                 loss: nan
agent1:                 episode reward: 0.0450,                 loss: 0.1479
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.6798s / 5038.9870 s
agent0:                 episode reward: -0.2907,                 loss: nan
agent1:                 episode reward: 0.2907,                 loss: 0.1475
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5529s / 5176.5399 s
agent0:                 episode reward: 0.0571,                 loss: nan
agent1:                 episode reward: -0.0571,                 loss: 0.1475
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9175s / 5314.4573 s
agent0:                 episode reward: 0.0246,                 loss: nan
agent1:                 episode reward: -0.0246,                 loss: 0.1480
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9909s / 5452.4482 s
agent0:                 episode reward: 0.1339,                 loss: nan
agent1:                 episode reward: -0.1339,                 loss: 0.1469
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.5757s / 5595.0239 s
agent0:                 episode reward: -0.0498,                 loss: nan
agent1:                 episode reward: 0.0498,                 loss: 0.1467
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5403s / 5730.5642 s
agent0:                 episode reward: 0.1322,                 loss: nan
agent1:                 episode reward: -0.1322,                 loss: 0.1481
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4933s / 5869.0574 s
agent0:                 episode reward: 0.0360,                 loss: nan
agent1:                 episode reward: -0.0360,                 loss: 0.1497
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.4825s / 6010.5399 s
agent0:                 episode reward: 0.1317,                 loss: nan
agent1:                 episode reward: -0.1317,                 loss: 0.1514
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.9593s / 6151.4992 s
agent0:                 episode reward: -0.5152,                 loss: nan
agent1:                 episode reward: 0.5152,                 loss: 0.1517
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.2001s / 6290.6993 s
agent0:                 episode reward: -0.4252,                 loss: nan
agent1:                 episode reward: 0.4252,                 loss: 0.1515
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2611s / 6428.9603 s
agent0:                 episode reward: 0.3535,                 loss: nan
agent1:                 episode reward: -0.3535,                 loss: 0.1520
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3758s / 6566.3361 s
agent0:                 episode reward: 0.0019,                 loss: nan
agent1:                 episode reward: -0.0019,                 loss: 0.1523
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.2357s / 6706.5718 s
agent0:                 episode reward: 0.0209,                 loss: nan
agent1:                 episode reward: -0.0209,                 loss: 0.1520
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7635s / 6843.3354 s
agent0:                 episode reward: -0.4920,                 loss: nan
agent1:                 episode reward: 0.4920,                 loss: 0.1531
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0317s / 6981.3671 s
agent0:                 episode reward: 0.1115,                 loss: nan
agent1:                 episode reward: -0.1115,                 loss: 0.1529
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.3532s / 7121.7203 s
agent0:                 episode reward: 0.1888,                 loss: nan
agent1:                 episode reward: -0.1888,                 loss: 0.1513
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2365s / 7258.9568 s
agent0:                 episode reward: -0.1748,                 loss: nan
agent1:                 episode reward: 0.1748,                 loss: 0.1521
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.3474s / 7399.3042 s
agent0:                 episode reward: 0.1873,                 loss: nan
agent1:                 episode reward: -0.1873,                 loss: 0.1529
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.8288s / 7539.1331 s
agent0:                 episode reward: -0.0797,                 loss: nan
agent1:                 episode reward: 0.0797,                 loss: 0.1530
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.8805s / 7680.0136 s
agent0:                 episode reward: 0.1179,                 loss: nan
agent1:                 episode reward: -0.1179,                 loss: 0.1527
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.3747s / 7820.3882 s
agent0:                 episode reward: 0.5063,                 loss: nan
agent1:                 episode reward: -0.5063,                 loss: 0.1512
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3224s / 7956.7106 s
agent0:                 episode reward: -0.2033,                 loss: nan
agent1:                 episode reward: 0.2033,                 loss: 0.1517
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.5700s / 8097.2807 s
agent0:                 episode reward: 0.0214,                 loss: nan
agent1:                 episode reward: -0.0214,                 loss: 0.1497
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3235s / 8234.6042 s
agent0:                 episode reward: -0.2202,                 loss: nan
agent1:                 episode reward: 0.2202,                 loss: 0.1527
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2806s / 8370.8848 s
agent0:                 episode reward: -0.1768,                 loss: nan
agent1:                 episode reward: 0.1768,                 loss: 0.1538
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.9161s / 8509.8008 s
agent0:                 episode reward: -0.0693,                 loss: nan
agent1:                 episode reward: 0.0693,                 loss: 0.1538
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.1408s / 8650.9417 s
agent0:                 episode reward: -0.3884,                 loss: nan
agent1:                 episode reward: 0.3884,                 loss: 0.1549
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.2102s / 8792.1519 s
agent0:                 episode reward: 0.1243,                 loss: nan
agent1:                 episode reward: -0.1243,                 loss: 0.1541
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2292s / 8927.3811 s
agent0:                 episode reward: -0.3814,                 loss: nan
agent1:                 episode reward: 0.3814,                 loss: 0.1527
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.2915s / 9066.6726 s
agent0:                 episode reward: -0.4391,                 loss: nan
agent1:                 episode reward: 0.4391,                 loss: 0.1540
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.4040s / 9206.0766 s
agent0:                 episode reward: 0.0386,                 loss: nan
agent1:                 episode reward: -0.0386,                 loss: 0.1552
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8649s / 9343.9415 s
agent0:                 episode reward: -0.1279,                 loss: nan
agent1:                 episode reward: 0.1279,                 loss: 0.1536
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.8462s / 9484.7877 s
agent0:                 episode reward: -0.5293,                 loss: nan
agent1:                 episode reward: 0.5293,                 loss: 0.1535
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5038s / 9622.2915 s
agent0:                 episode reward: -0.1422,                 loss: nan
agent1:                 episode reward: 0.1422,                 loss: 0.1531
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2237s / 9760.5152 s
agent0:                 episode reward: 0.3512,                 loss: nan
agent1:                 episode reward: -0.3512,                 loss: 0.1529
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.4981s / 9900.0134 s
agent0:                 episode reward: -0.0086,                 loss: nan
agent1:                 episode reward: 0.0086,                 loss: 0.1541
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6478s / 10037.6612 s
agent0:                 episode reward: -0.1919,                 loss: nan
agent1:                 episode reward: 0.1919,                 loss: 0.1544
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.9230s / 10181.5841 s
agent0:                 episode reward: -0.2792,                 loss: nan
agent1:                 episode reward: 0.2792,                 loss: 0.1547
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.0327s / 10321.6169 s
agent0:                 episode reward: -0.1265,                 loss: nan
agent1:                 episode reward: 0.1265,                 loss: 0.1546
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7638s / 10459.3807 s
agent0:                 episode reward: -0.2970,                 loss: nan
agent1:                 episode reward: 0.2970,                 loss: 0.1550
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9856s / 10599.3663 s
agent0:                 episode reward: 0.1245,                 loss: nan
agent1:                 episode reward: -0.1245,                 loss: 0.1543
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2900s / 10735.6563 s
agent0:                 episode reward: -0.1338,                 loss: nan
agent1:                 episode reward: 0.1338,                 loss: 0.1536
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5698s / 10875.2261 s
agent0:                 episode reward: 0.2708,                 loss: nan
agent1:                 episode reward: -0.2708,                 loss: 0.1526
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.3361s / 11014.5622 s
agent0:                 episode reward: -0.1156,                 loss: nan
agent1:                 episode reward: 0.1156,                 loss: 0.1549
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9472s / 11154.5094 s
agent0:                 episode reward: -0.5897,                 loss: nan
agent1:                 episode reward: 0.5897,                 loss: 0.1542
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.5709s / 11295.0802 s
agent0:                 episode reward: 0.1450,                 loss: nan
agent1:                 episode reward: -0.1450,                 loss: 0.1526
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3045s / 11432.3847 s
agent0:                 episode reward: -0.1066,                 loss: nan
agent1:                 episode reward: 0.1066,                 loss: 0.1522
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6496s / 11571.0343 s
agent0:                 episode reward: -0.3045,                 loss: nan
agent1:                 episode reward: 0.3045,                 loss: 0.1535
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8602s / 11709.8945 s
agent0:                 episode reward: 0.0032,                 loss: nan
agent1:                 episode reward: -0.0032,                 loss: 0.1530
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.3821s / 11849.2766 s
agent0:                 episode reward: -0.2242,                 loss: nan
agent1:                 episode reward: 0.2242,                 loss: 0.1528
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6870s / 11985.9636 s
agent0:                 episode reward: 0.2759,                 loss: nan
agent1:                 episode reward: -0.2759,                 loss: 0.1533
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2949s / 12123.2586 s
agent0:                 episode reward: -0.0078,                 loss: nan
agent1:                 episode reward: 0.0078,                 loss: 0.1531
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.1124s / 12265.3709 s
agent0:                 episode reward: -0.0951,                 loss: nan
agent1:                 episode reward: 0.0951,                 loss: 0.1528
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.5511s / 12407.9221 s
agent0:                 episode reward: -0.2258,                 loss: nan
agent1:                 episode reward: 0.2258,                 loss: 0.1527
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.6009s / 12547.5230 s
agent0:                 episode reward: -0.2603,                 loss: nan
agent1:                 episode reward: 0.2603,                 loss: 0.1530
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.3110s / 12689.8340 s
agent0:                 episode reward: 0.0727,                 loss: nan
agent1:                 episode reward: -0.0727,                 loss: 0.1516
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.3577s / 12833.1917 s
agent0:                 episode reward: 0.1782,                 loss: nan
agent1:                 episode reward: -0.1782,                 loss: 0.1531
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.7474s / 12974.9390 s
agent0:                 episode reward: 0.0735,                 loss: nan
agent1:                 episode reward: -0.0735,                 loss: 0.1538
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.0819s / 13117.0209 s
agent0:                 episode reward: -0.0861,                 loss: nan
agent1:                 episode reward: 0.0861,                 loss: 0.1555
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.4991s / 13258.5201 s
agent0:                 episode reward: 0.0367,                 loss: nan
agent1:                 episode reward: -0.0367,                 loss: 0.1555
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.7505s / 13399.2706 s
agent0:                 episode reward: -0.2868,                 loss: nan
agent1:                 episode reward: 0.2868,                 loss: 0.1538
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.5836s / 13539.8541 s
agent0:                 episode reward: -0.1519,                 loss: nan
agent1:                 episode reward: 0.1519,                 loss: 0.1555
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.8854s / 13680.7396 s
agent0:                 episode reward: -0.5105,                 loss: nan
agent1:                 episode reward: 0.5105,                 loss: 0.1537
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.3494s / 13823.0889 s
agent0:                 episode reward: 0.1524,                 loss: nan
agent1:                 episode reward: -0.1524,                 loss: 0.1547
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.3847s / 13964.4737 s
agent0:                 episode reward: 0.0946,                 loss: nan
agent1:                 episode reward: -0.0946,                 loss: 0.1549
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.4971s / 14107.9707 s
agent0:                 episode reward: 0.1499,                 loss: nan
agent1:                 episode reward: -0.1499,                 loss: 0.1540
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.3560s / 14248.3268 s
agent0:                 episode reward: 0.3877,                 loss: nan
agent1:                 episode reward: -0.3877,                 loss: 0.1551
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8223s / 14387.1491 s
agent0:                 episode reward: 0.0636,                 loss: nan
agent1:                 episode reward: -0.0636,                 loss: 0.1545
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8718s / 14526.0209 s
agent0:                 episode reward: -0.1228,                 loss: nan
agent1:                 episode reward: 0.1228,                 loss: 0.1545
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.8393s / 14667.8601 s
agent0:                 episode reward: 0.0433,                 loss: nan
agent1:                 episode reward: -0.0433,                 loss: 0.1543
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.9458s / 14811.8059 s
agent0:                 episode reward: 0.0514,                 loss: nan
agent1:                 episode reward: -0.0514,                 loss: 0.1541
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.4918s / 14952.2978 s
agent0:                 episode reward: 0.0045,                 loss: nan
agent1:                 episode reward: -0.0045,                 loss: 0.1550
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.7929s / 15095.0907 s
agent0:                 episode reward: 0.2666,                 loss: nan
agent1:                 episode reward: -0.2666,                 loss: 0.1545
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.5635s / 15238.6542 s
agent0:                 episode reward: -0.2377,                 loss: nan
agent1:                 episode reward: 0.2377,                 loss: 0.1551
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0366s / 15376.6909 s
agent0:                 episode reward: 0.0306,                 loss: nan
agent1:                 episode reward: -0.0306,                 loss: 0.1554
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.1953s / 15517.8861 s
agent0:                 episode reward: -0.2876,                 loss: nan
agent1:                 episode reward: 0.2876,                 loss: 0.1547
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 145.3691s / 15663.2552 s
agent0:                 episode reward: -0.0848,                 loss: nan
agent1:                 episode reward: 0.0848,                 loss: 0.1548
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.3511s / 15806.6064 s
agent0:                 episode reward: 0.1920,                 loss: nan
agent1:                 episode reward: -0.1920,                 loss: 0.1543
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.2023s / 15949.8087 s
agent0:                 episode reward: 0.2532,                 loss: nan
agent1:                 episode reward: -0.2532,                 loss: 0.1539
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.0757s / 16092.8844 s
agent0:                 episode reward: -0.0161,                 loss: nan
agent1:                 episode reward: 0.0161,                 loss: 0.1574
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.4207s / 16237.3051 s
agent0:                 episode reward: -0.4978,                 loss: nan
agent1:                 episode reward: 0.4978,                 loss: 0.1577
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8607s / 16375.1658 s
agent0:                 episode reward: -0.1910,                 loss: nan
agent1:                 episode reward: 0.1910,                 loss: 0.1560
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.1308s / 16516.2966 s
agent0:                 episode reward: -0.3699,                 loss: nan
agent1:                 episode reward: 0.3699,                 loss: 0.1554
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.0133s / 16656.3099 s
agent0:                 episode reward: -0.1360,                 loss: nan
agent1:                 episode reward: 0.1360,                 loss: 0.1558
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6663s / 16794.9762 s
agent0:                 episode reward: 0.0241,                 loss: nan
agent1:                 episode reward: -0.0241,                 loss: 0.1560
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.5963s / 16938.5725 s
agent0:                 episode reward: -0.3050,                 loss: nan
agent1:                 episode reward: 0.3050,                 loss: 0.1554
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8691s / 17076.4416 s
agent0:                 episode reward: 0.0580,                 loss: nan
agent1:                 episode reward: -0.0580,                 loss: 0.1560
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5896s / 17215.0312 s
agent0:                 episode reward: -0.2077,                 loss: nan
agent1:                 episode reward: 0.2077,                 loss: 0.1560
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.5903s / 17357.6215 s
agent0:                 episode reward: -0.4088,                 loss: nan
agent1:                 episode reward: 0.4088,                 loss: 0.1538
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.0578s / 17497.6792 s
agent0:                 episode reward: -0.2382,                 loss: nan
agent1:                 episode reward: 0.2382,                 loss: 0.1562
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8311s / 17636.5103 s
agent0:                 episode reward: 0.3149,                 loss: nan
agent1:                 episode reward: -0.3149,                 loss: 0.1539
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.7522s / 17778.2626 s
agent0:                 episode reward: -0.0715,                 loss: nan
agent1:                 episode reward: 0.0715,                 loss: 0.1549
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.3954s / 17918.6580 s
agent0:                 episode reward: -0.1871,                 loss: nan
agent1:                 episode reward: 0.1871,                 loss: 0.1546
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.1202s / 18059.7782 s
agent0:                 episode reward: -0.5381,                 loss: nan
agent1:                 episode reward: 0.5381,                 loss: 0.1545
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.8683s / 18199.6465 s
agent0:                 episode reward: 0.0525,                 loss: nan
agent1:                 episode reward: -0.0525,                 loss: 0.1561
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.1480s / 18342.7945 s
agent0:                 episode reward: 0.2084,                 loss: nan
agent1:                 episode reward: -0.2084,                 loss: 0.1546
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.8361s / 18486.6305 s
agent0:                 episode reward: -0.4032,                 loss: nan
agent1:                 episode reward: 0.4032,                 loss: 0.1538
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.1669s / 18626.7974 s
agent0:                 episode reward: 0.1281,                 loss: nan
agent1:                 episode reward: -0.1281,                 loss: 0.1551
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.2054s / 18770.0028 s
agent0:                 episode reward: -0.0973,                 loss: nan
agent1:                 episode reward: 0.0973,                 loss: 0.1561
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 145.4017s / 18915.4045 s
agent0:                 episode reward: -0.2009,                 loss: nan
agent1:                 episode reward: 0.2009,                 loss: 0.1554
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.3207s / 19054.7252 s
agent0:                 episode reward: 0.0048,                 loss: nan
agent1:                 episode reward: -0.0048,                 loss: 0.1557
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.8389s / 19196.5640 s
agent0:                 episode reward: -0.0916,                 loss: nan
agent1:                 episode reward: 0.0916,                 loss: 0.1548
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.4711s / 19339.0352 s
agent0:                 episode reward: -0.3469,                 loss: nan
agent1:                 episode reward: 0.3469,                 loss: 0.1555
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.2377s / 19481.2728 s
agent0:                 episode reward: -0.3949,                 loss: nan
agent1:                 episode reward: 0.3949,                 loss: 0.1544
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.6470s / 19624.9198 s
agent0:                 episode reward: -0.2429,                 loss: nan
agent1:                 episode reward: 0.2429,                 loss: 0.1546
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.2662s / 19768.1860 s
agent0:                 episode reward: 0.3331,                 loss: nan
agent1:                 episode reward: -0.3331,                 loss: 0.1563
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.1033s / 19911.2893 s
agent0:                 episode reward: -0.1216,                 loss: nan
agent1:                 episode reward: 0.1216,                 loss: 0.1564
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8967s / 20050.1860 s
agent0:                 episode reward: 0.0937,                 loss: nan
agent1:                 episode reward: -0.0937,                 loss: 0.1601
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0772s / 20188.2632 s
agent0:                 episode reward: -0.0902,                 loss: nan
agent1:                 episode reward: 0.0902,                 loss: 0.1592
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.1874s / 20331.4506 s
agent0:                 episode reward: -0.1390,                 loss: nan
agent1:                 episode reward: 0.1390,                 loss: 0.1604
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.2912s / 20474.7419 s
agent0:                 episode reward: -0.2876,                 loss: nan
agent1:                 episode reward: 0.2876,                 loss: 0.1599
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.4197s / 20618.1616 s
agent0:                 episode reward: -0.2305,                 loss: nan
agent1:                 episode reward: 0.2305,                 loss: 0.1600
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1889s / 20756.3505 s
agent0:                 episode reward: -0.0192,                 loss: nan
agent1:                 episode reward: 0.0192,                 loss: 0.1587
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4488s / 20891.7993 s
agent0:                 episode reward: 0.2405,                 loss: nan
agent1:                 episode reward: -0.2405,                 loss: 0.1592
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 130.8304s / 21022.6297 s
agent0:                 episode reward: -0.0425,                 loss: nan
agent1:                 episode reward: 0.0425,                 loss: 0.1602
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5067s / 21157.1364 s
agent0:                 episode reward: -0.4050,                 loss: nan
agent1:                 episode reward: 0.4050,                 loss: 0.1577
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7741s / 21293.9105 s
agent0:                 episode reward: 0.0309,                 loss: nan
agent1:                 episode reward: -0.0309,                 loss: 0.1594
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.5520s / 21435.4625 s
agent0:                 episode reward: 0.0871,                 loss: nan
agent1:                 episode reward: -0.0871,                 loss: 0.1584
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.6710s / 21579.1334 s
agent0:                 episode reward: 0.0367,                 loss: nan
agent1:                 episode reward: -0.0367,                 loss: 0.1577
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.5432s / 21722.6766 s
agent0:                 episode reward: -0.2581,                 loss: nan
agent1:                 episode reward: 0.2581,                 loss: 0.1586
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.7029s / 21866.3795 s
agent0:                 episode reward: 0.2843,                 loss: nan
agent1:                 episode reward: -0.2843,                 loss: 0.1590
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.9064s / 22010.2860 s
agent0:                 episode reward: -0.2379,                 loss: nan
agent1:                 episode reward: 0.2379,                 loss: 0.1598
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.4071s / 22152.6930 s
agent0:                 episode reward: -0.1633,                 loss: nan
agent1:                 episode reward: 0.1633,                 loss: 0.1578
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.7890s / 22295.4821 s
agent0:                 episode reward: 0.1953,                 loss: nan
agent1:                 episode reward: -0.1953,                 loss: 0.1591
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.7012s / 22439.1833 s
agent0:                 episode reward: -0.0627,                 loss: nan
agent1:                 episode reward: 0.0627,                 loss: 0.1593
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.8868s / 22581.0701 s
agent0:                 episode reward: -0.0742,                 loss: nan
agent1:                 episode reward: 0.0742,                 loss: 0.1601
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 145.3703s / 22726.4404 s
agent0:                 episode reward: -0.2119,                 loss: nan
agent1:                 episode reward: 0.2119,                 loss: 0.1587
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.1798s / 22867.6203 s
agent0:                 episode reward: 0.0140,                 loss: nan
agent1:                 episode reward: -0.0140,                 loss: 0.1580
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.8714s / 23011.4917 s
agent0:                 episode reward: -0.0903,                 loss: nan
agent1:                 episode reward: 0.0903,                 loss: 0.1585
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 144.1809s / 23155.6725 s
agent0:                 episode reward: -0.4057,                 loss: nan
agent1:                 episode reward: 0.4057,                 loss: 0.1582
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.8381s / 23298.5106 s
agent0:                 episode reward: -0.6734,                 loss: nan
agent1:                 episode reward: 0.6734,                 loss: 0.1591
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.2896s / 23438.8002 s
agent0:                 episode reward: -0.6212,                 loss: nan
agent1:                 episode reward: 0.6212,                 loss: 0.1596
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.8740s / 23579.6742 s
agent0:                 episode reward: -0.2301,                 loss: nan
agent1:                 episode reward: 0.2301,                 loss: 0.1587
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.0238s / 23722.6979 s
agent0:                 episode reward: -0.2331,                 loss: nan
agent1:                 episode reward: 0.2331,                 loss: 0.1587
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.4111s / 23867.1091 s
agent0:                 episode reward: -0.4620,                 loss: nan
agent1:                 episode reward: 0.4620,                 loss: 0.1580
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.8138s / 24009.9228 s
agent0:                 episode reward: -0.0905,                 loss: nan
agent1:                 episode reward: 0.0905,                 loss: 0.1590
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.4620s / 24154.3848 s
agent0:                 episode reward: -0.3385,                 loss: nan
agent1:                 episode reward: 0.3385,                 loss: 0.1582
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.1938s / 24296.5786 s
agent0:                 episode reward: -0.1631,                 loss: nan
agent1:                 episode reward: 0.1631,                 loss: 0.1569
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.2930s / 24439.8716 s
agent0:                 episode reward: -0.1067,                 loss: nan
agent1:                 episode reward: 0.1067,                 loss: 0.1602
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.7166s / 24584.5882 s
agent0:                 episode reward: -0.4165,                 loss: nan
agent1:                 episode reward: 0.4165,                 loss: 0.1590
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.8077s / 24728.3959 s
agent0:                 episode reward: -0.0689,                 loss: nan
agent1:                 episode reward: 0.0689,                 loss: 0.1552
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.7008s / 24870.0967 s
agent0:                 episode reward: -0.1186,                 loss: nan
agent1:                 episode reward: 0.1186,                 loss: 0.1548
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 145.0606s / 25015.1574 s
agent0:                 episode reward: 0.1104,                 loss: nan
agent1:                 episode reward: -0.1104,                 loss: 0.1558
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.1037s / 25157.2610 s
agent0:                 episode reward: -0.1603,                 loss: nan
agent1:                 episode reward: 0.1603,                 loss: 0.1567
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.1971s / 25300.4581 s
agent0:                 episode reward: -0.2130,                 loss: nan
agent1:                 episode reward: 0.2130,                 loss: 0.1560
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.5262s / 25441.9843 s
agent0:                 episode reward: -0.4916,                 loss: nan
agent1:                 episode reward: 0.4916,                 loss: 0.1561
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.0381s / 25586.0224 s
agent0:                 episode reward: -0.0024,                 loss: nan
agent1:                 episode reward: 0.0024,                 loss: 0.1574
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.3448s / 25728.3672 s
agent0:                 episode reward: 0.1889,                 loss: nan
agent1:                 episode reward: -0.1889,                 loss: 0.1566
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 145.8017s / 25874.1689 s
agent0:                 episode reward: 0.0130,                 loss: nan
agent1:                 episode reward: -0.0130,                 loss: 0.1560
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.3417s / 26014.5106 s
agent0:                 episode reward: -0.0958,                 loss: nan
agent1:                 episode reward: 0.0958,                 loss: 0.1555
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 144.3762s / 26158.8868 s
agent0:                 episode reward: -0.2487,                 loss: nan
agent1:                 episode reward: 0.2487,                 loss: 0.1565
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.5378s / 26301.4245 s
agent0:                 episode reward: -0.1408,                 loss: nan
agent1:                 episode reward: 0.1408,                 loss: 0.1560
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.9862s / 26446.4108 s
agent0:                 episode reward: -0.0170,                 loss: nan
agent1:                 episode reward: 0.0170,                 loss: 0.1565
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 145.1879s / 26591.5987 s
agent0:                 episode reward: 0.2249,                 loss: nan
agent1:                 episode reward: -0.2249,                 loss: 0.1565
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.1292s / 26735.7278 s
agent0:                 episode reward: -0.0131,                 loss: nan
agent1:                 episode reward: 0.0131,                 loss: 0.1564
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 145.3008s / 26881.0286 s
agent0:                 episode reward: -0.1039,                 loss: nan
agent1:                 episode reward: 0.1039,                 loss: 0.1551
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.0298s / 27023.0585 s
agent0:                 episode reward: 0.0959,                 loss: nan
agent1:                 episode reward: -0.0959,                 loss: 0.1564
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.9192s / 27167.9776 s
agent0:                 episode reward: -0.2882,                 loss: nan
agent1:                 episode reward: 0.2882,                 loss: 0.1577
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.4563s / 27312.4339 s
agent0:                 episode reward: -0.2421,                 loss: nan
agent1:                 episode reward: 0.2421,                 loss: 0.1560
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0471s / 27447.4810 s
agent0:                 episode reward: -0.0534,                 loss: nan
agent1:                 episode reward: 0.0534,                 loss: 0.1573
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0183s / 27584.4993 s
agent0:                 episode reward: -0.3701,                 loss: nan
agent1:                 episode reward: 0.3701,                 loss: 0.1578
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3282s / 27718.8276 s
agent0:                 episode reward: -0.1359,                 loss: nan
agent1:                 episode reward: 0.1359,                 loss: 0.1549
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9327s / 27852.7603 s
agent0:                 episode reward: 0.2468,                 loss: nan
agent1:                 episode reward: -0.2468,                 loss: 0.1549
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9054s / 27987.6656 s
agent0:                 episode reward: -0.1677,                 loss: nan
agent1:                 episode reward: 0.1677,                 loss: 0.1550
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0700s / 28120.7356 s
agent0:                 episode reward: 0.0874,                 loss: nan
agent1:                 episode reward: -0.0874,                 loss: 0.1557
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6399s / 28254.3755 s
agent0:                 episode reward: -0.2991,                 loss: nan
agent1:                 episode reward: 0.2991,                 loss: 0.1568
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9120s / 28388.2875 s
agent0:                 episode reward: -0.1665,                 loss: nan
agent1:                 episode reward: 0.1665,                 loss: 0.1558
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2948s / 28524.5823 s
agent0:                 episode reward: -0.2570,                 loss: nan
agent1:                 episode reward: 0.2570,                 loss: 0.1561
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4326s / 28659.0149 s
agent0:                 episode reward: -0.0797,                 loss: nan
agent1:                 episode reward: 0.0797,                 loss: 0.1561
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0666s / 28794.0815 s
agent0:                 episode reward: -0.0170,                 loss: nan
agent1:                 episode reward: 0.0170,                 loss: 0.1556
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4482s / 28930.5297 s
agent0:                 episode reward: -0.1455,                 loss: nan
agent1:                 episode reward: 0.1455,                 loss: 0.1571
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5875s / 29065.1173 s
agent0:                 episode reward: -0.1502,                 loss: nan
agent1:                 episode reward: 0.1502,                 loss: 0.1554
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4876s / 29197.6049 s
agent0:                 episode reward: 0.2033,                 loss: nan
agent1:                 episode reward: -0.2033,                 loss: 0.1564
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4790s / 29335.0839 s
agent0:                 episode reward: 0.2130,                 loss: nan
agent1:                 episode reward: -0.2130,                 loss: 0.1586
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8753s / 29471.9592 s
agent0:                 episode reward: -0.1443,                 loss: nan
agent1:                 episode reward: 0.1443,                 loss: 0.1588
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5455s / 29605.5047 s
agent0:                 episode reward: -0.0655,                 loss: nan
agent1:                 episode reward: 0.0655,                 loss: 0.1607
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7432s / 29739.2479 s
agent0:                 episode reward: -0.5364,                 loss: nan
agent1:                 episode reward: 0.5364,                 loss: 0.1594
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3004s / 29874.5482 s
agent0:                 episode reward: 0.1387,                 loss: nan
agent1:                 episode reward: -0.1387,                 loss: 0.1597
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3336s / 30006.8818 s
agent0:                 episode reward: -0.0666,                 loss: nan
agent1:                 episode reward: 0.0666,                 loss: 0.1593
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5588s / 30146.4406 s
agent0:                 episode reward: -0.2263,                 loss: nan
agent1:                 episode reward: 0.2263,                 loss: 0.1605
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5316s / 30278.9722 s
agent0:                 episode reward: 0.2559,                 loss: nan
agent1:                 episode reward: -0.2559,                 loss: 0.1596
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5495s / 30411.5217 s
agent0:                 episode reward: 0.1299,                 loss: nan
agent1:                 episode reward: -0.1299,                 loss: 0.1595
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2680s / 30547.7897 s
agent0:                 episode reward: -0.2617,                 loss: nan
agent1:                 episode reward: 0.2617,                 loss: 0.1611
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3448s / 30682.1345 s
agent0:                 episode reward: 0.0671,                 loss: nan
agent1:                 episode reward: -0.0671,                 loss: 0.1597
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5115s / 30816.6460 s
agent0:                 episode reward: -0.1087,                 loss: nan
agent1:                 episode reward: 0.1087,                 loss: 0.1586
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7656s / 30951.4115 s
agent0:                 episode reward: 0.1977,                 loss: nan
agent1:                 episode reward: -0.1977,                 loss: 0.1608
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9266s / 31084.3382 s
agent0:                 episode reward: -0.4061,                 loss: nan
agent1:                 episode reward: 0.4061,                 loss: 0.1606
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2697s / 31220.6079 s
agent0:                 episode reward: -0.0997,                 loss: nan
agent1:                 episode reward: 0.0997,                 loss: 0.1587
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5211s / 31357.1290 s
agent0:                 episode reward: 0.0201,                 loss: nan
agent1:                 episode reward: -0.0201,                 loss: 0.1599
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5886s / 31494.7176 s
agent0:                 episode reward: -0.4588,                 loss: nan
agent1:                 episode reward: 0.4588,                 loss: 0.1576
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6141s / 31631.3316 s
agent0:                 episode reward: -0.2516,                 loss: nan
agent1:                 episode reward: 0.2516,                 loss: 0.1601
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8517s / 31765.1833 s
agent0:                 episode reward: -0.1927,                 loss: nan
agent1:                 episode reward: 0.1927,                 loss: 0.1590
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7346s / 31901.9179 s
agent0:                 episode reward: -0.2643,                 loss: nan
agent1:                 episode reward: 0.2643,                 loss: 0.1597
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 129.4130s / 32031.3309 s
agent0:                 episode reward: -0.4763,                 loss: nan
agent1:                 episode reward: 0.4763,                 loss: 0.1603
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1880s / 32164.5189 s
agent0:                 episode reward: -0.1867,                 loss: nan
agent1:                 episode reward: 0.1867,                 loss: 0.1601
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7844s / 32297.3033 s
agent0:                 episode reward: -0.2004,                 loss: nan
agent1:                 episode reward: 0.2004,                 loss: 0.1592
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0676s / 32433.3708 s
agent0:                 episode reward: 0.0006,                 loss: nan
agent1:                 episode reward: -0.0006,                 loss: 0.1582
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4716s / 32568.8424 s
agent0:                 episode reward: -0.2171,                 loss: nan
agent1:                 episode reward: 0.2171,                 loss: 0.1602
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5876s / 32704.4301 s
agent0:                 episode reward: -0.1845,                 loss: nan
agent1:                 episode reward: 0.1845,                 loss: 0.1590
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.2530s / 32836.6830 s
agent0:                 episode reward: 0.1923,                 loss: nan
agent1:                 episode reward: -0.1923,                 loss: 0.1579
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.2130s / 32968.8960 s
agent0:                 episode reward: -0.2306,                 loss: nan
agent1:                 episode reward: 0.2306,                 loss: 0.1606
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6435s / 33101.5395 s
agent0:                 episode reward: -0.0773,                 loss: nan
agent1:                 episode reward: 0.0773,                 loss: 0.1570
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4483s / 33235.9877 s
agent0:                 episode reward: -0.4596,                 loss: nan
agent1:                 episode reward: 0.4596,                 loss: 0.1590
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0641s / 33369.0518 s
agent0:                 episode reward: -0.4154,                 loss: nan
agent1:                 episode reward: 0.4154,                 loss: 0.1588
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0441s / 33502.0959 s
agent0:                 episode reward: 0.0167,                 loss: nan
agent1:                 episode reward: -0.0167,                 loss: 0.1593
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5830s / 33635.6789 s
agent0:                 episode reward: -0.1494,                 loss: nan
agent1:                 episode reward: 0.1494,                 loss: 0.1590
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3637s / 33770.0426 s
agent0:                 episode reward: -0.4297,                 loss: nan
agent1:                 episode reward: 0.4297,                 loss: 0.1589
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9536s / 33903.9962 s
agent0:                 episode reward: -0.2047,                 loss: nan
agent1:                 episode reward: 0.2047,                 loss: 0.1546
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3604s / 34042.3566 s
agent0:                 episode reward: -0.0836,                 loss: nan
agent1:                 episode reward: 0.0836,                 loss: 0.1541
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6593s / 34178.0158 s
agent0:                 episode reward: -0.2586,                 loss: nan
agent1:                 episode reward: 0.2586,                 loss: 0.1549
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3383s / 34313.3542 s
agent0:                 episode reward: -0.7871,                 loss: nan
agent1:                 episode reward: 0.7871,                 loss: 0.1563
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2474s / 34446.6015 s
agent0:                 episode reward: -0.4080,                 loss: nan
agent1:                 episode reward: 0.4080,                 loss: 0.1554
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1722s / 34579.7738 s
agent0:                 episode reward: -0.0354,                 loss: nan
agent1:                 episode reward: 0.0354,                 loss: 0.1550
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0021s / 34714.7758 s
agent0:                 episode reward: -0.0403,                 loss: nan
agent1:                 episode reward: 0.0403,                 loss: 0.1557
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.2966s / 34847.0725 s
agent0:                 episode reward: 0.3535,                 loss: nan
agent1:                 episode reward: -0.3535,                 loss: 0.1552
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0286s / 34982.1010 s
agent0:                 episode reward: 0.0193,                 loss: nan
agent1:                 episode reward: -0.0193,                 loss: 0.1557
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.2248s / 35114.3258 s
agent0:                 episode reward: -0.4079,                 loss: nan
agent1:                 episode reward: 0.4079,                 loss: 0.1569
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2653s / 35251.5911 s
agent0:                 episode reward: -0.6488,                 loss: nan
agent1:                 episode reward: 0.6488,                 loss: 0.1559
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8406s / 35385.4317 s
agent0:                 episode reward: -0.4708,                 loss: nan
agent1:                 episode reward: 0.4708,                 loss: 0.1564
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4885s / 35519.9203 s
agent0:                 episode reward: 0.1056,                 loss: nan
agent1:                 episode reward: -0.1056,                 loss: 0.1551
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8039s / 35654.7242 s
agent0:                 episode reward: -0.2654,                 loss: nan
agent1:                 episode reward: 0.2654,                 loss: 0.1551
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5576s / 35787.2818 s
agent0:                 episode reward: -0.4608,                 loss: nan
agent1:                 episode reward: 0.4608,                 loss: 0.1563
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9770s / 35922.2588 s
agent0:                 episode reward: -0.4325,                 loss: nan
agent1:                 episode reward: 0.4325,                 loss: 0.1544
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8551s / 36055.1140 s
agent0:                 episode reward: -0.1525,                 loss: nan
agent1:                 episode reward: 0.1525,                 loss: 0.1570
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5584s / 36188.6724 s
agent0:                 episode reward: -0.0716,                 loss: nan
agent1:                 episode reward: 0.0716,                 loss: 0.1566
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3564s / 36326.0288 s
agent0:                 episode reward: -0.0183,                 loss: nan
agent1:                 episode reward: 0.0183,                 loss: 0.1576
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7716s / 36459.8003 s
agent0:                 episode reward: -0.1426,                 loss: nan
agent1:                 episode reward: 0.1426,                 loss: 0.1580
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6415s / 36596.4418 s
agent0:                 episode reward: -0.2823,                 loss: nan
agent1:                 episode reward: 0.2823,                 loss: 0.1560
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5057s / 36728.9475 s
agent0:                 episode reward: -0.3763,                 loss: nan
agent1:                 episode reward: 0.3763,                 loss: 0.1562
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7191s / 36862.6666 s
agent0:                 episode reward: 0.3777,                 loss: nan
agent1:                 episode reward: -0.3777,                 loss: 0.1572
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7084s / 36999.3749 s
agent0:                 episode reward: -0.2028,                 loss: nan
agent1:                 episode reward: 0.2028,                 loss: 0.1586
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3198s / 37134.6948 s
agent0:                 episode reward: 0.0075,                 loss: nan
agent1:                 episode reward: -0.0075,                 loss: 0.1559
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7869s / 37270.4816 s
agent0:                 episode reward: -0.2153,                 loss: nan
agent1:                 episode reward: 0.2153,                 loss: 0.1566
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5812s / 37408.0628 s
agent0:                 episode reward: -0.0688,                 loss: nan
agent1:                 episode reward: 0.0688,                 loss: 0.1557
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0327s / 37545.0955 s
agent0:                 episode reward: -0.5161,                 loss: nan
agent1:                 episode reward: 0.5161,                 loss: 0.1560
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5890s / 37680.6845 s
agent0:                 episode reward: -0.0075,                 loss: nan
agent1:                 episode reward: 0.0075,                 loss: 0.1570
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1385s / 37815.8229 s
agent0:                 episode reward: -0.3248,                 loss: nan
agent1:                 episode reward: 0.3248,                 loss: 0.1572
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5376s / 37952.3605 s
agent0:                 episode reward: 0.3459,                 loss: nan
agent1:                 episode reward: -0.3459,                 loss: 0.1568
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3053s / 38088.6658 s
agent0:                 episode reward: -0.4511,                 loss: nan
agent1:                 episode reward: 0.4511,                 loss: 0.1577
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8225s / 38225.4883 s
agent0:                 episode reward: -0.2192,                 loss: nan
agent1:                 episode reward: 0.2192,                 loss: 0.1564
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8513s / 38363.3395 s
agent0:                 episode reward: -0.1361,                 loss: nan
agent1:                 episode reward: 0.1361,                 loss: 0.1583
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5927s / 38496.9322 s
agent0:                 episode reward: -0.2063,                 loss: nan
agent1:                 episode reward: 0.2063,                 loss: 0.1576
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8657s / 38631.7979 s
agent0:                 episode reward: -0.4404,                 loss: nan
agent1:                 episode reward: 0.4404,                 loss: 0.1594
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1592s / 38766.9571 s
agent0:                 episode reward: 0.1040,                 loss: nan
agent1:                 episode reward: -0.1040,                 loss: 0.1590
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0686s / 38901.0257 s
agent0:                 episode reward: -0.4755,                 loss: nan
agent1:                 episode reward: 0.4755,                 loss: 0.1585
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4722s / 39038.4979 s
agent0:                 episode reward: -0.0842,                 loss: nan
agent1:                 episode reward: 0.0842,                 loss: 0.1593
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9605s / 39176.4584 s
agent0:                 episode reward: -0.3550,                 loss: nan
agent1:                 episode reward: 0.3550,                 loss: 0.1577
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9625s / 39311.4209 s
agent0:                 episode reward: -0.2450,                 loss: nan
agent1:                 episode reward: 0.2450,                 loss: 0.1573
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.0038s / 39442.4247 s
agent0:                 episode reward: -0.1763,                 loss: nan
agent1:                 episode reward: 0.1763,                 loss: 0.1573
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0413s / 39577.4661 s
agent0:                 episode reward: 0.1379,                 loss: nan
agent1:                 episode reward: -0.1379,                 loss: 0.1584
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1646s / 39711.6306 s
agent0:                 episode reward: -0.2183,                 loss: nan
agent1:                 episode reward: 0.2183,                 loss: 0.1581
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0992s / 39848.7298 s
agent0:                 episode reward: -0.3066,                 loss: nan
agent1:                 episode reward: 0.3066,                 loss: 0.1576
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3388s / 39983.0686 s
agent0:                 episode reward: 0.0027,                 loss: nan
agent1:                 episode reward: -0.0027,                 loss: 0.1575
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7258s / 40117.7943 s
agent0:                 episode reward: -0.3616,                 loss: nan
agent1:                 episode reward: 0.3616,                 loss: 0.1583
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1155s / 40252.9098 s
agent0:                 episode reward: 0.2372,                 loss: nan
agent1:                 episode reward: -0.2372,                 loss: 0.1581
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6654s / 40385.5752 s
agent0:                 episode reward: 0.0881,                 loss: nan
agent1:                 episode reward: -0.0881,                 loss: 0.1575
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8861s / 40521.4613 s
agent0:                 episode reward: -0.1627,                 loss: nan
agent1:                 episode reward: 0.1627,                 loss: 0.1575
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1050s / 40657.5663 s
agent0:                 episode reward: 0.0035,                 loss: nan
agent1:                 episode reward: -0.0035,                 loss: 0.1572
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3050s / 40793.8713 s
agent0:                 episode reward: 0.1140,                 loss: nan
agent1:                 episode reward: -0.1140,                 loss: 0.1569
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.0197s / 40932.8910 s
agent0:                 episode reward: -0.3190,                 loss: nan
agent1:                 episode reward: 0.3190,                 loss: 0.1582
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3131s / 41066.2041 s
agent0:                 episode reward: -0.2989,                 loss: nan
agent1:                 episode reward: 0.2989,                 loss: 0.1565
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7427s / 41199.9468 s
agent0:                 episode reward: -0.3076,                 loss: nan
agent1:                 episode reward: 0.3076,                 loss: 0.1572
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6439s / 41336.5907 s
agent0:                 episode reward: -0.1133,                 loss: nan
agent1:                 episode reward: 0.1133,                 loss: 0.1580
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2852s / 41471.8759 s
agent0:                 episode reward: -0.3738,                 loss: nan
agent1:                 episode reward: 0.3738,                 loss: 0.1572
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4756s / 41610.3515 s
agent0:                 episode reward: -0.4493,                 loss: nan
agent1:                 episode reward: 0.4493,                 loss: 0.1564
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7115s / 41744.0630 s
agent0:                 episode reward: -0.4736,                 loss: nan
agent1:                 episode reward: 0.4736,                 loss: 0.1555
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5029s / 41877.5659 s
agent0:                 episode reward: -0.3748,                 loss: nan
agent1:                 episode reward: 0.3748,                 loss: 0.1589
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5556s / 42016.1216 s
agent0:                 episode reward: -0.0022,                 loss: nan
agent1:                 episode reward: 0.0022,                 loss: 0.1559
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4174s / 42148.5390 s
agent0:                 episode reward: -0.2104,                 loss: nan
agent1:                 episode reward: 0.2104,                 loss: 0.1575
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7586s / 42283.2975 s
agent0:                 episode reward: -0.3472,                 loss: nan
agent1:                 episode reward: 0.3472,                 loss: 0.1572
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6578s / 42419.9554 s
agent0:                 episode reward: -0.3283,                 loss: nan
agent1:                 episode reward: 0.3283,                 loss: 0.1590
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4435s / 42555.3989 s
agent0:                 episode reward: -0.3819,                 loss: nan
agent1:                 episode reward: 0.3819,                 loss: 0.1582
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0211s / 42690.4200 s
agent0:                 episode reward: -0.4079,                 loss: nan
agent1:                 episode reward: 0.4079,                 loss: 0.1575
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8543s / 42824.2743 s
agent0:                 episode reward: -0.1155,                 loss: nan
agent1:                 episode reward: 0.1155,                 loss: 0.1567
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7017s / 42959.9760 s
agent0:                 episode reward: -0.0622,                 loss: nan
agent1:                 episode reward: 0.0622,                 loss: 0.1581
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2832s / 43093.2593 s
agent0:                 episode reward: -0.0030,                 loss: nan
agent1:                 episode reward: 0.0030,                 loss: 0.1581
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7442s / 43227.0034 s
agent0:                 episode reward: -0.3021,                 loss: nan
agent1:                 episode reward: 0.3021,                 loss: 0.1582
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8130s / 43359.8164 s
agent0:                 episode reward: -0.0626,                 loss: nan
agent1:                 episode reward: 0.0626,                 loss: 0.1581
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3732s / 43493.1896 s
agent0:                 episode reward: 0.0932,                 loss: nan
agent1:                 episode reward: -0.0932,                 loss: 0.1569
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7060s / 43627.8956 s
agent0:                 episode reward: -0.0241,                 loss: nan
agent1:                 episode reward: 0.0241,                 loss: 0.1590
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2656s / 43761.1612 s
agent0:                 episode reward: -0.1642,                 loss: nan
agent1:                 episode reward: 0.1642,                 loss: 0.1578
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4966s / 43894.6577 s
agent0:                 episode reward: -0.4463,                 loss: nan
agent1:                 episode reward: 0.4463,                 loss: 0.1581
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5609s / 44029.2186 s
agent0:                 episode reward: -0.5143,                 loss: nan
agent1:                 episode reward: 0.5143,                 loss: 0.1583
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8692s / 44165.0878 s
agent0:                 episode reward: -0.1635,                 loss: nan
agent1:                 episode reward: 0.1635,                 loss: 0.1577
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2257s / 44301.3135 s
agent0:                 episode reward: -0.1378,                 loss: nan
agent1:                 episode reward: 0.1378,                 loss: 0.1564
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8457s / 44435.1592 s
agent0:                 episode reward: -0.1705,                 loss: nan
agent1:                 episode reward: 0.1705,                 loss: 0.1573
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8004s / 44570.9596 s
agent0:                 episode reward: -0.1020,                 loss: nan
agent1:                 episode reward: 0.1020,                 loss: 0.1575
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2410s / 44704.2006 s
agent0:                 episode reward: 0.3048,                 loss: nan
agent1:                 episode reward: -0.3048,                 loss: 0.1574
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1460s / 44839.3466 s
agent0:                 episode reward: -0.2021,                 loss: nan
agent1:                 episode reward: 0.2021,                 loss: 0.1579
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.0813s / 44978.4279 s
agent0:                 episode reward: -0.2236,                 loss: nan
agent1:                 episode reward: 0.2236,                 loss: 0.1580
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3185s / 45114.7464 s
agent0:                 episode reward: 0.1880,                 loss: nan
agent1:                 episode reward: -0.1880,                 loss: 0.1590
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0971s / 45250.8436 s
agent0:                 episode reward: 0.1533,                 loss: nan
agent1:                 episode reward: -0.1533,                 loss: 0.1558
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.2010s / 45390.0446 s
agent0:                 episode reward: -0.4119,                 loss: nan
agent1:                 episode reward: 0.4119,                 loss: 0.1573
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4936s / 45526.5382 s
agent0:                 episode reward: -0.0153,                 loss: nan
agent1:                 episode reward: 0.0153,                 loss: 0.1574
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1764s / 45663.7146 s
agent0:                 episode reward: -0.0975,                 loss: nan
agent1:                 episode reward: 0.0975,                 loss: 0.1556
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.5215s / 45795.2361 s
agent0:                 episode reward: 0.0067,                 loss: nan
agent1:                 episode reward: -0.0067,                 loss: 0.1564
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1133s / 45933.3494 s
agent0:                 episode reward: -0.0085,                 loss: nan
agent1:                 episode reward: 0.0085,                 loss: 0.1578
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 129.4675s / 46062.8169 s
agent0:                 episode reward: -0.2252,                 loss: nan
agent1:                 episode reward: 0.2252,                 loss: 0.1563
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6181s / 46196.4350 s
agent0:                 episode reward: -0.6881,                 loss: nan
agent1:                 episode reward: 0.6881,                 loss: 0.1565
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0013s / 46333.4363 s
agent0:                 episode reward: -0.0541,                 loss: nan
agent1:                 episode reward: 0.0541,                 loss: 0.1569
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4359s / 46467.8722 s
agent0:                 episode reward: -0.4202,                 loss: nan
agent1:                 episode reward: 0.4202,                 loss: 0.1550
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0813s / 46602.9535 s
agent0:                 episode reward: -0.2267,                 loss: nan
agent1:                 episode reward: 0.2267,                 loss: 0.1571
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9448s / 46739.8983 s
agent0:                 episode reward: -0.3332,                 loss: nan
agent1:                 episode reward: 0.3332,                 loss: 0.1577
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1165s / 46876.0148 s
agent0:                 episode reward: 0.1086,                 loss: nan
agent1:                 episode reward: -0.1086,                 loss: 0.1548
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4974s / 47008.5122 s
agent0:                 episode reward: -0.2230,                 loss: nan
agent1:                 episode reward: 0.2230,                 loss: 0.1569
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2697s / 47143.7819 s
agent0:                 episode reward: -0.0286,                 loss: nan
agent1:                 episode reward: 0.0286,                 loss: 0.1572
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1676s / 47277.9494 s
agent0:                 episode reward: -0.0929,                 loss: nan
agent1:                 episode reward: 0.0929,                 loss: 0.1577
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4772s / 47411.4266 s
agent0:                 episode reward: -0.1716,                 loss: nan
agent1:                 episode reward: 0.1716,                 loss: 0.1594
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3875s / 47547.8140 s
agent0:                 episode reward: 0.0581,                 loss: nan
agent1:                 episode reward: -0.0581,                 loss: 0.1594
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5015s / 47684.3156 s
agent0:                 episode reward: 0.0344,                 loss: nan
agent1:                 episode reward: -0.0344,                 loss: 0.1593
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3124s / 47820.6279 s
agent0:                 episode reward: -0.1721,                 loss: nan
agent1:                 episode reward: 0.1721,                 loss: 0.1585
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3263s / 47954.9543 s
agent0:                 episode reward: -0.3364,                 loss: nan
agent1:                 episode reward: 0.3364,                 loss: 0.1606
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2874s / 48091.2417 s
agent0:                 episode reward: -0.0039,                 loss: nan
agent1:                 episode reward: 0.0039,                 loss: 0.1589
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.0615s / 48230.3032 s
agent0:                 episode reward: -0.1524,                 loss: nan
agent1:                 episode reward: 0.1524,                 loss: 0.1598
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3464s / 48365.6496 s
agent0:                 episode reward: -0.1263,                 loss: nan
agent1:                 episode reward: 0.1263,                 loss: 0.1601
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2469s / 48500.8965 s
agent0:                 episode reward: -0.2717,                 loss: nan
agent1:                 episode reward: 0.2717,                 loss: 0.1602
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8602s / 48638.7567 s
agent0:                 episode reward: -0.2899,                 loss: nan
agent1:                 episode reward: 0.2899,                 loss: 0.1590
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3177s / 48772.0744 s
agent0:                 episode reward: 0.1183,                 loss: nan
agent1:                 episode reward: -0.1183,                 loss: 0.1607
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8225s / 48908.8969 s
agent0:                 episode reward: 0.0752,                 loss: nan
agent1:                 episode reward: -0.0752,                 loss: 0.1580
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2735s / 49044.1703 s
agent0:                 episode reward: -0.5072,                 loss: nan
agent1:                 episode reward: 0.5072,                 loss: 0.1594
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9255s / 49178.0958 s
agent0:                 episode reward: -0.2470,                 loss: nan
agent1:                 episode reward: 0.2470,                 loss: 0.1597
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8490s / 49311.9448 s
agent0:                 episode reward: 0.0466,                 loss: nan
agent1:                 episode reward: -0.0466,                 loss: 0.1602
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9962s / 49446.9410 s
agent0:                 episode reward: -0.5643,                 loss: nan
agent1:                 episode reward: 0.5643,                 loss: 0.1607
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2752s / 49582.2163 s
agent0:                 episode reward: 0.1790,                 loss: nan
agent1:                 episode reward: -0.1790,                 loss: 0.1564
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4354s / 49717.6517 s
agent0:                 episode reward: -0.4127,                 loss: nan
agent1:                 episode reward: 0.4127,                 loss: 0.1522
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3713s / 49851.0230 s
agent0:                 episode reward: -0.0726,                 loss: nan
agent1:                 episode reward: 0.0726,                 loss: 0.1541
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5795s / 49986.6025 s
agent0:                 episode reward: -0.2912,                 loss: nan
agent1:                 episode reward: 0.2912,                 loss: 0.1549
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6458s / 50122.2483 s
agent0:                 episode reward: -0.1361,                 loss: nan
agent1:                 episode reward: 0.1361,                 loss: 0.1527
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2646s / 50258.5129 s
agent0:                 episode reward: -0.1267,                 loss: nan
agent1:                 episode reward: 0.1267,                 loss: 0.1547
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7657s / 50393.2786 s
agent0:                 episode reward: 0.0714,                 loss: nan
agent1:                 episode reward: -0.0714,                 loss: 0.1542
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3639s / 50528.6425 s
agent0:                 episode reward: -0.1357,                 loss: nan
agent1:                 episode reward: 0.1357,                 loss: 0.1542
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2481s / 50666.8906 s
agent0:                 episode reward: -0.2515,                 loss: nan
agent1:                 episode reward: 0.2515,                 loss: 0.1551
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1634s / 50801.0540 s
agent0:                 episode reward: -0.1467,                 loss: nan
agent1:                 episode reward: 0.1467,                 loss: 0.1543
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2499s / 50935.3039 s
agent0:                 episode reward: -0.2106,                 loss: nan
agent1:                 episode reward: 0.2106,                 loss: 0.1548
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7591s / 51069.0630 s
agent0:                 episode reward: -0.5487,                 loss: nan
agent1:                 episode reward: 0.5487,                 loss: 0.1538
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6470s / 51203.7100 s
agent0:                 episode reward: -0.7320,                 loss: nan
agent1:                 episode reward: 0.7320,                 loss: 0.1527
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5563s / 51338.2662 s
agent0:                 episode reward: 0.0922,                 loss: nan
agent1:                 episode reward: -0.0922,                 loss: 0.1547
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3725s / 51471.6387 s
agent0:                 episode reward: -0.0654,                 loss: nan
agent1:                 episode reward: 0.0654,                 loss: 0.1543
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9518s / 51606.5905 s
agent0:                 episode reward: -0.5845,                 loss: nan
agent1:                 episode reward: 0.5845,                 loss: 0.1542
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6317s / 51741.2222 s
agent0:                 episode reward: -0.2150,                 loss: nan
agent1:                 episode reward: 0.2150,                 loss: 0.1534
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3748s / 51875.5970 s
agent0:                 episode reward: -0.1332,                 loss: nan
agent1:                 episode reward: 0.1332,                 loss: 0.1580
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1596s / 52010.7567 s
agent0:                 episode reward: 0.1963,                 loss: nan
agent1:                 episode reward: -0.1963,                 loss: 0.1592
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6954s / 52147.4521 s
agent0:                 episode reward: -0.2445,                 loss: nan
agent1:                 episode reward: 0.2445,                 loss: 0.1592
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7988s / 52282.2509 s
agent0:                 episode reward: 0.0417,                 loss: nan
agent1:                 episode reward: -0.0417,                 loss: 0.1574
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6286s / 52414.8795 s
agent0:                 episode reward: -0.2939,                 loss: nan
agent1:                 episode reward: 0.2939,                 loss: 0.1575
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5824s / 52547.4619 s
agent0:                 episode reward: -0.0851,                 loss: nan
agent1:                 episode reward: 0.0851,                 loss: 0.1588
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5563s / 52681.0183 s
agent0:                 episode reward: -0.1755,                 loss: nan
agent1:                 episode reward: 0.1755,                 loss: 0.1574
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8093s / 52815.8275 s
agent0:                 episode reward: -0.1506,                 loss: nan
agent1:                 episode reward: 0.1506,                 loss: 0.1595
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5493s / 52952.3769 s
agent0:                 episode reward: -0.1779,                 loss: nan
agent1:                 episode reward: 0.1779,                 loss: 0.1580
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7685s / 53086.1454 s
agent0:                 episode reward: -0.4688,                 loss: nan
agent1:                 episode reward: 0.4688,                 loss: 0.1587
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6166s / 53220.7620 s
agent0:                 episode reward: -0.2209,                 loss: nan
agent1:                 episode reward: 0.2209,                 loss: 0.1582
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5987s / 53357.3607 s
agent0:                 episode reward: -0.1935,                 loss: nan
agent1:                 episode reward: 0.1935,                 loss: 0.1566
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6007s / 53491.9615 s
agent0:                 episode reward: -0.3778,                 loss: nan
agent1:                 episode reward: 0.3778,                 loss: 0.1573
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1844s / 53627.1459 s
agent0:                 episode reward: -0.5555,                 loss: nan
agent1:                 episode reward: 0.5555,                 loss: 0.1562
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4636s / 53764.6094 s
agent0:                 episode reward: -0.2478,                 loss: nan
agent1:                 episode reward: 0.2478,                 loss: 0.1584
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8538s / 53900.4632 s
agent0:                 episode reward: 0.2194,                 loss: nan
agent1:                 episode reward: -0.2194,                 loss: 0.1569
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4928s / 54034.9560 s
agent0:                 episode reward: -0.4399,                 loss: nan
agent1:                 episode reward: 0.4399,                 loss: 0.1558
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5121s / 54170.4681 s
agent0:                 episode reward: -0.2718,                 loss: nan
agent1:                 episode reward: 0.2718,                 loss: 0.1509
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5295s / 54306.9976 s
agent0:                 episode reward: -0.2733,                 loss: nan
agent1:                 episode reward: 0.2733,                 loss: 0.1518
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3932s / 54440.3908 s
agent0:                 episode reward: -0.2681,                 loss: nan
agent1:                 episode reward: 0.2681,                 loss: 0.1527
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6524s / 54576.0432 s
agent0:                 episode reward: -0.6700,                 loss: nan
agent1:                 episode reward: 0.6700,                 loss: 0.1518
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0637s / 54710.1069 s
agent0:                 episode reward: -0.9171,                 loss: nan
agent1:                 episode reward: 0.9171,                 loss: 0.1509
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7529s / 54847.8598 s
agent0:                 episode reward: -0.2629,                 loss: nan
agent1:                 episode reward: 0.2629,                 loss: 0.1532
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1995s / 54983.0594 s
agent0:                 episode reward: -0.0504,                 loss: nan
agent1:                 episode reward: 0.0504,                 loss: 0.1527
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7436s / 55119.8030 s
agent0:                 episode reward: -0.1720,                 loss: nan
agent1:                 episode reward: 0.1720,                 loss: 0.1524
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4041s / 55255.2071 s
agent0:                 episode reward: -0.0673,                 loss: nan
agent1:                 episode reward: 0.0673,                 loss: 0.1522
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4663s / 55390.6733 s
agent0:                 episode reward: -0.2467,                 loss: nan
agent1:                 episode reward: 0.2467,                 loss: 0.1528
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2010s / 55525.8743 s
agent0:                 episode reward: -0.3409,                 loss: nan
agent1:                 episode reward: 0.3409,                 loss: 0.1519
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1407s / 55664.0150 s
agent0:                 episode reward: -0.2327,                 loss: nan
agent1:                 episode reward: 0.2327,                 loss: 0.1512
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2156s / 55797.2306 s
agent0:                 episode reward: 0.1634,                 loss: nan
agent1:                 episode reward: -0.1634,                 loss: 0.1532
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9802s / 55932.2108 s
agent0:                 episode reward: -0.0908,                 loss: nan
agent1:                 episode reward: 0.0908,                 loss: 0.1527
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4196s / 56068.6305 s
agent0:                 episode reward: -0.4364,                 loss: nan
agent1:                 episode reward: 0.4364,                 loss: 0.1516
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.3077s / 56207.9382 s
agent0:                 episode reward: -0.0765,                 loss: nan
agent1:                 episode reward: 0.0765,                 loss: 0.1528
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7139s / 56344.6522 s
agent0:                 episode reward: -0.2282,                 loss: nan
agent1:                 episode reward: 0.2282,                 loss: 0.1553
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.1899s / 56483.8420 s
agent0:                 episode reward: -0.3521,                 loss: nan
agent1:                 episode reward: 0.3521,                 loss: 0.1569
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6341s / 56618.4762 s
agent0:                 episode reward: -0.0812,                 loss: nan
agent1:                 episode reward: 0.0812,                 loss: 0.1561
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8075s / 56754.2836 s
agent0:                 episode reward: -0.2782,                 loss: nan
agent1:                 episode reward: 0.2782,                 loss: 0.1541
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2621s / 56887.5458 s
agent0:                 episode reward: -0.0547,                 loss: nan
agent1:                 episode reward: 0.0547,                 loss: 0.1569
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5593s / 57024.1051 s
agent0:                 episode reward: -0.4824,                 loss: nan
agent1:                 episode reward: 0.4824,                 loss: 0.1558
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 130.2958s / 57154.4009 s
agent0:                 episode reward: -0.1593,                 loss: nan
agent1:                 episode reward: 0.1593,                 loss: 0.1551
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3250s / 57291.7259 s
agent0:                 episode reward: -0.2943,                 loss: nan
agent1:                 episode reward: 0.2943,                 loss: 0.1567
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3161s / 57427.0420 s
agent0:                 episode reward: -0.1139,                 loss: nan
agent1:                 episode reward: 0.1139,                 loss: 0.1558
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5768s / 57561.6188 s
agent0:                 episode reward: 0.0272,                 loss: nan
agent1:                 episode reward: -0.0272,                 loss: 0.1572
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4257s / 57696.0444 s
agent0:                 episode reward: -0.3251,                 loss: nan
agent1:                 episode reward: 0.3251,                 loss: 0.1570
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8329s / 57830.8773 s
agent0:                 episode reward: -0.3650,                 loss: nan
agent1:                 episode reward: 0.3650,                 loss: 0.1578
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6860s / 57967.5633 s
agent0:                 episode reward: -0.6170,                 loss: nan
agent1:                 episode reward: 0.6170,                 loss: 0.1546
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2276s / 58103.7909 s
agent0:                 episode reward: -0.6774,                 loss: nan
agent1:                 episode reward: 0.6774,                 loss: 0.1551
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4370s / 58239.2279 s
agent0:                 episode reward: -0.5571,                 loss: nan
agent1:                 episode reward: 0.5571,                 loss: 0.1565
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1556s / 58372.3835 s
agent0:                 episode reward: -0.1543,                 loss: nan
agent1:                 episode reward: 0.1543,                 loss: 0.1560
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0007s / 58508.3842 s
agent0:                 episode reward: -0.2840,                 loss: nan
agent1:                 episode reward: 0.2840,                 loss: 0.1550
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6592s / 58642.0434 s
agent0:                 episode reward: -0.6134,                 loss: nan
agent1:                 episode reward: 0.6134,                 loss: 0.1536
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3323s / 58776.3757 s
agent0:                 episode reward: -0.2323,                 loss: nan
agent1:                 episode reward: 0.2323,                 loss: 0.1528
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6774s / 58912.0531 s
agent0:                 episode reward: -0.2028,                 loss: nan
agent1:                 episode reward: 0.2028,                 loss: 0.1532
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8423s / 59047.8954 s
agent0:                 episode reward: -0.5185,                 loss: nan
agent1:                 episode reward: 0.5185,                 loss: 0.1537
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.2703s / 59180.1658 s
agent0:                 episode reward: -0.1278,                 loss: nan
agent1:                 episode reward: 0.1278,                 loss: 0.1542
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1324s / 59316.2981 s
agent0:                 episode reward: -0.4179,                 loss: nan
agent1:                 episode reward: 0.4179,                 loss: 0.1540
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6764s / 59453.9745 s
agent0:                 episode reward: -0.1664,                 loss: nan
agent1:                 episode reward: 0.1664,                 loss: 0.1535
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9841s / 59589.9586 s
agent0:                 episode reward: 0.1389,                 loss: nan
agent1:                 episode reward: -0.1389,                 loss: 0.1536
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0282s / 59721.9869 s
agent0:                 episode reward: -0.3728,                 loss: nan
agent1:                 episode reward: 0.3728,                 loss: 0.1548
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8917s / 59855.8786 s
agent0:                 episode reward: -0.4231,                 loss: nan
agent1:                 episode reward: 0.4231,                 loss: 0.1557
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9503s / 59990.8289 s
agent0:                 episode reward: -0.4184,                 loss: nan
agent1:                 episode reward: 0.4184,                 loss: 0.1527
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8546s / 60124.6835 s
agent0:                 episode reward: -0.2096,                 loss: nan
agent1:                 episode reward: 0.2096,                 loss: 0.1529
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8805s / 60257.5640 s
agent0:                 episode reward: -0.5036,                 loss: nan
agent1:                 episode reward: 0.5036,                 loss: 0.1546
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8722s / 60391.4362 s
agent0:                 episode reward: -0.3037,                 loss: nan
agent1:                 episode reward: 0.3037,                 loss: 0.1542
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0589s / 60526.4951 s
agent0:                 episode reward: -0.5229,                 loss: nan
agent1:                 episode reward: 0.5229,                 loss: 0.1525
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0743s / 60661.5694 s
agent0:                 episode reward: -0.1567,                 loss: nan
agent1:                 episode reward: 0.1567,                 loss: 0.1539
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7664s / 60795.3359 s
agent0:                 episode reward: -0.3191,                 loss: nan
agent1:                 episode reward: 0.3191,                 loss: 0.1558
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9602s / 60930.2961 s
agent0:                 episode reward: -0.0250,                 loss: nan
agent1:                 episode reward: 0.0250,                 loss: 0.1586
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4596s / 61064.7557 s
agent0:                 episode reward: -0.2861,                 loss: nan
agent1:                 episode reward: 0.2861,                 loss: 0.1568
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1356s / 61201.8913 s
agent0:                 episode reward: -0.3636,                 loss: nan
agent1:                 episode reward: 0.3636,                 loss: 0.1586
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6179s / 61338.5092 s
agent0:                 episode reward: -0.2995,                 loss: nan
agent1:                 episode reward: 0.2995,                 loss: 0.1589
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1248s / 61475.6340 s
agent0:                 episode reward: -0.1709,                 loss: nan
agent1:                 episode reward: 0.1709,                 loss: 0.1565
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3561s / 61611.9901 s
agent0:                 episode reward: -0.4284,                 loss: nan
agent1:                 episode reward: 0.4284,                 loss: 0.1579
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.7299s / 61751.7199 s
agent0:                 episode reward: -0.3089,                 loss: nan
agent1:                 episode reward: 0.3089,                 loss: 0.1582
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2808s / 61886.0008 s
agent0:                 episode reward: -0.1424,                 loss: nan
agent1:                 episode reward: 0.1424,                 loss: 0.1580
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7699s / 62020.7706 s
agent0:                 episode reward: 0.1956,                 loss: nan
agent1:                 episode reward: -0.1956,                 loss: 0.1577
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2824s / 62158.0531 s
agent0:                 episode reward: -0.1879,                 loss: nan
agent1:                 episode reward: 0.1879,                 loss: 0.1573
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.0483s / 62298.1014 s
agent0:                 episode reward: 0.0128,                 loss: nan
agent1:                 episode reward: -0.0128,                 loss: 0.1596
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8007s / 62431.9021 s
agent0:                 episode reward: -0.1534,                 loss: nan
agent1:                 episode reward: 0.1534,                 loss: 0.1584
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7041s / 62564.6062 s
agent0:                 episode reward: -0.5903,                 loss: nan
agent1:                 episode reward: 0.5903,                 loss: 0.1567
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1798s / 62700.7860 s
agent0:                 episode reward: -0.5267,                 loss: nan
agent1:                 episode reward: 0.5267,                 loss: 0.1588
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8149s / 62835.6009 s
agent0:                 episode reward: -0.5938,                 loss: nan
agent1:                 episode reward: 0.5938,                 loss: 0.1558
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0964s / 62971.6973 s
agent0:                 episode reward: -0.1367,                 loss: nan
agent1:                 episode reward: 0.1367,                 loss: 0.1575
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1544s / 63105.8517 s
agent0:                 episode reward: 0.0517,                 loss: nan
agent1:                 episode reward: -0.0517,                 loss: 0.1560
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8831s / 63243.7348 s
agent0:                 episode reward: 0.1237,                 loss: nan
agent1:                 episode reward: -0.1237,                 loss: 0.1559
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0224s / 63378.7572 s
agent0:                 episode reward: -0.4535,                 loss: nan
agent1:                 episode reward: 0.4535,                 loss: 0.1551
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1399s / 63512.8971 s
agent0:                 episode reward: -0.1882,                 loss: nan
agent1:                 episode reward: 0.1882,                 loss: 0.1555
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0854s / 63648.9825 s
agent0:                 episode reward: -0.1615,                 loss: nan
agent1:                 episode reward: 0.1615,                 loss: 0.1561
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5612s / 63784.5437 s
agent0:                 episode reward: -0.2429,                 loss: nan
agent1:                 episode reward: 0.2429,                 loss: 0.1558
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2527s / 63922.7964 s
agent0:                 episode reward: -0.4222,                 loss: nan
agent1:                 episode reward: 0.4222,                 loss: 0.1553
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6101s / 64058.4065 s
agent0:                 episode reward: 0.0573,                 loss: nan
agent1:                 episode reward: -0.0573,                 loss: 0.1550
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6762s / 64194.0827 s
agent0:                 episode reward: -0.3817,                 loss: nan
agent1:                 episode reward: 0.3817,                 loss: 0.1534
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8176s / 64326.9003 s
agent0:                 episode reward: -0.2627,                 loss: nan
agent1:                 episode reward: 0.2627,                 loss: 0.1551
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8527s / 64464.7530 s
agent0:                 episode reward: 0.0341,                 loss: nan
agent1:                 episode reward: -0.0341,                 loss: 0.1567
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7196s / 64601.4726 s
agent0:                 episode reward: -0.2098,                 loss: nan
agent1:                 episode reward: 0.2098,                 loss: 0.1558
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6464s / 64736.1189 s
agent0:                 episode reward: -0.4501,                 loss: nan
agent1:                 episode reward: 0.4501,                 loss: 0.1553
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7956s / 64872.9146 s
agent0:                 episode reward: -0.5124,                 loss: nan
agent1:                 episode reward: 0.5124,                 loss: 0.1550
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2370s / 65008.1516 s
agent0:                 episode reward: -0.3180,                 loss: nan
agent1:                 episode reward: 0.3180,                 loss: 0.1543
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0915s / 65143.2431 s
agent0:                 episode reward: -0.0496,                 loss: nan
agent1:                 episode reward: 0.0496,                 loss: 0.1557
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8123s / 65278.0554 s
agent0:                 episode reward: -0.3540,                 loss: nan
agent1:                 episode reward: 0.3540,                 loss: 0.1557
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.7837s / 65417.8391 s
agent0:                 episode reward: -0.5543,                 loss: nan
agent1:                 episode reward: 0.5543,                 loss: 0.1565
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8756s / 65551.7147 s
agent0:                 episode reward: -0.5490,                 loss: nan
agent1:                 episode reward: 0.5490,                 loss: 0.1569
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3283s / 65687.0430 s
agent0:                 episode reward: 0.2292,                 loss: nan
agent1:                 episode reward: -0.2292,                 loss: 0.1571
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5593s / 65821.6023 s
agent0:                 episode reward: -0.7304,                 loss: nan
agent1:                 episode reward: 0.7304,                 loss: 0.1578
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7096s / 65958.3119 s
agent0:                 episode reward: -0.3397,                 loss: nan
agent1:                 episode reward: 0.3397,                 loss: 0.1566
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6852s / 66093.9971 s
agent0:                 episode reward: -0.0978,                 loss: nan
agent1:                 episode reward: 0.0978,                 loss: 0.1563
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7632s / 66228.7603 s
agent0:                 episode reward: -0.1428,                 loss: nan
agent1:                 episode reward: 0.1428,                 loss: 0.1580
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5308s / 66365.2911 s
agent0:                 episode reward: -0.2885,                 loss: nan
agent1:                 episode reward: 0.2885,                 loss: 0.1565
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4586s / 66497.7497 s
agent0:                 episode reward: -0.5489,                 loss: nan
agent1:                 episode reward: 0.5489,                 loss: 0.1579
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9806s / 66631.7303 s
agent0:                 episode reward: -0.2203,                 loss: nan
agent1:                 episode reward: 0.2203,                 loss: 0.1570
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6001s / 66765.3304 s
agent0:                 episode reward: 0.0147,                 loss: nan
agent1:                 episode reward: -0.0147,                 loss: 0.1576
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8954s / 66903.2257 s
agent0:                 episode reward: -0.3042,                 loss: nan
agent1:                 episode reward: 0.3042,                 loss: 0.1578
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0615s / 67039.2872 s
agent0:                 episode reward: 0.0467,                 loss: nan
agent1:                 episode reward: -0.0467,                 loss: 0.1593
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1209s / 67173.4081 s
agent0:                 episode reward: -0.0363,                 loss: nan
agent1:                 episode reward: 0.0363,                 loss: 0.1573
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7085s / 67308.1167 s
agent0:                 episode reward: -0.7695,                 loss: nan
agent1:                 episode reward: 0.7695,                 loss: 0.1566
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7679s / 67444.8846 s
agent0:                 episode reward: -0.4327,                 loss: nan
agent1:                 episode reward: 0.4327,                 loss: 0.1567
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2214s / 67583.1060 s
agent0:                 episode reward: -0.8062,                 loss: nan
agent1:                 episode reward: 0.8062,                 loss: 0.1564
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0995s / 67716.2055 s
agent0:                 episode reward: -0.3218,                 loss: nan
agent1:                 episode reward: 0.3218,                 loss: 0.1563
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5584s / 67853.7639 s
agent0:                 episode reward: -0.3206,                 loss: nan
agent1:                 episode reward: 0.3206,                 loss: 0.1568
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7872s / 67989.5511 s
agent0:                 episode reward: -0.2157,                 loss: nan
agent1:                 episode reward: 0.2157,                 loss: 0.1551
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6558s / 68123.2069 s
agent0:                 episode reward: -0.0318,                 loss: nan
agent1:                 episode reward: 0.0318,                 loss: 0.1569
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4408s / 68258.6477 s
agent0:                 episode reward: -0.0498,                 loss: nan
agent1:                 episode reward: 0.0498,                 loss: 0.1571
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9608s / 68393.6085 s
agent0:                 episode reward: -0.5341,                 loss: nan
agent1:                 episode reward: 0.5341,                 loss: 0.1573
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1107s / 68528.7191 s
agent0:                 episode reward: -0.4021,                 loss: nan
agent1:                 episode reward: 0.4021,                 loss: 0.1573
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2020s / 68664.9211 s
agent0:                 episode reward: -0.1122,                 loss: nan
agent1:                 episode reward: 0.1122,                 loss: 0.1553
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5733s / 68801.4944 s
agent0:                 episode reward: -0.1177,                 loss: nan
agent1:                 episode reward: 0.1177,                 loss: 0.1573
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8949s / 68937.3893 s
agent0:                 episode reward: -0.4401,                 loss: nan
agent1:                 episode reward: 0.4401,                 loss: 0.1577
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6491s / 69073.0384 s
agent0:                 episode reward: -0.1999,                 loss: nan
agent1:                 episode reward: 0.1999,                 loss: 0.1583
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 130.3071s / 69203.3455 s
agent0:                 episode reward: -0.1158,                 loss: nan
agent1:                 episode reward: 0.1158,                 loss: 0.1566
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 129.9163s / 69333.2618 s
agent0:                 episode reward: -0.5379,                 loss: nan
agent1:                 episode reward: 0.5379,                 loss: 0.1580
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9339s / 69467.1956 s
agent0:                 episode reward: -0.4986,                 loss: nan
agent1:                 episode reward: 0.4986,                 loss: 0.1555
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6686s / 69599.8642 s
agent0:                 episode reward: -0.4685,                 loss: nan
agent1:                 episode reward: 0.4685,                 loss: 0.1589
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3856s / 69734.2498 s
agent0:                 episode reward: -0.2815,                 loss: nan
agent1:                 episode reward: 0.2815,                 loss: 0.1582
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9349s / 69869.1847 s
agent0:                 episode reward: -0.4051,                 loss: nan
agent1:                 episode reward: 0.4051,                 loss: 0.1533
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9963s / 70004.1811 s
agent0:                 episode reward: -0.2141,                 loss: nan
agent1:                 episode reward: 0.2141,                 loss: 0.1543
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8756s / 70139.0566 s
agent0:                 episode reward: -0.4428,                 loss: nan
agent1:                 episode reward: 0.4428,                 loss: 0.1536
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6929s / 70273.7495 s
agent0:                 episode reward: -0.6501,                 loss: nan
agent1:                 episode reward: 0.6501,                 loss: 0.1546
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8667s / 70411.6162 s
agent0:                 episode reward: -0.0332,                 loss: nan
agent1:                 episode reward: 0.0332,                 loss: 0.1556
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2874s / 70544.9036 s
agent0:                 episode reward: -0.2568,                 loss: nan
agent1:                 episode reward: 0.2568,                 loss: 0.1535
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4917s / 70680.3953 s
agent0:                 episode reward: -0.4460,                 loss: nan
agent1:                 episode reward: 0.4460,                 loss: 0.1546
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3798s / 70816.7751 s
agent0:                 episode reward: -0.4044,                 loss: nan
agent1:                 episode reward: 0.4044,                 loss: 0.1560
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0774s / 70950.8525 s
agent0:                 episode reward: -0.1250,                 loss: nan
agent1:                 episode reward: 0.1250,                 loss: 0.1545
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1200s / 71084.9725 s
agent0:                 episode reward: -0.0029,                 loss: nan
agent1:                 episode reward: 0.0029,                 loss: 0.1552
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.7394s / 71216.7119 s
agent0:                 episode reward: -0.3724,                 loss: nan
agent1:                 episode reward: 0.3724,                 loss: 0.1540
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0159s / 71351.7278 s
agent0:                 episode reward: -0.3813,                 loss: nan
agent1:                 episode reward: 0.3813,                 loss: 0.1563
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2339s / 71484.9617 s
agent0:                 episode reward: -0.4843,                 loss: nan
agent1:                 episode reward: 0.4843,                 loss: 0.1552
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9678s / 71619.9295 s
agent0:                 episode reward: -0.2765,                 loss: nan
agent1:                 episode reward: 0.2765,                 loss: 0.1555
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6274s / 71756.5569 s
agent0:                 episode reward: -0.3737,                 loss: nan
agent1:                 episode reward: 0.3737,                 loss: 0.1553
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0940s / 71890.6509 s
agent0:                 episode reward: -0.5291,                 loss: nan
agent1:                 episode reward: 0.5291,                 loss: 0.1553
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9654s / 72028.6162 s
agent0:                 episode reward: -0.1784,                 loss: nan
agent1:                 episode reward: 0.1784,                 loss: 0.1549
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1724s / 72164.7886 s
agent0:                 episode reward: -0.2934,                 loss: nan
agent1:                 episode reward: 0.2934,                 loss: 0.1573
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5421s / 72297.3307 s
agent0:                 episode reward: -0.6927,                 loss: nan
agent1:                 episode reward: 0.6927,                 loss: 0.1555
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9238s / 72431.2546 s
agent0:                 episode reward: -0.5832,                 loss: nan
agent1:                 episode reward: 0.5832,                 loss: 0.1566
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 130.9573s / 72562.2119 s
agent0:                 episode reward: -0.3535,                 loss: nan
agent1:                 episode reward: 0.3535,                 loss: 0.1582
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.2155s / 72694.4274 s
agent0:                 episode reward: -0.4022,                 loss: nan
agent1:                 episode reward: 0.4022,                 loss: 0.1582
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6843s / 72828.1117 s
agent0:                 episode reward: -0.3721,                 loss: nan
agent1:                 episode reward: 0.3721,                 loss: 0.1564
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7419s / 72963.8536 s
agent0:                 episode reward: -0.5186,                 loss: nan
agent1:                 episode reward: 0.5186,                 loss: 0.1570
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9013s / 73099.7549 s
agent0:                 episode reward: -0.6736,                 loss: nan
agent1:                 episode reward: 0.6736,                 loss: 0.1565
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0383s / 73234.7932 s
agent0:                 episode reward: -0.1126,                 loss: nan
agent1:                 episode reward: 0.1126,                 loss: 0.1582
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7166s / 73370.5098 s
agent0:                 episode reward: -0.0618,                 loss: nan
agent1:                 episode reward: 0.0618,                 loss: 0.1558
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2279s / 73505.7378 s
agent0:                 episode reward: -0.3848,                 loss: nan
agent1:                 episode reward: 0.3848,                 loss: 0.1578
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8668s / 73642.6046 s
agent0:                 episode reward: -0.5907,                 loss: nan
agent1:                 episode reward: 0.5907,                 loss: 0.1577
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5180s / 73777.1226 s
agent0:                 episode reward: -0.4122,                 loss: nan
agent1:                 episode reward: 0.4122,                 loss: 0.1587
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1664s / 73911.2890 s
agent0:                 episode reward: 0.0905,                 loss: nan
agent1:                 episode reward: -0.0905,                 loss: 0.1575
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0277s / 74045.3166 s
agent0:                 episode reward: -0.6217,                 loss: nan
agent1:                 episode reward: 0.6217,                 loss: 0.1561
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1046s / 74182.4213 s
agent0:                 episode reward: -0.6807,                 loss: nan
agent1:                 episode reward: 0.6807,                 loss: 0.1568
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9952s / 74317.4164 s
agent0:                 episode reward: -0.5208,                 loss: nan
agent1:                 episode reward: 0.5208,                 loss: 0.1549
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3981s / 74453.8145 s
agent0:                 episode reward: -0.4560,                 loss: nan
agent1:                 episode reward: 0.4560,                 loss: 0.1562
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1371s / 74586.9516 s
agent0:                 episode reward: 0.0914,                 loss: nan
agent1:                 episode reward: -0.0914,                 loss: 0.1565
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8032s / 74724.7548 s
agent0:                 episode reward: -0.1966,                 loss: nan
agent1:                 episode reward: 0.1966,                 loss: 0.1556
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3108s / 74862.0656 s
agent0:                 episode reward: -0.0627,                 loss: nan
agent1:                 episode reward: 0.0627,                 loss: 0.1567
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5119s / 74995.5776 s
agent0:                 episode reward: -0.2769,                 loss: nan
agent1:                 episode reward: 0.2769,                 loss: 0.1566
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4562s / 75134.0337 s
agent0:                 episode reward: -0.0269,                 loss: nan
agent1:                 episode reward: 0.0269,                 loss: 0.1546
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6396s / 75267.6733 s
agent0:                 episode reward: -0.0259,                 loss: nan
agent1:                 episode reward: 0.0259,                 loss: 0.1568
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9767s / 75401.6500 s
agent0:                 episode reward: -0.2440,                 loss: nan
agent1:                 episode reward: 0.2440,                 loss: 0.1568
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1535s / 75536.8035 s
agent0:                 episode reward: -0.6254,                 loss: nan
agent1:                 episode reward: 0.6254,                 loss: 0.1547
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2580s / 75670.0615 s
agent0:                 episode reward: -0.4251,                 loss: nan
agent1:                 episode reward: 0.4251,                 loss: 0.1562
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8724s / 75806.9339 s
agent0:                 episode reward: -0.4504,                 loss: nan
agent1:                 episode reward: 0.4504,                 loss: 0.1567
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8913s / 75941.8252 s
agent0:                 episode reward: -0.3534,                 loss: nan
agent1:                 episode reward: 0.3534,                 loss: 0.1577
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6567s / 76077.4819 s
agent0:                 episode reward: -0.3250,                 loss: nan
agent1:                 episode reward: 0.3250,                 loss: 0.1552
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3687s / 76212.8506 s
agent0:                 episode reward: -0.4017,                 loss: nan
agent1:                 episode reward: 0.4017,                 loss: 0.1558
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2666s / 76349.1172 s
agent0:                 episode reward: 0.1759,                 loss: nan
agent1:                 episode reward: -0.1759,                 loss: 0.1555
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0042s / 76485.1214 s
agent0:                 episode reward: -0.0034,                 loss: nan
agent1:                 episode reward: 0.0034,                 loss: 0.1565
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9932s / 76619.1145 s
agent0:                 episode reward: 0.0721,                 loss: nan
agent1:                 episode reward: -0.0721,                 loss: 0.1545
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2551s / 76757.3697 s
agent0:                 episode reward: -0.6172,                 loss: nan
agent1:                 episode reward: 0.6172,                 loss: 0.1529
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0474s / 76893.4171 s
agent0:                 episode reward: -0.2628,                 loss: nan
agent1:                 episode reward: 0.2628,                 loss: 0.1535
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.6914s / 77025.1085 s
agent0:                 episode reward: -0.6568,                 loss: nan
agent1:                 episode reward: 0.6568,                 loss: 0.1531
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6082s / 77159.7166 s
agent0:                 episode reward: -0.0005,                 loss: nan
agent1:                 episode reward: 0.0005,                 loss: 0.1534
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8281s / 77294.5448 s
agent0:                 episode reward: 0.0638,                 loss: nan
agent1:                 episode reward: -0.0638,                 loss: 0.1537
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0770s / 77429.6218 s
agent0:                 episode reward: 0.0235,                 loss: nan
agent1:                 episode reward: -0.0235,                 loss: 0.1535
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7298s / 77563.3516 s
agent0:                 episode reward: -0.3595,                 loss: nan
agent1:                 episode reward: 0.3595,                 loss: 0.1522
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6734s / 77700.0249 s
agent0:                 episode reward: 0.1691,                 loss: nan
agent1:                 episode reward: -0.1691,                 loss: 0.1540
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7033s / 77835.7282 s
agent0:                 episode reward: -0.0385,                 loss: nan
agent1:                 episode reward: 0.0385,                 loss: 0.1534
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1014s / 77970.8296 s
agent0:                 episode reward: -0.6524,                 loss: nan
agent1:                 episode reward: 0.6524,                 loss: 0.1533
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7508s / 78106.5804 s
agent0:                 episode reward: -0.4835,                 loss: nan
agent1:                 episode reward: 0.4835,                 loss: 0.1531
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6551s / 78240.2355 s
agent0:                 episode reward: -0.3661,                 loss: nan
agent1:                 episode reward: 0.3661,                 loss: 0.1521
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0792s / 78377.3147 s
agent0:                 episode reward: -0.2017,                 loss: nan
agent1:                 episode reward: 0.2017,                 loss: 0.1543
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3230s / 78510.6377 s
agent0:                 episode reward: 0.0748,                 loss: nan
agent1:                 episode reward: -0.0748,                 loss: 0.1536
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7201s / 78648.3578 s
agent0:                 episode reward: -0.2720,                 loss: nan
agent1:                 episode reward: 0.2720,                 loss: 0.1521
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6837s / 78782.0415 s
agent0:                 episode reward: -0.4466,                 loss: nan
agent1:                 episode reward: 0.4466,                 loss: 0.1523
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1195s / 78915.1609 s
agent0:                 episode reward: -0.5439,                 loss: nan
agent1:                 episode reward: 0.5439,                 loss: 0.1532
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6979s / 79051.8588 s
agent0:                 episode reward: -0.3916,                 loss: nan
agent1:                 episode reward: 0.3916,                 loss: 0.1501
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2735s / 79187.1323 s
agent0:                 episode reward: 0.1145,                 loss: nan
agent1:                 episode reward: -0.1145,                 loss: 0.1504
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5613s / 79320.6936 s
agent0:                 episode reward: -0.2611,                 loss: nan
agent1:                 episode reward: 0.2611,                 loss: 0.1522
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6308s / 79456.3244 s
agent0:                 episode reward: -0.1572,                 loss: nan
agent1:                 episode reward: 0.1572,                 loss: 0.1529
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0789s / 79590.4033 s
agent0:                 episode reward: -0.3242,                 loss: nan
agent1:                 episode reward: 0.3242,                 loss: 0.1507
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3999s / 79724.8032 s
agent0:                 episode reward: -0.5149,                 loss: nan
agent1:                 episode reward: 0.5149,                 loss: 0.1524
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3175s / 79862.1207 s
agent0:                 episode reward: -0.1968,                 loss: nan
agent1:                 episode reward: 0.1968,                 loss: 0.1526
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3459s / 79995.4666 s
agent0:                 episode reward: -0.5281,                 loss: nan
agent1:                 episode reward: 0.5281,                 loss: 0.1530
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.2612s / 80127.7278 s
agent0:                 episode reward: -0.2872,                 loss: nan
agent1:                 episode reward: 0.2872,                 loss: 0.1512
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4085s / 80265.1363 s
agent0:                 episode reward: -0.5798,                 loss: nan
agent1:                 episode reward: 0.5798,                 loss: 0.1526
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0264s / 80399.1627 s
agent0:                 episode reward: -0.1481,                 loss: nan
agent1:                 episode reward: 0.1481,                 loss: 0.1528
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2380s / 80537.4007 s
agent0:                 episode reward: -0.1157,                 loss: nan
agent1:                 episode reward: 0.1157,                 loss: 0.1524
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7743s / 80673.1750 s
agent0:                 episode reward: -0.2187,                 loss: nan
agent1:                 episode reward: 0.2187,                 loss: 0.1515
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3644s / 80805.5394 s
agent0:                 episode reward: 0.1145,                 loss: nan
agent1:                 episode reward: -0.1145,                 loss: 0.1521
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6090s / 80941.1484 s
agent0:                 episode reward: -0.2752,                 loss: nan
agent1:                 episode reward: 0.2752,                 loss: 0.1519
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4784s / 81075.6268 s
agent0:                 episode reward: -0.0830,                 loss: nan
agent1:                 episode reward: 0.0830,                 loss: 0.1530
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9707s / 81208.5975 s
agent0:                 episode reward: -0.0023,                 loss: nan
agent1:                 episode reward: 0.0023,                 loss: 0.1566
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2276s / 81343.8251 s
agent0:                 episode reward: -0.9837,                 loss: nan
agent1:                 episode reward: 0.9837,                 loss: 0.1559
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8549s / 81481.6800 s
agent0:                 episode reward: -0.2130,                 loss: nan
agent1:                 episode reward: 0.2130,                 loss: 0.1555
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6273s / 81620.3073 s
agent0:                 episode reward: -0.4572,                 loss: nan
agent1:                 episode reward: 0.4572,                 loss: 0.1570
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6512s / 81755.9585 s
agent0:                 episode reward: -0.2158,                 loss: nan
agent1:                 episode reward: 0.2158,                 loss: 0.1568
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.2851s / 81888.2436 s
agent0:                 episode reward: -0.0266,                 loss: nan
agent1:                 episode reward: 0.0266,                 loss: 0.1559
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6887s / 82026.9323 s
agent0:                 episode reward: -0.4812,                 loss: nan
agent1:                 episode reward: 0.4812,                 loss: 0.1548
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4039s / 82163.3362 s
agent0:                 episode reward: -0.0511,                 loss: nan
agent1:                 episode reward: 0.0511,                 loss: 0.1550
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.7255s / 82295.0617 s
agent0:                 episode reward: -0.1157,                 loss: nan
agent1:                 episode reward: 0.1157,                 loss: 0.1556
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8547s / 82429.9164 s
agent0:                 episode reward: -0.4845,                 loss: nan
agent1:                 episode reward: 0.4845,                 loss: 0.1563
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3635s / 82565.2799 s
agent0:                 episode reward: -0.4173,                 loss: nan
agent1:                 episode reward: 0.4173,                 loss: 0.1560
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1884s / 82703.4683 s
agent0:                 episode reward: -0.2444,                 loss: nan
agent1:                 episode reward: 0.2444,                 loss: 0.1559
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 129.3018s / 82832.7701 s
agent0:                 episode reward: -0.2071,                 loss: nan
agent1:                 episode reward: 0.2071,                 loss: 0.1559
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4807s / 82969.2508 s
agent0:                 episode reward: -0.2781,                 loss: nan
agent1:                 episode reward: 0.2781,                 loss: 0.1563
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8572s / 83105.1079 s
agent0:                 episode reward: -0.2145,                 loss: nan
agent1:                 episode reward: 0.2145,                 loss: 0.1559
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4364s / 83242.5443 s
agent0:                 episode reward: -0.6374,                 loss: nan
agent1:                 episode reward: 0.6374,                 loss: 0.1558
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1073s / 83380.6516 s
agent0:                 episode reward: -0.2961,                 loss: nan
agent1:                 episode reward: 0.2961,                 loss: 0.1564
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2584s / 83515.9100 s
agent0:                 episode reward: -0.4517,                 loss: nan
agent1:                 episode reward: 0.4517,                 loss: 0.1589
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8318s / 83650.7418 s
agent0:                 episode reward: -0.4504,                 loss: nan
agent1:                 episode reward: 0.4504,                 loss: 0.1573
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9522s / 83785.6940 s
agent0:                 episode reward: 0.0021,                 loss: nan
agent1:                 episode reward: -0.0021,                 loss: 0.1578
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2479s / 83921.9419 s
agent0:                 episode reward: -0.1088,                 loss: nan
agent1:                 episode reward: 0.1088,                 loss: 0.1562
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0866s / 84056.0285 s
agent0:                 episode reward: -0.6476,                 loss: nan
agent1:                 episode reward: 0.6476,                 loss: 0.1573
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4865s / 84191.5150 s
agent0:                 episode reward: -0.4474,                 loss: nan
agent1:                 episode reward: 0.4474,                 loss: 0.1557
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5789s / 84329.0939 s
agent0:                 episode reward: -0.1741,                 loss: nan
agent1:                 episode reward: 0.1741,                 loss: 0.1574
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0613s / 84465.1553 s
agent0:                 episode reward: -0.4787,                 loss: nan
agent1:                 episode reward: 0.4787,                 loss: 0.1573
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0735s / 84599.2288 s
agent0:                 episode reward: -0.2099,                 loss: nan
agent1:                 episode reward: 0.2099,                 loss: 0.1583
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0217s / 84731.2505 s
agent0:                 episode reward: -0.1831,                 loss: nan
agent1:                 episode reward: 0.1831,                 loss: 0.1572
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4277s / 84865.6782 s
agent0:                 episode reward: -0.4039,                 loss: nan
agent1:                 episode reward: 0.4039,                 loss: 0.1585
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3071s / 85001.9853 s
agent0:                 episode reward: -0.0657,                 loss: nan
agent1:                 episode reward: 0.0657,                 loss: 0.1577
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3208s / 85137.3061 s
agent0:                 episode reward: -0.3196,                 loss: nan
agent1:                 episode reward: 0.3196,                 loss: 0.1590
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7673s / 85274.0735 s
agent0:                 episode reward: -0.1983,                 loss: nan
agent1:                 episode reward: 0.1983,                 loss: 0.1573
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6991s / 85408.7725 s
agent0:                 episode reward: -0.2436,                 loss: nan
agent1:                 episode reward: 0.2436,                 loss: 0.1579
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8365s / 85544.6090 s
agent0:                 episode reward: -0.2794,                 loss: nan
agent1:                 episode reward: 0.2794,                 loss: 0.1570
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4468s / 85680.0558 s
agent0:                 episode reward: -0.3679,                 loss: nan
agent1:                 episode reward: 0.3679,                 loss: 0.1579
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7727s / 85816.8285 s
agent0:                 episode reward: -0.2967,                 loss: nan
agent1:                 episode reward: 0.2967,                 loss: 0.1567
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0835s / 85952.9120 s
agent0:                 episode reward: -0.2630,                 loss: nan
agent1:                 episode reward: 0.2630,                 loss: 0.1577
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5516s / 86085.4636 s
agent0:                 episode reward: -0.1983,                 loss: nan
agent1:                 episode reward: 0.1983,                 loss: 0.1573
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2692s / 86219.7327 s
agent0:                 episode reward: 0.1208,                 loss: nan
agent1:                 episode reward: -0.1208,                 loss: 0.1552
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7393s / 86355.4720 s
agent0:                 episode reward: -0.0401,                 loss: nan
agent1:                 episode reward: 0.0401,                 loss: 0.1582
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4448s / 86488.9168 s
agent0:                 episode reward: -0.5253,                 loss: nan
agent1:                 episode reward: 0.5253,                 loss: 0.1571
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7952s / 86623.7120 s
agent0:                 episode reward: -0.4317,                 loss: nan
agent1:                 episode reward: 0.4317,                 loss: 0.1577
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7424s / 86758.4545 s
agent0:                 episode reward: -0.1143,                 loss: nan
agent1:                 episode reward: 0.1143,                 loss: 0.1578
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7247s / 86891.1791 s
agent0:                 episode reward: -0.2041,                 loss: nan
agent1:                 episode reward: 0.2041,                 loss: 0.1574
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4745s / 87028.6536 s
agent0:                 episode reward: -0.5291,                 loss: nan
agent1:                 episode reward: 0.5291,                 loss: 0.1572
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1346s / 87163.7882 s
agent0:                 episode reward: -0.1418,                 loss: nan
agent1:                 episode reward: 0.1418,                 loss: 0.1565
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0319s / 87299.8201 s
agent0:                 episode reward: -0.3520,                 loss: nan
agent1:                 episode reward: 0.3520,                 loss: 0.1588
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7733s / 87433.5934 s
agent0:                 episode reward: -0.2755,                 loss: nan
agent1:                 episode reward: 0.2755,                 loss: 0.1580
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5483s / 87568.1416 s
agent0:                 episode reward: -0.4595,                 loss: nan
agent1:                 episode reward: 0.4595,                 loss: 0.1579
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8526s / 87702.9943 s
agent0:                 episode reward: -0.1554,                 loss: nan
agent1:                 episode reward: 0.1554,                 loss: 0.1586
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4467s / 87840.4410 s
agent0:                 episode reward: -0.4872,                 loss: nan
agent1:                 episode reward: 0.4872,                 loss: 0.1572
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6722s / 87976.1132 s
agent0:                 episode reward: -0.3797,                 loss: nan
agent1:                 episode reward: 0.3797,                 loss: 0.1554
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.2371s / 88115.3502 s
agent0:                 episode reward: -0.3525,                 loss: nan
agent1:                 episode reward: 0.3525,                 loss: 0.1574
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3605s / 88251.7108 s
agent0:                 episode reward: -0.1761,                 loss: nan
agent1:                 episode reward: 0.1761,                 loss: 0.1578
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2060s / 88387.9168 s
agent0:                 episode reward: -0.3899,                 loss: nan
agent1:                 episode reward: 0.3899,                 loss: 0.1572
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2958s / 88523.2125 s
agent0:                 episode reward: -0.5825,                 loss: nan
agent1:                 episode reward: 0.5825,                 loss: 0.1548
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1423s / 88656.3549 s
agent0:                 episode reward: -0.3203,                 loss: nan
agent1:                 episode reward: 0.3203,                 loss: 0.1553
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4800s / 88791.8348 s
agent0:                 episode reward: -0.0454,                 loss: nan
agent1:                 episode reward: 0.0454,                 loss: 0.1553
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3934s / 88926.2283 s
agent0:                 episode reward: -0.2227,                 loss: nan
agent1:                 episode reward: 0.2227,                 loss: 0.1571
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8018s / 89061.0301 s
agent0:                 episode reward: -0.6238,                 loss: nan
agent1:                 episode reward: 0.6238,                 loss: 0.1558
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7417s / 89196.7718 s
agent0:                 episode reward: -0.5516,                 loss: nan
agent1:                 episode reward: 0.5516,                 loss: 0.1573
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1904s / 89332.9622 s
agent0:                 episode reward: -0.3369,                 loss: nan
agent1:                 episode reward: 0.3369,                 loss: 0.1572
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4420s / 89467.4042 s
agent0:                 episode reward: 0.1310,                 loss: nan
agent1:                 episode reward: -0.1310,                 loss: 0.1575
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5817s / 89603.9860 s
agent0:                 episode reward: -0.4379,                 loss: nan
agent1:                 episode reward: 0.4379,                 loss: 0.1565
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0615s / 89740.0474 s
agent0:                 episode reward: -0.2340,                 loss: nan
agent1:                 episode reward: 0.2340,                 loss: 0.1578
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9807s / 89874.0281 s
agent0:                 episode reward: -0.6931,                 loss: nan
agent1:                 episode reward: 0.6931,                 loss: 0.1570
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4038s / 90007.4319 s
agent0:                 episode reward: -0.4647,                 loss: nan
agent1:                 episode reward: 0.4647,                 loss: 0.1564
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1191s / 90144.5510 s
agent0:                 episode reward: -0.2082,                 loss: nan
agent1:                 episode reward: 0.2082,                 loss: 0.1572
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0624s / 90278.6134 s
agent0:                 episode reward: -0.5388,                 loss: nan
agent1:                 episode reward: 0.5388,                 loss: 0.1581
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0706s / 90414.6839 s
agent0:                 episode reward: -0.7706,                 loss: nan
agent1:                 episode reward: 0.7706,                 loss: 0.1580
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7948s / 90550.4787 s
agent0:                 episode reward: 0.3980,                 loss: nan
agent1:                 episode reward: -0.3980,                 loss: 0.1595
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0591s / 90688.5378 s
agent0:                 episode reward: -0.3295,                 loss: nan
agent1:                 episode reward: 0.3295,                 loss: 0.1584
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1822s / 90823.7200 s
agent0:                 episode reward: -0.2289,                 loss: nan
agent1:                 episode reward: 0.2289,                 loss: 0.1588
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6743s / 90960.3943 s
agent0:                 episode reward: -0.5326,                 loss: nan
agent1:                 episode reward: 0.5326,                 loss: 0.1582
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9556s / 91097.3499 s
agent0:                 episode reward: -0.1961,                 loss: nan
agent1:                 episode reward: 0.1961,                 loss: 0.1586
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2089s / 91231.5588 s
agent0:                 episode reward: 0.0186,                 loss: nan
agent1:                 episode reward: -0.0186,                 loss: 0.1576
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3861s / 91366.9449 s
agent0:                 episode reward: -0.6684,                 loss: nan
agent1:                 episode reward: 0.6684,                 loss: 0.1581
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0091s / 91502.9540 s
agent0:                 episode reward: -0.2421,                 loss: nan
agent1:                 episode reward: 0.2421,                 loss: 0.1586
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2146s / 91638.1687 s
agent0:                 episode reward: 0.0986,                 loss: nan
agent1:                 episode reward: -0.0986,                 loss: 0.1593
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1542s / 91773.3229 s
agent0:                 episode reward: -0.4901,                 loss: nan
agent1:                 episode reward: 0.4901,                 loss: 0.1587
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.8508s / 91905.1737 s
agent0:                 episode reward: -0.5661,                 loss: nan
agent1:                 episode reward: 0.5661,                 loss: 0.1573
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4700s / 92040.6437 s
agent0:                 episode reward: -0.2904,                 loss: nan
agent1:                 episode reward: 0.2904,                 loss: 0.1575
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4148s / 92176.0584 s
agent0:                 episode reward: -0.1253,                 loss: nan
agent1:                 episode reward: 0.1253,                 loss: 0.1580
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7412s / 92313.7996 s
agent0:                 episode reward: -0.2165,                 loss: nan
agent1:                 episode reward: 0.2165,                 loss: 0.1581
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3191s / 92448.1187 s
agent0:                 episode reward: -0.2002,                 loss: nan
agent1:                 episode reward: 0.2002,                 loss: 0.1580
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0304s / 92584.1491 s
agent0:                 episode reward: -0.5133,                 loss: nan
agent1:                 episode reward: 0.5133,                 loss: 0.1584
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3155s / 92719.4646 s
agent0:                 episode reward: -0.2924,                 loss: nan
agent1:                 episode reward: 0.2924,                 loss: 0.1585
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7699s / 92856.2346 s
agent0:                 episode reward: -0.4678,                 loss: nan
agent1:                 episode reward: 0.4678,                 loss: 0.1583
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6945s / 92990.9291 s
agent0:                 episode reward: 0.0105,                 loss: nan
agent1:                 episode reward: -0.0105,                 loss: 0.1595
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0090s / 93125.9381 s
agent0:                 episode reward: 0.1106,                 loss: nan
agent1:                 episode reward: -0.1106,                 loss: 0.1602
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6774s / 93261.6155 s
agent0:                 episode reward: -0.2957,                 loss: nan
agent1:                 episode reward: 0.2957,                 loss: 0.1592
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6880s / 93399.3035 s
agent0:                 episode reward: -0.6248,                 loss: nan
agent1:                 episode reward: 0.6248,                 loss: 0.1579
Episode: 14061/30000 (46.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.8768s / 93539.1803 s
agent0:                 episode reward: -0.2428,                 loss: nan
agent1:                 episode reward: 0.2428,                 loss: 0.1589
Episode: 14081/30000 (46.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8467s / 93676.0270 s
agent0:                 episode reward: -0.4666,                 loss: nan
agent1:                 episode reward: 0.4666,                 loss: 0.1581
Episode: 14101/30000 (47.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6305s / 93811.6575 s
agent0:                 episode reward: -0.1148,                 loss: nan
agent1:                 episode reward: 0.1148,                 loss: 0.1584
Episode: 14121/30000 (47.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3612s / 93948.0187 s
agent0:                 episode reward: -0.6651,                 loss: nan
agent1:                 episode reward: 0.6651,                 loss: 0.1597
Episode: 14141/30000 (47.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5398s / 94081.5584 s
agent0:                 episode reward: -0.3872,                 loss: nan
agent1:                 episode reward: 0.3872,                 loss: 0.1592
Episode: 14161/30000 (47.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9014s / 94214.4598 s
agent0:                 episode reward: -0.5709,                 loss: nan
agent1:                 episode reward: 0.5709,                 loss: 0.1577
Episode: 14181/30000 (47.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3713s / 94347.8311 s
agent0:                 episode reward: -0.2421,                 loss: nan
agent1:                 episode reward: 0.2421,                 loss: 0.1585
Episode: 14201/30000 (47.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2886s / 94481.1197 s
agent0:                 episode reward: -0.4998,                 loss: nan
agent1:                 episode reward: 0.4998,                 loss: 0.1584
Episode: 14221/30000 (47.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0578s / 94616.1775 s
agent0:                 episode reward: -0.3312,                 loss: nan
agent1:                 episode reward: 0.3312,                 loss: 0.1588
Episode: 14241/30000 (47.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2305s / 94751.4080 s
agent0:                 episode reward: -0.0558,                 loss: nan
agent1:                 episode reward: 0.0558,                 loss: 0.1610
Episode: 14261/30000 (47.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9787s / 94887.3866 s
agent0:                 episode reward: -0.3245,                 loss: nan
agent1:                 episode reward: 0.3245,                 loss: 0.1613
Episode: 14281/30000 (47.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.8480s / 95027.2346 s
agent0:                 episode reward: -0.2585,                 loss: nan
agent1:                 episode reward: 0.2585,                 loss: 0.1610
Episode: 14301/30000 (47.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0088s / 95159.2434 s
agent0:                 episode reward: -0.2230,                 loss: nan
agent1:                 episode reward: 0.2230,                 loss: 0.1612
Episode: 14321/30000 (47.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3550s / 95296.5984 s
agent0:                 episode reward: -0.5517,                 loss: nan
agent1:                 episode reward: 0.5517,                 loss: 0.1605
Episode: 14341/30000 (47.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5324s / 95434.1308 s
agent0:                 episode reward: -0.3999,                 loss: nan
agent1:                 episode reward: 0.3999,                 loss: 0.1614
Episode: 14361/30000 (47.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7994s / 95569.9302 s
agent0:                 episode reward: -0.2948,                 loss: nan
agent1:                 episode reward: 0.2948,                 loss: 0.1628
Episode: 14381/30000 (47.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7017s / 95706.6320 s
agent0:                 episode reward: -0.4851,                 loss: nan
agent1:                 episode reward: 0.4851,                 loss: 0.1597
Episode: 14401/30000 (48.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1314s / 95844.7634 s
agent0:                 episode reward: -0.4592,                 loss: nan
agent1:                 episode reward: 0.4592,                 loss: 0.1612