pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7f8475075c50>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518033032/mdp_arbitrary_mdp_nfsp/6000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518033032/mdp_arbitrary_mdp_nfsp/6000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518033032_exploit_6000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518033032_exploit_6000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6700s / 0.6700 s
agent0:                 episode reward: -1.7468,                 loss: nan
agent1:                 episode reward: 1.7468,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1088s / 0.7788 s
agent0:                 episode reward: 0.1193,                 loss: nan
agent1:                 episode reward: -0.1193,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1836s / 0.9623 s
agent0:                 episode reward: 0.2191,                 loss: nan
agent1:                 episode reward: -0.2191,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 1.1599 s
agent0:                 episode reward: -0.0533,                 loss: nan
agent1:                 episode reward: 0.0533,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 1.3606 s
agent0:                 episode reward: 0.2900,                 loss: nan
agent1:                 episode reward: -0.2900,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 1.5588 s
agent0:                 episode reward: -0.1384,                 loss: nan
agent1:                 episode reward: 0.1384,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 1.7589 s
agent0:                 episode reward: 0.2429,                 loss: nan
agent1:                 episode reward: -0.2429,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 1.9553 s
agent0:                 episode reward: 0.1407,                 loss: nan
agent1:                 episode reward: -0.1407,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 2.1526 s
agent0:                 episode reward: 0.4943,                 loss: nan
agent1:                 episode reward: -0.4943,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 2.3513 s
agent0:                 episode reward: 0.0674,                 loss: nan
agent1:                 episode reward: -0.0674,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1951s / 2.5464 s
agent0:                 episode reward: -0.1206,                 loss: nan
agent1:                 episode reward: 0.1206,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 2.7454 s
agent0:                 episode reward: 0.2421,                 loss: nan
agent1:                 episode reward: -0.2421,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 2.9418 s
agent0:                 episode reward: -0.0369,                 loss: nan
agent1:                 episode reward: 0.0369,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 3.1377 s
agent0:                 episode reward: 0.2445,                 loss: nan
agent1:                 episode reward: -0.2445,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 3.3341 s
agent0:                 episode reward: 0.1293,                 loss: nan
agent1:                 episode reward: -0.1293,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 3.5337 s
agent0:                 episode reward: -0.1672,                 loss: nan
agent1:                 episode reward: 0.1672,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2015s / 3.7351 s
agent0:                 episode reward: 0.1282,                 loss: nan
agent1:                 episode reward: -0.1282,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 3.9373 s
agent0:                 episode reward: 0.0669,                 loss: nan
agent1:                 episode reward: -0.0669,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 4.1353 s
agent0:                 episode reward: -0.1581,                 loss: nan
agent1:                 episode reward: 0.1581,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 4.3336 s
agent0:                 episode reward: 0.4106,                 loss: nan
agent1:                 episode reward: -0.4106,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 4.5306 s
agent0:                 episode reward: 0.3388,                 loss: nan
agent1:                 episode reward: -0.3388,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 4.7276 s
agent0:                 episode reward: 0.4386,                 loss: nan
agent1:                 episode reward: -0.4386,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 4.9272 s
agent0:                 episode reward: -0.0433,                 loss: nan
agent1:                 episode reward: 0.0433,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 5.1232 s
agent0:                 episode reward: 0.1126,                 loss: nan
agent1:                 episode reward: -0.1126,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 5.3217 s
agent0:                 episode reward: 0.2982,                 loss: nan
agent1:                 episode reward: -0.2982,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 5.5203 s
agent0:                 episode reward: -0.0900,                 loss: nan
agent1:                 episode reward: 0.0900,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 5.7189 s
agent0:                 episode reward: 0.3142,                 loss: nan
agent1:                 episode reward: -0.3142,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 5.9153 s
agent0:                 episode reward: -0.0461,                 loss: nan
agent1:                 episode reward: 0.0461,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1980s / 6.1133 s
agent0:                 episode reward: -0.1784,                 loss: nan
agent1:                 episode reward: 0.1784,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1997s / 6.3130 s
agent0:                 episode reward: 0.1391,                 loss: nan
agent1:                 episode reward: -0.1391,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1945s / 6.5076 s
agent0:                 episode reward: -0.2650,                 loss: nan
agent1:                 episode reward: 0.2650,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 6.7017 s
agent0:                 episode reward: 0.0734,                 loss: nan
agent1:                 episode reward: -0.0734,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2028s / 6.9045 s
agent0:                 episode reward: 0.4331,                 loss: nan
agent1:                 episode reward: -0.4331,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1942s / 7.0987 s
agent0:                 episode reward: 0.1405,                 loss: nan
agent1:                 episode reward: -0.1405,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 7.2952 s
agent0:                 episode reward: -0.0867,                 loss: nan
agent1:                 episode reward: 0.0867,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 7.4920 s
agent0:                 episode reward: -0.2873,                 loss: nan
agent1:                 episode reward: 0.2873,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 7.6892 s
agent0:                 episode reward: 0.2464,                 loss: nan
agent1:                 episode reward: -0.2464,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 7.8854 s
agent0:                 episode reward: 0.0763,                 loss: nan
agent1:                 episode reward: -0.0763,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 8.0817 s
agent0:                 episode reward: 0.0544,                 loss: nan
agent1:                 episode reward: -0.0544,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2009s / 8.2826 s
agent0:                 episode reward: 0.1473,                 loss: nan
agent1:                 episode reward: -0.1473,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 8.4779 s
agent0:                 episode reward: -0.1534,                 loss: nan
agent1:                 episode reward: 0.1534,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1941s / 8.6720 s
agent0:                 episode reward: 0.2019,                 loss: nan
agent1:                 episode reward: -0.2019,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 8.8706 s
agent0:                 episode reward: 0.0335,                 loss: nan
agent1:                 episode reward: -0.0335,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 9.0686 s
agent0:                 episode reward: 0.3665,                 loss: nan
agent1:                 episode reward: -0.3665,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 9.2691 s
agent0:                 episode reward: 0.1597,                 loss: nan
agent1:                 episode reward: -0.1597,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 9.4670 s
agent0:                 episode reward: 0.3265,                 loss: nan
agent1:                 episode reward: -0.3265,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1934s / 9.6604 s
agent0:                 episode reward: -0.0472,                 loss: nan
agent1:                 episode reward: 0.0472,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 9.8598 s
agent0:                 episode reward: 0.1817,                 loss: nan
agent1:                 episode reward: -0.1817,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 10.0579 s
agent0:                 episode reward: 0.1211,                 loss: nan
agent1:                 episode reward: -0.1211,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 10.2555 s
agent0:                 episode reward: 0.0943,                 loss: nan
agent1:                 episode reward: -0.0943,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 10.4532 s
agent0:                 episode reward: 0.2752,                 loss: nan
agent1:                 episode reward: -0.2752,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 10.6508 s
agent0:                 episode reward: 0.3701,                 loss: nan
agent1:                 episode reward: -0.3701,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1938s / 10.8446 s
agent0:                 episode reward: -0.0569,                 loss: nan
agent1:                 episode reward: 0.0569,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 11.0417 s
agent0:                 episode reward: 0.1617,                 loss: nan
agent1:                 episode reward: -0.1617,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 11.2399 s
agent0:                 episode reward: 0.7357,                 loss: nan
agent1:                 episode reward: -0.7357,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 11.4405 s
agent0:                 episode reward: 0.0489,                 loss: nan
agent1:                 episode reward: -0.0489,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 11.6405 s
agent0:                 episode reward: 0.0320,                 loss: nan
agent1:                 episode reward: -0.0320,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 11.8405 s
agent0:                 episode reward: -0.0101,                 loss: nan
agent1:                 episode reward: 0.0101,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 12.0373 s
agent0:                 episode reward: 0.3366,                 loss: nan
agent1:                 episode reward: -0.3366,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 12.2399 s
agent0:                 episode reward: -0.2414,                 loss: nan
agent1:                 episode reward: 0.2414,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 12.4383 s
agent0:                 episode reward: 0.1348,                 loss: nan
agent1:                 episode reward: -0.1348,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1968s / 12.6351 s
agent0:                 episode reward: 0.4100,                 loss: nan
agent1:                 episode reward: -0.4100,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1961s / 12.8312 s
agent0:                 episode reward: 0.4119,                 loss: nan
agent1:                 episode reward: -0.4119,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 13.0301 s
agent0:                 episode reward: 0.3770,                 loss: nan
agent1:                 episode reward: -0.3770,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 13.2312 s
agent0:                 episode reward: 0.0280,                 loss: nan
agent1:                 episode reward: -0.0280,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1935s / 13.4247 s
agent0:                 episode reward: 0.3190,                 loss: nan
agent1:                 episode reward: -0.3190,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1971s / 13.6218 s
agent0:                 episode reward: -0.2701,                 loss: nan
agent1:                 episode reward: 0.2701,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1952s / 13.8170 s
agent0:                 episode reward: 0.1759,                 loss: nan
agent1:                 episode reward: -0.1759,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2022s / 14.0192 s
agent0:                 episode reward: 0.1730,                 loss: nan
agent1:                 episode reward: -0.1730,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 14.2184 s
agent0:                 episode reward: 0.0496,                 loss: nan
agent1:                 episode reward: -0.0496,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 14.4166 s
agent0:                 episode reward: 0.0028,                 loss: nan
agent1:                 episode reward: -0.0028,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 14.6167 s
agent0:                 episode reward: 0.4385,                 loss: nan
agent1:                 episode reward: -0.4385,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 14.8156 s
agent0:                 episode reward: 0.2036,                 loss: nan
agent1:                 episode reward: -0.2036,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1932s / 15.0088 s
agent0:                 episode reward: -0.1986,                 loss: nan
agent1:                 episode reward: 0.1986,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 15.2089 s
agent0:                 episode reward: 0.2417,                 loss: nan
agent1:                 episode reward: -0.2417,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1947s / 15.4037 s
agent0:                 episode reward: 0.0926,                 loss: nan
agent1:                 episode reward: -0.0926,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1986s / 15.6023 s
agent0:                 episode reward: 0.2485,                 loss: nan
agent1:                 episode reward: -0.2485,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1924s / 15.7947 s
agent0:                 episode reward: 0.0531,                 loss: nan
agent1:                 episode reward: -0.0531,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1987s / 15.9934 s
agent0:                 episode reward: 0.4312,                 loss: nan
agent1:                 episode reward: -0.4312,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 16.1898 s
agent0:                 episode reward: 0.4526,                 loss: nan
agent1:                 episode reward: -0.4526,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 16.3873 s
agent0:                 episode reward: -0.0720,                 loss: nan
agent1:                 episode reward: 0.0720,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1972s / 16.5846 s
agent0:                 episode reward: 0.1891,                 loss: nan
agent1:                 episode reward: -0.1891,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2026s / 16.7872 s
agent0:                 episode reward: 0.2429,                 loss: nan
agent1:                 episode reward: -0.2429,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2017s / 16.9889 s
agent0:                 episode reward: 0.3481,                 loss: nan
agent1:                 episode reward: -0.3481,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 17.1852 s
agent0:                 episode reward: 0.1485,                 loss: nan
agent1:                 episode reward: -0.1485,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 17.3836 s
agent0:                 episode reward: 0.1110,                 loss: nan
agent1:                 episode reward: -0.1110,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 17.5793 s
agent0:                 episode reward: -0.2466,                 loss: nan
agent1:                 episode reward: 0.2466,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 17.7778 s
agent0:                 episode reward: -0.1805,                 loss: nan
agent1:                 episode reward: 0.1805,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 17.9747 s
agent0:                 episode reward: 0.1063,                 loss: nan
agent1:                 episode reward: -0.1063,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 18.1722 s
agent0:                 episode reward: -0.0740,                 loss: nan
agent1:                 episode reward: 0.0740,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1938s / 18.3660 s
agent0:                 episode reward: -0.2930,                 loss: nan
agent1:                 episode reward: 0.2930,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 18.5614 s
agent0:                 episode reward: 0.6618,                 loss: nan
agent1:                 episode reward: -0.6618,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1982s / 18.7596 s
agent0:                 episode reward: -0.5151,                 loss: nan
agent1:                 episode reward: 0.5151,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1967s / 18.9563 s
agent0:                 episode reward: 0.4073,                 loss: nan
agent1:                 episode reward: -0.4073,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 19.1538 s
agent0:                 episode reward: -0.2153,                 loss: nan
agent1:                 episode reward: 0.2153,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2029s / 19.3567 s
agent0:                 episode reward: 0.0196,                 loss: nan
agent1:                 episode reward: -0.0196,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 19.5575 s
agent0:                 episode reward: 0.1822,                 loss: nan
agent1:                 episode reward: -0.1822,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1970s / 19.7545 s
agent0:                 episode reward: -0.1532,                 loss: nan
agent1:                 episode reward: 0.1532,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1983s / 19.9528 s
agent0:                 episode reward: -0.0020,                 loss: nan
agent1:                 episode reward: 0.0020,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 20.1503 s
agent0:                 episode reward: 0.4655,                 loss: nan
agent1:                 episode reward: -0.4655,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1985s / 20.3488 s
agent0:                 episode reward: 0.0844,                 loss: nan
agent1:                 episode reward: -0.0844,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2005s / 20.5493 s
agent0:                 episode reward: -0.0652,                 loss: nan
agent1:                 episode reward: 0.0652,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1943s / 20.7436 s
agent0:                 episode reward: -0.2814,                 loss: nan
agent1:                 episode reward: 0.2814,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 20.9429 s
agent0:                 episode reward: 0.2533,                 loss: nan
agent1:                 episode reward: -0.2533,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 21.1398 s
agent0:                 episode reward: 0.0900,                 loss: nan
agent1:                 episode reward: -0.0900,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2028s / 21.3427 s
agent0:                 episode reward: 0.1178,                 loss: nan
agent1:                 episode reward: -0.1178,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2013s / 21.5440 s
agent0:                 episode reward: 0.1768,                 loss: nan
agent1:                 episode reward: -0.1768,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2010s / 21.7450 s
agent0:                 episode reward: 0.0540,                 loss: nan
agent1:                 episode reward: -0.0540,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1959s / 21.9409 s
agent0:                 episode reward: 0.2138,                 loss: nan
agent1:                 episode reward: -0.2138,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 22.1399 s
agent0:                 episode reward: 0.4842,                 loss: nan
agent1:                 episode reward: -0.4842,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1969s / 22.3368 s
agent0:                 episode reward: -0.3538,                 loss: nan
agent1:                 episode reward: 0.3538,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2004s / 22.5372 s
agent0:                 episode reward: 0.1046,                 loss: nan
agent1:                 episode reward: -0.1046,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1976s / 22.7348 s
agent0:                 episode reward: 0.1848,                 loss: nan
agent1:                 episode reward: -0.1848,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2011s / 22.9360 s
agent0:                 episode reward: 0.2631,                 loss: nan
agent1:                 episode reward: -0.2631,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1993s / 23.1352 s
agent0:                 episode reward: 0.3251,                 loss: nan
agent1:                 episode reward: -0.3251,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1994s / 23.3347 s
agent0:                 episode reward: 0.1159,                 loss: nan
agent1:                 episode reward: -0.1159,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1963s / 23.5310 s
agent0:                 episode reward: 0.0185,                 loss: nan
agent1:                 episode reward: -0.0185,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 23.7310 s
agent0:                 episode reward: 0.5201,                 loss: nan
agent1:                 episode reward: -0.5201,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1950s / 23.9260 s
agent0:                 episode reward: 0.0817,                 loss: nan
agent1:                 episode reward: -0.0817,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1958s / 24.1218 s
agent0:                 episode reward: 0.2225,                 loss: nan
agent1:                 episode reward: -0.2225,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1966s / 24.3184 s
agent0:                 episode reward: 0.0042,                 loss: nan
agent1:                 episode reward: -0.0042,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1991s / 24.5175 s
agent0:                 episode reward: 0.3332,                 loss: nan
agent1:                 episode reward: -0.3332,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2029s / 24.7204 s
agent0:                 episode reward: -0.2703,                 loss: nan
agent1:                 episode reward: 0.2703,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1939s / 24.9143 s
agent0:                 episode reward: 0.1326,                 loss: nan
agent1:                 episode reward: -0.1326,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1995s / 25.1137 s
agent0:                 episode reward: 0.4828,                 loss: nan
agent1:                 episode reward: -0.4828,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 25.3138 s
agent0:                 episode reward: 0.1160,                 loss: nan
agent1:                 episode reward: -0.1160,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1956s / 25.5094 s
agent0:                 episode reward: -0.1875,                 loss: nan
agent1:                 episode reward: 0.1875,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1940s / 25.7034 s
agent0:                 episode reward: -0.2086,                 loss: nan
agent1:                 episode reward: 0.2086,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1917s / 25.8952 s
agent0:                 episode reward: 0.4119,                 loss: nan
agent1:                 episode reward: -0.4119,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1975s / 26.0927 s
agent0:                 episode reward: 0.2533,                 loss: nan
agent1:                 episode reward: -0.2533,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1960s / 26.2886 s
agent0:                 episode reward: -0.2654,                 loss: nan
agent1:                 episode reward: 0.2654,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1840s / 26.4726 s
agent0:                 episode reward: 0.0521,                 loss: nan
agent1:                 episode reward: -0.0521,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1984s / 26.6710 s
agent0:                 episode reward: 0.0392,                 loss: nan
agent1:                 episode reward: -0.0392,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 26.8711 s
agent0:                 episode reward: 0.1130,                 loss: nan
agent1:                 episode reward: -0.1130,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1962s / 27.0673 s
agent0:                 episode reward: 0.5199,                 loss: nan
agent1:                 episode reward: -0.5199,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1957s / 27.2631 s
agent0:                 episode reward: 0.3062,                 loss: nan
agent1:                 episode reward: -0.3062,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1954s / 27.4584 s
agent0:                 episode reward: 0.2945,                 loss: nan
agent1:                 episode reward: -0.2945,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1989s / 27.6573 s
agent0:                 episode reward: 0.1415,                 loss: nan
agent1:                 episode reward: -0.1415,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2412s / 27.8985 s
agent0:                 episode reward: -0.3815,                 loss: nan
agent1:                 episode reward: 0.3815,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1627s / 28.0612 s
agent0:                 episode reward: 0.4870,                 loss: nan
agent1:                 episode reward: -0.4870,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1918s / 28.2530 s
agent0:                 episode reward: 0.2644,                 loss: nan
agent1:                 episode reward: -0.2644,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1996s / 28.4526 s
agent0:                 episode reward: 0.0087,                 loss: nan
agent1:                 episode reward: -0.0087,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1953s / 28.6479 s
agent0:                 episode reward: 0.0100,                 loss: nan
agent1:                 episode reward: -0.0100,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1990s / 28.8469 s
agent0:                 episode reward: 0.3978,                 loss: nan
agent1:                 episode reward: -0.3978,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 29.0448 s
agent0:                 episode reward: 0.1990,                 loss: nan
agent1:                 episode reward: -0.1990,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2001s / 29.2450 s
agent0:                 episode reward: 0.0101,                 loss: nan
agent1:                 episode reward: -0.0101,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1915s / 29.4365 s
agent0:                 episode reward: -0.0328,                 loss: nan
agent1:                 episode reward: 0.0328,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2016s / 29.6381 s
agent0:                 episode reward: 0.0637,                 loss: nan
agent1:                 episode reward: -0.0637,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 29.8354 s
agent0:                 episode reward: 0.4127,                 loss: nan
agent1:                 episode reward: -0.4127,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2035s / 30.0389 s
agent0:                 episode reward: 0.5923,                 loss: nan
agent1:                 episode reward: -0.5923,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2000s / 30.2389 s
agent0:                 episode reward: -0.0740,                 loss: nan
agent1:                 episode reward: 0.0740,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1977s / 30.4367 s
agent0:                 episode reward: 0.2211,                 loss: nan
agent1:                 episode reward: -0.2211,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 30.6346 s
agent0:                 episode reward: 0.4509,                 loss: nan
agent1:                 episode reward: -0.4509,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2024s / 30.8370 s
agent0:                 episode reward: 0.2656,                 loss: nan
agent1:                 episode reward: -0.2656,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1973s / 31.0343 s
agent0:                 episode reward: -0.1111,                 loss: nan
agent1:                 episode reward: 0.1111,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1981s / 31.2324 s
agent0:                 episode reward: 0.0766,                 loss: nan
agent1:                 episode reward: -0.0766,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2007s / 31.4331 s
agent0:                 episode reward: -0.0497,                 loss: nan
agent1:                 episode reward: 0.0497,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2030s / 31.6361 s
agent0:                 episode reward: -0.2516,                 loss: nan
agent1:                 episode reward: 0.2516,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1999s / 31.8360 s
agent0:                 episode reward: 0.1926,                 loss: nan
agent1:                 episode reward: -0.1926,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2008s / 32.0368 s
agent0:                 episode reward: 0.0596,                 loss: nan
agent1:                 episode reward: -0.0596,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1979s / 32.2347 s
agent0:                 episode reward: 0.0984,                 loss: nan
agent1:                 episode reward: -0.0984,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1936s / 32.4283 s
agent0:                 episode reward: -0.0506,                 loss: nan
agent1:                 episode reward: 0.0506,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1919s / 32.6202 s
agent0:                 episode reward: 0.0610,                 loss: nan
agent1:                 episode reward: -0.0610,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1955s / 32.8157 s
agent0:                 episode reward: 0.0431,                 loss: nan
agent1:                 episode reward: -0.0431,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1965s / 33.0123 s
agent0:                 episode reward: 0.4535,                 loss: nan
agent1:                 episode reward: -0.4535,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1883s / 33.2006 s
agent0:                 episode reward: 0.2571,                 loss: nan
agent1:                 episode reward: -0.2571,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1905s / 33.3911 s
agent0:                 episode reward: 0.1193,                 loss: nan
agent1:                 episode reward: -0.1193,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3606s / 33.7516 s
agent0:                 episode reward: -0.3502,                 loss: nan
agent1:                 episode reward: 0.3502,                 loss: 0.4523
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5959s / 34.3475 s
agent0:                 episode reward: -0.2810,                 loss: nan
agent1:                 episode reward: 0.2810,                 loss: 0.4384
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5845s / 34.9319 s
agent0:                 episode reward: 0.0745,                 loss: nan
agent1:                 episode reward: -0.0745,                 loss: 0.4293
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5903s / 35.5222 s
agent0:                 episode reward: 0.0403,                 loss: nan
agent1:                 episode reward: -0.0403,                 loss: 0.4243
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 36.1133 s
agent0:                 episode reward: 0.0046,                 loss: nan
agent1:                 episode reward: -0.0046,                 loss: 0.4213
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 36.7054 s
agent0:                 episode reward: 0.1075,                 loss: nan
agent1:                 episode reward: -0.1075,                 loss: 0.4171
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5790s / 37.2844 s
agent0:                 episode reward: 0.1265,                 loss: nan
agent1:                 episode reward: -0.1265,                 loss: 0.4128
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5817s / 37.8661 s
agent0:                 episode reward: 0.3360,                 loss: nan
agent1:                 episode reward: -0.3360,                 loss: 0.4087
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5830s / 38.4491 s
agent0:                 episode reward: 0.1888,                 loss: nan
agent1:                 episode reward: -0.1888,                 loss: 0.4036
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5820s / 39.0311 s
agent0:                 episode reward: -0.1631,                 loss: nan
agent1:                 episode reward: 0.1631,                 loss: 0.3950
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5922s / 39.6233 s
agent0:                 episode reward: 0.2697,                 loss: nan
agent1:                 episode reward: -0.2697,                 loss: 0.3865
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5852s / 40.2085 s
agent0:                 episode reward: -0.0220,                 loss: nan
agent1:                 episode reward: 0.0220,                 loss: 0.3766
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5857s / 40.7942 s
agent0:                 episode reward: 0.2847,                 loss: nan
agent1:                 episode reward: -0.2847,                 loss: 0.3667
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5860s / 41.3802 s
agent0:                 episode reward: 0.0929,                 loss: nan
agent1:                 episode reward: -0.0929,                 loss: 0.3543
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5936s / 41.9738 s
agent0:                 episode reward: -0.5567,                 loss: nan
agent1:                 episode reward: 0.5567,                 loss: 0.3447
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5829s / 42.5567 s
agent0:                 episode reward: -0.3505,                 loss: nan
agent1:                 episode reward: 0.3505,                 loss: 0.3382
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5911s / 43.1478 s
agent0:                 episode reward: -0.4090,                 loss: nan
agent1:                 episode reward: 0.4090,                 loss: 0.3271
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5936s / 43.7415 s
agent0:                 episode reward: -0.6798,                 loss: nan
agent1:                 episode reward: 0.6798,                 loss: 0.2921
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5911s / 44.3326 s
agent0:                 episode reward: -0.9258,                 loss: nan
agent1:                 episode reward: 0.9258,                 loss: 0.2779
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5811s / 44.9137 s
agent0:                 episode reward: -0.6983,                 loss: nan
agent1:                 episode reward: 0.6983,                 loss: 0.2739
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5881s / 45.5018 s
agent0:                 episode reward: -0.7601,                 loss: nan
agent1:                 episode reward: 0.7601,                 loss: 0.2756
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 46.0877 s
agent0:                 episode reward: -0.7899,                 loss: nan
agent1:                 episode reward: 0.7899,                 loss: 0.2738
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 46.6800 s
agent0:                 episode reward: -0.6664,                 loss: nan
agent1:                 episode reward: 0.6664,                 loss: 0.2730
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5871s / 47.2671 s
agent0:                 episode reward: -0.7216,                 loss: nan
agent1:                 episode reward: 0.7216,                 loss: 0.2695
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5870s / 47.8541 s
agent0:                 episode reward: -0.6792,                 loss: nan
agent1:                 episode reward: 0.6792,                 loss: 0.2691
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5813s / 48.4354 s
agent0:                 episode reward: -0.8539,                 loss: nan
agent1:                 episode reward: 0.8539,                 loss: 0.2688
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5880s / 49.0234 s
agent0:                 episode reward: -1.0755,                 loss: nan
agent1:                 episode reward: 1.0755,                 loss: 0.2710
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5929s / 49.6163 s
agent0:                 episode reward: -0.9260,                 loss: nan
agent1:                 episode reward: 0.9260,                 loss: 0.2698
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5870s / 50.2033 s
agent0:                 episode reward: -0.5169,                 loss: nan
agent1:                 episode reward: 0.5169,                 loss: 0.2686
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5854s / 50.7887 s
agent0:                 episode reward: -0.6479,                 loss: nan
agent1:                 episode reward: 0.6479,                 loss: 0.2670
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5890s / 51.3777 s
agent0:                 episode reward: -0.8633,                 loss: nan
agent1:                 episode reward: 0.8633,                 loss: 0.2652
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5837s / 51.9614 s
agent0:                 episode reward: -0.8596,                 loss: nan
agent1:                 episode reward: 0.8596,                 loss: 0.2661
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5832s / 52.5446 s
agent0:                 episode reward: -0.7419,                 loss: nan
agent1:                 episode reward: 0.7419,                 loss: 0.2647
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5820s / 53.1266 s
agent0:                 episode reward: -0.5788,                 loss: nan
agent1:                 episode reward: 0.5788,                 loss: 0.2714
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 53.7220 s
agent0:                 episode reward: -0.8093,                 loss: nan
agent1:                 episode reward: 0.8093,                 loss: 0.2808
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5890s / 54.3110 s
agent0:                 episode reward: -1.2497,                 loss: nan
agent1:                 episode reward: 1.2497,                 loss: 0.2662
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5861s / 54.8971 s
agent0:                 episode reward: -0.5312,                 loss: nan
agent1:                 episode reward: 0.5312,                 loss: 0.2647
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5857s / 55.4828 s
agent0:                 episode reward: -0.5381,                 loss: nan
agent1:                 episode reward: 0.5381,                 loss: 0.2656
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5861s / 56.0689 s
agent0:                 episode reward: -0.8800,                 loss: nan
agent1:                 episode reward: 0.8800,                 loss: 0.2662
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5876s / 56.6564 s
agent0:                 episode reward: -0.3827,                 loss: nan
agent1:                 episode reward: 0.3827,                 loss: 0.2634
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5889s / 57.2454 s
agent0:                 episode reward: -0.5526,                 loss: nan
agent1:                 episode reward: 0.5526,                 loss: 0.2617
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5875s / 57.8329 s
agent0:                 episode reward: -0.9003,                 loss: nan
agent1:                 episode reward: 0.9003,                 loss: 0.2590
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5833s / 58.4162 s
agent0:                 episode reward: -0.9012,                 loss: nan
agent1:                 episode reward: 0.9012,                 loss: 0.2626
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5955s / 59.0117 s
agent0:                 episode reward: -0.7235,                 loss: nan
agent1:                 episode reward: 0.7235,                 loss: 0.2611
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5911s / 59.6028 s
agent0:                 episode reward: -0.7460,                 loss: nan
agent1:                 episode reward: 0.7460,                 loss: 0.2636
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5887s / 60.1914 s
agent0:                 episode reward: -0.6891,                 loss: nan
agent1:                 episode reward: 0.6891,                 loss: 0.2618
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5874s / 60.7788 s
agent0:                 episode reward: -0.7807,                 loss: nan
agent1:                 episode reward: 0.7807,                 loss: 0.2596
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5910s / 61.3698 s
agent0:                 episode reward: -1.1916,                 loss: nan
agent1:                 episode reward: 1.1916,                 loss: 0.2612
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5869s / 61.9567 s
agent0:                 episode reward: -0.5666,                 loss: nan
agent1:                 episode reward: 0.5666,                 loss: 0.2590
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5824s / 62.5392 s
agent0:                 episode reward: -0.7088,                 loss: nan
agent1:                 episode reward: 0.7088,                 loss: 0.2615
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5926s / 63.1317 s
agent0:                 episode reward: -0.7287,                 loss: nan
agent1:                 episode reward: 0.7287,                 loss: 0.2629
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5886s / 63.7203 s
agent0:                 episode reward: -0.7694,                 loss: nan
agent1:                 episode reward: 0.7694,                 loss: 0.2640
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5876s / 64.3079 s
agent0:                 episode reward: -0.8733,                 loss: nan
agent1:                 episode reward: 0.8733,                 loss: 0.2624
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5904s / 64.8982 s
agent0:                 episode reward: -0.9235,                 loss: nan
agent1:                 episode reward: 0.9235,                 loss: 0.2641
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 65.4936 s
agent0:                 episode reward: -0.7543,                 loss: nan
agent1:                 episode reward: 0.7543,                 loss: 0.2643
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5857s / 66.0793 s
agent0:                 episode reward: -0.9269,                 loss: nan
agent1:                 episode reward: 0.9269,                 loss: 0.2616
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 66.6783 s
agent0:                 episode reward: -0.9282,                 loss: nan
agent1:                 episode reward: 0.9282,                 loss: 0.2591
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 67.2735 s
agent0:                 episode reward: -0.7577,                 loss: nan
agent1:                 episode reward: 0.7577,                 loss: 0.2622
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5969s / 67.8704 s
agent0:                 episode reward: -0.6784,                 loss: nan
agent1:                 episode reward: 0.6784,                 loss: 0.2573
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5913s / 68.4617 s
agent0:                 episode reward: -0.6887,                 loss: nan
agent1:                 episode reward: 0.6887,                 loss: 0.2631
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5963s / 69.0580 s
agent0:                 episode reward: -0.8081,                 loss: nan
agent1:                 episode reward: 0.8081,                 loss: 0.2608
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5895s / 69.6475 s
agent0:                 episode reward: -0.5912,                 loss: nan
agent1:                 episode reward: 0.5912,                 loss: 0.2575
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5877s / 70.2352 s
agent0:                 episode reward: -0.6554,                 loss: nan
agent1:                 episode reward: 0.6554,                 loss: 0.2584
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5858s / 70.8210 s
agent0:                 episode reward: -0.6448,                 loss: nan
agent1:                 episode reward: 0.6448,                 loss: 0.2590
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5867s / 71.4076 s
agent0:                 episode reward: -0.7987,                 loss: nan
agent1:                 episode reward: 0.7987,                 loss: 0.2594
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5968s / 72.0044 s
agent0:                 episode reward: -0.5453,                 loss: nan
agent1:                 episode reward: 0.5453,                 loss: 0.2648
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 72.5946 s
agent0:                 episode reward: -0.6384,                 loss: nan
agent1:                 episode reward: 0.6384,                 loss: 0.2637
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5892s / 73.1839 s
agent0:                 episode reward: -0.9694,                 loss: nan
agent1:                 episode reward: 0.9694,                 loss: 0.2534
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5847s / 73.7685 s
agent0:                 episode reward: -0.7739,                 loss: nan
agent1:                 episode reward: 0.7739,                 loss: 0.2556
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5952s / 74.3638 s
agent0:                 episode reward: -0.7363,                 loss: nan
agent1:                 episode reward: 0.7363,                 loss: 0.2547
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5864s / 74.9501 s
agent0:                 episode reward: -0.7936,                 loss: nan
agent1:                 episode reward: 0.7936,                 loss: 0.2553
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5843s / 75.5344 s
agent0:                 episode reward: -0.7128,                 loss: nan
agent1:                 episode reward: 0.7128,                 loss: 0.2522
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5862s / 76.1206 s
agent0:                 episode reward: -0.9866,                 loss: nan
agent1:                 episode reward: 0.9866,                 loss: 0.2541
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5891s / 76.7096 s
agent0:                 episode reward: -0.6390,                 loss: nan
agent1:                 episode reward: 0.6390,                 loss: 0.2561
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5906s / 77.3003 s
agent0:                 episode reward: -0.4583,                 loss: nan
agent1:                 episode reward: 0.4583,                 loss: 0.2561
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5923s / 77.8926 s
agent0:                 episode reward: -0.9993,                 loss: nan
agent1:                 episode reward: 0.9993,                 loss: 0.2541
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5886s / 78.4812 s
agent0:                 episode reward: -0.7053,                 loss: nan
agent1:                 episode reward: 0.7053,                 loss: 0.2557
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5866s / 79.0678 s
agent0:                 episode reward: -0.8228,                 loss: nan
agent1:                 episode reward: 0.8228,                 loss: 0.2555
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5951s / 79.6628 s
agent0:                 episode reward: -0.7286,                 loss: nan
agent1:                 episode reward: 0.7286,                 loss: 0.2554
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5934s / 80.2562 s
agent0:                 episode reward: -0.8012,                 loss: nan
agent1:                 episode reward: 0.8012,                 loss: 0.2557
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5998s / 80.8559 s
agent0:                 episode reward: -1.2022,                 loss: nan
agent1:                 episode reward: 1.2022,                 loss: 0.2559
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5892s / 81.4452 s
agent0:                 episode reward: -0.6229,                 loss: nan
agent1:                 episode reward: 0.6229,                 loss: 0.2522
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5939s / 82.0390 s
agent0:                 episode reward: -0.8605,                 loss: nan
agent1:                 episode reward: 0.8605,                 loss: 0.2569
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5889s / 82.6280 s
agent0:                 episode reward: -0.6853,                 loss: nan
agent1:                 episode reward: 0.6853,                 loss: 0.2517
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5928s / 83.2207 s
agent0:                 episode reward: -0.5593,                 loss: nan
agent1:                 episode reward: 0.5593,                 loss: 0.2385
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 83.8192 s
agent0:                 episode reward: -0.3489,                 loss: nan
agent1:                 episode reward: 0.3489,                 loss: 0.2432
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5819s / 84.4011 s
agent0:                 episode reward: -0.9752,                 loss: nan
agent1:                 episode reward: 0.9752,                 loss: 0.2419
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6002s / 85.0013 s
agent0:                 episode reward: -0.8566,                 loss: nan
agent1:                 episode reward: 0.8566,                 loss: 0.2446
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5971s / 85.5984 s
agent0:                 episode reward: -0.3575,                 loss: nan
agent1:                 episode reward: 0.3575,                 loss: 0.2452
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5908s / 86.1892 s
agent0:                 episode reward: -0.8125,                 loss: nan
agent1:                 episode reward: 0.8125,                 loss: 0.2413
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6010s / 86.7902 s
agent0:                 episode reward: -0.6452,                 loss: nan
agent1:                 episode reward: 0.6452,                 loss: 0.2465
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5865s / 87.3767 s
agent0:                 episode reward: -0.8931,                 loss: nan
agent1:                 episode reward: 0.8931,                 loss: 0.2439
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5961s / 87.9728 s
agent0:                 episode reward: -1.2115,                 loss: nan
agent1:                 episode reward: 1.2115,                 loss: 0.2462
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 88.5671 s
agent0:                 episode reward: -0.9716,                 loss: nan
agent1:                 episode reward: 0.9716,                 loss: 0.2426
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5932s / 89.1603 s
agent0:                 episode reward: -0.7239,                 loss: nan
agent1:                 episode reward: 0.7239,                 loss: 0.2439
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5995s / 89.7599 s
agent0:                 episode reward: -0.7802,                 loss: nan
agent1:                 episode reward: 0.7802,                 loss: 0.2434
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5915s / 90.3514 s
agent0:                 episode reward: -0.8373,                 loss: nan
agent1:                 episode reward: 0.8373,                 loss: 0.2443
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5918s / 90.9432 s
agent0:                 episode reward: -0.7315,                 loss: nan
agent1:                 episode reward: 0.7315,                 loss: 0.2454
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5916s / 91.5348 s
agent0:                 episode reward: -0.7170,                 loss: nan
agent1:                 episode reward: 0.7170,                 loss: 0.2443
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5897s / 92.1244 s
agent0:                 episode reward: -1.0445,                 loss: nan
agent1:                 episode reward: 1.0445,                 loss: 0.2459
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 92.7186 s
agent0:                 episode reward: -0.8748,                 loss: nan
agent1:                 episode reward: 0.8748,                 loss: 0.2488
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5853s / 93.3039 s
agent0:                 episode reward: -0.6237,                 loss: nan
agent1:                 episode reward: 0.6237,                 loss: 0.2574
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 93.8936 s
agent0:                 episode reward: -0.7429,                 loss: nan
agent1:                 episode reward: 0.7429,                 loss: 0.2570
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6087s / 94.5023 s
agent0:                 episode reward: -1.3407,                 loss: nan
agent1:                 episode reward: 1.3407,                 loss: 0.2581
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5894s / 95.0917 s
agent0:                 episode reward: -0.4849,                 loss: nan
agent1:                 episode reward: 0.4849,                 loss: 0.2553
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5906s / 95.6822 s
agent0:                 episode reward: -0.7017,                 loss: nan
agent1:                 episode reward: 0.7017,                 loss: 0.2586
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5866s / 96.2688 s
agent0:                 episode reward: -0.7041,                 loss: nan
agent1:                 episode reward: 0.7041,                 loss: 0.2579
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5907s / 96.8595 s
agent0:                 episode reward: -0.5637,                 loss: nan
agent1:                 episode reward: 0.5637,                 loss: 0.2587
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5847s / 97.4442 s
agent0:                 episode reward: -0.8132,                 loss: nan
agent1:                 episode reward: 0.8132,                 loss: 0.2579
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6008s / 98.0450 s
agent0:                 episode reward: -0.8269,                 loss: nan
agent1:                 episode reward: 0.8269,                 loss: 0.2549
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5900s / 98.6350 s
agent0:                 episode reward: -0.5320,                 loss: nan
agent1:                 episode reward: 0.5320,                 loss: 0.2568
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 99.2325 s
agent0:                 episode reward: -0.7148,                 loss: nan
agent1:                 episode reward: 0.7148,                 loss: 0.2562
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5947s / 99.8272 s
agent0:                 episode reward: -0.5317,                 loss: nan
agent1:                 episode reward: 0.5317,                 loss: 0.2551
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6023s / 100.4295 s
agent0:                 episode reward: -0.8725,                 loss: nan
agent1:                 episode reward: 0.8725,                 loss: 0.2594
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5976s / 101.0271 s
agent0:                 episode reward: -0.7285,                 loss: nan
agent1:                 episode reward: 0.7285,                 loss: 0.2532
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5989s / 101.6260 s
agent0:                 episode reward: -0.5239,                 loss: nan
agent1:                 episode reward: 0.5239,                 loss: 0.2584
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5948s / 102.2209 s
agent0:                 episode reward: -0.8215,                 loss: nan
agent1:                 episode reward: 0.8215,                 loss: 0.2562
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5930s / 102.8138 s
agent0:                 episode reward: -0.9198,                 loss: nan
agent1:                 episode reward: 0.9198,                 loss: 0.2562
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5943s / 103.4081 s
agent0:                 episode reward: -0.4950,                 loss: nan
agent1:                 episode reward: 0.4950,                 loss: 0.2574
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5946s / 104.0027 s
agent0:                 episode reward: -0.7803,                 loss: nan
agent1:                 episode reward: 0.7803,                 loss: 0.2530
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5982s / 104.6009 s
agent0:                 episode reward: -0.6121,                 loss: nan
agent1:                 episode reward: 0.6121,                 loss: 0.2556
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6001s / 105.2010 s
agent0:                 episode reward: -0.6697,                 loss: nan
agent1:                 episode reward: 0.6697,                 loss: 0.2544
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5997s / 105.8007 s
agent0:                 episode reward: -0.9396,                 loss: nan
agent1:                 episode reward: 0.9396,                 loss: 0.2520
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6012s / 106.4020 s
agent0:                 episode reward: -0.7189,                 loss: nan
agent1:                 episode reward: 0.7189,                 loss: 0.2512
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6027s / 107.0046 s
agent0:                 episode reward: -0.5810,                 loss: nan
agent1:                 episode reward: 0.5810,                 loss: 0.2560
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6022s / 107.6068 s
agent0:                 episode reward: -0.9228,                 loss: nan
agent1:                 episode reward: 0.9228,                 loss: 0.2534
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5954s / 108.2023 s
agent0:                 episode reward: -0.5244,                 loss: nan
agent1:                 episode reward: 0.5244,                 loss: 0.2526
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6043s / 108.8066 s
agent0:                 episode reward: -0.8222,                 loss: nan
agent1:                 episode reward: 0.8222,                 loss: 0.2549
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5983s / 109.4049 s
agent0:                 episode reward: -0.7196,                 loss: nan
agent1:                 episode reward: 0.7196,                 loss: 0.2555
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5920s / 109.9969 s
agent0:                 episode reward: -0.7988,                 loss: nan
agent1:                 episode reward: 0.7988,                 loss: 0.2568
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5983s / 110.5952 s
agent0:                 episode reward: -0.8773,                 loss: nan
agent1:                 episode reward: 0.8773,                 loss: 0.2541
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6000s / 111.1952 s
agent0:                 episode reward: -0.3590,                 loss: nan
agent1:                 episode reward: 0.3590,                 loss: 0.2572
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5865s / 111.7818 s
agent0:                 episode reward: -0.8898,                 loss: nan
agent1:                 episode reward: 0.8898,                 loss: 0.2541
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5942s / 112.3760 s
agent0:                 episode reward: -0.6842,                 loss: nan
agent1:                 episode reward: 0.6842,                 loss: 0.2532
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5995s / 112.9755 s
agent0:                 episode reward: -0.6818,                 loss: nan
agent1:                 episode reward: 0.6818,                 loss: 0.2430
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5959s / 113.5713 s
agent0:                 episode reward: -0.4574,                 loss: nan
agent1:                 episode reward: 0.4574,                 loss: 0.2400
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 114.1735 s
agent0:                 episode reward: -0.8333,                 loss: nan
agent1:                 episode reward: 0.8333,                 loss: 0.2384
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5966s / 114.7701 s
agent0:                 episode reward: -0.7265,                 loss: nan
agent1:                 episode reward: 0.7265,                 loss: 0.2396
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5902s / 115.3603 s
agent0:                 episode reward: -0.8124,                 loss: nan
agent1:                 episode reward: 0.8124,                 loss: 0.2404
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 115.9587 s
agent0:                 episode reward: -0.8976,                 loss: nan
agent1:                 episode reward: 0.8976,                 loss: 0.2376
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5935s / 116.5522 s
agent0:                 episode reward: -1.0211,                 loss: nan
agent1:                 episode reward: 1.0211,                 loss: 0.2377
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5944s / 117.1466 s
agent0:                 episode reward: -0.6909,                 loss: nan
agent1:                 episode reward: 0.6909,                 loss: 0.2403
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5971s / 117.7437 s
agent0:                 episode reward: -0.7898,                 loss: nan
agent1:                 episode reward: 0.7898,                 loss: 0.2408
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5953s / 118.3390 s
agent0:                 episode reward: -0.7435,                 loss: nan
agent1:                 episode reward: 0.7435,                 loss: 0.2388
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5906s / 118.9295 s
agent0:                 episode reward: -0.7826,                 loss: nan
agent1:                 episode reward: 0.7826,                 loss: 0.2406
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5984s / 119.5280 s
agent0:                 episode reward: -0.7961,                 loss: nan
agent1:                 episode reward: 0.7961,                 loss: 0.2389
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5971s / 120.1251 s
agent0:                 episode reward: -1.1022,                 loss: nan
agent1:                 episode reward: 1.1022,                 loss: 0.2393
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5941s / 120.7192 s
agent0:                 episode reward: -0.7067,                 loss: nan
agent1:                 episode reward: 0.7067,                 loss: 0.2375
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5988s / 121.3179 s
agent0:                 episode reward: -0.8758,                 loss: nan
agent1:                 episode reward: 0.8758,                 loss: 0.2383
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5907s / 121.9086 s
agent0:                 episode reward: -0.7709,                 loss: nan
agent1:                 episode reward: 0.7709,                 loss: 0.2406
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5963s / 122.5050 s
agent0:                 episode reward: -0.7138,                 loss: nan
agent1:                 episode reward: 0.7138,                 loss: 0.2526
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6064s / 123.1113 s
agent0:                 episode reward: -0.6959,                 loss: nan
agent1:                 episode reward: 0.6959,                 loss: 0.2695
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6032s / 123.7145 s
agent0:                 episode reward: -0.9773,                 loss: nan
agent1:                 episode reward: 0.9773,                 loss: 0.2650
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5917s / 124.3062 s
agent0:                 episode reward: -0.3924,                 loss: nan
agent1:                 episode reward: 0.3924,                 loss: 0.2674
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5896s / 124.8958 s
agent0:                 episode reward: -0.6221,                 loss: nan
agent1:                 episode reward: 0.6221,                 loss: 0.2683
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5981s / 125.4939 s
agent0:                 episode reward: -0.9490,                 loss: nan
agent1:                 episode reward: 0.9490,                 loss: 0.2664
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6070s / 126.1009 s
agent0:                 episode reward: -0.5647,                 loss: nan
agent1:                 episode reward: 0.5647,                 loss: 0.2669
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6011s / 126.7020 s
agent0:                 episode reward: -0.5119,                 loss: nan
agent1:                 episode reward: 0.5119,                 loss: 0.2680
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6066s / 127.3086 s
agent0:                 episode reward: -0.6400,                 loss: nan
agent1:                 episode reward: 0.6400,                 loss: 0.2705
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6022s / 127.9108 s
agent0:                 episode reward: -0.2113,                 loss: nan
agent1:                 episode reward: 0.2113,                 loss: 0.2683
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5941s / 128.5049 s
agent0:                 episode reward: -0.6301,                 loss: nan
agent1:                 episode reward: 0.6301,                 loss: 0.2694
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6000s / 129.1048 s
agent0:                 episode reward: -0.6200,                 loss: nan
agent1:                 episode reward: 0.6200,                 loss: 0.2660
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6048s / 129.7096 s
agent0:                 episode reward: -0.6396,                 loss: nan
agent1:                 episode reward: 0.6396,                 loss: 0.2647
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6040s / 130.3136 s
agent0:                 episode reward: -0.9155,                 loss: nan
agent1:                 episode reward: 0.9155,                 loss: 0.2704
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6013s / 130.9149 s
agent0:                 episode reward: -0.9600,                 loss: nan
agent1:                 episode reward: 0.9600,                 loss: 0.2654
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5966s / 131.5115 s
agent0:                 episode reward: -0.8224,                 loss: nan
agent1:                 episode reward: 0.8224,                 loss: 0.2690
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5975s / 132.1090 s
agent0:                 episode reward: -0.5752,                 loss: nan
agent1:                 episode reward: 0.5752,                 loss: 0.2692
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5994s / 132.7084 s
agent0:                 episode reward: -0.4821,                 loss: nan
agent1:                 episode reward: 0.4821,                 loss: 0.2670
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5973s / 133.3057 s
agent0:                 episode reward: -0.6568,                 loss: nan
agent1:                 episode reward: 0.6568,                 loss: 0.2647
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6071s / 133.9128 s
agent0:                 episode reward: -0.9709,                 loss: nan
agent1:                 episode reward: 0.9709,                 loss: 0.2617
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6088s / 134.5216 s
agent0:                 episode reward: -0.7907,                 loss: nan
agent1:                 episode reward: 0.7907,                 loss: 0.2647
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6023s / 135.1239 s
agent0:                 episode reward: -0.6710,                 loss: nan
agent1:                 episode reward: 0.6710,                 loss: 0.2624
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6058s / 135.7297 s
agent0:                 episode reward: -0.9020,                 loss: nan
agent1:                 episode reward: 0.9020,                 loss: 0.2617
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6082s / 136.3379 s
agent0:                 episode reward: -0.9534,                 loss: nan
agent1:                 episode reward: 0.9534,                 loss: 0.2627
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6091s / 136.9469 s
agent0:                 episode reward: -0.5984,                 loss: nan
agent1:                 episode reward: 0.5984,                 loss: 0.2616
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5979s / 137.5448 s
agent0:                 episode reward: -0.6367,                 loss: nan
agent1:                 episode reward: 0.6367,                 loss: 0.2645
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6134s / 138.1582 s
agent0:                 episode reward: -0.9337,                 loss: nan
agent1:                 episode reward: 0.9337,                 loss: 0.2622
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6034s / 138.7616 s
agent0:                 episode reward: -0.8452,                 loss: nan
agent1:                 episode reward: 0.8452,                 loss: 0.2619
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 139.3606 s
agent0:                 episode reward: -0.8076,                 loss: nan
agent1:                 episode reward: 0.8076,                 loss: 0.2624
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6119s / 139.9724 s
agent0:                 episode reward: -0.7084,                 loss: nan
agent1:                 episode reward: 0.7084,                 loss: 0.2620
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6091s / 140.5816 s
agent0:                 episode reward: -0.6690,                 loss: nan
agent1:                 episode reward: 0.6690,                 loss: 0.2641
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6084s / 141.1899 s
agent0:                 episode reward: -0.6614,                 loss: nan
agent1:                 episode reward: 0.6614,                 loss: 0.2650
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6103s / 141.8002 s
agent0:                 episode reward: -0.8900,                 loss: nan
agent1:                 episode reward: 0.8900,                 loss: 0.2605
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6043s / 142.4045 s
agent0:                 episode reward: -0.8100,                 loss: nan
agent1:                 episode reward: 0.8100,                 loss: 0.2644
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6112s / 143.0157 s
agent0:                 episode reward: -0.3794,                 loss: nan
agent1:                 episode reward: 0.3794,                 loss: 0.2481
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6097s / 143.6254 s
agent0:                 episode reward: -0.5709,                 loss: nan
agent1:                 episode reward: 0.5709,                 loss: 0.2408
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6077s / 144.2331 s
agent0:                 episode reward: -0.8068,                 loss: nan
agent1:                 episode reward: 0.8068,                 loss: 0.2428
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6058s / 144.8388 s
agent0:                 episode reward: -0.3505,                 loss: nan
agent1:                 episode reward: 0.3505,                 loss: 0.2424
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6047s / 145.4436 s
agent0:                 episode reward: -0.4414,                 loss: nan
agent1:                 episode reward: 0.4414,                 loss: 0.2442
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6131s / 146.0567 s
agent0:                 episode reward: -0.7109,                 loss: nan
agent1:                 episode reward: 0.7109,                 loss: 0.2397
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6046s / 146.6613 s
agent0:                 episode reward: -0.8993,                 loss: nan
agent1:                 episode reward: 0.8993,                 loss: 0.2411
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6029s / 147.2642 s
agent0:                 episode reward: -0.6946,                 loss: nan
agent1:                 episode reward: 0.6946,                 loss: 0.2419
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6097s / 147.8739 s
agent0:                 episode reward: -0.6007,                 loss: nan
agent1:                 episode reward: 0.6007,                 loss: 0.2405
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6079s / 148.4818 s
agent0:                 episode reward: -0.7552,                 loss: nan
agent1:                 episode reward: 0.7552,                 loss: 0.2392
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6060s / 149.0878 s
agent0:                 episode reward: -0.9151,                 loss: nan
agent1:                 episode reward: 0.9151,                 loss: 0.2432
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6005s / 149.6883 s
agent0:                 episode reward: -0.8257,                 loss: nan
agent1:                 episode reward: 0.8257,                 loss: 0.2446
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6101s / 150.2984 s
agent0:                 episode reward: -0.8752,                 loss: nan
agent1:                 episode reward: 0.8752,                 loss: 0.2475
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6145s / 150.9129 s
agent0:                 episode reward: -0.6747,                 loss: nan
agent1:                 episode reward: 0.6747,                 loss: 0.2431
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6044s / 151.5173 s
agent0:                 episode reward: -1.0988,                 loss: nan
agent1:                 episode reward: 1.0988,                 loss: 0.2417
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6029s / 152.1202 s
agent0:                 episode reward: -0.5710,                 loss: nan
agent1:                 episode reward: 0.5710,                 loss: 0.2435
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6017s / 152.7219 s
agent0:                 episode reward: -0.5559,                 loss: nan
agent1:                 episode reward: 0.5559,                 loss: 0.2698
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6088s / 153.3307 s
agent0:                 episode reward: -0.8442,                 loss: nan
agent1:                 episode reward: 0.8442,                 loss: 0.2841
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6063s / 153.9370 s
agent0:                 episode reward: -1.1793,                 loss: nan
agent1:                 episode reward: 1.1793,                 loss: 0.2875
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6030s / 154.5400 s
agent0:                 episode reward: -0.7224,                 loss: nan
agent1:                 episode reward: 0.7224,                 loss: 0.2831
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6081s / 155.1481 s
agent0:                 episode reward: -0.6445,                 loss: nan
agent1:                 episode reward: 0.6445,                 loss: 0.2818
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6145s / 155.7626 s
agent0:                 episode reward: -0.4918,                 loss: nan
agent1:                 episode reward: 0.4918,                 loss: 0.2846
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6061s / 156.3686 s
agent0:                 episode reward: -0.7037,                 loss: nan
agent1:                 episode reward: 0.7037,                 loss: 0.2821
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6076s / 156.9762 s
agent0:                 episode reward: -0.7909,                 loss: nan
agent1:                 episode reward: 0.7909,                 loss: 0.2851
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6053s / 157.5815 s
agent0:                 episode reward: -0.7924,                 loss: nan
agent1:                 episode reward: 0.7924,                 loss: 0.2849
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6035s / 158.1850 s
agent0:                 episode reward: -0.8594,                 loss: nan
agent1:                 episode reward: 0.8594,                 loss: 0.2848
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6108s / 158.7959 s
agent0:                 episode reward: -0.7178,                 loss: nan
agent1:                 episode reward: 0.7178,                 loss: 0.2843
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6021s / 159.3980 s
agent0:                 episode reward: -0.8058,                 loss: nan
agent1:                 episode reward: 0.8058,                 loss: 0.2852
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5967s / 159.9947 s
agent0:                 episode reward: -0.5952,                 loss: nan
agent1:                 episode reward: 0.5952,                 loss: 0.2830
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6143s / 160.6090 s
agent0:                 episode reward: -0.8935,                 loss: nan
agent1:                 episode reward: 0.8935,                 loss: 0.2827
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6192s / 161.2282 s
agent0:                 episode reward: -0.8614,                 loss: nan
agent1:                 episode reward: 0.8614,                 loss: 0.2820
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6095s / 161.8378 s
agent0:                 episode reward: -1.0904,                 loss: nan
agent1:                 episode reward: 1.0904,                 loss: 0.2856
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.5990s / 162.4368 s
agent0:                 episode reward: -0.9542,                 loss: nan
agent1:                 episode reward: 0.9542,                 loss: 0.2870
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6049s / 163.0417 s
agent0:                 episode reward: -0.7375,                 loss: nan
agent1:                 episode reward: 0.7375,                 loss: 0.2687
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 163.6473 s
agent0:                 episode reward: -0.8463,                 loss: nan
agent1:                 episode reward: 0.8463,                 loss: 0.2589
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6048s / 164.2522 s
agent0:                 episode reward: -0.8900,                 loss: nan
agent1:                 episode reward: 0.8900,                 loss: 0.2618
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6095s / 164.8617 s
agent0:                 episode reward: -0.6550,                 loss: nan
agent1:                 episode reward: 0.6550,                 loss: 0.2579
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6106s / 165.4722 s
agent0:                 episode reward: -0.8573,                 loss: nan
agent1:                 episode reward: 0.8573,                 loss: 0.2566
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6072s / 166.0794 s
agent0:                 episode reward: -0.8847,                 loss: nan
agent1:                 episode reward: 0.8847,                 loss: 0.2572
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6119s / 166.6913 s
agent0:                 episode reward: -0.6052,                 loss: nan
agent1:                 episode reward: 0.6052,                 loss: 0.2597
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6063s / 167.2976 s
agent0:                 episode reward: -0.5772,                 loss: nan
agent1:                 episode reward: 0.5772,                 loss: 0.2569
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6075s / 167.9051 s
agent0:                 episode reward: -0.6917,                 loss: nan
agent1:                 episode reward: 0.6917,                 loss: 0.2585
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6095s / 168.5146 s
agent0:                 episode reward: -0.5894,                 loss: nan
agent1:                 episode reward: 0.5894,                 loss: 0.2588
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6042s / 169.1188 s
agent0:                 episode reward: -0.7195,                 loss: nan
agent1:                 episode reward: 0.7195,                 loss: 0.2591
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6064s / 169.7252 s
agent0:                 episode reward: -0.6005,                 loss: nan
agent1:                 episode reward: 0.6005,                 loss: 0.2622
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6131s / 170.3383 s
agent0:                 episode reward: -0.9792,                 loss: nan
agent1:                 episode reward: 0.9792,                 loss: 0.2593
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6056s / 170.9439 s
agent0:                 episode reward: -0.8744,                 loss: nan
agent1:                 episode reward: 0.8744,                 loss: 0.2567
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6090s / 171.5529 s
agent0:                 episode reward: -0.6668,                 loss: nan
agent1:                 episode reward: 0.6668,                 loss: 0.2560
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6129s / 172.1658 s
agent0:                 episode reward: -0.9234,                 loss: nan
agent1:                 episode reward: 0.9234,                 loss: 0.2562
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6072s / 172.7729 s
agent0:                 episode reward: -0.9048,                 loss: nan
agent1:                 episode reward: 0.9048,                 loss: 0.2582
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6176s / 173.3905 s
agent0:                 episode reward: -0.7465,                 loss: nan
agent1:                 episode reward: 0.7465,                 loss: 0.2539
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6070s / 173.9976 s
agent0:                 episode reward: -0.6180,                 loss: nan
agent1:                 episode reward: 0.6180,                 loss: 0.2438
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6077s / 174.6053 s
agent0:                 episode reward: -0.5103,                 loss: nan
agent1:                 episode reward: 0.5103,                 loss: 0.2452
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6133s / 175.2185 s
agent0:                 episode reward: -0.6756,                 loss: nan
agent1:                 episode reward: 0.6756,                 loss: 0.2435
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6180s / 175.8365 s
agent0:                 episode reward: -0.5022,                 loss: nan
agent1:                 episode reward: 0.5022,                 loss: 0.2436
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6033s / 176.4399 s
agent0:                 episode reward: -0.5903,                 loss: nan
agent1:                 episode reward: 0.5903,                 loss: 0.2439
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6057s / 177.0456 s
agent0:                 episode reward: -0.4620,                 loss: nan
agent1:                 episode reward: 0.4620,                 loss: 0.2470
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6143s / 177.6598 s
agent0:                 episode reward: -0.7382,                 loss: nan
agent1:                 episode reward: 0.7382,                 loss: 0.2475
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.6125s / 178.2723 s
