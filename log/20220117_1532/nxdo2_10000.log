pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 12.0, (1,), float32) action space: Discrete(3)
random seed: 91
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fb490256250>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=3, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.284 0.369 0.348]
 [0.355 0.408 0.236]]
Load checkpoints (policy family):  [['83' '5753' '6419']
 ['121' '6342' '6627']]
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'update_itr': 1}, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'cpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220116204408/epi_10000/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nxdo2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'selfplay_score_delta': 1.5, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220116204408_exploit_10000/mdp_arbitrary_mdp_nxdo2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220116204408_exploit_10000/mdp_arbitrary_mdp_nxdo2.
Episode: 1/30000 (0.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 1.2763s / 1.2763 s
agent0:                 episode reward: 1.1516,                 loss: nan
agent1:                 episode reward: -1.1516,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1887s / 1.4650 s
agent0:                 episode reward: -0.0587,                 loss: nan
agent1:                 episode reward: 0.0587,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2285s / 1.6935 s
agent0:                 episode reward: -0.1900,                 loss: nan
agent1:                 episode reward: 0.1900,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.3286s / 2.0220 s
agent0:                 episode reward: 0.0623,                 loss: nan
agent1:                 episode reward: -0.0623,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0865s / 2.1085 s
agent0:                 episode reward: 0.1206,                 loss: nan
agent1:                 episode reward: -0.1206,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0807s / 2.1892 s
agent0:                 episode reward: 0.3041,                 loss: nan
agent1:                 episode reward: -0.3041,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.0919s / 2.2811 s
agent0:                 episode reward: 0.2781,                 loss: nan
agent1:                 episode reward: -0.2781,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1529s / 2.4340 s
agent0:                 episode reward: 0.3576,                 loss: nan
agent1:                 episode reward: -0.3576,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 0.2048s / 2.6388 s
agent0:                 episode reward: 0.0128,                 loss: nan
agent1:                 episode reward: -0.0128,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1931s / 2.8319 s
agent0:                 episode reward: 0.2631,                 loss: nan
agent1:                 episode reward: -0.2631,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 0.1964s / 3.0283 s
agent0:                 episode reward: -0.0921,                 loss: nan
agent1:                 episode reward: 0.0921,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 27.5073s / 30.5356 s
agent0:                 episode reward: 0.0764,                 loss: nan
agent1:                 episode reward: -0.0764,                 loss: 0.1838
Episode: 241/30000 (0.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 102.8260s / 133.3616 s
agent0:                 episode reward: 0.0852,                 loss: nan
agent1:                 episode reward: -0.0852,                 loss: 0.1753
Episode: 261/30000 (0.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 96.6351s / 229.9967 s
agent0:                 episode reward: -0.1071,                 loss: nan
agent1:                 episode reward: 0.1071,                 loss: 0.1705
Episode: 281/30000 (0.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 96.1527s / 326.1494 s
agent0:                 episode reward: -0.0984,                 loss: nan
agent1:                 episode reward: 0.0984,                 loss: 0.1672
Episode: 301/30000 (1.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 97.2173s / 423.3667 s
agent0:                 episode reward: -0.0253,                 loss: nan
agent1:                 episode reward: 0.0253,                 loss: 0.1624
Episode: 321/30000 (1.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 99.0320s / 522.3987 s
agent0:                 episode reward: 0.0326,                 loss: nan
agent1:                 episode reward: -0.0326,                 loss: 0.1585
Episode: 341/30000 (1.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 98.5462s / 620.9449 s
agent0:                 episode reward: 0.5321,                 loss: nan
agent1:                 episode reward: -0.5321,                 loss: 0.1564
Episode: 361/30000 (1.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 100.0778s / 721.0227 s
agent0:                 episode reward: -0.3230,                 loss: nan
agent1:                 episode reward: 0.3230,                 loss: 0.1552
Episode: 381/30000 (1.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 102.0341s / 823.0567 s
agent0:                 episode reward: 0.2010,                 loss: nan
agent1:                 episode reward: -0.2010,                 loss: 0.1522
Episode: 401/30000 (1.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 99.9927s / 923.0495 s
agent0:                 episode reward: 0.2431,                 loss: nan
agent1:                 episode reward: -0.2431,                 loss: 0.1520
Episode: 421/30000 (1.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 99.8111s / 1022.8606 s
agent0:                 episode reward: 0.0709,                 loss: nan
agent1:                 episode reward: -0.0709,                 loss: 0.1503
Episode: 441/30000 (1.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 96.3217s / 1119.1822 s
agent0:                 episode reward: 0.2799,                 loss: nan
agent1:                 episode reward: -0.2799,                 loss: 0.1475
Episode: 461/30000 (1.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 99.1141s / 1218.2964 s
agent0:                 episode reward: 0.2573,                 loss: nan
agent1:                 episode reward: -0.2573,                 loss: 0.1485
Episode: 481/30000 (1.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 90.3888s / 1308.6851 s
agent0:                 episode reward: -0.2670,                 loss: nan
agent1:                 episode reward: 0.2670,                 loss: 0.1494
Episode: 501/30000 (1.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 98.1984s / 1406.8836 s
agent0:                 episode reward: -0.0495,                 loss: nan
agent1:                 episode reward: 0.0495,                 loss: 0.1473
Episode: 521/30000 (1.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 98.1895s / 1505.0731 s
agent0:                 episode reward: -0.2892,                 loss: nan
agent1:                 episode reward: 0.2892,                 loss: 0.1460
Episode: 541/30000 (1.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 100.6652s / 1605.7383 s
agent0:                 episode reward: 0.0704,                 loss: nan
agent1:                 episode reward: -0.0704,                 loss: 0.1457
Episode: 561/30000 (1.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 102.1674s / 1707.9057 s
agent0:                 episode reward: -0.0285,                 loss: nan
agent1:                 episode reward: 0.0285,                 loss: 0.1454
Episode: 581/30000 (1.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 102.0417s / 1809.9474 s
agent0:                 episode reward: 0.4083,                 loss: nan
agent1:                 episode reward: -0.4083,                 loss: 0.1440
Episode: 601/30000 (2.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 96.8298s / 1906.7772 s
agent0:                 episode reward: 0.2390,                 loss: nan
agent1:                 episode reward: -0.2390,                 loss: 0.1441
Episode: 621/30000 (2.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 99.0020s / 2005.7792 s
agent0:                 episode reward: 0.2483,                 loss: nan
agent1:                 episode reward: -0.2483,                 loss: 0.1417
Episode: 641/30000 (2.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 96.9261s / 2102.7053 s
agent0:                 episode reward: 0.0660,                 loss: nan
agent1:                 episode reward: -0.0660,                 loss: 0.1413
Episode: 661/30000 (2.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 98.3126s / 2201.0179 s
agent0:                 episode reward: 0.1697,                 loss: nan
agent1:                 episode reward: -0.1697,                 loss: 0.1404
Episode: 681/30000 (2.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 100.1367s / 2301.1546 s
agent0:                 episode reward: 0.0415,                 loss: nan
agent1:                 episode reward: -0.0415,                 loss: 0.1414
Episode: 701/30000 (2.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 98.8887s / 2400.0433 s
agent0:                 episode reward: -0.2196,                 loss: nan
agent1:                 episode reward: 0.2196,                 loss: 0.1413
Episode: 721/30000 (2.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 98.4073s / 2498.4506 s
agent0:                 episode reward: -0.1829,                 loss: nan
agent1:                 episode reward: 0.1829,                 loss: 0.1414
Episode: 741/30000 (2.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 101.4970s / 2599.9477 s
agent0:                 episode reward: -0.7450,                 loss: nan
agent1:                 episode reward: 0.7450,                 loss: 0.1423
Episode: 761/30000 (2.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 96.1026s / 2696.0503 s
agent0:                 episode reward: 0.2218,                 loss: nan
agent1:                 episode reward: -0.2218,                 loss: 0.1410
Episode: 781/30000 (2.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 122.6964s / 2818.7467 s
agent0:                 episode reward: 0.0595,                 loss: nan
agent1:                 episode reward: -0.0595,                 loss: 0.1414
Episode: 801/30000 (2.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.0893s / 2957.8360 s
agent0:                 episode reward: 0.2981,                 loss: nan
agent1:                 episode reward: -0.2981,                 loss: 0.1407
Episode: 821/30000 (2.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.8277s / 3098.6637 s
agent0:                 episode reward: -0.1877,                 loss: nan
agent1:                 episode reward: 0.1877,                 loss: 0.1418
Episode: 841/30000 (2.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4011s / 3235.0648 s
agent0:                 episode reward: 0.3700,                 loss: nan
agent1:                 episode reward: -0.3700,                 loss: 0.1399
Episode: 861/30000 (2.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7926s / 3370.8574 s
agent0:                 episode reward: 0.2242,                 loss: nan
agent1:                 episode reward: -0.2242,                 loss: 0.1400
Episode: 881/30000 (2.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5618s / 3507.4191 s
agent0:                 episode reward: -0.1475,                 loss: nan
agent1:                 episode reward: 0.1475,                 loss: 0.1402
Episode: 901/30000 (3.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8553s / 3645.2744 s
agent0:                 episode reward: -0.2379,                 loss: nan
agent1:                 episode reward: 0.2379,                 loss: 0.1482
Episode: 921/30000 (3.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6196s / 3780.8940 s
agent0:                 episode reward: -0.0323,                 loss: nan
agent1:                 episode reward: 0.0323,                 loss: 0.1455
Episode: 941/30000 (3.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8961s / 3917.7901 s
agent0:                 episode reward: 0.3953,                 loss: nan
agent1:                 episode reward: -0.3953,                 loss: 0.1441
Episode: 961/30000 (3.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4602s / 4054.2503 s
agent0:                 episode reward: -0.1554,                 loss: nan
agent1:                 episode reward: 0.1554,                 loss: 0.1447
Episode: 981/30000 (3.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9609s / 4191.2112 s
agent0:                 episode reward: -0.0588,                 loss: nan
agent1:                 episode reward: 0.0588,                 loss: 0.1454
Episode: 1001/30000 (3.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0816s / 4327.2929 s
agent0:                 episode reward: 0.0824,                 loss: nan
agent1:                 episode reward: -0.0824,                 loss: 0.1440
Episode: 1021/30000 (3.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0432s / 4465.3360 s
agent0:                 episode reward: -0.0518,                 loss: nan
agent1:                 episode reward: 0.0518,                 loss: 0.1430
Episode: 1041/30000 (3.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3493s / 4602.6854 s
agent0:                 episode reward: 0.1926,                 loss: nan
agent1:                 episode reward: -0.1926,                 loss: 0.1434
Episode: 1061/30000 (3.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.7163s / 4746.4017 s
agent0:                 episode reward: 0.2443,                 loss: nan
agent1:                 episode reward: -0.2443,                 loss: 0.1433
Episode: 1081/30000 (3.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4604s / 4883.8621 s
agent0:                 episode reward: 0.0548,                 loss: nan
agent1:                 episode reward: -0.0548,                 loss: 0.1429
Episode: 1101/30000 (3.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.9214s / 5024.7835 s
agent0:                 episode reward: 0.0853,                 loss: nan
agent1:                 episode reward: -0.0853,                 loss: 0.1408
Episode: 1121/30000 (3.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.0322s / 5166.8157 s
agent0:                 episode reward: 0.2971,                 loss: nan
agent1:                 episode reward: -0.2971,                 loss: 0.1429
Episode: 1141/30000 (3.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8937s / 5305.7094 s
agent0:                 episode reward: -0.0308,                 loss: nan
agent1:                 episode reward: 0.0308,                 loss: 0.1431
Episode: 1161/30000 (3.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.1299s / 5444.8392 s
agent0:                 episode reward: -0.0454,                 loss: nan
agent1:                 episode reward: 0.0454,                 loss: 0.1419
Episode: 1181/30000 (3.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.5445s / 5585.3837 s
agent0:                 episode reward: -0.1361,                 loss: nan
agent1:                 episode reward: 0.1361,                 loss: 0.1433
Episode: 1201/30000 (4.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4164s / 5722.8002 s
agent0:                 episode reward: -0.3703,                 loss: nan
agent1:                 episode reward: 0.3703,                 loss: 0.1419
Episode: 1221/30000 (4.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8175s / 5858.6176 s
agent0:                 episode reward: 0.0556,                 loss: nan
agent1:                 episode reward: -0.0556,                 loss: 0.1414
Episode: 1241/30000 (4.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.8636s / 5998.4812 s
agent0:                 episode reward: 0.3238,                 loss: nan
agent1:                 episode reward: -0.3238,                 loss: 0.1372
Episode: 1261/30000 (4.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.4451s / 6138.9263 s
agent0:                 episode reward: 0.2208,                 loss: nan
agent1:                 episode reward: -0.2208,                 loss: 0.1358
Episode: 1281/30000 (4.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3564s / 6277.2827 s
agent0:                 episode reward: 0.0491,                 loss: nan
agent1:                 episode reward: -0.0491,                 loss: 0.1371
Episode: 1301/30000 (4.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.9302s / 6416.2129 s
agent0:                 episode reward: -0.2484,                 loss: nan
agent1:                 episode reward: 0.2484,                 loss: 0.1364
Episode: 1321/30000 (4.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9438s / 6552.1567 s
agent0:                 episode reward: 0.0632,                 loss: nan
agent1:                 episode reward: -0.0632,                 loss: 0.1350
Episode: 1341/30000 (4.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6903s / 6688.8470 s
agent0:                 episode reward: 0.3496,                 loss: nan
agent1:                 episode reward: -0.3496,                 loss: 0.1346
Episode: 1361/30000 (4.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2340s / 6827.0810 s
agent0:                 episode reward: -0.1582,                 loss: nan
agent1:                 episode reward: 0.1582,                 loss: 0.1351
Episode: 1381/30000 (4.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.3348s / 6967.4158 s
agent0:                 episode reward: 0.0474,                 loss: nan
agent1:                 episode reward: -0.0474,                 loss: 0.1353
Episode: 1401/30000 (4.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.5580s / 7108.9738 s
agent0:                 episode reward: -0.1664,                 loss: nan
agent1:                 episode reward: 0.1664,                 loss: 0.1363
Episode: 1421/30000 (4.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2517s / 7245.2255 s
agent0:                 episode reward: 0.1314,                 loss: nan
agent1:                 episode reward: -0.1314,                 loss: 0.1360
Episode: 1441/30000 (4.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5011s / 7383.7266 s
agent0:                 episode reward: -0.0362,                 loss: nan
agent1:                 episode reward: 0.0362,                 loss: 0.1358
Episode: 1461/30000 (4.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.8654s / 7525.5920 s
agent0:                 episode reward: 0.0676,                 loss: nan
agent1:                 episode reward: -0.0676,                 loss: 0.1374
Episode: 1481/30000 (4.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.7120s / 7665.3040 s
agent0:                 episode reward: -0.0759,                 loss: nan
agent1:                 episode reward: 0.0759,                 loss: 0.1359
Episode: 1501/30000 (5.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1676s / 7802.4715 s
agent0:                 episode reward: -0.1373,                 loss: nan
agent1:                 episode reward: 0.1373,                 loss: 0.1350
Episode: 1521/30000 (5.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9855s / 7940.4570 s
agent0:                 episode reward: -0.3518,                 loss: nan
agent1:                 episode reward: 0.3518,                 loss: 0.1358
Episode: 1541/30000 (5.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.4864s / 8079.9434 s
agent0:                 episode reward: -0.1035,                 loss: nan
agent1:                 episode reward: 0.1035,                 loss: 0.1379
Episode: 1561/30000 (5.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3508s / 8217.2942 s
agent0:                 episode reward: 0.1942,                 loss: nan
agent1:                 episode reward: -0.1942,                 loss: 0.1358
Episode: 1581/30000 (5.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8840s / 8354.1782 s
agent0:                 episode reward: 0.0778,                 loss: nan
agent1:                 episode reward: -0.0778,                 loss: 0.1359
Episode: 1601/30000 (5.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6596s / 8494.8378 s
agent0:                 episode reward: 0.0030,                 loss: nan
agent1:                 episode reward: -0.0030,                 loss: 0.1349
Episode: 1621/30000 (5.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.4286s / 8634.2664 s
agent0:                 episode reward: 0.1143,                 loss: nan
agent1:                 episode reward: -0.1143,                 loss: 0.1361
Episode: 1641/30000 (5.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.1171s / 8773.3835 s
agent0:                 episode reward: -0.4018,                 loss: nan
agent1:                 episode reward: 0.4018,                 loss: 0.1370
Episode: 1661/30000 (5.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7428s / 8910.1263 s
agent0:                 episode reward: 0.4249,                 loss: nan
agent1:                 episode reward: -0.4249,                 loss: 0.1355
Episode: 1681/30000 (5.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5059s / 9048.6322 s
agent0:                 episode reward: -0.1752,                 loss: nan
agent1:                 episode reward: 0.1752,                 loss: 0.1350
Episode: 1701/30000 (5.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.9565s / 9190.5887 s
agent0:                 episode reward: 0.0493,                 loss: nan
agent1:                 episode reward: -0.0493,                 loss: 0.1366
Episode: 1721/30000 (5.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1972s / 9328.7859 s
agent0:                 episode reward: -0.1531,                 loss: nan
agent1:                 episode reward: 0.1531,                 loss: 0.1365
Episode: 1741/30000 (5.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.3660s / 9471.1519 s
agent0:                 episode reward: 0.2764,                 loss: nan
agent1:                 episode reward: -0.2764,                 loss: 0.1350
Episode: 1761/30000 (5.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1277s / 9607.2796 s
agent0:                 episode reward: 0.2820,                 loss: nan
agent1:                 episode reward: -0.2820,                 loss: 0.1362
Episode: 1781/30000 (5.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.6787s / 9746.9583 s
agent0:                 episode reward: -0.2909,                 loss: nan
agent1:                 episode reward: 0.2909,                 loss: 0.1350
Episode: 1801/30000 (6.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.3350s / 9887.2933 s
agent0:                 episode reward: 0.0142,                 loss: nan
agent1:                 episode reward: -0.0142,                 loss: 0.1345
Episode: 1821/30000 (6.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0391s / 10024.3323 s
agent0:                 episode reward: -0.3929,                 loss: nan
agent1:                 episode reward: 0.3929,                 loss: 0.1349
Episode: 1841/30000 (6.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.3983s / 10165.7307 s
agent0:                 episode reward: 0.0534,                 loss: nan
agent1:                 episode reward: -0.0534,                 loss: 0.1354
Episode: 1861/30000 (6.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.6652s / 10307.3959 s
agent0:                 episode reward: -0.1943,                 loss: nan
agent1:                 episode reward: 0.1943,                 loss: 0.1355
Episode: 1881/30000 (6.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8526s / 10445.2485 s
agent0:                 episode reward: 0.0842,                 loss: nan
agent1:                 episode reward: -0.0842,                 loss: 0.1361
Episode: 1901/30000 (6.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.8236s / 10584.0722 s
agent0:                 episode reward: -0.1555,                 loss: nan
agent1:                 episode reward: 0.1555,                 loss: 0.1412
Episode: 1921/30000 (6.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.1328s / 10723.2050 s
agent0:                 episode reward: 0.1643,                 loss: nan
agent1:                 episode reward: -0.1643,                 loss: 0.1411
Episode: 1941/30000 (6.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6233s / 10861.8283 s
agent0:                 episode reward: -0.0636,                 loss: nan
agent1:                 episode reward: 0.0636,                 loss: 0.1416
Episode: 1961/30000 (6.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2081s / 10997.0364 s
agent0:                 episode reward: -0.2461,                 loss: nan
agent1:                 episode reward: 0.2461,                 loss: 0.1421
Episode: 1981/30000 (6.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.9934s / 11136.0297 s
agent0:                 episode reward: 0.0169,                 loss: nan
agent1:                 episode reward: -0.0169,                 loss: 0.1424
Episode: 2001/30000 (6.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.7848s / 11274.8146 s
agent0:                 episode reward: -0.3753,                 loss: nan
agent1:                 episode reward: 0.3753,                 loss: 0.1407
Episode: 2021/30000 (6.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4937s / 11413.3083 s
agent0:                 episode reward: -0.5091,                 loss: nan
agent1:                 episode reward: 0.5091,                 loss: 0.1398
Episode: 2041/30000 (6.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.1808s / 11555.4890 s
agent0:                 episode reward: -0.2313,                 loss: nan
agent1:                 episode reward: 0.2313,                 loss: 0.1390
Episode: 2061/30000 (6.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2312s / 11691.7203 s
agent0:                 episode reward: 0.1618,                 loss: nan
agent1:                 episode reward: -0.1618,                 loss: 0.1415
Episode: 2081/30000 (6.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.2082s / 11829.9284 s
agent0:                 episode reward: -0.1479,                 loss: nan
agent1:                 episode reward: 0.1479,                 loss: 0.1389
Episode: 2101/30000 (7.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0945s / 11966.0229 s
agent0:                 episode reward: -0.0864,                 loss: nan
agent1:                 episode reward: 0.0864,                 loss: 0.1402
Episode: 2121/30000 (7.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1479s / 12101.1708 s
agent0:                 episode reward: -0.3281,                 loss: nan
agent1:                 episode reward: 0.3281,                 loss: 0.1419
Episode: 2141/30000 (7.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.1269s / 12243.2977 s
agent0:                 episode reward: 0.1014,                 loss: nan
agent1:                 episode reward: -0.1014,                 loss: 0.1399
Episode: 2161/30000 (7.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.1531s / 12383.4508 s
agent0:                 episode reward: -0.2802,                 loss: nan
agent1:                 episode reward: 0.2802,                 loss: 0.1402
Episode: 2181/30000 (7.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.0629s / 12526.5137 s
agent0:                 episode reward: -0.1604,                 loss: nan
agent1:                 episode reward: 0.1604,                 loss: 0.1404
Episode: 2201/30000 (7.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.5926s / 12668.1064 s
agent0:                 episode reward: 0.4303,                 loss: nan
agent1:                 episode reward: -0.4303,                 loss: 0.1406
Episode: 2221/30000 (7.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.0710s / 12811.1774 s
agent0:                 episode reward: 0.4934,                 loss: nan
agent1:                 episode reward: -0.4934,                 loss: 0.1401
Episode: 2241/30000 (7.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.5073s / 12953.6847 s
agent0:                 episode reward: 0.0228,                 loss: nan
agent1:                 episode reward: -0.0228,                 loss: 0.1375
Episode: 2261/30000 (7.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.8524s / 13096.5370 s
agent0:                 episode reward: 0.0271,                 loss: nan
agent1:                 episode reward: -0.0271,                 loss: 0.1379
Episode: 2281/30000 (7.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.1058s / 13238.6428 s
agent0:                 episode reward: 0.0845,                 loss: nan
agent1:                 episode reward: -0.0845,                 loss: 0.1376
Episode: 2301/30000 (7.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6810s / 13379.3238 s
agent0:                 episode reward: -0.0700,                 loss: nan
agent1:                 episode reward: 0.0700,                 loss: 0.1380
Episode: 2321/30000 (7.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.3381s / 13520.6619 s
agent0:                 episode reward: 0.0017,                 loss: nan
agent1:                 episode reward: -0.0017,                 loss: 0.1372
Episode: 2341/30000 (7.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.5486s / 13664.2106 s
agent0:                 episode reward: 0.0857,                 loss: nan
agent1:                 episode reward: -0.0857,                 loss: 0.1387
Episode: 2361/30000 (7.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.2647s / 13805.4753 s
agent0:                 episode reward: 0.1433,                 loss: nan
agent1:                 episode reward: -0.1433,                 loss: 0.1380
Episode: 2381/30000 (7.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.2622s / 13945.7375 s
agent0:                 episode reward: 0.1089,                 loss: nan
agent1:                 episode reward: -0.1089,                 loss: 0.1377
Episode: 2401/30000 (8.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.4702s / 14089.2077 s
agent0:                 episode reward: 0.3015,                 loss: nan
agent1:                 episode reward: -0.3015,                 loss: 0.1391
Episode: 2421/30000 (8.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.4524s / 14230.6601 s
agent0:                 episode reward: 0.4189,                 loss: nan
agent1:                 episode reward: -0.4189,                 loss: 0.1362
Episode: 2441/30000 (8.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5031s / 14370.1632 s
agent0:                 episode reward: 0.0409,                 loss: nan
agent1:                 episode reward: -0.0409,                 loss: 0.1375
Episode: 2461/30000 (8.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.1106s / 14510.2737 s
agent0:                 episode reward: 0.1106,                 loss: nan
agent1:                 episode reward: -0.1106,                 loss: 0.1372
Episode: 2481/30000 (8.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.2369s / 14653.5107 s
agent0:                 episode reward: 0.0973,                 loss: nan
agent1:                 episode reward: -0.0973,                 loss: 0.1378
Episode: 2501/30000 (8.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.0784s / 14795.5890 s
agent0:                 episode reward: -0.3443,                 loss: nan
agent1:                 episode reward: 0.3443,                 loss: 0.1385
Episode: 2521/30000 (8.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.9674s / 14936.5564 s
agent0:                 episode reward: -0.1706,                 loss: nan
agent1:                 episode reward: 0.1706,                 loss: 0.1386
Episode: 2541/30000 (8.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.3995s / 15079.9559 s
agent0:                 episode reward: 0.0444,                 loss: nan
agent1:                 episode reward: -0.0444,                 loss: 0.1403
Episode: 2561/30000 (8.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.3036s / 15221.2596 s
agent0:                 episode reward: -0.2667,                 loss: nan
agent1:                 episode reward: 0.2667,                 loss: 0.1379
Episode: 2581/30000 (8.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.6082s / 15364.8678 s
agent0:                 episode reward: -0.2354,                 loss: nan
agent1:                 episode reward: 0.2354,                 loss: 0.1373
Episode: 2601/30000 (8.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.2557s / 15507.1235 s
agent0:                 episode reward: -0.0505,                 loss: nan
agent1:                 episode reward: 0.0505,                 loss: 0.1380
Episode: 2621/30000 (8.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.4351s / 15648.5586 s
agent0:                 episode reward: 0.0379,                 loss: nan
agent1:                 episode reward: -0.0379,                 loss: 0.1368
Episode: 2641/30000 (8.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.5243s / 15792.0830 s
agent0:                 episode reward: 0.2191,                 loss: nan
agent1:                 episode reward: -0.2191,                 loss: 0.1359
Episode: 2661/30000 (8.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.6527s / 15933.7357 s
agent0:                 episode reward: 0.5106,                 loss: nan
agent1:                 episode reward: -0.5106,                 loss: 0.1363
Episode: 2681/30000 (8.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.9753s / 16076.7110 s
agent0:                 episode reward: -0.0717,                 loss: nan
agent1:                 episode reward: 0.0717,                 loss: 0.1356
Episode: 2701/30000 (9.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.7262s / 16221.4372 s
agent0:                 episode reward: 0.2066,                 loss: nan
agent1:                 episode reward: -0.2066,                 loss: 0.1361
Episode: 2721/30000 (9.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6531s / 16362.0903 s
agent0:                 episode reward: -0.0309,                 loss: nan
agent1:                 episode reward: 0.0309,                 loss: 0.1352
Episode: 2741/30000 (9.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9267s / 16502.0170 s
agent0:                 episode reward: -0.3200,                 loss: nan
agent1:                 episode reward: 0.3200,                 loss: 0.1353
Episode: 2761/30000 (9.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.1223s / 16643.1394 s
agent0:                 episode reward: 0.0142,                 loss: nan
agent1:                 episode reward: -0.0142,                 loss: 0.1351
Episode: 2781/30000 (9.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6160s / 16781.7554 s
agent0:                 episode reward: 0.1039,                 loss: nan
agent1:                 episode reward: -0.1039,                 loss: 0.1365
Episode: 2801/30000 (9.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.4657s / 16925.2210 s
agent0:                 episode reward: -0.1902,                 loss: nan
agent1:                 episode reward: 0.1902,                 loss: 0.1369
Episode: 2821/30000 (9.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6300s / 17063.8511 s
agent0:                 episode reward: -0.0978,                 loss: nan
agent1:                 episode reward: 0.0978,                 loss: 0.1361
Episode: 2841/30000 (9.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9418s / 17203.7929 s
agent0:                 episode reward: -0.3800,                 loss: nan
agent1:                 episode reward: 0.3800,                 loss: 0.1347
Episode: 2861/30000 (9.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.5194s / 17346.3123 s
agent0:                 episode reward: 0.1414,                 loss: nan
agent1:                 episode reward: -0.1414,                 loss: 0.1334
Episode: 2881/30000 (9.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.8178s / 17488.1301 s
agent0:                 episode reward: -0.3219,                 loss: nan
agent1:                 episode reward: 0.3219,                 loss: 0.1366
Episode: 2901/30000 (9.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.1799s / 17627.3101 s
agent0:                 episode reward: 0.3441,                 loss: nan
agent1:                 episode reward: -0.3441,                 loss: 0.1364
Episode: 2921/30000 (9.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6679s / 17767.9780 s
agent0:                 episode reward: 0.0062,                 loss: nan
agent1:                 episode reward: -0.0062,                 loss: 0.1360
Episode: 2941/30000 (9.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.1525s / 17908.1304 s
agent0:                 episode reward: -0.6627,                 loss: nan
agent1:                 episode reward: 0.6627,                 loss: 0.1362
Episode: 2961/30000 (9.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.1900s / 18049.3204 s
agent0:                 episode reward: -0.3510,                 loss: nan
agent1:                 episode reward: 0.3510,                 loss: 0.1365
Episode: 2981/30000 (9.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.3411s / 18189.6615 s
agent0:                 episode reward: -0.2425,                 loss: nan
agent1:                 episode reward: 0.2425,                 loss: 0.1350
Episode: 3001/30000 (10.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.9492s / 18331.6107 s
agent0:                 episode reward: -0.2348,                 loss: nan
agent1:                 episode reward: 0.2348,                 loss: 0.1361
Episode: 3021/30000 (10.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.7892s / 18475.3999 s
agent0:                 episode reward: 0.1662,                 loss: nan
agent1:                 episode reward: -0.1662,                 loss: 0.1362
Episode: 3041/30000 (10.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9589s / 18613.3588 s
agent0:                 episode reward: -0.2362,                 loss: nan
agent1:                 episode reward: 0.2362,                 loss: 0.1359
Episode: 3061/30000 (10.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.3725s / 18753.7312 s
agent0:                 episode reward: -0.4028,                 loss: nan
agent1:                 episode reward: 0.4028,                 loss: 0.1361
Episode: 3081/30000 (10.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.5211s / 18896.2524 s
agent0:                 episode reward: -0.2768,                 loss: nan
agent1:                 episode reward: 0.2768,                 loss: 0.1356
Episode: 3101/30000 (10.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6775s / 19034.9299 s
agent0:                 episode reward: -0.2502,                 loss: nan
agent1:                 episode reward: 0.2502,                 loss: 0.1351
Episode: 3121/30000 (10.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.4914s / 19176.4213 s
agent0:                 episode reward: 0.0505,                 loss: nan
agent1:                 episode reward: -0.0505,                 loss: 0.1358
Episode: 3141/30000 (10.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.5154s / 19319.9367 s
agent0:                 episode reward: -0.1823,                 loss: nan
agent1:                 episode reward: 0.1823,                 loss: 0.1344
Episode: 3161/30000 (10.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.5702s / 19463.5069 s
agent0:                 episode reward: -0.2941,                 loss: nan
agent1:                 episode reward: 0.2941,                 loss: 0.1357
Episode: 3181/30000 (10.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.2730s / 19606.7799 s
agent0:                 episode reward: -0.2990,                 loss: nan
agent1:                 episode reward: 0.2990,                 loss: 0.1358
Episode: 3201/30000 (10.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.4252s / 19749.2051 s
agent0:                 episode reward: -0.2018,                 loss: nan
agent1:                 episode reward: 0.2018,                 loss: 0.1352
Episode: 3221/30000 (10.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.2142s / 19893.4193 s
agent0:                 episode reward: -0.4931,                 loss: nan
agent1:                 episode reward: 0.4931,                 loss: 0.1353
Episode: 3241/30000 (10.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.7672s / 20035.1865 s
agent0:                 episode reward: 0.1032,                 loss: nan
agent1:                 episode reward: -0.1032,                 loss: 0.1381
Episode: 3261/30000 (10.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.0347s / 20174.2212 s
agent0:                 episode reward: -0.1632,                 loss: nan
agent1:                 episode reward: 0.1632,                 loss: 0.1363
Episode: 3281/30000 (10.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.9658s / 20317.1869 s
agent0:                 episode reward: -0.4094,                 loss: nan
agent1:                 episode reward: 0.4094,                 loss: 0.1383
Episode: 3301/30000 (11.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.6427s / 20461.8296 s
agent0:                 episode reward: -0.0599,                 loss: nan
agent1:                 episode reward: 0.0599,                 loss: 0.1363
Episode: 3321/30000 (11.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.9061s / 20605.7357 s
agent0:                 episode reward: 0.0198,                 loss: nan
agent1:                 episode reward: -0.0198,                 loss: 0.1367
Episode: 3341/30000 (11.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.6038s / 20747.3395 s
agent0:                 episode reward: 0.1172,                 loss: nan
agent1:                 episode reward: -0.1172,                 loss: 0.1362
Episode: 3361/30000 (11.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0525s / 20882.3921 s
agent0:                 episode reward: -0.1146,                 loss: nan
agent1:                 episode reward: 0.1146,                 loss: 0.1379
Episode: 3381/30000 (11.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.0337s / 21013.4258 s
agent0:                 episode reward: -0.0102,                 loss: nan
agent1:                 episode reward: 0.0102,                 loss: 0.1368
Episode: 3401/30000 (11.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9514s / 21147.3772 s
agent0:                 episode reward: -0.2831,                 loss: nan
agent1:                 episode reward: 0.2831,                 loss: 0.1364
Episode: 3421/30000 (11.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.6038s / 21285.9810 s
agent0:                 episode reward: 0.2261,                 loss: nan
agent1:                 episode reward: -0.2261,                 loss: 0.1366
Episode: 3441/30000 (11.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.2776s / 21429.2586 s
agent0:                 episode reward: -0.2680,                 loss: nan
agent1:                 episode reward: 0.2680,                 loss: 0.1370
Episode: 3461/30000 (11.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 148.3407s / 21577.5993 s
agent0:                 episode reward: -0.2293,                 loss: nan
agent1:                 episode reward: 0.2293,                 loss: 0.1373
Episode: 3481/30000 (11.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.1139s / 21719.7132 s
agent0:                 episode reward: -0.1335,                 loss: nan
agent1:                 episode reward: 0.1335,                 loss: 0.1379
Episode: 3501/30000 (11.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.9971s / 21861.7103 s
agent0:                 episode reward: -0.1226,                 loss: nan
agent1:                 episode reward: 0.1226,                 loss: 0.1362
Episode: 3521/30000 (11.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.1468s / 22004.8571 s
agent0:                 episode reward: -0.6149,                 loss: nan
agent1:                 episode reward: 0.6149,                 loss: 0.1359
Episode: 3541/30000 (11.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.0719s / 22146.9290 s
agent0:                 episode reward: 0.2816,                 loss: nan
agent1:                 episode reward: -0.2816,                 loss: 0.1368
Episode: 3561/30000 (11.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.9152s / 22288.8442 s
agent0:                 episode reward: -0.4885,                 loss: nan
agent1:                 episode reward: 0.4885,                 loss: 0.1352
Episode: 3581/30000 (11.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 145.8459s / 22434.6900 s
agent0:                 episode reward: -0.4045,                 loss: nan
agent1:                 episode reward: 0.4045,                 loss: 0.1356
Episode: 3601/30000 (12.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.9808s / 22577.6709 s
agent0:                 episode reward: -0.1645,                 loss: nan
agent1:                 episode reward: 0.1645,                 loss: 0.1347
Episode: 3621/30000 (12.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 145.7753s / 22723.4461 s
agent0:                 episode reward: 0.0544,                 loss: nan
agent1:                 episode reward: -0.0544,                 loss: 0.1373
Episode: 3641/30000 (12.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.0863s / 22866.5324 s
agent0:                 episode reward: -0.2673,                 loss: nan
agent1:                 episode reward: 0.2673,                 loss: 0.1345
Episode: 3661/30000 (12.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.6700s / 23011.2024 s
agent0:                 episode reward: 0.0358,                 loss: nan
agent1:                 episode reward: -0.0358,                 loss: 0.1341
Episode: 3681/30000 (12.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.9902s / 23155.1926 s
agent0:                 episode reward: 0.1373,                 loss: nan
agent1:                 episode reward: -0.1373,                 loss: 0.1346
Episode: 3701/30000 (12.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.8438s / 23298.0364 s
agent0:                 episode reward: -0.1408,                 loss: nan
agent1:                 episode reward: 0.1408,                 loss: 0.1351
Episode: 3721/30000 (12.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.7934s / 23438.8298 s
agent0:                 episode reward: 0.1790,                 loss: nan
agent1:                 episode reward: -0.1790,                 loss: 0.1348
Episode: 3741/30000 (12.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 141.9166s / 23580.7464 s
agent0:                 episode reward: 0.1376,                 loss: nan
agent1:                 episode reward: -0.1376,                 loss: 0.1349
Episode: 3761/30000 (12.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.1656s / 23724.9120 s
agent0:                 episode reward: -0.4377,                 loss: nan
agent1:                 episode reward: 0.4377,                 loss: 0.1362
Episode: 3781/30000 (12.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.9910s / 23867.9030 s
agent0:                 episode reward: -0.3663,                 loss: nan
agent1:                 episode reward: 0.3663,                 loss: 0.1342
Episode: 3801/30000 (12.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.4444s / 24010.3474 s
agent0:                 episode reward: -0.0210,                 loss: nan
agent1:                 episode reward: 0.0210,                 loss: 0.1340
Episode: 3821/30000 (12.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.1824s / 24151.5298 s
agent0:                 episode reward: -0.3745,                 loss: nan
agent1:                 episode reward: 0.3745,                 loss: 0.1340
Episode: 3841/30000 (12.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 142.5808s / 24294.1107 s
agent0:                 episode reward: -0.0669,                 loss: nan
agent1:                 episode reward: 0.0669,                 loss: 0.1342
Episode: 3861/30000 (12.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.9098s / 24438.0205 s
agent0:                 episode reward: -0.0501,                 loss: nan
agent1:                 episode reward: 0.0501,                 loss: 0.1347
Episode: 3881/30000 (12.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.9717s / 24579.9922 s
agent0:                 episode reward: -0.1314,                 loss: nan
agent1:                 episode reward: 0.1314,                 loss: 0.1336
Episode: 3901/30000 (13.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.4608s / 24723.4530 s
agent0:                 episode reward: -0.2168,                 loss: nan
agent1:                 episode reward: 0.2168,                 loss: 0.1324
Episode: 3921/30000 (13.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.3168s / 24866.7698 s
agent0:                 episode reward: -0.2854,                 loss: nan
agent1:                 episode reward: 0.2854,                 loss: 0.1339
Episode: 3941/30000 (13.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.4273s / 25011.1971 s
agent0:                 episode reward: 0.0797,                 loss: nan
agent1:                 episode reward: -0.0797,                 loss: 0.1332
Episode: 3961/30000 (13.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.8571s / 25153.0543 s
agent0:                 episode reward: -0.2855,                 loss: nan
agent1:                 episode reward: 0.2855,                 loss: 0.1335
Episode: 3981/30000 (13.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.1845s / 25296.2387 s
agent0:                 episode reward: 0.0977,                 loss: nan
agent1:                 episode reward: -0.0977,                 loss: 0.1331
Episode: 4001/30000 (13.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 142.7415s / 25438.9802 s
agent0:                 episode reward: 0.1483,                 loss: nan
agent1:                 episode reward: -0.1483,                 loss: 0.1328
Episode: 4021/30000 (13.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.8947s / 25583.8748 s
agent0:                 episode reward: -0.3924,                 loss: nan
agent1:                 episode reward: 0.3924,                 loss: 0.1318
Episode: 4041/30000 (13.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 142.2740s / 25726.1488 s
agent0:                 episode reward: -0.6627,                 loss: nan
agent1:                 episode reward: 0.6627,                 loss: 0.1325
Episode: 4061/30000 (13.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 147.0759s / 25873.2247 s
agent0:                 episode reward: 0.1853,                 loss: nan
agent1:                 episode reward: -0.1853,                 loss: 0.1320
Episode: 4081/30000 (13.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.2869s / 26017.5115 s
agent0:                 episode reward: -0.4577,                 loss: nan
agent1:                 episode reward: 0.4577,                 loss: 0.1307
Episode: 4101/30000 (13.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 144.0097s / 26161.5213 s
agent0:                 episode reward: -0.2584,                 loss: nan
agent1:                 episode reward: 0.2584,                 loss: 0.1332
Episode: 4121/30000 (13.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 141.4829s / 26303.0042 s
agent0:                 episode reward: 0.2031,                 loss: nan
agent1:                 episode reward: -0.2031,                 loss: 0.1317
Episode: 4141/30000 (13.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 143.8246s / 26446.8288 s
agent0:                 episode reward: -0.3371,                 loss: nan
agent1:                 episode reward: 0.3371,                 loss: 0.1331
Episode: 4161/30000 (13.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.2651s / 26590.0939 s
agent0:                 episode reward: -0.0278,                 loss: nan
agent1:                 episode reward: 0.0278,                 loss: 0.1330
Episode: 4181/30000 (13.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 143.2518s / 26733.3457 s
agent0:                 episode reward: -0.2195,                 loss: nan
agent1:                 episode reward: 0.2195,                 loss: 0.1323
Episode: 4201/30000 (14.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.1645s / 26877.5102 s
agent0:                 episode reward: -0.0045,                 loss: nan
agent1:                 episode reward: 0.0045,                 loss: 0.1329
Episode: 4221/30000 (14.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 143.8141s / 27021.3243 s
agent0:                 episode reward: -0.1589,                 loss: nan
agent1:                 episode reward: 0.1589,                 loss: 0.1334
Episode: 4241/30000 (14.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 144.3307s / 27165.6550 s
agent0:                 episode reward: -0.1685,                 loss: nan
agent1:                 episode reward: 0.1685,                 loss: 0.1358
Episode: 4261/30000 (14.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 144.9234s / 27310.5784 s
agent0:                 episode reward: -0.4426,                 loss: nan
agent1:                 episode reward: 0.4426,                 loss: 0.1365
Episode: 4281/30000 (14.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5156s / 27446.0941 s
agent0:                 episode reward: -0.1394,                 loss: nan
agent1:                 episode reward: 0.1394,                 loss: 0.1342
Episode: 4301/30000 (14.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4861s / 27580.5802 s
agent0:                 episode reward: -0.1062,                 loss: nan
agent1:                 episode reward: 0.1062,                 loss: 0.1345
Episode: 4321/30000 (14.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2103s / 27716.7905 s
agent0:                 episode reward: 0.0300,                 loss: nan
agent1:                 episode reward: -0.0300,                 loss: 0.1364
Episode: 4341/30000 (14.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4984s / 27851.2888 s
agent0:                 episode reward: 0.3484,                 loss: nan
agent1:                 episode reward: -0.3484,                 loss: 0.1366
Episode: 4361/30000 (14.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0963s / 27988.3851 s
agent0:                 episode reward: 0.0681,                 loss: nan
agent1:                 episode reward: -0.0681,                 loss: 0.1351
Episode: 4381/30000 (14.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.2080s / 28120.5931 s
agent0:                 episode reward: -0.1386,                 loss: nan
agent1:                 episode reward: 0.1386,                 loss: 0.1366
Episode: 4401/30000 (14.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7671s / 28254.3602 s
agent0:                 episode reward: -0.2487,                 loss: nan
agent1:                 episode reward: 0.2487,                 loss: 0.1380
Episode: 4421/30000 (14.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3892s / 28388.7494 s
agent0:                 episode reward: 0.1214,                 loss: nan
agent1:                 episode reward: -0.1214,                 loss: 0.1373
Episode: 4441/30000 (14.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8302s / 28526.5797 s
agent0:                 episode reward: -0.3697,                 loss: nan
agent1:                 episode reward: 0.3697,                 loss: 0.1369
Episode: 4461/30000 (14.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2071s / 28662.7868 s
agent0:                 episode reward: -0.0241,                 loss: nan
agent1:                 episode reward: 0.0241,                 loss: 0.1368
Episode: 4481/30000 (14.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9148s / 28795.7016 s
agent0:                 episode reward: -0.3111,                 loss: nan
agent1:                 episode reward: 0.3111,                 loss: 0.1371
Episode: 4501/30000 (15.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1260s / 28930.8276 s
agent0:                 episode reward: 0.1807,                 loss: nan
agent1:                 episode reward: -0.1807,                 loss: 0.1369
Episode: 4521/30000 (15.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9233s / 29063.7509 s
agent0:                 episode reward: 0.0982,                 loss: nan
agent1:                 episode reward: -0.0982,                 loss: 0.1356
Episode: 4541/30000 (15.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4110s / 29197.1619 s
agent0:                 episode reward: -0.2210,                 loss: nan
agent1:                 episode reward: 0.2210,                 loss: 0.1367
Episode: 4561/30000 (15.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3078s / 29335.4698 s
agent0:                 episode reward: -0.2791,                 loss: nan
agent1:                 episode reward: 0.2791,                 loss: 0.1354
Episode: 4581/30000 (15.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8481s / 29473.3178 s
agent0:                 episode reward: 0.1571,                 loss: nan
agent1:                 episode reward: -0.1571,                 loss: 0.1360
Episode: 4601/30000 (15.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3387s / 29606.6566 s
agent0:                 episode reward: -0.4229,                 loss: nan
agent1:                 episode reward: 0.4229,                 loss: 0.1347
Episode: 4621/30000 (15.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7030s / 29739.3595 s
agent0:                 episode reward: 0.3197,                 loss: nan
agent1:                 episode reward: -0.3197,                 loss: 0.1372
Episode: 4641/30000 (15.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6131s / 29874.9726 s
agent0:                 episode reward: -0.2589,                 loss: nan
agent1:                 episode reward: 0.2589,                 loss: 0.1372
Episode: 4661/30000 (15.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4420s / 30008.4146 s
agent0:                 episode reward: -0.3853,                 loss: nan
agent1:                 episode reward: 0.3853,                 loss: 0.1356
Episode: 4681/30000 (15.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9547s / 30146.3694 s
agent0:                 episode reward: -0.3997,                 loss: nan
agent1:                 episode reward: 0.3997,                 loss: 0.1365
Episode: 4701/30000 (15.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9761s / 30278.3454 s
agent0:                 episode reward: -0.0699,                 loss: nan
agent1:                 episode reward: 0.0699,                 loss: 0.1348
Episode: 4721/30000 (15.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0999s / 30415.4453 s
agent0:                 episode reward: -0.6364,                 loss: nan
agent1:                 episode reward: 0.6364,                 loss: 0.1347
Episode: 4741/30000 (15.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6531s / 30551.0984 s
agent0:                 episode reward: -0.3025,                 loss: nan
agent1:                 episode reward: 0.3025,                 loss: 0.1351
Episode: 4761/30000 (15.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2042s / 30686.3026 s
agent0:                 episode reward: 0.0470,                 loss: nan
agent1:                 episode reward: -0.0470,                 loss: 0.1348
Episode: 4781/30000 (15.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2709s / 30821.5735 s
agent0:                 episode reward: -0.0810,                 loss: nan
agent1:                 episode reward: 0.0810,                 loss: 0.1357
Episode: 4801/30000 (16.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3598s / 30955.9333 s
agent0:                 episode reward: -0.3326,                 loss: nan
agent1:                 episode reward: 0.3326,                 loss: 0.1356
Episode: 4821/30000 (16.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0381s / 31091.9713 s
agent0:                 episode reward: 0.0164,                 loss: nan
agent1:                 episode reward: -0.0164,                 loss: 0.1362
Episode: 4841/30000 (16.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4848s / 31228.4561 s
agent0:                 episode reward: 0.1028,                 loss: nan
agent1:                 episode reward: -0.1028,                 loss: 0.1356
Episode: 4861/30000 (16.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9082s / 31366.3643 s
agent0:                 episode reward: -0.6562,                 loss: nan
agent1:                 episode reward: 0.6562,                 loss: 0.1362
Episode: 4881/30000 (16.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1784s / 31501.5428 s
agent0:                 episode reward: -0.6237,                 loss: nan
agent1:                 episode reward: 0.6237,                 loss: 0.1373
Episode: 4901/30000 (16.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4121s / 31638.9549 s
agent0:                 episode reward: -0.2485,                 loss: nan
agent1:                 episode reward: 0.2485,                 loss: 0.1348
Episode: 4921/30000 (16.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6738s / 31772.6286 s
agent0:                 episode reward: -0.0926,                 loss: nan
agent1:                 episode reward: 0.0926,                 loss: 0.1361
Episode: 4941/30000 (16.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2640s / 31906.8926 s
agent0:                 episode reward: -0.6133,                 loss: nan
agent1:                 episode reward: 0.6133,                 loss: 0.1364
Episode: 4961/30000 (16.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 130.0564s / 32036.9490 s
agent0:                 episode reward: -0.2644,                 loss: nan
agent1:                 episode reward: 0.2644,                 loss: 0.1355
Episode: 4981/30000 (16.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0472s / 32171.9963 s
agent0:                 episode reward: -0.3615,                 loss: nan
agent1:                 episode reward: 0.3615,                 loss: 0.1348
Episode: 5001/30000 (16.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6944s / 32306.6907 s
agent0:                 episode reward: 0.0176,                 loss: nan
agent1:                 episode reward: -0.0176,                 loss: 0.1343
Episode: 5021/30000 (16.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3808s / 32441.0715 s
agent0:                 episode reward: -0.6758,                 loss: nan
agent1:                 episode reward: 0.6758,                 loss: 0.1340
Episode: 5041/30000 (16.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6079s / 32576.6794 s
agent0:                 episode reward: -0.1279,                 loss: nan
agent1:                 episode reward: 0.1279,                 loss: 0.1340
Episode: 5061/30000 (16.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9369s / 32712.6163 s
agent0:                 episode reward: -0.1089,                 loss: nan
agent1:                 episode reward: 0.1089,                 loss: 0.1358
Episode: 5081/30000 (16.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 130.1940s / 32842.8103 s
agent0:                 episode reward: -0.1734,                 loss: nan
agent1:                 episode reward: 0.1734,                 loss: 0.1359
Episode: 5101/30000 (17.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9461s / 32974.7563 s
agent0:                 episode reward: -0.3864,                 loss: nan
agent1:                 episode reward: 0.3864,                 loss: 0.1352
Episode: 5121/30000 (17.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6845s / 33108.4408 s
agent0:                 episode reward: -0.0373,                 loss: nan
agent1:                 episode reward: 0.0373,                 loss: 0.1353
Episode: 5141/30000 (17.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6745s / 33243.1153 s
agent0:                 episode reward: -0.2690,                 loss: nan
agent1:                 episode reward: 0.2690,                 loss: 0.1352
Episode: 5161/30000 (17.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6675s / 33375.7828 s
agent0:                 episode reward: -0.4051,                 loss: nan
agent1:                 episode reward: 0.4051,                 loss: 0.1342
Episode: 5181/30000 (17.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0768s / 33507.8597 s
agent0:                 episode reward: -0.3631,                 loss: nan
agent1:                 episode reward: 0.3631,                 loss: 0.1352
Episode: 5201/30000 (17.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8602s / 33641.7199 s
agent0:                 episode reward: -0.3221,                 loss: nan
agent1:                 episode reward: 0.3221,                 loss: 0.1362
Episode: 5221/30000 (17.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5871s / 33775.3070 s
agent0:                 episode reward: -0.1680,                 loss: nan
agent1:                 episode reward: 0.1680,                 loss: 0.1376
Episode: 5241/30000 (17.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4404s / 33909.7474 s
agent0:                 episode reward: 0.0176,                 loss: nan
agent1:                 episode reward: -0.0176,                 loss: 0.1373
Episode: 5261/30000 (17.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2998s / 34046.0473 s
agent0:                 episode reward: -0.4263,                 loss: nan
agent1:                 episode reward: 0.4263,                 loss: 0.1382
Episode: 5281/30000 (17.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7371s / 34183.7844 s
agent0:                 episode reward: -0.3796,                 loss: nan
agent1:                 episode reward: 0.3796,                 loss: 0.1373
Episode: 5301/30000 (17.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4384s / 34319.2228 s
agent0:                 episode reward: -0.2747,                 loss: nan
agent1:                 episode reward: 0.2747,                 loss: 0.1370
Episode: 5321/30000 (17.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3301s / 34452.5529 s
agent0:                 episode reward: -0.7951,                 loss: nan
agent1:                 episode reward: 0.7951,                 loss: 0.1379
Episode: 5341/30000 (17.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5836s / 34587.1365 s
agent0:                 episode reward: 0.0079,                 loss: nan
agent1:                 episode reward: -0.0079,                 loss: 0.1377
Episode: 5361/30000 (17.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3320s / 34722.4686 s
agent0:                 episode reward: 0.3730,                 loss: nan
agent1:                 episode reward: -0.3730,                 loss: 0.1372
Episode: 5381/30000 (17.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2119s / 34855.6805 s
agent0:                 episode reward: -0.3812,                 loss: nan
agent1:                 episode reward: 0.3812,                 loss: 0.1369
Episode: 5401/30000 (18.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5903s / 34991.2708 s
agent0:                 episode reward: -0.2762,                 loss: nan
agent1:                 episode reward: 0.2762,                 loss: 0.1360
Episode: 5421/30000 (18.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8172s / 35127.0880 s
agent0:                 episode reward: -0.3137,                 loss: nan
agent1:                 episode reward: 0.3137,                 loss: 0.1370
Episode: 5441/30000 (18.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6255s / 35262.7135 s
agent0:                 episode reward: -0.2864,                 loss: nan
agent1:                 episode reward: 0.2864,                 loss: 0.1366
Episode: 5461/30000 (18.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1637s / 35398.8772 s
agent0:                 episode reward: -0.3323,                 loss: nan
agent1:                 episode reward: 0.3323,                 loss: 0.1375
Episode: 5481/30000 (18.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1735s / 35534.0507 s
agent0:                 episode reward: -0.1137,                 loss: nan
agent1:                 episode reward: 0.1137,                 loss: 0.1367
Episode: 5501/30000 (18.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1390s / 35668.1897 s
agent0:                 episode reward: 0.0812,                 loss: nan
agent1:                 episode reward: -0.0812,                 loss: 0.1356
Episode: 5521/30000 (18.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.8400s / 35800.0297 s
agent0:                 episode reward: -0.2409,                 loss: nan
agent1:                 episode reward: 0.2409,                 loss: 0.1374
Episode: 5541/30000 (18.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3125s / 35932.3422 s
agent0:                 episode reward: -0.0455,                 loss: nan
agent1:                 episode reward: 0.0455,                 loss: 0.1372
Episode: 5561/30000 (18.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6003s / 36064.9425 s
agent0:                 episode reward: 0.3051,                 loss: nan
agent1:                 episode reward: -0.3051,                 loss: 0.1394
Episode: 5581/30000 (18.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.4537s / 36196.3962 s
agent0:                 episode reward: 0.3992,                 loss: nan
agent1:                 episode reward: -0.3992,                 loss: 0.1382
Episode: 5601/30000 (18.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6411s / 36332.0373 s
agent0:                 episode reward: -0.2932,                 loss: nan
agent1:                 episode reward: 0.2932,                 loss: 0.1388
Episode: 5621/30000 (18.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7579s / 36465.7952 s
agent0:                 episode reward: -0.3383,                 loss: nan
agent1:                 episode reward: 0.3383,                 loss: 0.1384
Episode: 5641/30000 (18.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4810s / 36602.2762 s
agent0:                 episode reward: -0.5391,                 loss: nan
agent1:                 episode reward: 0.5391,                 loss: 0.1377
Episode: 5661/30000 (18.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6973s / 36736.9735 s
agent0:                 episode reward: -0.5832,                 loss: nan
agent1:                 episode reward: 0.5832,                 loss: 0.1366
Episode: 5681/30000 (18.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3419s / 36872.3154 s
agent0:                 episode reward: -0.1242,                 loss: nan
agent1:                 episode reward: 0.1242,                 loss: 0.1385
Episode: 5701/30000 (19.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3255s / 37008.6409 s
agent0:                 episode reward: -0.2253,                 loss: nan
agent1:                 episode reward: 0.2253,                 loss: 0.1385
Episode: 5721/30000 (19.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8408s / 37143.4818 s
agent0:                 episode reward: -0.1693,                 loss: nan
agent1:                 episode reward: 0.1693,                 loss: 0.1386
Episode: 5741/30000 (19.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5803s / 37277.0620 s
agent0:                 episode reward: -0.2318,                 loss: nan
agent1:                 episode reward: 0.2318,                 loss: 0.1379
Episode: 5761/30000 (19.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7263s / 37413.7883 s
agent0:                 episode reward: 0.1332,                 loss: nan
agent1:                 episode reward: -0.1332,                 loss: 0.1398
Episode: 5781/30000 (19.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1963s / 37549.9846 s
agent0:                 episode reward: -0.3806,                 loss: nan
agent1:                 episode reward: 0.3806,                 loss: 0.1382
Episode: 5801/30000 (19.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9804s / 37684.9651 s
agent0:                 episode reward: -0.5231,                 loss: nan
agent1:                 episode reward: 0.5231,                 loss: 0.1388
Episode: 5821/30000 (19.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5764s / 37820.5415 s
agent0:                 episode reward: -0.8081,                 loss: nan
agent1:                 episode reward: 0.8081,                 loss: 0.1381
Episode: 5841/30000 (19.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4918s / 37957.0333 s
agent0:                 episode reward: -0.3048,                 loss: nan
agent1:                 episode reward: 0.3048,                 loss: 0.1387
Episode: 5861/30000 (19.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8952s / 38093.9285 s
agent0:                 episode reward: -0.3871,                 loss: nan
agent1:                 episode reward: 0.3871,                 loss: 0.1371
Episode: 5881/30000 (19.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6401s / 38230.5686 s
agent0:                 episode reward: -0.4321,                 loss: nan
agent1:                 episode reward: 0.4321,                 loss: 0.1379
Episode: 5901/30000 (19.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7632s / 38367.3318 s
agent0:                 episode reward: -0.1686,                 loss: nan
agent1:                 episode reward: 0.1686,                 loss: 0.1382
Episode: 5921/30000 (19.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9063s / 38502.2381 s
agent0:                 episode reward: -0.5942,                 loss: nan
agent1:                 episode reward: 0.5942,                 loss: 0.1355
Episode: 5941/30000 (19.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6741s / 38639.9122 s
agent0:                 episode reward: -0.4728,                 loss: nan
agent1:                 episode reward: 0.4728,                 loss: 0.1364
Episode: 5961/30000 (19.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2635s / 38776.1756 s
agent0:                 episode reward: -0.1461,                 loss: nan
agent1:                 episode reward: 0.1461,                 loss: 0.1367
Episode: 5981/30000 (19.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5211s / 38909.6967 s
agent0:                 episode reward: -0.2499,                 loss: nan
agent1:                 episode reward: 0.2499,                 loss: 0.1364
Episode: 6001/30000 (20.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1105s / 39044.8072 s
agent0:                 episode reward: -0.0922,                 loss: nan
agent1:                 episode reward: 0.0922,                 loss: 0.1365
Episode: 6021/30000 (20.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8211s / 39182.6283 s
agent0:                 episode reward: -0.0397,                 loss: nan
agent1:                 episode reward: 0.0397,                 loss: 0.1363
Episode: 6041/30000 (20.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0576s / 39318.6859 s
agent0:                 episode reward: -0.3104,                 loss: nan
agent1:                 episode reward: 0.3104,                 loss: 0.1364
Episode: 6061/30000 (20.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6181s / 39453.3040 s
agent0:                 episode reward: -0.2589,                 loss: nan
agent1:                 episode reward: 0.2589,                 loss: 0.1370
Episode: 6081/30000 (20.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4801s / 39587.7841 s
agent0:                 episode reward: -0.2861,                 loss: nan
agent1:                 episode reward: 0.2861,                 loss: 0.1370
Episode: 6101/30000 (20.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5056s / 39721.2897 s
agent0:                 episode reward: -0.0443,                 loss: nan
agent1:                 episode reward: 0.0443,                 loss: 0.1359
Episode: 6121/30000 (20.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0617s / 39858.3513 s
agent0:                 episode reward: -0.5695,                 loss: nan
agent1:                 episode reward: 0.5695,                 loss: 0.1363
Episode: 6141/30000 (20.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0688s / 39993.4202 s
agent0:                 episode reward: -0.0446,                 loss: nan
agent1:                 episode reward: 0.0446,                 loss: 0.1372
Episode: 6161/30000 (20.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5204s / 40126.9406 s
agent0:                 episode reward: -0.0668,                 loss: nan
agent1:                 episode reward: 0.0668,                 loss: 0.1367
Episode: 6181/30000 (20.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8490s / 40264.7896 s
agent0:                 episode reward: -0.0222,                 loss: nan
agent1:                 episode reward: 0.0222,                 loss: 0.1359
Episode: 6201/30000 (20.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1993s / 40397.9889 s
agent0:                 episode reward: -0.1061,                 loss: nan
agent1:                 episode reward: 0.1061,                 loss: 0.1365
Episode: 6221/30000 (20.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8451s / 40532.8340 s
agent0:                 episode reward: -0.6862,                 loss: nan
agent1:                 episode reward: 0.6862,                 loss: 0.1386
Episode: 6241/30000 (20.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2932s / 40669.1272 s
agent0:                 episode reward: -0.1355,                 loss: nan
agent1:                 episode reward: 0.1355,                 loss: 0.1372
Episode: 6261/30000 (20.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7728s / 40806.9000 s
agent0:                 episode reward: -0.2481,                 loss: nan
agent1:                 episode reward: 0.2481,                 loss: 0.1373
Episode: 6281/30000 (20.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 138.7367s / 40945.6367 s
agent0:                 episode reward: -0.0349,                 loss: nan
agent1:                 episode reward: 0.0349,                 loss: 0.1373
Episode: 6301/30000 (21.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3590s / 41077.9956 s
agent0:                 episode reward: -0.1795,                 loss: nan
agent1:                 episode reward: 0.1795,                 loss: 0.1371
Episode: 6321/30000 (21.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0327s / 41214.0283 s
agent0:                 episode reward: -0.2539,                 loss: nan
agent1:                 episode reward: 0.2539,                 loss: 0.1377
Episode: 6341/30000 (21.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8762s / 41348.9044 s
agent0:                 episode reward: 0.0042,                 loss: nan
agent1:                 episode reward: -0.0042,                 loss: 0.1374
Episode: 6361/30000 (21.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8126s / 41484.7170 s
agent0:                 episode reward: -0.4344,                 loss: nan
agent1:                 episode reward: 0.4344,                 loss: 0.1377
Episode: 6381/30000 (21.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0034s / 41621.7204 s
agent0:                 episode reward: -0.3360,                 loss: nan
agent1:                 episode reward: 0.3360,                 loss: 0.1381
Episode: 6401/30000 (21.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9425s / 41756.6629 s
agent0:                 episode reward: -0.2750,                 loss: nan
agent1:                 episode reward: 0.2750,                 loss: 0.1369
Episode: 6421/30000 (21.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7723s / 41891.4352 s
agent0:                 episode reward: -0.2772,                 loss: nan
agent1:                 episode reward: 0.2772,                 loss: 0.1377
Episode: 6441/30000 (21.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9066s / 42026.3418 s
agent0:                 episode reward: -0.2903,                 loss: nan
agent1:                 episode reward: 0.2903,                 loss: 0.1354
Episode: 6461/30000 (21.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8302s / 42159.1720 s
agent0:                 episode reward: -0.2944,                 loss: nan
agent1:                 episode reward: 0.2944,                 loss: 0.1360
Episode: 6481/30000 (21.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3142s / 42293.4862 s
agent0:                 episode reward: -0.1554,                 loss: nan
agent1:                 episode reward: 0.1554,                 loss: 0.1372
Episode: 6501/30000 (21.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1327s / 42430.6190 s
agent0:                 episode reward: -0.3043,                 loss: nan
agent1:                 episode reward: 0.3043,                 loss: 0.1376
Episode: 6521/30000 (21.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1347s / 42565.7537 s
agent0:                 episode reward: -0.0768,                 loss: nan
agent1:                 episode reward: 0.0768,                 loss: 0.1373
Episode: 6541/30000 (21.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9349s / 42701.6886 s
agent0:                 episode reward: -0.1521,                 loss: nan
agent1:                 episode reward: 0.1521,                 loss: 0.1382
Episode: 6561/30000 (21.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0290s / 42835.7176 s
agent0:                 episode reward: -0.4012,                 loss: nan
agent1:                 episode reward: 0.4012,                 loss: 0.1352
Episode: 6581/30000 (21.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2776s / 42970.9953 s
agent0:                 episode reward: -0.2907,                 loss: nan
agent1:                 episode reward: 0.2907,                 loss: 0.1361
Episode: 6601/30000 (22.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6809s / 43104.6762 s
agent0:                 episode reward: -0.0706,                 loss: nan
agent1:                 episode reward: 0.0706,                 loss: 0.1370
Episode: 6621/30000 (22.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3396s / 43239.0158 s
agent0:                 episode reward: -0.5066,                 loss: nan
agent1:                 episode reward: 0.5066,                 loss: 0.1363
Episode: 6641/30000 (22.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7210s / 43371.7368 s
agent0:                 episode reward: -0.0803,                 loss: nan
agent1:                 episode reward: 0.0803,                 loss: 0.1358
Episode: 6661/30000 (22.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2370s / 43505.9738 s
agent0:                 episode reward: -0.2606,                 loss: nan
agent1:                 episode reward: 0.2606,                 loss: 0.1367
Episode: 6681/30000 (22.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0703s / 43643.0441 s
agent0:                 episode reward: -0.1947,                 loss: nan
agent1:                 episode reward: 0.1947,                 loss: 0.1365
Episode: 6701/30000 (22.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8885s / 43777.9326 s
agent0:                 episode reward: 0.0153,                 loss: nan
agent1:                 episode reward: -0.0153,                 loss: 0.1374
Episode: 6721/30000 (22.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0664s / 43912.9990 s
agent0:                 episode reward: -0.3739,                 loss: nan
agent1:                 episode reward: 0.3739,                 loss: 0.1375
Episode: 6741/30000 (22.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6366s / 44046.6356 s
agent0:                 episode reward: -0.3378,                 loss: nan
agent1:                 episode reward: 0.3378,                 loss: 0.1363
Episode: 6761/30000 (22.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4047s / 44183.0403 s
agent0:                 episode reward: -0.2422,                 loss: nan
agent1:                 episode reward: 0.2422,                 loss: 0.1359
Episode: 6781/30000 (22.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5075s / 44319.5478 s
agent0:                 episode reward: 0.0733,                 loss: nan
agent1:                 episode reward: -0.0733,                 loss: 0.1362
Episode: 6801/30000 (22.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.3518s / 44451.8996 s
agent0:                 episode reward: -0.2746,                 loss: nan
agent1:                 episode reward: 0.2746,                 loss: 0.1378
Episode: 6821/30000 (22.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8570s / 44586.7566 s
agent0:                 episode reward: -0.1309,                 loss: nan
agent1:                 episode reward: 0.1309,                 loss: 0.1365
Episode: 6841/30000 (22.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8658s / 44720.6224 s
agent0:                 episode reward: 0.0254,                 loss: nan
agent1:                 episode reward: -0.0254,                 loss: 0.1370
Episode: 6861/30000 (22.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8710s / 44855.4934 s
agent0:                 episode reward: 0.1153,                 loss: nan
agent1:                 episode reward: -0.1153,                 loss: 0.1353
Episode: 6881/30000 (22.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.1999s / 44995.6933 s
agent0:                 episode reward: -0.4173,                 loss: nan
agent1:                 episode reward: 0.4173,                 loss: 0.1336
Episode: 6901/30000 (23.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1002s / 45132.7935 s
agent0:                 episode reward: 0.3771,                 loss: nan
agent1:                 episode reward: -0.3771,                 loss: 0.1364
Episode: 6921/30000 (23.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2530s / 45269.0464 s
agent0:                 episode reward: -0.2294,                 loss: nan
agent1:                 episode reward: 0.2294,                 loss: 0.1375
Episode: 6941/30000 (23.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2825s / 45406.3289 s
agent0:                 episode reward: -0.2849,                 loss: nan
agent1:                 episode reward: 0.2849,                 loss: 0.1368
Episode: 6961/30000 (23.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0235s / 45543.3524 s
agent0:                 episode reward: -0.2980,                 loss: nan
agent1:                 episode reward: 0.2980,                 loss: 0.1356
Episode: 6981/30000 (23.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7297s / 45678.0822 s
agent0:                 episode reward: -0.6262,                 loss: nan
agent1:                 episode reward: 0.6262,                 loss: 0.1375
Episode: 7001/30000 (23.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6307s / 45812.7129 s
agent0:                 episode reward: -0.5791,                 loss: nan
agent1:                 episode reward: 0.5791,                 loss: 0.1361
Episode: 7021/30000 (23.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0243s / 45950.7372 s
agent0:                 episode reward: -0.2060,                 loss: nan
agent1:                 episode reward: 0.2060,                 loss: 0.1356
Episode: 7041/30000 (23.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.0433s / 46081.7805 s
agent0:                 episode reward: -0.3365,                 loss: nan
agent1:                 episode reward: 0.3365,                 loss: 0.1368
Episode: 7061/30000 (23.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0009s / 46215.7814 s
agent0:                 episode reward: -0.1808,                 loss: nan
agent1:                 episode reward: 0.1808,                 loss: 0.1364
Episode: 7081/30000 (23.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0277s / 46351.8091 s
agent0:                 episode reward: 0.0690,                 loss: nan
agent1:                 episode reward: -0.0690,                 loss: 0.1365
Episode: 7101/30000 (23.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2360s / 46489.0450 s
agent0:                 episode reward: -0.5319,                 loss: nan
agent1:                 episode reward: 0.5319,                 loss: 0.1354
Episode: 7121/30000 (23.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9203s / 46625.9654 s
agent0:                 episode reward: -0.4282,                 loss: nan
agent1:                 episode reward: 0.4282,                 loss: 0.1355
Episode: 7141/30000 (23.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.3254s / 46764.2908 s
agent0:                 episode reward: -0.1505,                 loss: nan
agent1:                 episode reward: 0.1505,                 loss: 0.1364
Episode: 7161/30000 (23.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2826s / 46900.5734 s
agent0:                 episode reward: -0.1652,                 loss: nan
agent1:                 episode reward: 0.1652,                 loss: 0.1364
Episode: 7181/30000 (23.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0915s / 47033.6649 s
agent0:                 episode reward: -0.1235,                 loss: nan
agent1:                 episode reward: 0.1235,                 loss: 0.1375
Episode: 7201/30000 (24.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4019s / 47168.0668 s
agent0:                 episode reward: 0.0449,                 loss: nan
agent1:                 episode reward: -0.0449,                 loss: 0.1363
Episode: 7221/30000 (24.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2312s / 47303.2980 s
agent0:                 episode reward: 0.0728,                 loss: nan
agent1:                 episode reward: -0.0728,                 loss: 0.1364
Episode: 7241/30000 (24.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6201s / 47435.9181 s
agent0:                 episode reward: -0.2481,                 loss: nan
agent1:                 episode reward: 0.2481,                 loss: 0.1372
Episode: 7261/30000 (24.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.1871s / 47575.1052 s
agent0:                 episode reward: 0.0955,                 loss: nan
agent1:                 episode reward: -0.0955,                 loss: 0.1379
Episode: 7281/30000 (24.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1458s / 47710.2510 s
agent0:                 episode reward: -0.6698,                 loss: nan
agent1:                 episode reward: 0.6698,                 loss: 0.1369
Episode: 7301/30000 (24.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8030s / 47845.0540 s
agent0:                 episode reward: -0.2453,                 loss: nan
agent1:                 episode reward: 0.2453,                 loss: 0.1368
Episode: 7321/30000 (24.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1710s / 47979.2250 s
agent0:                 episode reward: -0.1871,                 loss: nan
agent1:                 episode reward: 0.1871,                 loss: 0.1359
Episode: 7341/30000 (24.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9945s / 48113.2195 s
agent0:                 episode reward: 0.0089,                 loss: nan
agent1:                 episode reward: -0.0089,                 loss: 0.1365
Episode: 7361/30000 (24.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.4326s / 48252.6521 s
agent0:                 episode reward: -0.2463,                 loss: nan
agent1:                 episode reward: 0.2463,                 loss: 0.1358
Episode: 7381/30000 (24.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0053s / 48384.6574 s
agent0:                 episode reward: -0.3523,                 loss: nan
agent1:                 episode reward: 0.3523,                 loss: 0.1363
Episode: 7401/30000 (24.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4434s / 48517.1008 s
agent0:                 episode reward: 0.0310,                 loss: nan
agent1:                 episode reward: -0.0310,                 loss: 0.1378
Episode: 7421/30000 (24.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9822s / 48653.0831 s
agent0:                 episode reward: -0.1002,                 loss: nan
agent1:                 episode reward: 0.1002,                 loss: 0.1353
Episode: 7441/30000 (24.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8642s / 48787.9473 s
agent0:                 episode reward: -0.3303,                 loss: nan
agent1:                 episode reward: 0.3303,                 loss: 0.1369
Episode: 7461/30000 (24.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6266s / 48922.5739 s
agent0:                 episode reward: -0.3491,                 loss: nan
agent1:                 episode reward: 0.3491,                 loss: 0.1379
Episode: 7481/30000 (24.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.4926s / 49057.0665 s
agent0:                 episode reward: -0.1505,                 loss: nan
agent1:                 episode reward: 0.1505,                 loss: 0.1369
Episode: 7501/30000 (25.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6454s / 49191.7119 s
agent0:                 episode reward: -0.1609,                 loss: nan
agent1:                 episode reward: 0.1609,                 loss: 0.1373
Episode: 7521/30000 (25.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0848s / 49327.7967 s
agent0:                 episode reward: -0.0587,                 loss: nan
agent1:                 episode reward: 0.0587,                 loss: 0.1342
Episode: 7541/30000 (25.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9269s / 49465.7236 s
agent0:                 episode reward: -0.4344,                 loss: nan
agent1:                 episode reward: 0.4344,                 loss: 0.1368
Episode: 7561/30000 (25.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7998s / 49601.5234 s
agent0:                 episode reward: -0.3291,                 loss: nan
agent1:                 episode reward: 0.3291,                 loss: 0.1362
Episode: 7581/30000 (25.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6358s / 49735.1592 s
agent0:                 episode reward: 0.0208,                 loss: nan
agent1:                 episode reward: -0.0208,                 loss: 0.1351
Episode: 7601/30000 (25.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2849s / 49870.4440 s
agent0:                 episode reward: -0.4737,                 loss: nan
agent1:                 episode reward: 0.4737,                 loss: 0.1351
Episode: 7621/30000 (25.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9947s / 50007.4387 s
agent0:                 episode reward: -0.0422,                 loss: nan
agent1:                 episode reward: 0.0422,                 loss: 0.1346
Episode: 7641/30000 (25.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1214s / 50141.5601 s
agent0:                 episode reward: -0.2491,                 loss: nan
agent1:                 episode reward: 0.2491,                 loss: 0.1335
Episode: 7661/30000 (25.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7273s / 50276.2874 s
agent0:                 episode reward: -0.1451,                 loss: nan
agent1:                 episode reward: 0.1451,                 loss: 0.1341
Episode: 7681/30000 (25.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6451s / 50411.9325 s
agent0:                 episode reward: -0.1596,                 loss: nan
agent1:                 episode reward: 0.1596,                 loss: 0.1359
Episode: 7701/30000 (25.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1759s / 50547.1083 s
agent0:                 episode reward: -0.1746,                 loss: nan
agent1:                 episode reward: 0.1746,                 loss: 0.1347
Episode: 7721/30000 (25.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8573s / 50683.9656 s
agent0:                 episode reward: -0.5452,                 loss: nan
agent1:                 episode reward: 0.5452,                 loss: 0.1356
Episode: 7741/30000 (25.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6073s / 50818.5730 s
agent0:                 episode reward: -0.3710,                 loss: nan
agent1:                 episode reward: 0.3710,                 loss: 0.1334
Episode: 7761/30000 (25.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0478s / 50954.6207 s
agent0:                 episode reward: -0.1517,                 loss: nan
agent1:                 episode reward: 0.1517,                 loss: 0.1359
Episode: 7781/30000 (25.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8139s / 51088.4347 s
agent0:                 episode reward: -0.5578,                 loss: nan
agent1:                 episode reward: 0.5578,                 loss: 0.1359
Episode: 7801/30000 (26.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8320s / 51221.2667 s
agent0:                 episode reward: -0.2643,                 loss: nan
agent1:                 episode reward: 0.2643,                 loss: 0.1346
Episode: 7821/30000 (26.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0801s / 51354.3468 s
agent0:                 episode reward: -0.1927,                 loss: nan
agent1:                 episode reward: 0.1927,                 loss: 0.1348
Episode: 7841/30000 (26.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2719s / 51487.6187 s
agent0:                 episode reward: 0.0338,                 loss: nan
agent1:                 episode reward: -0.0338,                 loss: 0.1335
Episode: 7861/30000 (26.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5047s / 51625.1234 s
agent0:                 episode reward: -0.1744,                 loss: nan
agent1:                 episode reward: 0.1744,                 loss: 0.1354
Episode: 7881/30000 (26.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7529s / 51757.8763 s
agent0:                 episode reward: -0.2175,                 loss: nan
agent1:                 episode reward: 0.2175,                 loss: 0.1364
Episode: 7901/30000 (26.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6705s / 51892.5468 s
agent0:                 episode reward: -0.3415,                 loss: nan
agent1:                 episode reward: 0.3415,                 loss: 0.1369
Episode: 7921/30000 (26.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5526s / 52029.0994 s
agent0:                 episode reward: -0.1865,                 loss: nan
agent1:                 episode reward: 0.1865,                 loss: 0.1379
Episode: 7941/30000 (26.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2492s / 52165.3486 s
agent0:                 episode reward: -0.2525,                 loss: nan
agent1:                 episode reward: 0.2525,                 loss: 0.1372
Episode: 7961/30000 (26.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6838s / 52300.0324 s
agent0:                 episode reward: -0.3655,                 loss: nan
agent1:                 episode reward: 0.3655,                 loss: 0.1361
Episode: 7981/30000 (26.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6488s / 52432.6812 s
agent0:                 episode reward: -0.2443,                 loss: nan
agent1:                 episode reward: 0.2443,                 loss: 0.1375
Episode: 8001/30000 (26.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6068s / 52566.2879 s
agent0:                 episode reward: -0.4999,                 loss: nan
agent1:                 episode reward: 0.4999,                 loss: 0.1382
Episode: 8021/30000 (26.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2585s / 52700.5464 s
agent0:                 episode reward: -0.2195,                 loss: nan
agent1:                 episode reward: 0.2195,                 loss: 0.1358
Episode: 8041/30000 (26.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7102s / 52834.2566 s
agent0:                 episode reward: -0.0847,                 loss: nan
agent1:                 episode reward: 0.0847,                 loss: 0.1371
Episode: 8061/30000 (26.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3186s / 52968.5752 s
agent0:                 episode reward: -0.3471,                 loss: nan
agent1:                 episode reward: 0.3471,                 loss: 0.1357
Episode: 8081/30000 (26.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7916s / 53104.3668 s
agent0:                 episode reward: -0.2541,                 loss: nan
agent1:                 episode reward: 0.2541,                 loss: 0.1356
Episode: 8101/30000 (27.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0123s / 53238.3791 s
agent0:                 episode reward: -0.1602,                 loss: nan
agent1:                 episode reward: 0.1602,                 loss: 0.1363
Episode: 8121/30000 (27.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.5193s / 53376.8985 s
agent0:                 episode reward: -0.1088,                 loss: nan
agent1:                 episode reward: 0.1088,                 loss: 0.1349
Episode: 8141/30000 (27.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0068s / 53508.9052 s
agent0:                 episode reward: -0.4270,                 loss: nan
agent1:                 episode reward: 0.4270,                 loss: 0.1371
Episode: 8161/30000 (27.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3253s / 53642.2305 s
agent0:                 episode reward: -0.3644,                 loss: nan
agent1:                 episode reward: 0.3644,                 loss: 0.1375
Episode: 8181/30000 (27.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2156s / 53778.4461 s
agent0:                 episode reward: -0.0063,                 loss: nan
agent1:                 episode reward: 0.0063,                 loss: 0.1367
Episode: 8201/30000 (27.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2643s / 53914.7104 s
agent0:                 episode reward: -0.3094,                 loss: nan
agent1:                 episode reward: 0.3094,                 loss: 0.1365
Episode: 8221/30000 (27.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5432s / 54049.2536 s
agent0:                 episode reward: -0.4784,                 loss: nan
agent1:                 episode reward: 0.4784,                 loss: 0.1365
Episode: 8241/30000 (27.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5157s / 54185.7694 s
agent0:                 episode reward: -0.0171,                 loss: nan
agent1:                 episode reward: 0.0171,                 loss: 0.1369
Episode: 8261/30000 (27.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7363s / 54322.5057 s
agent0:                 episode reward: -0.5800,                 loss: nan
agent1:                 episode reward: 0.5800,                 loss: 0.1358
Episode: 8281/30000 (27.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4812s / 54457.9869 s
agent0:                 episode reward: -0.3140,                 loss: nan
agent1:                 episode reward: 0.3140,                 loss: 0.1360
Episode: 8301/30000 (27.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6814s / 54591.6683 s
agent0:                 episode reward: -0.7776,                 loss: nan
agent1:                 episode reward: 0.7776,                 loss: 0.1380
Episode: 8321/30000 (27.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1543s / 54724.8226 s
agent0:                 episode reward: -0.2201,                 loss: nan
agent1:                 episode reward: 0.2201,                 loss: 0.1369
Episode: 8341/30000 (27.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8228s / 54859.6454 s
agent0:                 episode reward: -0.2689,                 loss: nan
agent1:                 episode reward: 0.2689,                 loss: 0.1357
Episode: 8361/30000 (27.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1190s / 54995.7644 s
agent0:                 episode reward: -0.6168,                 loss: nan
agent1:                 episode reward: 0.6168,                 loss: 0.1355
Episode: 8381/30000 (27.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7721s / 55132.5364 s
agent0:                 episode reward: -0.4336,                 loss: nan
agent1:                 episode reward: 0.4336,                 loss: 0.1353
Episode: 8401/30000 (28.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0547s / 55267.5912 s
agent0:                 episode reward: -0.4007,                 loss: nan
agent1:                 episode reward: 0.4007,                 loss: 0.1343
Episode: 8421/30000 (28.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0333s / 55401.6245 s
agent0:                 episode reward: -0.6328,                 loss: nan
agent1:                 episode reward: 0.6328,                 loss: 0.1372
Episode: 8441/30000 (28.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6389s / 55538.2634 s
agent0:                 episode reward: -0.5702,                 loss: nan
agent1:                 episode reward: 0.5702,                 loss: 0.1341
Episode: 8461/30000 (28.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9350s / 55674.1984 s
agent0:                 episode reward: -0.0993,                 loss: nan
agent1:                 episode reward: 0.0993,                 loss: 0.1360
Episode: 8481/30000 (28.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.1944s / 55811.3928 s
agent0:                 episode reward: -0.7750,                 loss: nan
agent1:                 episode reward: 0.7750,                 loss: 0.1351
Episode: 8501/30000 (28.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.0098s / 55943.4026 s
agent0:                 episode reward: -0.3056,                 loss: nan
agent1:                 episode reward: 0.3056,                 loss: 0.1354
Episode: 8521/30000 (28.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1784s / 56079.5810 s
agent0:                 episode reward: -0.1829,                 loss: nan
agent1:                 episode reward: 0.1829,                 loss: 0.1348
Episode: 8541/30000 (28.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9713s / 56217.5524 s
agent0:                 episode reward: -0.3983,                 loss: nan
agent1:                 episode reward: 0.3983,                 loss: 0.1355
Episode: 8561/30000 (28.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3571s / 56351.9094 s
agent0:                 episode reward: -0.5821,                 loss: nan
agent1:                 episode reward: 0.5821,                 loss: 0.1332
Episode: 8581/30000 (28.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4691s / 56488.3785 s
agent0:                 episode reward: -0.6468,                 loss: nan
agent1:                 episode reward: 0.6468,                 loss: 0.1340
Episode: 8601/30000 (28.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3465s / 56624.7251 s
agent0:                 episode reward: -0.6454,                 loss: nan
agent1:                 episode reward: 0.6454,                 loss: 0.1322
Episode: 8621/30000 (28.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2178s / 56757.9428 s
agent0:                 episode reward: 0.0995,                 loss: nan
agent1:                 episode reward: -0.0995,                 loss: 0.1334
Episode: 8641/30000 (28.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4490s / 56890.3918 s
agent0:                 episode reward: -0.7502,                 loss: nan
agent1:                 episode reward: 0.7502,                 loss: 0.1329
Episode: 8661/30000 (28.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9479s / 57028.3397 s
agent0:                 episode reward: -0.3014,                 loss: nan
agent1:                 episode reward: 0.3014,                 loss: 0.1320
Episode: 8681/30000 (28.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8517s / 57161.1914 s
agent0:                 episode reward: -0.5463,                 loss: nan
agent1:                 episode reward: 0.5463,                 loss: 0.1328
Episode: 8701/30000 (29.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.2655s / 57298.4569 s
agent0:                 episode reward: -0.1503,                 loss: nan
agent1:                 episode reward: 0.1503,                 loss: 0.1317
Episode: 8721/30000 (29.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9361s / 57432.3930 s
agent0:                 episode reward: -0.2569,                 loss: nan
agent1:                 episode reward: 0.2569,                 loss: 0.1321
Episode: 8741/30000 (29.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6629s / 57569.0559 s
agent0:                 episode reward: -0.2416,                 loss: nan
agent1:                 episode reward: 0.2416,                 loss: 0.1321
Episode: 8761/30000 (29.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8966s / 57703.9526 s
agent0:                 episode reward: -0.3644,                 loss: nan
agent1:                 episode reward: 0.3644,                 loss: 0.1342
Episode: 8781/30000 (29.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6391s / 57841.5916 s
agent0:                 episode reward: -0.4940,                 loss: nan
agent1:                 episode reward: 0.4940,                 loss: 0.1305
Episode: 8801/30000 (29.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0038s / 57978.5954 s
agent0:                 episode reward: -0.4744,                 loss: nan
agent1:                 episode reward: 0.4744,                 loss: 0.1315
Episode: 8821/30000 (29.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3472s / 58115.9426 s
agent0:                 episode reward: -0.1378,                 loss: nan
agent1:                 episode reward: 0.1378,                 loss: 0.1342
Episode: 8841/30000 (29.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8244s / 58251.7671 s
agent0:                 episode reward: -0.1659,                 loss: nan
agent1:                 episode reward: 0.1659,                 loss: 0.1326
Episode: 8861/30000 (29.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4254s / 58387.1925 s
agent0:                 episode reward: 0.0348,                 loss: nan
agent1:                 episode reward: -0.0348,                 loss: 0.1331
Episode: 8881/30000 (29.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2561s / 58521.4485 s
agent0:                 episode reward: -0.3500,                 loss: nan
agent1:                 episode reward: 0.3500,                 loss: 0.1337
Episode: 8901/30000 (29.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4720s / 58653.9206 s
agent0:                 episode reward: -0.2068,                 loss: nan
agent1:                 episode reward: 0.2068,                 loss: 0.1344
Episode: 8921/30000 (29.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1713s / 58789.0919 s
agent0:                 episode reward: -0.3827,                 loss: nan
agent1:                 episode reward: 0.3827,                 loss: 0.1328
Episode: 8941/30000 (29.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2673s / 58922.3592 s
agent0:                 episode reward: -0.7783,                 loss: nan
agent1:                 episode reward: 0.7783,                 loss: 0.1336
Episode: 8961/30000 (29.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.4129s / 59060.7720 s
agent0:                 episode reward: -0.3486,                 loss: nan
agent1:                 episode reward: 0.3486,                 loss: 0.1340
Episode: 8981/30000 (29.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1944s / 59193.9664 s
agent0:                 episode reward: -0.5786,                 loss: nan
agent1:                 episode reward: 0.5786,                 loss: 0.1337
Episode: 9001/30000 (30.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9684s / 59328.9349 s
agent0:                 episode reward: -0.6119,                 loss: nan
agent1:                 episode reward: 0.6119,                 loss: 0.1342
Episode: 9021/30000 (30.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.4669s / 59469.4018 s
agent0:                 episode reward: -0.5470,                 loss: nan
agent1:                 episode reward: 0.5470,                 loss: 0.1341
Episode: 9041/30000 (30.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5827s / 59603.9845 s
agent0:                 episode reward: -0.2443,                 loss: nan
agent1:                 episode reward: 0.2443,                 loss: 0.1331
Episode: 9061/30000 (30.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3872s / 59740.3717 s
agent0:                 episode reward: -0.3625,                 loss: nan
agent1:                 episode reward: 0.3625,                 loss: 0.1336
Episode: 9081/30000 (30.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7492s / 59876.1209 s
agent0:                 episode reward: -0.4061,                 loss: nan
agent1:                 episode reward: 0.4061,                 loss: 0.1333
Episode: 9101/30000 (30.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6864s / 60009.8073 s
agent0:                 episode reward: -0.1851,                 loss: nan
agent1:                 episode reward: 0.1851,                 loss: 0.1333
Episode: 9121/30000 (30.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8829s / 60142.6902 s
agent0:                 episode reward: -0.1705,                 loss: nan
agent1:                 episode reward: 0.1705,                 loss: 0.1326
Episode: 9141/30000 (30.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7021s / 60279.3923 s
agent0:                 episode reward: -0.5747,                 loss: nan
agent1:                 episode reward: 0.5747,                 loss: 0.1329
Episode: 9161/30000 (30.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3847s / 60413.7770 s
agent0:                 episode reward: -0.6321,                 loss: nan
agent1:                 episode reward: 0.6321,                 loss: 0.1346
Episode: 9181/30000 (30.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9328s / 60546.7099 s
agent0:                 episode reward: -0.2697,                 loss: nan
agent1:                 episode reward: 0.2697,                 loss: 0.1326
Episode: 9201/30000 (30.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1874s / 60679.8972 s
agent0:                 episode reward: -0.8215,                 loss: nan
agent1:                 episode reward: 0.8215,                 loss: 0.1344
Episode: 9221/30000 (30.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2710s / 60815.1682 s
agent0:                 episode reward: -0.7330,                 loss: nan
agent1:                 episode reward: 0.7330,                 loss: 0.1329
Episode: 9241/30000 (30.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5993s / 60950.7676 s
agent0:                 episode reward: -0.6970,                 loss: nan
agent1:                 episode reward: 0.6970,                 loss: 0.1326
Episode: 9261/30000 (30.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0957s / 61084.8633 s
agent0:                 episode reward: -0.2523,                 loss: nan
agent1:                 episode reward: 0.2523,                 loss: 0.1325
Episode: 9281/30000 (30.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7779s / 61221.6411 s
agent0:                 episode reward: -0.4275,                 loss: nan
agent1:                 episode reward: 0.4275,                 loss: 0.1363
Episode: 9301/30000 (31.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8013s / 61357.4424 s
agent0:                 episode reward: 0.1665,                 loss: nan
agent1:                 episode reward: -0.1665,                 loss: 0.1345
Episode: 9321/30000 (31.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6092s / 61492.0516 s
agent0:                 episode reward: -0.1617,                 loss: nan
agent1:                 episode reward: 0.1617,                 loss: 0.1346
Episode: 9341/30000 (31.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9938s / 61630.0454 s
agent0:                 episode reward: -0.2194,                 loss: nan
agent1:                 episode reward: 0.2194,                 loss: 0.1324
Episode: 9361/30000 (31.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.2279s / 61769.2734 s
agent0:                 episode reward: -0.4637,                 loss: nan
agent1:                 episode reward: 0.4637,                 loss: 0.1348
Episode: 9381/30000 (31.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5929s / 61902.8663 s
agent0:                 episode reward: -0.4525,                 loss: nan
agent1:                 episode reward: 0.4525,                 loss: 0.1341
Episode: 9401/30000 (31.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1722s / 62038.0385 s
agent0:                 episode reward: -0.3868,                 loss: nan
agent1:                 episode reward: 0.3868,                 loss: 0.1331
Episode: 9421/30000 (31.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9043s / 62175.9429 s
agent0:                 episode reward: -0.2502,                 loss: nan
agent1:                 episode reward: 0.2502,                 loss: 0.1329
Episode: 9441/30000 (31.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.2290s / 62316.1719 s
agent0:                 episode reward: -0.2678,                 loss: nan
agent1:                 episode reward: 0.2678,                 loss: 0.1337
Episode: 9461/30000 (31.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9353s / 62450.1072 s
agent0:                 episode reward: -0.5904,                 loss: nan
agent1:                 episode reward: 0.5904,                 loss: 0.1337
Episode: 9481/30000 (31.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2140s / 62584.3212 s
agent0:                 episode reward: -0.3050,                 loss: nan
agent1:                 episode reward: 0.3050,                 loss: 0.1336
Episode: 9501/30000 (31.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9465s / 62720.2677 s
agent0:                 episode reward: -0.4700,                 loss: nan
agent1:                 episode reward: 0.4700,                 loss: 0.1331
Episode: 9521/30000 (31.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0850s / 62855.3527 s
agent0:                 episode reward: -0.2810,                 loss: nan
agent1:                 episode reward: 0.2810,                 loss: 0.1340
Episode: 9541/30000 (31.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.5679s / 62986.9206 s
agent0:                 episode reward: 0.0850,                 loss: nan
agent1:                 episode reward: -0.0850,                 loss: 0.1342
Episode: 9561/30000 (31.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0533s / 63121.9738 s
agent0:                 episode reward: -0.4018,                 loss: nan
agent1:                 episode reward: 0.4018,                 loss: 0.1345
Episode: 9581/30000 (31.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 139.0193s / 63260.9931 s
agent0:                 episode reward: -0.5660,                 loss: nan
agent1:                 episode reward: 0.5660,                 loss: 0.1331
Episode: 9601/30000 (32.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7590s / 63396.7521 s
agent0:                 episode reward: -0.3520,                 loss: nan
agent1:                 episode reward: 0.3520,                 loss: 0.1336
Episode: 9621/30000 (32.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2898s / 63533.0420 s
agent0:                 episode reward: -0.4073,                 loss: nan
agent1:                 episode reward: 0.4073,                 loss: 0.1324
Episode: 9641/30000 (32.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2303s / 63669.2723 s
agent0:                 episode reward: -0.4801,                 loss: nan
agent1:                 episode reward: 0.4801,                 loss: 0.1335
Episode: 9661/30000 (32.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 141.6191s / 63810.8914 s
agent0:                 episode reward: -0.4147,                 loss: nan
agent1:                 episode reward: 0.4147,                 loss: 0.1340
Episode: 9681/30000 (32.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5189s / 63947.4103 s
agent0:                 episode reward: -0.0954,                 loss: nan
agent1:                 episode reward: 0.0954,                 loss: 0.1334
Episode: 9701/30000 (32.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7273s / 64083.1376 s
agent0:                 episode reward: -0.2930,                 loss: nan
agent1:                 episode reward: 0.2930,                 loss: 0.1335
Episode: 9721/30000 (32.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9165s / 64217.0541 s
agent0:                 episode reward: -0.4142,                 loss: nan
agent1:                 episode reward: 0.4142,                 loss: 0.1352
Episode: 9741/30000 (32.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0664s / 64352.1206 s
agent0:                 episode reward: -0.3088,                 loss: nan
agent1:                 episode reward: 0.3088,                 loss: 0.1350
Episode: 9761/30000 (32.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 140.6279s / 64492.7485 s
agent0:                 episode reward: -0.6901,                 loss: nan
agent1:                 episode reward: 0.6901,                 loss: 0.1332
Episode: 9781/30000 (32.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1608s / 64626.9093 s
agent0:                 episode reward: -0.4231,                 loss: nan
agent1:                 episode reward: 0.4231,                 loss: 0.1342
Episode: 9801/30000 (32.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.8036s / 64759.7129 s
agent0:                 episode reward: -0.4803,                 loss: nan
agent1:                 episode reward: 0.4803,                 loss: 0.1348
Episode: 9821/30000 (32.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7218s / 64897.4347 s
agent0:                 episode reward: -0.4882,                 loss: nan
agent1:                 episode reward: 0.4882,                 loss: 0.1348
Episode: 9841/30000 (32.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8125s / 65032.2472 s
agent0:                 episode reward: -0.2467,                 loss: nan
agent1:                 episode reward: 0.2467,                 loss: 0.1341
Episode: 9861/30000 (32.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6176s / 65168.8648 s
agent0:                 episode reward: -0.2926,                 loss: nan
agent1:                 episode reward: 0.2926,                 loss: 0.1351
Episode: 9881/30000 (32.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6046s / 65304.4695 s
agent0:                 episode reward: -0.5041,                 loss: nan
agent1:                 episode reward: 0.5041,                 loss: 0.1347
Episode: 9901/30000 (33.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5350s / 65442.0045 s
agent0:                 episode reward: -0.5642,                 loss: nan
agent1:                 episode reward: 0.5642,                 loss: 0.1335
Episode: 9921/30000 (33.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9799s / 65575.9844 s
agent0:                 episode reward: -0.1049,                 loss: nan
agent1:                 episode reward: 0.1049,                 loss: 0.1334
Episode: 9941/30000 (33.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5395s / 65710.5238 s
agent0:                 episode reward: -0.6665,                 loss: nan
agent1:                 episode reward: 0.6665,                 loss: 0.1325
Episode: 9961/30000 (33.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1966s / 65844.7204 s
agent0:                 episode reward: -0.1846,                 loss: nan
agent1:                 episode reward: 0.1846,                 loss: 0.1318
Episode: 9981/30000 (33.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3819s / 65982.1023 s
agent0:                 episode reward: -0.5270,                 loss: nan
agent1:                 episode reward: 0.5270,                 loss: 0.1331
Episode: 10001/30000 (33.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5593s / 66117.6617 s
agent0:                 episode reward: -0.4084,                 loss: nan
agent1:                 episode reward: 0.4084,                 loss: 0.1340
Episode: 10021/30000 (33.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6595s / 66254.3212 s
agent0:                 episode reward: -0.3349,                 loss: nan
agent1:                 episode reward: 0.3349,                 loss: 0.1306
Episode: 10041/30000 (33.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4895s / 66391.8107 s
agent0:                 episode reward: -0.2359,                 loss: nan
agent1:                 episode reward: 0.2359,                 loss: 0.1314
Episode: 10061/30000 (33.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4723s / 66524.2830 s
agent0:                 episode reward: -0.3377,                 loss: nan
agent1:                 episode reward: 0.3377,                 loss: 0.1320
Episode: 10081/30000 (33.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.4427s / 66655.7257 s
agent0:                 episode reward: -0.4968,                 loss: nan
agent1:                 episode reward: 0.4968,                 loss: 0.1332
Episode: 10101/30000 (33.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7332s / 66791.4589 s
agent0:                 episode reward: -0.3195,                 loss: nan
agent1:                 episode reward: 0.3195,                 loss: 0.1318
Episode: 10121/30000 (33.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6901s / 66927.1490 s
agent0:                 episode reward: -0.1900,                 loss: nan
agent1:                 episode reward: 0.1900,                 loss: 0.1328
Episode: 10141/30000 (33.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9399s / 67063.0890 s
agent0:                 episode reward: -0.3462,                 loss: nan
agent1:                 episode reward: 0.3462,                 loss: 0.1314
Episode: 10161/30000 (33.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7215s / 67196.8105 s
agent0:                 episode reward: -0.5861,                 loss: nan
agent1:                 episode reward: 0.5861,                 loss: 0.1322
Episode: 10181/30000 (33.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4769s / 67330.2874 s
agent0:                 episode reward: -0.4443,                 loss: nan
agent1:                 episode reward: 0.4443,                 loss: 0.1318
Episode: 10201/30000 (34.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6624s / 67462.9498 s
agent0:                 episode reward: -0.1882,                 loss: nan
agent1:                 episode reward: 0.1882,                 loss: 0.1327
Episode: 10221/30000 (34.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 140.2097s / 67603.1595 s
agent0:                 episode reward: -0.6220,                 loss: nan
agent1:                 episode reward: 0.6220,                 loss: 0.1330
Episode: 10241/30000 (34.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8369s / 67738.9963 s
agent0:                 episode reward: -0.0999,                 loss: nan
agent1:                 episode reward: 0.0999,                 loss: 0.1319
Episode: 10261/30000 (34.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0144s / 67875.0108 s
agent0:                 episode reward: -0.4393,                 loss: nan
agent1:                 episode reward: 0.4393,                 loss: 0.1316
Episode: 10281/30000 (34.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2638s / 68010.2746 s
agent0:                 episode reward: -0.9402,                 loss: nan
agent1:                 episode reward: 0.9402,                 loss: 0.1327
Episode: 10301/30000 (34.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 130.5225s / 68140.7971 s
agent0:                 episode reward: -0.2754,                 loss: nan
agent1:                 episode reward: 0.2754,                 loss: 0.1342
Episode: 10321/30000 (34.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.1949s / 68272.9920 s
agent0:                 episode reward: -0.5677,                 loss: nan
agent1:                 episode reward: 0.5677,                 loss: 0.1324
Episode: 10341/30000 (34.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8868s / 68409.8788 s
agent0:                 episode reward: -0.5540,                 loss: nan
agent1:                 episode reward: 0.5540,                 loss: 0.1311
Episode: 10361/30000 (34.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3849s / 68543.2637 s
agent0:                 episode reward: -0.4483,                 loss: nan
agent1:                 episode reward: 0.4483,                 loss: 0.1325
Episode: 10381/30000 (34.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3290s / 68679.5928 s
agent0:                 episode reward: -0.3317,                 loss: nan
agent1:                 episode reward: 0.3317,                 loss: 0.1339
Episode: 10401/30000 (34.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1159s / 68813.7087 s
agent0:                 episode reward: -0.4146,                 loss: nan
agent1:                 episode reward: 0.4146,                 loss: 0.1336
Episode: 10421/30000 (34.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5012s / 68948.2099 s
agent0:                 episode reward: -0.5445,                 loss: nan
agent1:                 episode reward: 0.5445,                 loss: 0.1343
Episode: 10441/30000 (34.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2456s / 69083.4555 s
agent0:                 episode reward: -0.2117,                 loss: nan
agent1:                 episode reward: 0.2117,                 loss: 0.1325
Episode: 10461/30000 (34.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4975s / 69215.9530 s
agent0:                 episode reward: -0.2224,                 loss: nan
agent1:                 episode reward: 0.2224,                 loss: 0.1322
Episode: 10481/30000 (34.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7461s / 69348.6990 s
agent0:                 episode reward: -0.5256,                 loss: nan
agent1:                 episode reward: 0.5256,                 loss: 0.1322
Episode: 10501/30000 (35.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7725s / 69484.4716 s
agent0:                 episode reward: -0.7265,                 loss: nan
agent1:                 episode reward: 0.7265,                 loss: 0.1333
Episode: 10521/30000 (35.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5675s / 69618.0390 s
agent0:                 episode reward: -0.3428,                 loss: nan
agent1:                 episode reward: 0.3428,                 loss: 0.1328
Episode: 10541/30000 (35.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2558s / 69752.2948 s
agent0:                 episode reward: -0.3978,                 loss: nan
agent1:                 episode reward: 0.3978,                 loss: 0.1330
Episode: 10561/30000 (35.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8741s / 69889.1690 s
agent0:                 episode reward: -0.5699,                 loss: nan
agent1:                 episode reward: 0.5699,                 loss: 0.1314
Episode: 10581/30000 (35.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8709s / 70025.0398 s
agent0:                 episode reward: -0.7764,                 loss: nan
agent1:                 episode reward: 0.7764,                 loss: 0.1296
Episode: 10601/30000 (35.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1865s / 70159.2263 s
agent0:                 episode reward: -0.4653,                 loss: nan
agent1:                 episode reward: 0.4653,                 loss: 0.1334
Episode: 10621/30000 (35.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3774s / 70294.6037 s
agent0:                 episode reward: -0.4652,                 loss: nan
agent1:                 episode reward: 0.4652,                 loss: 0.1306
Episode: 10641/30000 (35.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3219s / 70429.9256 s
agent0:                 episode reward: -0.6177,                 loss: nan
agent1:                 episode reward: 0.6177,                 loss: 0.1317
Episode: 10661/30000 (35.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5808s / 70563.5064 s
agent0:                 episode reward: -0.4588,                 loss: nan
agent1:                 episode reward: 0.4588,                 loss: 0.1318
Episode: 10681/30000 (35.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3843s / 70699.8907 s
agent0:                 episode reward: -1.0436,                 loss: nan
agent1:                 episode reward: 1.0436,                 loss: 0.1321
Episode: 10701/30000 (35.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5078s / 70835.3985 s
agent0:                 episode reward: -0.2923,                 loss: nan
agent1:                 episode reward: 0.2923,                 loss: 0.1311
Episode: 10721/30000 (35.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3090s / 70969.7075 s
agent0:                 episode reward: -0.6775,                 loss: nan
agent1:                 episode reward: 0.6775,                 loss: 0.1314
Episode: 10741/30000 (35.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7531s / 71105.4606 s
agent0:                 episode reward: -0.2712,                 loss: nan
agent1:                 episode reward: 0.2712,                 loss: 0.1318
Episode: 10761/30000 (35.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.1429s / 71237.6035 s
agent0:                 episode reward: -0.1668,                 loss: nan
agent1:                 episode reward: 0.1668,                 loss: 0.1312
Episode: 10781/30000 (35.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4351s / 71371.0387 s
agent0:                 episode reward: -0.3063,                 loss: nan
agent1:                 episode reward: 0.3063,                 loss: 0.1309
Episode: 10801/30000 (36.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0867s / 71505.1254 s
agent0:                 episode reward: -0.5029,                 loss: nan
agent1:                 episode reward: 0.5029,                 loss: 0.1305
Episode: 10821/30000 (36.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8846s / 71641.0099 s
agent0:                 episode reward: -0.4278,                 loss: nan
agent1:                 episode reward: 0.4278,                 loss: 0.1320
Episode: 10841/30000 (36.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2640s / 71776.2739 s
agent0:                 episode reward: -0.7539,                 loss: nan
agent1:                 episode reward: 0.7539,                 loss: 0.1299
Episode: 10861/30000 (36.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 130.8866s / 71907.1605 s
agent0:                 episode reward: -0.3316,                 loss: nan
agent1:                 episode reward: 0.3316,                 loss: 0.1313
Episode: 10881/30000 (36.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0662s / 72043.2267 s
agent0:                 episode reward: -0.9092,                 loss: nan
agent1:                 episode reward: 0.9092,                 loss: 0.1310
Episode: 10901/30000 (36.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4982s / 72179.7249 s
agent0:                 episode reward: -0.8480,                 loss: nan
agent1:                 episode reward: 0.8480,                 loss: 0.1345
Episode: 10921/30000 (36.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4585s / 72312.1834 s
agent0:                 episode reward: -0.0906,                 loss: nan
agent1:                 episode reward: 0.0906,                 loss: 0.1340
Episode: 10941/30000 (36.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7275s / 72446.9110 s
agent0:                 episode reward: -0.2144,                 loss: nan
agent1:                 episode reward: 0.2144,                 loss: 0.1320
Episode: 10961/30000 (36.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.7446s / 72578.6555 s
agent0:                 episode reward: -0.5007,                 loss: nan
agent1:                 episode reward: 0.5007,                 loss: 0.1339
Episode: 10981/30000 (36.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9025s / 72714.5580 s
agent0:                 episode reward: -0.4659,                 loss: nan
agent1:                 episode reward: 0.4659,                 loss: 0.1329
Episode: 11001/30000 (36.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.4538s / 72847.0118 s
agent0:                 episode reward: -0.4155,                 loss: nan
agent1:                 episode reward: 0.4155,                 loss: 0.1339
Episode: 11021/30000 (36.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6987s / 72979.7105 s
agent0:                 episode reward: -0.2246,                 loss: nan
agent1:                 episode reward: 0.2246,                 loss: 0.1327
Episode: 11041/30000 (36.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3930s / 73113.1035 s
agent0:                 episode reward: -0.6151,                 loss: nan
agent1:                 episode reward: 0.6151,                 loss: 0.1334
Episode: 11061/30000 (36.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8272s / 73249.9307 s
agent0:                 episode reward: -0.2583,                 loss: nan
agent1:                 episode reward: 0.2583,                 loss: 0.1324
Episode: 11081/30000 (36.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8140s / 73386.7447 s
agent0:                 episode reward: -0.3655,                 loss: nan
agent1:                 episode reward: 0.3655,                 loss: 0.1337
Episode: 11101/30000 (37.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.5046s / 73520.2493 s
agent0:                 episode reward: -0.4029,                 loss: nan
agent1:                 episode reward: 0.4029,                 loss: 0.1343
Episode: 11121/30000 (37.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.6713s / 73657.9206 s
agent0:                 episode reward: -0.2476,                 loss: nan
agent1:                 episode reward: 0.2476,                 loss: 0.1323
Episode: 11141/30000 (37.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4438s / 73791.3644 s
agent0:                 episode reward: -0.2543,                 loss: nan
agent1:                 episode reward: 0.2543,                 loss: 0.1331
Episode: 11161/30000 (37.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8467s / 73927.2111 s
agent0:                 episode reward: -0.2577,                 loss: nan
agent1:                 episode reward: 0.2577,                 loss: 0.1325
Episode: 11181/30000 (37.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 139.9610s / 74067.1721 s
agent0:                 episode reward: -0.5816,                 loss: nan
agent1:                 episode reward: 0.5816,                 loss: 0.1320
Episode: 11201/30000 (37.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6376s / 74201.8097 s
agent0:                 episode reward: -0.8949,                 loss: nan
agent1:                 episode reward: 0.8949,                 loss: 0.1328
Episode: 11221/30000 (37.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3451s / 74338.1548 s
agent0:                 episode reward: -0.5125,                 loss: nan
agent1:                 episode reward: 0.5125,                 loss: 0.1327
Episode: 11241/30000 (37.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0147s / 74473.1695 s
agent0:                 episode reward: -0.3225,                 loss: nan
agent1:                 episode reward: 0.3225,                 loss: 0.1324
Episode: 11261/30000 (37.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2179s / 74608.3874 s
agent0:                 episode reward: -0.5697,                 loss: nan
agent1:                 episode reward: 0.5697,                 loss: 0.1331
Episode: 11281/30000 (37.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7822s / 74743.1696 s
agent0:                 episode reward: -0.3940,                 loss: nan
agent1:                 episode reward: 0.3940,                 loss: 0.1320
Episode: 11301/30000 (37.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9247s / 74880.0943 s
agent0:                 episode reward: -0.1743,                 loss: nan
agent1:                 episode reward: 0.1743,                 loss: 0.1343
Episode: 11321/30000 (37.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3463s / 75013.4406 s
agent0:                 episode reward: -0.7553,                 loss: nan
agent1:                 episode reward: 0.7553,                 loss: 0.1333
Episode: 11341/30000 (37.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0945s / 75151.5352 s
agent0:                 episode reward: -0.3002,                 loss: nan
agent1:                 episode reward: 0.3002,                 loss: 0.1334
Episode: 11361/30000 (37.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3654s / 75284.9006 s
agent0:                 episode reward: -0.6902,                 loss: nan
agent1:                 episode reward: 0.6902,                 loss: 0.1330
Episode: 11381/30000 (37.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7134s / 75421.6140 s
agent0:                 episode reward: -0.3349,                 loss: nan
agent1:                 episode reward: 0.3349,                 loss: 0.1322
Episode: 11401/30000 (38.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4523s / 75555.0663 s
agent0:                 episode reward: -0.2913,                 loss: nan
agent1:                 episode reward: 0.2913,                 loss: 0.1338
Episode: 11421/30000 (38.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.6456s / 75687.7120 s
agent0:                 episode reward: -0.6785,                 loss: nan
agent1:                 episode reward: 0.6785,                 loss: 0.1315
Episode: 11441/30000 (38.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6836s / 75824.3956 s
agent0:                 episode reward: -0.3588,                 loss: nan
agent1:                 episode reward: 0.3588,                 loss: 0.1336
Episode: 11461/30000 (38.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7919s / 75958.1875 s
agent0:                 episode reward: -0.5158,                 loss: nan
agent1:                 episode reward: 0.5158,                 loss: 0.1322
Episode: 11481/30000 (38.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9190s / 76092.1064 s
agent0:                 episode reward: -0.3125,                 loss: nan
agent1:                 episode reward: 0.3125,                 loss: 0.1323
Episode: 11501/30000 (38.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5339s / 76226.6403 s
agent0:                 episode reward: -0.2000,                 loss: nan
agent1:                 episode reward: 0.2000,                 loss: 0.1342
Episode: 11521/30000 (38.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7391s / 76364.3794 s
agent0:                 episode reward: -0.3519,                 loss: nan
agent1:                 episode reward: 0.3519,                 loss: 0.1323
Episode: 11541/30000 (38.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.4891s / 76500.8685 s
agent0:                 episode reward: -0.6309,                 loss: nan
agent1:                 episode reward: 0.6309,                 loss: 0.1334
Episode: 11561/30000 (38.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9724s / 76635.8409 s
agent0:                 episode reward: -0.6265,                 loss: nan
agent1:                 episode reward: 0.6265,                 loss: 0.1316
Episode: 11581/30000 (38.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.7651s / 76772.6060 s
agent0:                 episode reward: -0.2979,                 loss: nan
agent1:                 episode reward: 0.2979,                 loss: 0.1316
Episode: 11601/30000 (38.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2785s / 76908.8844 s
agent0:                 episode reward: -0.7380,                 loss: nan
agent1:                 episode reward: 0.7380,                 loss: 0.1327
Episode: 11621/30000 (38.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1751s / 77042.0595 s
agent0:                 episode reward: -0.1072,                 loss: nan
agent1:                 episode reward: 0.1072,                 loss: 0.1311
Episode: 11641/30000 (38.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1015s / 77176.1611 s
agent0:                 episode reward: -0.1980,                 loss: nan
agent1:                 episode reward: 0.1980,                 loss: 0.1318
Episode: 11661/30000 (38.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7954s / 77309.9565 s
agent0:                 episode reward: -0.3281,                 loss: nan
agent1:                 episode reward: 0.3281,                 loss: 0.1322
Episode: 11681/30000 (38.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3076s / 77444.2641 s
agent0:                 episode reward: -0.4341,                 loss: nan
agent1:                 episode reward: 0.4341,                 loss: 0.1308
Episode: 11701/30000 (39.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9455s / 77579.2095 s
agent0:                 episode reward: -0.4268,                 loss: nan
agent1:                 episode reward: 0.4268,                 loss: 0.1331
Episode: 11721/30000 (39.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8354s / 77714.0450 s
agent0:                 episode reward: -0.3486,                 loss: nan
agent1:                 episode reward: 0.3486,                 loss: 0.1325
Episode: 11741/30000 (39.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2659s / 77848.3108 s
agent0:                 episode reward: -0.3794,                 loss: nan
agent1:                 episode reward: 0.3794,                 loss: 0.1325
Episode: 11761/30000 (39.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.5878s / 77984.8986 s
agent0:                 episode reward: -0.5520,                 loss: nan
agent1:                 episode reward: 0.5520,                 loss: 0.1319
Episode: 11781/30000 (39.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2353s / 78120.1339 s
agent0:                 episode reward: -0.2122,                 loss: nan
agent1:                 episode reward: 0.2122,                 loss: 0.1311
Episode: 11801/30000 (39.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 131.1131s / 78251.2470 s
agent0:                 episode reward: -0.6505,                 loss: nan
agent1:                 episode reward: 0.6505,                 loss: 0.1313
Episode: 11821/30000 (39.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 139.5065s / 78390.7536 s
agent0:                 episode reward: -0.6790,                 loss: nan
agent1:                 episode reward: 0.6790,                 loss: 0.1326
Episode: 11841/30000 (39.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.7675s / 78523.5211 s
agent0:                 episode reward: -0.6995,                 loss: nan
agent1:                 episode reward: 0.6995,                 loss: 0.1314
Episode: 11861/30000 (39.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7503s / 78661.2714 s
agent0:                 episode reward: -0.6359,                 loss: nan
agent1:                 episode reward: 0.6359,                 loss: 0.1314
Episode: 11881/30000 (39.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.9772s / 78793.2486 s
agent0:                 episode reward: -0.2550,                 loss: nan
agent1:                 episode reward: 0.2550,                 loss: 0.1319
Episode: 11901/30000 (39.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0243s / 78928.2729 s
agent0:                 episode reward: -0.2357,                 loss: nan
agent1:                 episode reward: 0.2357,                 loss: 0.1321
Episode: 11921/30000 (39.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6534s / 79062.9263 s
agent0:                 episode reward: -0.4127,                 loss: nan
agent1:                 episode reward: 0.4127,                 loss: 0.1322
Episode: 11941/30000 (39.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4101s / 79196.3363 s
agent0:                 episode reward: -0.5170,                 loss: nan
agent1:                 episode reward: 0.5170,                 loss: 0.1322
Episode: 11961/30000 (39.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9096s / 79331.2459 s
agent0:                 episode reward: -0.7058,                 loss: nan
agent1:                 episode reward: 0.7058,                 loss: 0.1325
Episode: 11981/30000 (39.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.5902s / 79463.8361 s
agent0:                 episode reward: -0.4155,                 loss: nan
agent1:                 episode reward: 0.4155,                 loss: 0.1314
Episode: 12001/30000 (40.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5868s / 79598.4228 s
agent0:                 episode reward: -0.2552,                 loss: nan
agent1:                 episode reward: 0.2552,                 loss: 0.1302
Episode: 12021/30000 (40.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0655s / 79732.4883 s
agent0:                 episode reward: -0.2568,                 loss: nan
agent1:                 episode reward: 0.2568,                 loss: 0.1315
Episode: 12041/30000 (40.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7383s / 79870.2266 s
agent0:                 episode reward: -0.7422,                 loss: nan
agent1:                 episode reward: 0.7422,                 loss: 0.1314
Episode: 12061/30000 (40.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.3413s / 80007.5679 s
agent0:                 episode reward: -0.3727,                 loss: nan
agent1:                 episode reward: 0.3727,                 loss: 0.1299
Episode: 12081/30000 (40.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.3671s / 80140.9350 s
agent0:                 episode reward: -0.6248,                 loss: nan
agent1:                 episode reward: 0.6248,                 loss: 0.1322
Episode: 12101/30000 (40.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6055s / 80277.5405 s
agent0:                 episode reward: -0.7695,                 loss: nan
agent1:                 episode reward: 0.7695,                 loss: 0.1315
Episode: 12121/30000 (40.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4216s / 80410.9621 s
agent0:                 episode reward: -0.4399,                 loss: nan
agent1:                 episode reward: 0.4399,                 loss: 0.1304
Episode: 12141/30000 (40.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6263s / 80546.5884 s
agent0:                 episode reward: -0.4428,                 loss: nan
agent1:                 episode reward: 0.4428,                 loss: 0.1315
Episode: 12161/30000 (40.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8795s / 80682.4679 s
agent0:                 episode reward: -0.0073,                 loss: nan
agent1:                 episode reward: 0.0073,                 loss: 0.1318
Episode: 12181/30000 (40.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3445s / 80817.8124 s
agent0:                 episode reward: -0.3373,                 loss: nan
agent1:                 episode reward: 0.3373,                 loss: 0.1330
Episode: 12201/30000 (40.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3501s / 80954.1625 s
agent0:                 episode reward: -0.8192,                 loss: nan
agent1:                 episode reward: 0.8192,                 loss: 0.1308
Episode: 12221/30000 (40.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9380s / 81088.1005 s
agent0:                 episode reward: -0.4284,                 loss: nan
agent1:                 episode reward: 0.4284,                 loss: 0.1314
Episode: 12241/30000 (40.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1805s / 81222.2809 s
agent0:                 episode reward: -0.7201,                 loss: nan
agent1:                 episode reward: 0.7201,                 loss: 0.1320
Episode: 12261/30000 (40.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0439s / 81355.3248 s
agent0:                 episode reward: -0.3649,                 loss: nan
agent1:                 episode reward: 0.3649,                 loss: 0.1317
Episode: 12281/30000 (40.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0780s / 81492.4028 s
agent0:                 episode reward: -0.0237,                 loss: nan
agent1:                 episode reward: 0.0237,                 loss: 0.1317
Episode: 12301/30000 (41.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2233s / 81627.6260 s
agent0:                 episode reward: -0.6122,                 loss: nan
agent1:                 episode reward: 0.6122,                 loss: 0.1321
Episode: 12321/30000 (41.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4502s / 81763.0763 s
agent0:                 episode reward: -0.6766,                 loss: nan
agent1:                 episode reward: 0.6766,                 loss: 0.1310
Episode: 12341/30000 (41.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.1823s / 81895.2586 s
agent0:                 episode reward: -0.1937,                 loss: nan
agent1:                 episode reward: 0.1937,                 loss: 0.1316
Episode: 12361/30000 (41.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.9815s / 82033.2401 s
agent0:                 episode reward: -0.1236,                 loss: nan
agent1:                 episode reward: 0.1236,                 loss: 0.1306
Episode: 12381/30000 (41.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8072s / 82168.0473 s
agent0:                 episode reward: -0.1920,                 loss: nan
agent1:                 episode reward: 0.1920,                 loss: 0.1322
Episode: 12401/30000 (41.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3942s / 82302.4415 s
agent0:                 episode reward: -0.2910,                 loss: nan
agent1:                 episode reward: 0.2910,                 loss: 0.1330
Episode: 12421/30000 (41.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6992s / 82437.1406 s
agent0:                 episode reward: -0.0540,                 loss: nan
agent1:                 episode reward: 0.0540,                 loss: 0.1312
Episode: 12441/30000 (41.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3343s / 82572.4750 s
agent0:                 episode reward: -0.4814,                 loss: nan
agent1:                 episode reward: 0.4814,                 loss: 0.1309
Episode: 12461/30000 (41.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.1235s / 82708.5984 s
agent0:                 episode reward: -0.4871,                 loss: nan
agent1:                 episode reward: 0.4871,                 loss: 0.1303
Episode: 12481/30000 (41.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 130.2976s / 82838.8960 s
agent0:                 episode reward: -0.5732,                 loss: nan
agent1:                 episode reward: 0.5732,                 loss: 0.1323
Episode: 12501/30000 (41.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3930s / 82973.2890 s
agent0:                 episode reward: -0.5180,                 loss: nan
agent1:                 episode reward: 0.5180,                 loss: 0.1298
Episode: 12521/30000 (41.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6374s / 83109.9264 s
agent0:                 episode reward: -0.5692,                 loss: nan
agent1:                 episode reward: 0.5692,                 loss: 0.1310
Episode: 12541/30000 (41.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5145s / 83247.4408 s
agent0:                 episode reward: -0.3673,                 loss: nan
agent1:                 episode reward: 0.3673,                 loss: 0.1322
Episode: 12561/30000 (41.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8938s / 83385.3347 s
agent0:                 episode reward: -0.2634,                 loss: nan
agent1:                 episode reward: 0.2634,                 loss: 0.1321
Episode: 12581/30000 (41.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8724s / 83521.2070 s
agent0:                 episode reward: -0.2335,                 loss: nan
agent1:                 episode reward: 0.2335,                 loss: 0.1313
Episode: 12601/30000 (42.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9702s / 83658.1772 s
agent0:                 episode reward: -0.7117,                 loss: nan
agent1:                 episode reward: 0.7117,                 loss: 0.1322
Episode: 12621/30000 (42.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8597s / 83792.0369 s
agent0:                 episode reward: -0.5421,                 loss: nan
agent1:                 episode reward: 0.5421,                 loss: 0.1316
Episode: 12641/30000 (42.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0290s / 83927.0659 s
agent0:                 episode reward: -0.3351,                 loss: nan
agent1:                 episode reward: 0.3351,                 loss: 0.1310
Episode: 12661/30000 (42.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0216s / 84060.0875 s
agent0:                 episode reward: -0.1772,                 loss: nan
agent1:                 episode reward: 0.1772,                 loss: 0.1316
Episode: 12681/30000 (42.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1439s / 84194.2315 s
agent0:                 episode reward: -0.5491,                 loss: nan
agent1:                 episode reward: 0.5491,                 loss: 0.1321
Episode: 12701/30000 (42.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.4614s / 84331.6929 s
agent0:                 episode reward: -0.5332,                 loss: nan
agent1:                 episode reward: 0.5332,                 loss: 0.1311
Episode: 12721/30000 (42.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 137.5795s / 84469.2723 s
agent0:                 episode reward: -0.5663,                 loss: nan
agent1:                 episode reward: 0.5663,                 loss: 0.1317
Episode: 12741/30000 (42.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.8802s / 84601.1526 s
agent0:                 episode reward: -0.3103,                 loss: nan
agent1:                 episode reward: 0.3103,                 loss: 0.1320
Episode: 12761/30000 (42.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.8637s / 84735.0163 s
agent0:                 episode reward: -0.7819,                 loss: nan
agent1:                 episode reward: 0.7819,                 loss: 0.1319
Episode: 12781/30000 (42.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3845s / 84870.4007 s
agent0:                 episode reward: 0.0589,                 loss: nan
agent1:                 episode reward: -0.0589,                 loss: 0.1305
Episode: 12801/30000 (42.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7170s / 85008.1177 s
agent0:                 episode reward: -0.5562,                 loss: nan
agent1:                 episode reward: 0.5562,                 loss: 0.1322
Episode: 12821/30000 (42.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.2995s / 85141.4173 s
agent0:                 episode reward: -0.7219,                 loss: nan
agent1:                 episode reward: 0.7219,                 loss: 0.1324
Episode: 12841/30000 (42.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3348s / 85277.7520 s
agent0:                 episode reward: -0.5791,                 loss: nan
agent1:                 episode reward: 0.5791,                 loss: 0.1314
Episode: 12861/30000 (42.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.5992s / 85412.3512 s
agent0:                 episode reward: -0.2186,                 loss: nan
agent1:                 episode reward: 0.2186,                 loss: 0.1319
Episode: 12881/30000 (42.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7925s / 85548.1437 s
agent0:                 episode reward: -0.4291,                 loss: nan
agent1:                 episode reward: 0.4291,                 loss: 0.1330
Episode: 12901/30000 (43.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2763s / 85683.4200 s
agent0:                 episode reward: -0.2669,                 loss: nan
agent1:                 episode reward: 0.2669,                 loss: 0.1315
Episode: 12921/30000 (43.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.1882s / 85821.6082 s
agent0:                 episode reward: -0.4895,                 loss: nan
agent1:                 episode reward: 0.4895,                 loss: 0.1322
Episode: 12941/30000 (43.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9750s / 85957.5832 s
agent0:                 episode reward: -0.7457,                 loss: nan
agent1:                 episode reward: 0.7457,                 loss: 0.1320
Episode: 12961/30000 (43.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 131.3759s / 86088.9592 s
agent0:                 episode reward: -0.5809,                 loss: nan
agent1:                 episode reward: 0.5809,                 loss: 0.1305
Episode: 12981/30000 (43.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4082s / 86224.3674 s
agent0:                 episode reward: -0.5210,                 loss: nan
agent1:                 episode reward: 0.5210,                 loss: 0.1308
Episode: 13001/30000 (43.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 137.0296s / 86361.3970 s
agent0:                 episode reward: -0.4938,                 loss: nan
agent1:                 episode reward: 0.4938,                 loss: 0.1334
Episode: 13021/30000 (43.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.4803s / 86494.8772 s
agent0:                 episode reward: -0.2042,                 loss: nan
agent1:                 episode reward: 0.2042,                 loss: 0.1322
Episode: 13041/30000 (43.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.2091s / 86629.0863 s
agent0:                 episode reward: -0.6642,                 loss: nan
agent1:                 episode reward: 0.6642,                 loss: 0.1318
Episode: 13061/30000 (43.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.7610s / 86763.8473 s
agent0:                 episode reward: -0.2515,                 loss: nan
agent1:                 episode reward: 0.2515,                 loss: 0.1322
Episode: 13081/30000 (43.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 133.0283s / 86896.8756 s
agent0:                 episode reward: -0.7340,                 loss: nan
agent1:                 episode reward: 0.7340,                 loss: 0.1321
Episode: 13101/30000 (43.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.0220s / 87034.8976 s
agent0:                 episode reward: -0.6179,                 loss: nan
agent1:                 episode reward: 0.6179,                 loss: 0.1322
Episode: 13121/30000 (43.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.7999s / 87168.6975 s
agent0:                 episode reward: -0.3569,                 loss: nan
agent1:                 episode reward: 0.3569,                 loss: 0.1307
Episode: 13141/30000 (43.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8260s / 87304.5234 s
agent0:                 episode reward: -0.6596,                 loss: nan
agent1:                 episode reward: 0.6596,                 loss: 0.1321
Episode: 13161/30000 (43.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0250s / 87440.5485 s
agent0:                 episode reward: -0.5493,                 loss: nan
agent1:                 episode reward: 0.5493,                 loss: 0.1305
Episode: 13181/30000 (43.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.1107s / 87574.6592 s
agent0:                 episode reward: -0.5419,                 loss: nan
agent1:                 episode reward: 0.5419,                 loss: 0.1314
Episode: 13201/30000 (44.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3702s / 87710.0294 s
agent0:                 episode reward: -0.6097,                 loss: nan
agent1:                 episode reward: 0.6097,                 loss: 0.1321
Episode: 13221/30000 (44.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.8313s / 87844.8607 s
agent0:                 episode reward: -0.3670,                 loss: nan
agent1:                 episode reward: 0.3670,                 loss: 0.1316
Episode: 13241/30000 (44.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.1878s / 87978.0485 s
agent0:                 episode reward: -0.5540,                 loss: nan
agent1:                 episode reward: 0.5540,                 loss: 0.1319
Episode: 13261/30000 (44.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 140.7444s / 88118.7929 s
agent0:                 episode reward: -0.5183,                 loss: nan
agent1:                 episode reward: 0.5183,                 loss: 0.1303
Episode: 13281/30000 (44.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0666s / 88254.8595 s
agent0:                 episode reward: -0.1601,                 loss: nan
agent1:                 episode reward: 0.1601,                 loss: 0.1299
Episode: 13301/30000 (44.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9988s / 88391.8583 s
agent0:                 episode reward: -0.4679,                 loss: nan
agent1:                 episode reward: 0.4679,                 loss: 0.1327
Episode: 13321/30000 (44.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3485s / 88528.2067 s
agent0:                 episode reward: -0.7505,                 loss: nan
agent1:                 episode reward: 0.7505,                 loss: 0.1315
Episode: 13341/30000 (44.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8439s / 88666.0506 s
agent0:                 episode reward: -0.9292,                 loss: nan
agent1:                 episode reward: 0.9292,                 loss: 0.1301
Episode: 13361/30000 (44.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.6704s / 88799.7210 s
agent0:                 episode reward: -0.7434,                 loss: nan
agent1:                 episode reward: 0.7434,                 loss: 0.1306
Episode: 13381/30000 (44.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.3179s / 88935.0389 s
agent0:                 episode reward: -0.2140,                 loss: nan
agent1:                 episode reward: 0.2140,                 loss: 0.1313
Episode: 13401/30000 (44.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9035s / 89067.9424 s
agent0:                 episode reward: -0.3736,                 loss: nan
agent1:                 episode reward: 0.3736,                 loss: 0.1307
Episode: 13421/30000 (44.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.8582s / 89203.8006 s
agent0:                 episode reward: -0.5338,                 loss: nan
agent1:                 episode reward: 0.5338,                 loss: 0.1298
Episode: 13441/30000 (44.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.0399s / 89338.8405 s
agent0:                 episode reward: -0.3081,                 loss: nan
agent1:                 episode reward: 0.3081,                 loss: 0.1306
Episode: 13461/30000 (44.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.8362s / 89470.6767 s
agent0:                 episode reward: -0.1530,                 loss: nan
agent1:                 episode reward: 0.1530,                 loss: 0.1314
Episode: 13481/30000 (44.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.0520s / 89606.7286 s
agent0:                 episode reward: -0.5310,                 loss: nan
agent1:                 episode reward: 0.5310,                 loss: 0.1299
Episode: 13501/30000 (45.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9603s / 89741.6889 s
agent0:                 episode reward: -0.6163,                 loss: nan
agent1:                 episode reward: 0.6163,                 loss: 0.1305
Episode: 13521/30000 (45.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2626s / 89876.9515 s
agent0:                 episode reward: -0.4351,                 loss: nan
agent1:                 episode reward: 0.4351,                 loss: 0.1318
Episode: 13541/30000 (45.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.1297s / 90012.0813 s
agent0:                 episode reward: 0.3005,                 loss: nan
agent1:                 episode reward: -0.3005,                 loss: 0.1298
Episode: 13561/30000 (45.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.3172s / 90148.3985 s
agent0:                 episode reward: -0.6372,                 loss: nan
agent1:                 episode reward: 0.6372,                 loss: 0.1317
Episode: 13581/30000 (45.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.2886s / 90283.6871 s
agent0:                 episode reward: -0.4347,                 loss: nan
agent1:                 episode reward: 0.4347,                 loss: 0.1307
Episode: 13601/30000 (45.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0058s / 90417.6928 s
agent0:                 episode reward: -0.7242,                 loss: nan
agent1:                 episode reward: 0.7242,                 loss: 0.1301
Episode: 13621/30000 (45.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7262s / 90553.4191 s
agent0:                 episode reward: -0.2830,                 loss: nan
agent1:                 episode reward: 0.2830,                 loss: 0.1315
Episode: 13641/30000 (45.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 136.9692s / 90690.3882 s
agent0:                 episode reward: -0.6500,                 loss: nan
agent1:                 episode reward: 0.6500,                 loss: 0.1315
Episode: 13661/30000 (45.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.4523s / 90825.8406 s
agent0:                 episode reward: -0.7639,                 loss: nan
agent1:                 episode reward: 0.7639,                 loss: 0.1318
Episode: 13681/30000 (45.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.9755s / 90961.8161 s
agent0:                 episode reward: -0.5790,                 loss: nan
agent1:                 episode reward: 0.5790,                 loss: 0.1325
Episode: 13701/30000 (45.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7383s / 91099.5543 s
agent0:                 episode reward: -0.4724,                 loss: nan
agent1:                 episode reward: 0.4724,                 loss: 0.1311
Episode: 13721/30000 (45.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9325s / 91234.4868 s
agent0:                 episode reward: -0.4036,                 loss: nan
agent1:                 episode reward: 0.4036,                 loss: 0.1297
Episode: 13741/30000 (45.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.9941s / 91369.4809 s
agent0:                 episode reward: -0.4685,                 loss: nan
agent1:                 episode reward: 0.4685,                 loss: 0.1320
Episode: 13761/30000 (45.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 131.1082s / 91500.5891 s
agent0:                 episode reward: -0.2853,                 loss: nan
agent1:                 episode reward: 0.2853,                 loss: 0.1305
Episode: 13781/30000 (45.9367%),                 avg. length: 2.0,                last time consumption/overall running time: 133.9753s / 91634.5644 s
agent0:                 episode reward: -0.3552,                 loss: nan
agent1:                 episode reward: 0.3552,                 loss: 0.1311
Episode: 13801/30000 (46.0033%),                 avg. length: 2.0,                last time consumption/overall running time: 134.0060s / 91768.5704 s
agent0:                 episode reward: -0.1288,                 loss: nan
agent1:                 episode reward: 0.1288,                 loss: 0.1309
Episode: 13821/30000 (46.0700%),                 avg. length: 2.0,                last time consumption/overall running time: 134.6211s / 91903.1916 s
agent0:                 episode reward: -0.9002,                 loss: nan
agent1:                 episode reward: 0.9002,                 loss: 0.1305
Episode: 13841/30000 (46.1367%),                 avg. length: 2.0,                last time consumption/overall running time: 136.2857s / 92039.4772 s
agent0:                 episode reward: -0.8354,                 loss: nan
agent1:                 episode reward: 0.8354,                 loss: 0.1312
Episode: 13861/30000 (46.2033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6713s / 92176.1486 s
agent0:                 episode reward: -0.4889,                 loss: nan
agent1:                 episode reward: 0.4889,                 loss: 0.1321
Episode: 13881/30000 (46.2700%),                 avg. length: 2.0,                last time consumption/overall running time: 138.7214s / 92314.8699 s
agent0:                 episode reward: -0.6489,                 loss: nan
agent1:                 episode reward: 0.6489,                 loss: 0.1316
Episode: 13901/30000 (46.3367%),                 avg. length: 2.0,                last time consumption/overall running time: 132.9490s / 92447.8190 s
agent0:                 episode reward: -0.4719,                 loss: nan
agent1:                 episode reward: 0.4719,                 loss: 0.1312
Episode: 13921/30000 (46.4033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.8961s / 92584.7151 s
agent0:                 episode reward: -0.6124,                 loss: nan
agent1:                 episode reward: 0.6124,                 loss: 0.1314
Episode: 13941/30000 (46.4700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.7859s / 92722.5010 s
agent0:                 episode reward: -0.8992,                 loss: nan
agent1:                 episode reward: 0.8992,                 loss: 0.1314
Episode: 13961/30000 (46.5367%),                 avg. length: 2.0,                last time consumption/overall running time: 134.3285s / 92856.8294 s
agent0:                 episode reward: -0.5861,                 loss: nan
agent1:                 episode reward: 0.5861,                 loss: 0.1309
Episode: 13981/30000 (46.6033%),                 avg. length: 2.0,                last time consumption/overall running time: 135.7027s / 92992.5321 s
agent0:                 episode reward: -0.6316,                 loss: nan
agent1:                 episode reward: 0.6316,                 loss: 0.1323
Episode: 14001/30000 (46.6700%),                 avg. length: 2.0,                last time consumption/overall running time: 135.5386s / 93128.0706 s
agent0:                 episode reward: -0.3391,                 loss: nan
agent1:                 episode reward: 0.3391,                 loss: 0.1313
Episode: 14021/30000 (46.7367%),                 avg. length: 2.0,                last time consumption/overall running time: 135.6119s / 93263.6825 s
agent0:                 episode reward: -0.3410,                 loss: nan
agent1:                 episode reward: 0.3410,                 loss: 0.1322
Episode: 14041/30000 (46.8033%),                 avg. length: 2.0,                last time consumption/overall running time: 136.6833s / 93400.3658 s
agent0:                 episode reward: -0.4963,                 loss: nan
agent1:                 episode reward: 0.4963,                 loss: 0.1329
Episode: 14061/30000 (46.8700%),                 avg. length: 2.0,                last time consumption/overall running time: 137.8670s / 93538.2329 s