pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 42.0, (1,), float32) action space: Discrete(6)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fd890963cc0>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518032943/mdp_arbitrary_mdp_nfsp/50000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518032943/mdp_arbitrary_mdp_nfsp/50000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518032943_exploit_50000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518032943_exploit_50000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 7.4652s / 7.4652 s
agent0:                 episode reward: 1.9178,                 loss: nan
agent1:                 episode reward: -1.9178,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4080s / 7.8732 s
agent0:                 episode reward: 0.5265,                 loss: nan
agent1:                 episode reward: -0.5265,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4002s / 8.2735 s
agent0:                 episode reward: 0.5769,                 loss: nan
agent1:                 episode reward: -0.5769,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3973s / 8.6708 s
agent0:                 episode reward: 0.0755,                 loss: nan
agent1:                 episode reward: -0.0755,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4004s / 9.0711 s
agent0:                 episode reward: 0.2792,                 loss: nan
agent1:                 episode reward: -0.2792,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3982s / 9.4693 s
agent0:                 episode reward: 0.2811,                 loss: nan
agent1:                 episode reward: -0.2811,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4033s / 9.8726 s
agent0:                 episode reward: -0.1881,                 loss: nan
agent1:                 episode reward: 0.1881,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4026s / 10.2753 s
agent0:                 episode reward: -0.0048,                 loss: nan
agent1:                 episode reward: 0.0048,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3994s / 10.6747 s
agent0:                 episode reward: 0.3375,                 loss: nan
agent1:                 episode reward: -0.3375,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3942s / 11.0689 s
agent0:                 episode reward: 0.3295,                 loss: nan
agent1:                 episode reward: -0.3295,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3950s / 11.4638 s
agent0:                 episode reward: 0.4726,                 loss: nan
agent1:                 episode reward: -0.4726,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3943s / 11.8581 s
agent0:                 episode reward: 0.0057,                 loss: nan
agent1:                 episode reward: -0.0057,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3965s / 12.2547 s
agent0:                 episode reward: 0.1603,                 loss: nan
agent1:                 episode reward: -0.1603,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3946s / 12.6492 s
agent0:                 episode reward: -0.1273,                 loss: nan
agent1:                 episode reward: 0.1273,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3986s / 13.0478 s
agent0:                 episode reward: 0.3304,                 loss: nan
agent1:                 episode reward: -0.3304,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3924s / 13.4402 s
agent0:                 episode reward: 0.2071,                 loss: nan
agent1:                 episode reward: -0.2071,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3959s / 13.8361 s
agent0:                 episode reward: 0.7221,                 loss: nan
agent1:                 episode reward: -0.7221,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3946s / 14.2307 s
agent0:                 episode reward: 0.7553,                 loss: nan
agent1:                 episode reward: -0.7553,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3938s / 14.6246 s
agent0:                 episode reward: 0.9490,                 loss: nan
agent1:                 episode reward: -0.9490,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3963s / 15.0209 s
agent0:                 episode reward: 0.0467,                 loss: nan
agent1:                 episode reward: -0.0467,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3958s / 15.4167 s
agent0:                 episode reward: 0.3651,                 loss: nan
agent1:                 episode reward: -0.3651,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4018s / 15.8185 s
agent0:                 episode reward: 0.4340,                 loss: nan
agent1:                 episode reward: -0.4340,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3949s / 16.2134 s
agent0:                 episode reward: 0.1697,                 loss: nan
agent1:                 episode reward: -0.1697,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3964s / 16.6099 s
agent0:                 episode reward: 0.3847,                 loss: nan
agent1:                 episode reward: -0.3847,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3924s / 17.0023 s
agent0:                 episode reward: 0.2831,                 loss: nan
agent1:                 episode reward: -0.2831,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3916s / 17.3939 s
agent0:                 episode reward: 0.2960,                 loss: nan
agent1:                 episode reward: -0.2960,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3983s / 17.7922 s
agent0:                 episode reward: 0.0839,                 loss: nan
agent1:                 episode reward: -0.0839,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3878s / 18.1800 s
agent0:                 episode reward: -0.0769,                 loss: nan
agent1:                 episode reward: 0.0769,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3949s / 18.5749 s
agent0:                 episode reward: 0.0474,                 loss: nan
agent1:                 episode reward: -0.0474,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3949s / 18.9698 s
agent0:                 episode reward: 0.0256,                 loss: nan
agent1:                 episode reward: -0.0256,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3935s / 19.3633 s
agent0:                 episode reward: 0.8341,                 loss: nan
agent1:                 episode reward: -0.8341,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3984s / 19.7617 s
agent0:                 episode reward: 0.8895,                 loss: nan
agent1:                 episode reward: -0.8895,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3949s / 20.1566 s
agent0:                 episode reward: 0.6500,                 loss: nan
agent1:                 episode reward: -0.6500,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3915s / 20.5481 s
agent0:                 episode reward: -0.1572,                 loss: nan
agent1:                 episode reward: 0.1572,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3958s / 20.9439 s
agent0:                 episode reward: 0.2890,                 loss: nan
agent1:                 episode reward: -0.2890,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3893s / 21.3331 s
agent0:                 episode reward: 0.7366,                 loss: nan
agent1:                 episode reward: -0.7366,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3861s / 21.7192 s
agent0:                 episode reward: 0.5170,                 loss: nan
agent1:                 episode reward: -0.5170,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3919s / 22.1111 s
agent0:                 episode reward: 1.0998,                 loss: nan
agent1:                 episode reward: -1.0998,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3943s / 22.5054 s
agent0:                 episode reward: 0.1175,                 loss: nan
agent1:                 episode reward: -0.1175,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3935s / 22.8989 s
agent0:                 episode reward: 0.0292,                 loss: nan
agent1:                 episode reward: -0.0292,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3933s / 23.2922 s
agent0:                 episode reward: 0.4633,                 loss: nan
agent1:                 episode reward: -0.4633,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3913s / 23.6835 s
agent0:                 episode reward: -0.1000,                 loss: nan
agent1:                 episode reward: 0.1000,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3877s / 24.0712 s
agent0:                 episode reward: -0.4462,                 loss: nan
agent1:                 episode reward: 0.4462,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3970s / 24.4682 s
agent0:                 episode reward: 0.1810,                 loss: nan
agent1:                 episode reward: -0.1810,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3942s / 24.8624 s
agent0:                 episode reward: 0.3754,                 loss: nan
agent1:                 episode reward: -0.3754,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3870s / 25.2493 s
agent0:                 episode reward: 0.9331,                 loss: nan
agent1:                 episode reward: -0.9331,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3906s / 25.6400 s
agent0:                 episode reward: 0.0747,                 loss: nan
agent1:                 episode reward: -0.0747,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4014s / 26.0414 s
agent0:                 episode reward: -0.0146,                 loss: nan
agent1:                 episode reward: 0.0146,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3940s / 26.4353 s
agent0:                 episode reward: 0.0742,                 loss: nan
agent1:                 episode reward: -0.0742,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3945s / 26.8299 s
agent0:                 episode reward: 0.1707,                 loss: nan
agent1:                 episode reward: -0.1707,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3950s / 27.2249 s
agent0:                 episode reward: 0.1279,                 loss: nan
agent1:                 episode reward: -0.1279,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3996s / 27.6245 s
agent0:                 episode reward: 0.7484,                 loss: nan
agent1:                 episode reward: -0.7484,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3954s / 28.0198 s
agent0:                 episode reward: 0.3306,                 loss: nan
agent1:                 episode reward: -0.3306,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3925s / 28.4123 s
agent0:                 episode reward: 0.5061,                 loss: nan
agent1:                 episode reward: -0.5061,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3907s / 28.8030 s
agent0:                 episode reward: 0.7398,                 loss: nan
agent1:                 episode reward: -0.7398,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3938s / 29.1968 s
agent0:                 episode reward: -0.2000,                 loss: nan
agent1:                 episode reward: 0.2000,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3901s / 29.5869 s
agent0:                 episode reward: 0.0146,                 loss: nan
agent1:                 episode reward: -0.0146,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3942s / 29.9812 s
agent0:                 episode reward: 0.5778,                 loss: nan
agent1:                 episode reward: -0.5778,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4039s / 30.3851 s
agent0:                 episode reward: 0.1806,                 loss: nan
agent1:                 episode reward: -0.1806,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4005s / 30.7856 s
agent0:                 episode reward: -0.0483,                 loss: nan
agent1:                 episode reward: 0.0483,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3943s / 31.1799 s
agent0:                 episode reward: -0.0476,                 loss: nan
agent1:                 episode reward: 0.0476,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3946s / 31.5745 s
agent0:                 episode reward: 0.2950,                 loss: nan
agent1:                 episode reward: -0.2950,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3946s / 31.9691 s
agent0:                 episode reward: 0.1215,                 loss: nan
agent1:                 episode reward: -0.1215,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3990s / 32.3681 s
agent0:                 episode reward: 0.0288,                 loss: nan
agent1:                 episode reward: -0.0288,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3932s / 32.7614 s
agent0:                 episode reward: 0.3941,                 loss: nan
agent1:                 episode reward: -0.3941,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3952s / 33.1566 s
agent0:                 episode reward: 0.3937,                 loss: nan
agent1:                 episode reward: -0.3937,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3911s / 33.5477 s
agent0:                 episode reward: 0.6370,                 loss: nan
agent1:                 episode reward: -0.6370,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3914s / 33.9391 s
agent0:                 episode reward: 0.3884,                 loss: nan
agent1:                 episode reward: -0.3884,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3923s / 34.3314 s
agent0:                 episode reward: 0.7601,                 loss: nan
agent1:                 episode reward: -0.7601,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3913s / 34.7227 s
agent0:                 episode reward: 0.3972,                 loss: nan
agent1:                 episode reward: -0.3972,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3965s / 35.1192 s
agent0:                 episode reward: 0.2591,                 loss: nan
agent1:                 episode reward: -0.2591,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3946s / 35.5139 s
agent0:                 episode reward: 0.1078,                 loss: nan
agent1:                 episode reward: -0.1078,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3891s / 35.9029 s
agent0:                 episode reward: 0.0383,                 loss: nan
agent1:                 episode reward: -0.0383,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3936s / 36.2966 s
agent0:                 episode reward: 0.3440,                 loss: nan
agent1:                 episode reward: -0.3440,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3976s / 36.6941 s
agent0:                 episode reward: -0.2733,                 loss: nan
agent1:                 episode reward: 0.2733,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3812s / 37.0753 s
agent0:                 episode reward: 0.4240,                 loss: nan
agent1:                 episode reward: -0.4240,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4183s / 37.4936 s
agent0:                 episode reward: 0.3462,                 loss: nan
agent1:                 episode reward: -0.3462,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3899s / 37.8835 s
agent0:                 episode reward: 0.5221,                 loss: nan
agent1:                 episode reward: -0.5221,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3992s / 38.2826 s
agent0:                 episode reward: 0.4972,                 loss: nan
agent1:                 episode reward: -0.4972,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3945s / 38.6771 s
agent0:                 episode reward: 0.3070,                 loss: nan
agent1:                 episode reward: -0.3070,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3999s / 39.0771 s
agent0:                 episode reward: 0.3456,                 loss: nan
agent1:                 episode reward: -0.3456,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3973s / 39.4744 s
agent0:                 episode reward: 0.2071,                 loss: nan
agent1:                 episode reward: -0.2071,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3933s / 39.8676 s
agent0:                 episode reward: 0.5435,                 loss: nan
agent1:                 episode reward: -0.5435,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.2294s / 40.0970 s
agent0:                 episode reward: -0.1619,                 loss: nan
agent1:                 episode reward: 0.1619,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.9753s / 42.0723 s
agent0:                 episode reward: 0.0959,                 loss: nan
agent1:                 episode reward: -0.0959,                 loss: 0.4453
Episode: 1701/30000 (5.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1472s / 43.2194 s
agent0:                 episode reward: 0.1638,                 loss: nan
agent1:                 episode reward: -0.1638,                 loss: 0.4315
Episode: 1721/30000 (5.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1376s / 44.3570 s
agent0:                 episode reward: -0.1676,                 loss: nan
agent1:                 episode reward: 0.1676,                 loss: 0.4278
Episode: 1741/30000 (5.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1372s / 45.4942 s
agent0:                 episode reward: -0.1462,                 loss: nan
agent1:                 episode reward: 0.1462,                 loss: 0.4236
Episode: 1761/30000 (5.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1397s / 46.6339 s
agent0:                 episode reward: -0.1935,                 loss: nan
agent1:                 episode reward: 0.1935,                 loss: 0.4187
Episode: 1781/30000 (5.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1477s / 47.7816 s
agent0:                 episode reward: -0.3478,                 loss: nan
agent1:                 episode reward: 0.3478,                 loss: 0.4133
Episode: 1801/30000 (6.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1365s / 48.9181 s
agent0:                 episode reward: -0.0077,                 loss: nan
agent1:                 episode reward: 0.0077,                 loss: 0.4081
Episode: 1821/30000 (6.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1446s / 50.0627 s
agent0:                 episode reward: 0.1022,                 loss: nan
agent1:                 episode reward: -0.1022,                 loss: 0.4029
Episode: 1841/30000 (6.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1554s / 51.2180 s
agent0:                 episode reward: 0.1917,                 loss: nan
agent1:                 episode reward: -0.1917,                 loss: 0.4208
Episode: 1861/30000 (6.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1524s / 52.3705 s
agent0:                 episode reward: 0.7178,                 loss: nan
agent1:                 episode reward: -0.7178,                 loss: 0.4507
Episode: 1881/30000 (6.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1385s / 53.5090 s
agent0:                 episode reward: -0.4989,                 loss: nan
agent1:                 episode reward: 0.4989,                 loss: 0.4496
Episode: 1901/30000 (6.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1501s / 54.6591 s
agent0:                 episode reward: 0.5297,                 loss: nan
agent1:                 episode reward: -0.5297,                 loss: 0.4481
Episode: 1921/30000 (6.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1446s / 55.8037 s
agent0:                 episode reward: -0.1047,                 loss: nan
agent1:                 episode reward: 0.1047,                 loss: 0.4489
Episode: 1941/30000 (6.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1536s / 56.9573 s
agent0:                 episode reward: -0.3719,                 loss: nan
agent1:                 episode reward: 0.3719,                 loss: 0.4480
Episode: 1961/30000 (6.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1435s / 58.1008 s
agent0:                 episode reward: 0.1360,                 loss: nan
agent1:                 episode reward: -0.1360,                 loss: 0.4471
Episode: 1981/30000 (6.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1468s / 59.2475 s
agent0:                 episode reward: -0.4397,                 loss: nan
agent1:                 episode reward: 0.4397,                 loss: 0.4465
Episode: 2001/30000 (6.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1489s / 60.3964 s
agent0:                 episode reward: 0.3208,                 loss: nan
agent1:                 episode reward: -0.3208,                 loss: 0.4467
Episode: 2021/30000 (6.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1663s / 61.5627 s
agent0:                 episode reward: 0.3122,                 loss: nan
agent1:                 episode reward: -0.3122,                 loss: 0.4433
Episode: 2041/30000 (6.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1648s / 62.7275 s
agent0:                 episode reward: -0.3934,                 loss: nan
agent1:                 episode reward: 0.3934,                 loss: 0.4422
Episode: 2061/30000 (6.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1519s / 63.8794 s
agent0:                 episode reward: 0.2042,                 loss: nan