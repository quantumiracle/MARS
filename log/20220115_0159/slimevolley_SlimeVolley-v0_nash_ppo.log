pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [52, 9]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 2, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'batch_size': 32, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220115_0159/slimevolley_SlimeVolley-v0_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220115_0159/slimevolley_SlimeVolley-v0_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 662.0,                last time consumption/overall running time: 6.0725s / 6.0725 s
env0_first_0:                 episode reward: 1.0000,                 loss: -0.0224
env0_second_0:                 episode reward: -1.0000,                 loss: -0.0517
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 561.25,                last time consumption/overall running time: 68.2128s / 74.2854 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0168
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0130
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 583.55,                last time consumption/overall running time: 70.5511s / 144.8365 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.1640
env0_second_0:                 episode reward: -0.5000,                 loss: 0.1509
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 550.65,                last time consumption/overall running time: 68.0784s / 212.9149 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.1996
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1856
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 557.0,                last time consumption/overall running time: 69.3717s / 282.2865 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.1890
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1848
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 602.65,                last time consumption/overall running time: 73.6687s / 355.9552 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2014
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2012
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 552.1,                last time consumption/overall running time: 68.3703s / 424.3255 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2154
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2143
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 589.8,                last time consumption/overall running time: 72.1937s / 496.5193 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.1777
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1864
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 571.15,                last time consumption/overall running time: 70.8563s / 567.3756 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2012
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2219
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 558.45,                last time consumption/overall running time: 69.0299s / 636.4055 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.1684
env0_second_0:                 episode reward: -0.8500,                 loss: 0.1904
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 592.2,                last time consumption/overall running time: 71.7366s / 708.1421 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.1983
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2066
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 577.55,                last time consumption/overall running time: 70.5208s / 778.6629 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2048
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2105
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 564.85,                last time consumption/overall running time: 69.4537s / 848.1166 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2183
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2314
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 574.4,                last time consumption/overall running time: 70.9678s / 919.0844 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2380
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2445
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 532.3,                last time consumption/overall running time: 66.7955s / 985.8799 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.1811
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2043
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 571.4,                last time consumption/overall running time: 71.5948s / 1057.4747 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2538
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2524
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 566.9,                last time consumption/overall running time: 69.5626s / 1127.0373 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2016
env0_second_0:                 episode reward: 1.1500,                 loss: 0.2207
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 551.15,                last time consumption/overall running time: 68.4439s / 1195.4813 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2210
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2313
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 561.4,                last time consumption/overall running time: 69.1429s / 1264.6242 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2447
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2425
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 547.3,                last time consumption/overall running time: 68.8773s / 1333.5014 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.1843
env0_second_0:                 episode reward: -0.2000,                 loss: 0.1877
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 563.6,                last time consumption/overall running time: 69.2882s / 1402.7896 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2298
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2400
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 537.8,                last time consumption/overall running time: 66.5720s / 1469.3616 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2385
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2403
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 555.75,                last time consumption/overall running time: 68.0328s / 1537.3944 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2322
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2294
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 558.45,                last time consumption/overall running time: 69.1609s / 1606.5553 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2136
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2244
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 555.75,                last time consumption/overall running time: 68.8056s / 1675.3609 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2370
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2385
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 570.15,                last time consumption/overall running time: 70.3050s / 1745.6659 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2022
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2241
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 589.8,                last time consumption/overall running time: 73.0459s / 1818.7118 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2265
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2254
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 582.1,                last time consumption/overall running time: 71.3441s / 1890.0559 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2382
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2322
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 567.3,                last time consumption/overall running time: 70.2871s / 1960.3429 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.2204
env0_second_0:                 episode reward: -1.1500,                 loss: 0.2200
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 631.5,                last time consumption/overall running time: 76.9573s / 2037.3003 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2462
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2390
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 526.15,                last time consumption/overall running time: 65.2144s / 2102.5147 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2451
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2415
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 598.15,                last time consumption/overall running time: 74.1606s / 2176.6753 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2692
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2710
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 595.2,                last time consumption/overall running time: 73.5709s / 2250.2462 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2398
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2368
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 563.15,                last time consumption/overall running time: 69.5370s / 2319.7831 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2512
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2408
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 584.75,                last time consumption/overall running time: 71.6891s / 2391.4723 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2374
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2470
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 584.45,                last time consumption/overall running time: 72.4329s / 2463.9052 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2390
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2428
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 585.45,                last time consumption/overall running time: 72.6989s / 2536.6040 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2327
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2412
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 611.4,                last time consumption/overall running time: 75.0603s / 2611.6644 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2330
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2363
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 572.65,                last time consumption/overall running time: 70.3984s / 2682.0628 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2328
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2429
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 588.0,                last time consumption/overall running time: 72.8547s / 2754.9175 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2578
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2601
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 547.1,                last time consumption/overall running time: 68.0663s / 2822.9838 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2432
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2419
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 549.1,                last time consumption/overall running time: 67.6923s / 2890.6761 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2564
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2564
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 562.5,                last time consumption/overall running time: 69.1875s / 2959.8636 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2448
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2475
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 573.7,                last time consumption/overall running time: 70.6908s / 3030.5544 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2373
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2418
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 528.7,                last time consumption/overall running time: 66.1929s / 3096.7473 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2637
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2649
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 554.75,                last time consumption/overall running time: 69.2260s / 3165.9733 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2125
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2164
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 552.0,                last time consumption/overall running time: 68.5061s / 3234.4794 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2455
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2477
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 577.8,                last time consumption/overall running time: 71.4951s / 3305.9745 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2528
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2525
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 587.5,                last time consumption/overall running time: 72.7697s / 3378.7442 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2530
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2614
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 573.9,                last time consumption/overall running time: 70.3968s / 3449.1410 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2415
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2380
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 539.55,                last time consumption/overall running time: 67.8755s / 3517.0165 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2569
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2565
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 521.25,                last time consumption/overall running time: 64.6318s / 3581.6483 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2536
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2533
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 543.8,                last time consumption/overall running time: 66.9869s / 3648.6352 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2799
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2758
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 562.05,                last time consumption/overall running time: 69.6381s / 3718.2734 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2378
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2425
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 575.05,                last time consumption/overall running time: 71.5153s / 3789.7887 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2343
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2411
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 576.1,                last time consumption/overall running time: 70.7451s / 3860.5338 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2538
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2570
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 570.85,                last time consumption/overall running time: 70.2139s / 3930.7476 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2505
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2555
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 546.3,                last time consumption/overall running time: 68.4060s / 3999.1537 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2465
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2540
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 560.25,                last time consumption/overall running time: 68.8854s / 4068.0390 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2791
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2862
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 543.5,                last time consumption/overall running time: 67.5407s / 4135.5797 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2436
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2376
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 570.8,                last time consumption/overall running time: 70.9408s / 4206.5206 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2413
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2409
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 589.05,                last time consumption/overall running time: 71.9640s / 4278.4845 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2413
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2388
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 603.1,                last time consumption/overall running time: 72.2810s / 4350.7655 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2387
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2320
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 595.55,                last time consumption/overall running time: 72.7032s / 4423.4688 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2749
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2782
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 590.55,                last time consumption/overall running time: 71.2324s / 4494.7011 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2724
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2712
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 573.1,                last time consumption/overall running time: 71.5998s / 4566.3010 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2502
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2552
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 592.0,                last time consumption/overall running time: 72.2813s / 4638.5823 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2656
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2600
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 579.2,                last time consumption/overall running time: 71.9591s / 4710.5414 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2462
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2497
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 539.9,                last time consumption/overall running time: 66.7979s / 4777.3393 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2451
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2489
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 544.65,                last time consumption/overall running time: 67.0350s / 4844.3743 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2476
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2485
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 576.0,                last time consumption/overall running time: 70.9126s / 4915.2869 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2496
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2498
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 587.1,                last time consumption/overall running time: 71.6122s / 4986.8991 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2604
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2576
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 596.2,                last time consumption/overall running time: 72.5639s / 5059.4630 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2609
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2626
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 579.0,                last time consumption/overall running time: 71.1381s / 5130.6012 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2746
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2703
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 563.25,                last time consumption/overall running time: 69.2923s / 5199.8934 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2739
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2673
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 573.4,                last time consumption/overall running time: 70.1088s / 5270.0022 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2340
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2423
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 552.45,                last time consumption/overall running time: 67.5337s / 5337.5359 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2742
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2633
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 572.65,                last time consumption/overall running time: 69.9336s / 5407.4695 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2285
env0_second_0:                 episode reward: 1.2500,                 loss: 0.2420
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 586.85,                last time consumption/overall running time: 71.9758s / 5479.4453 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2717
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2761
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 569.65,                last time consumption/overall running time: 70.9119s / 5550.3572 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2508
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2493
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 578.75,                last time consumption/overall running time: 71.1659s / 5621.5231 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2502
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2457
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 599.1,                last time consumption/overall running time: 73.6371s / 5695.1602 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2597
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2576
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 575.6,                last time consumption/overall running time: 70.5170s / 5765.6772 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2495
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2480
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 546.3,                last time consumption/overall running time: 67.4632s / 5833.1404 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.2274
env0_second_0:                 episode reward: -1.5500,                 loss: 0.2245
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 521.75,                last time consumption/overall running time: 64.3353s / 5897.4756 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2558
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2641
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 578.15,                last time consumption/overall running time: 71.0338s / 5968.5095 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2368
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2403
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 550.8,                last time consumption/overall running time: 67.5733s / 6036.0827 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2702
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2669
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 523.0,                last time consumption/overall running time: 64.9882s / 6101.0709 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2478
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2506
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 536.8,                last time consumption/overall running time: 66.0482s / 6167.1191 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2610
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2507
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 569.85,                last time consumption/overall running time: 70.0282s / 6237.1473 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2517
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2455
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 542.7,                last time consumption/overall running time: 68.2297s / 6305.3770 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.2589
env0_second_0:                 episode reward: -1.2500,                 loss: 0.2580
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 582.05,                last time consumption/overall running time: 71.8814s / 6377.2584 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2624
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2620
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 591.95,                last time consumption/overall running time: 72.6144s / 6449.8728 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2295
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2331
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 552.55,                last time consumption/overall running time: 68.1317s / 6518.0045 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2702
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2727
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 556.0,                last time consumption/overall running time: 68.0583s / 6586.0628 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2636
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2647
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 607.95,                last time consumption/overall running time: 73.3997s / 6659.4625 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2596
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2609
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 532.95,                last time consumption/overall running time: 65.8690s / 6725.3315 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2458
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2406
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 581.05,                last time consumption/overall running time: 71.5649s / 6796.8964 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2693
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2747
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 590.35,                last time consumption/overall running time: 71.7950s / 6868.6915 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2613
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2590
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 580.9,                last time consumption/overall running time: 71.1146s / 6939.8060 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2402
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2413
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 531.7,                last time consumption/overall running time: 66.0068s / 7005.8128 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2618
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2616
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 543.05,                last time consumption/overall running time: 67.9135s / 7073.7263 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2462
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2483
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 566.05,                last time consumption/overall running time: 70.0258s / 7143.7521 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2439
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2516
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 615.4,                last time consumption/overall running time: 74.3951s / 7218.1472 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2600
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2629
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 607.7,                last time consumption/overall running time: 75.2092s / 7293.3564 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2549
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2597
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 572.85,                last time consumption/overall running time: 70.8554s / 7364.2118 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2478
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2508
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 596.2,                last time consumption/overall running time: 73.3785s / 7437.5903 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2481
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2542
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 559.2,                last time consumption/overall running time: 69.3671s / 7506.9574 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2603
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2616
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 593.9,                last time consumption/overall running time: 72.2910s / 7579.2484 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2538
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2468
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 565.75,                last time consumption/overall running time: 69.8360s / 7649.0843 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2747
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2808
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 582.45,                last time consumption/overall running time: 71.3616s / 7720.4459 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2520
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2503
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 584.4,                last time consumption/overall running time: 72.1602s / 7792.6061 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.2620
env0_second_0:                 episode reward: 1.5000,                 loss: 0.2551
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 586.05,                last time consumption/overall running time: 71.1807s / 7863.7868 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2610
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2644
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 541.4,                last time consumption/overall running time: 65.9939s / 7929.7807 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2666
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2661
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 532.5,                last time consumption/overall running time: 66.2711s / 7996.0518 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2766
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2724
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 570.45,                last time consumption/overall running time: 69.7305s / 8065.7823 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2609
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2537
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 564.9,                last time consumption/overall running time: 69.2715s / 8135.0539 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2263
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2359
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 578.1,                last time consumption/overall running time: 71.3520s / 8206.4059 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2795
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2821
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 599.6,                last time consumption/overall running time: 73.7764s / 8280.1823 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2748
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2740
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 563.45,                last time consumption/overall running time: 69.9184s / 8350.1006 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2648
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2678
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 569.05,                last time consumption/overall running time: 69.8991s / 8419.9997 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2537
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2625
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 589.75,                last time consumption/overall running time: 72.2879s / 8492.2876 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2588
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2576
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 542.25,                last time consumption/overall running time: 67.7676s / 8560.0553 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2585
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2524
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 585.35,                last time consumption/overall running time: 71.8944s / 8631.9496 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2764
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2838
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 548.85,                last time consumption/overall running time: 67.3233s / 8699.2729 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2847
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2835
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 569.85,                last time consumption/overall running time: 70.6566s / 8769.9296 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2450
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2475
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 579.75,                last time consumption/overall running time: 70.9102s / 8840.8398 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2888
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2924
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 562.65,                last time consumption/overall running time: 68.8725s / 8909.7123 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2615
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2582
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 572.15,                last time consumption/overall running time: 70.5608s / 8980.2731 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2862
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2841
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 568.2,                last time consumption/overall running time: 70.3664s / 9050.6395 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2810
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2809
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 573.9,                last time consumption/overall running time: 70.6518s / 9121.2913 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2561
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2534
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 576.0,                last time consumption/overall running time: 70.9845s / 9192.2758 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2697
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2569
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 530.1,                last time consumption/overall running time: 65.7082s / 9257.9839 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2866
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2767
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 597.0,                last time consumption/overall running time: 72.7664s / 9330.7503 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2560
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2624
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 609.9,                last time consumption/overall running time: 74.1188s / 9404.8691 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2711
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2667
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 556.05,                last time consumption/overall running time: 68.6678s / 9473.5368 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2749
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2664
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 556.8,                last time consumption/overall running time: 68.7397s / 9542.2765 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2682
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2752
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 575.2,                last time consumption/overall running time: 70.8428s / 9613.1193 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2797
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2811
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 538.35,                last time consumption/overall running time: 66.7189s / 9679.8382 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2496
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2502
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 596.95,                last time consumption/overall running time: 72.6060s / 9752.4442 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2734
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2821
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 561.45,                last time consumption/overall running time: 69.6843s / 9822.1285 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2648
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2611
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 580.45,                last time consumption/overall running time: 71.7650s / 9893.8934 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2773
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2762
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 587.45,                last time consumption/overall running time: 72.8477s / 9966.7411 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2531
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2605
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 548.95,                last time consumption/overall running time: 67.9144s / 10034.6555 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2521
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2666
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 591.4,                last time consumption/overall running time: 73.3347s / 10107.9902 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2515
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2638
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 581.1,                last time consumption/overall running time: 71.2762s / 10179.2664 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2586
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2600
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 560.85,                last time consumption/overall running time: 69.4070s / 10248.6734 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2671
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2675
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 582.7,                last time consumption/overall running time: 71.6429s / 10320.3164 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2599
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2566
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 541.45,                last time consumption/overall running time: 67.6270s / 10387.9433 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2563
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2567
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 576.0,                last time consumption/overall running time: 70.6132s / 10458.5565 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2864
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2855
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 555.55,                last time consumption/overall running time: 68.5920s / 10527.1486 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2697
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2679
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 571.1,                last time consumption/overall running time: 70.4451s / 10597.5937 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2826
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2789
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 594.65,                last time consumption/overall running time: 72.8659s / 10670.4595 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2631
env0_second_0:                 episode reward: 1.1500,                 loss: 0.2583
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 581.85,                last time consumption/overall running time: 71.6654s / 10742.1249 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.2666
env0_second_0:                 episode reward: 1.4000,                 loss: 0.2668
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 581.15,                last time consumption/overall running time: 71.6721s / 10813.7971 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2627
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2622
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 592.6,                last time consumption/overall running time: 71.6644s / 10885.4615 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2681
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2708
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 577.85,                last time consumption/overall running time: 70.8776s / 10956.3390 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2616
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2709
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 568.95,                last time consumption/overall running time: 71.0851s / 11027.4242 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2609
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2732
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 584.7,                last time consumption/overall running time: 71.0319s / 11098.4561 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2596
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2583
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 556.85,                last time consumption/overall running time: 68.8108s / 11167.2669 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2807
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2721
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 620.2,                last time consumption/overall running time: 75.2243s / 11242.4912 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2725
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2763
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 572.05,                last time consumption/overall running time: 70.0783s / 11312.5695 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2659
env0_second_0:                 episode reward: -1.0500,                 loss: 0.2662
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 587.4,                last time consumption/overall running time: 71.8238s / 11384.3933 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2562
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2626
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 595.9,                last time consumption/overall running time: 74.1571s / 11458.5505 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2731
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2743
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 565.35,                last time consumption/overall running time: 70.2992s / 11528.8497 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2588
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2625
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 577.45,                last time consumption/overall running time: 71.3247s / 11600.1745 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2637
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2630
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 569.25,                last time consumption/overall running time: 70.2584s / 11670.4329 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2822
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2748
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 565.05,                last time consumption/overall running time: 70.6307s / 11741.0635 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2402
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2482
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 575.55,                last time consumption/overall running time: 71.4250s / 11812.4886 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2651
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2733
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 548.6,                last time consumption/overall running time: 68.1161s / 11880.6047 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2430
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2511
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 572.8,                last time consumption/overall running time: 71.2581s / 11951.8628 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2705
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2676
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 588.1,                last time consumption/overall running time: 72.0922s / 12023.9550 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2632
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2637
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 597.4,                last time consumption/overall running time: 72.8015s / 12096.7565 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2496
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2441
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 569.95,                last time consumption/overall running time: 71.6029s / 12168.3594 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2535
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2513
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 594.7,                last time consumption/overall running time: 73.3997s / 12241.7591 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2883
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2848
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 552.85,                last time consumption/overall running time: 68.4497s / 12310.2088 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2440
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2466
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 581.05,                last time consumption/overall running time: 71.7181s / 12381.9269 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2720
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2830
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 557.45,                last time consumption/overall running time: 68.9102s / 12450.8370 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2723
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2701
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 593.2,                last time consumption/overall running time: 73.2496s / 12524.0866 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2666
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2596
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 549.8,                last time consumption/overall running time: 68.4209s / 12592.5075 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2736
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2813
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 557.2,                last time consumption/overall running time: 69.2814s / 12661.7889 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2803
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2893
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 570.75,                last time consumption/overall running time: 70.7847s / 12732.5736 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2702
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2663
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 540.75,                last time consumption/overall running time: 67.6419s / 12800.2155 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.2828
env0_second_0:                 episode reward: 1.5000,                 loss: 0.2735
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 578.2,                last time consumption/overall running time: 70.8305s / 12871.0459 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2620
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2728
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 564.25,                last time consumption/overall running time: 69.3053s / 12940.3512 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2693
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2736
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 578.65,                last time consumption/overall running time: 70.8221s / 13011.1734 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2606
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2557
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 609.5,                last time consumption/overall running time: 74.9732s / 13086.1466 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2742
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2772
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 580.0,                last time consumption/overall running time: 71.4715s / 13157.6181 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2708
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2752
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 616.3,                last time consumption/overall running time: 74.8635s / 13232.4816 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2611
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2644
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 586.25,                last time consumption/overall running time: 72.4230s / 13304.9045 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2342
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2342
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 571.4,                last time consumption/overall running time: 70.3827s / 13375.2872 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2561
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2526
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 593.45,                last time consumption/overall running time: 73.2552s / 13448.5424 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2571
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2578
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 564.95,                last time consumption/overall running time: 69.2279s / 13517.7703 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2955
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2951
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 545.25,                last time consumption/overall running time: 67.4176s / 13585.1878 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.2496
env0_second_0:                 episode reward: 1.4000,                 loss: 0.2671
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 558.0,                last time consumption/overall running time: 69.4254s / 13654.6133 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2698
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2716
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 586.45,                last time consumption/overall running time: 72.2353s / 13726.8485 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2764
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2690
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 554.9,                last time consumption/overall running time: 69.0275s / 13795.8760 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2619
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2535
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 569.05,                last time consumption/overall running time: 70.0792s / 13865.9552 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2680
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2618
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 612.9,                last time consumption/overall running time: 74.2307s / 13940.1859 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2777
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2808
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 525.95,                last time consumption/overall running time: 65.9293s / 14006.1152 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2642
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2717
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 560.35,                last time consumption/overall running time: 69.3838s / 14075.4990 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2748
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2717
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 570.85,                last time consumption/overall running time: 70.4374s / 14145.9365 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2666
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2677
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 575.3,                last time consumption/overall running time: 71.7459s / 14217.6824 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2518
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2542
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 578.9,                last time consumption/overall running time: 70.6968s / 14288.3792 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2579
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2700
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 539.5,                last time consumption/overall running time: 66.6245s / 14355.0037 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2583
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2513
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 588.2,                last time consumption/overall running time: 72.1362s / 14427.1399 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2634
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2578
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 551.95,                last time consumption/overall running time: 68.3431s / 14495.4830 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.2614
env0_second_0:                 episode reward: -1.5000,                 loss: 0.2532
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 607.35,                last time consumption/overall running time: 74.9567s / 14570.4397 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2768
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2594
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 580.1,                last time consumption/overall running time: 71.2506s / 14641.6903 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2715
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2703
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 606.35,                last time consumption/overall running time: 74.5255s / 14716.2158 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2672
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2683
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 599.35,                last time consumption/overall running time: 74.1703s / 14790.3861 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2734
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2822
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 563.4,                last time consumption/overall running time: 69.7100s / 14860.0961 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2474
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2447
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 613.7,                last time consumption/overall running time: 75.3888s / 14935.4849 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2592
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2607
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 591.75,                last time consumption/overall running time: 73.2190s / 15008.7039 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2540
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2511
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 552.1,                last time consumption/overall running time: 68.2410s / 15076.9448 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2597
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2521
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 541.9,                last time consumption/overall running time: 67.6569s / 15144.6017 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2665
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2803
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 572.6,                last time consumption/overall running time: 69.8865s / 15214.4882 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2557
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2468
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 563.3,                last time consumption/overall running time: 70.7583s / 15285.2465 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2632
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2533
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 533.25,                last time consumption/overall running time: 66.3018s / 15351.5483 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2695
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2661
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 578.35,                last time consumption/overall running time: 71.8984s / 15423.4467 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2787
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2685
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 539.45,                last time consumption/overall running time: 67.2799s / 15490.7265 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2490
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2378
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 583.7,                last time consumption/overall running time: 72.0871s / 15562.8137 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2645
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2590
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 595.35,                last time consumption/overall running time: 72.6455s / 15635.4592 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2558
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2423
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 551.4,                last time consumption/overall running time: 69.2424s / 15704.7016 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2504
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2469
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 610.85,                last time consumption/overall running time: 75.2914s / 15779.9930 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2419
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2322
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 574.1,                last time consumption/overall running time: 70.8930s / 15850.8860 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2746
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2773
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 582.65,                last time consumption/overall running time: 72.1319s / 15923.0179 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2956
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2845
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 567.5,                last time consumption/overall running time: 69.9322s / 15992.9501 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2644
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2629
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 560.0,                last time consumption/overall running time: 69.6205s / 16062.5706 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2586
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2589
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 570.15,                last time consumption/overall running time: 70.0328s / 16132.6034 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2691
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2645
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 587.35,                last time consumption/overall running time: 71.6405s / 16204.2439 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2653
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2616
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 580.3,                last time consumption/overall running time: 71.2859s / 16275.5298 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2489
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2334
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 546.75,                last time consumption/overall running time: 67.9063s / 16343.4361 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.2526
env0_second_0:                 episode reward: -1.3500,                 loss: 0.2592
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 559.6,                last time consumption/overall running time: 69.6092s / 16413.0453 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2748
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2716
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 575.0,                last time consumption/overall running time: 70.9179s / 16483.9632 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2636
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2503
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 571.55,                last time consumption/overall running time: 70.8166s / 16554.7798 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2596
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2517
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 552.05,                last time consumption/overall running time: 67.6941s / 16622.4739 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2519
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2528
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 598.7,                last time consumption/overall running time: 74.2207s / 16696.6946 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.2669
env0_second_0:                 episode reward: 1.9500,                 loss: 0.2616
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 557.65,                last time consumption/overall running time: 68.6337s / 16765.3283 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2531
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2518
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 601.55,                last time consumption/overall running time: 73.4900s / 16838.8183 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2554
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2537
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 541.1,                last time consumption/overall running time: 67.8615s / 16906.6798 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2816
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2643
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 587.7,                last time consumption/overall running time: 72.1479s / 16978.8277 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2622
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2513
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 566.9,                last time consumption/overall running time: 70.9388s / 17049.7665 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2517
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2483
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 564.3,                last time consumption/overall running time: 69.7857s / 17119.5522 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2621
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2542
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 563.25,                last time consumption/overall running time: 69.6336s / 17189.1858 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2573
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2532
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 596.7,                last time consumption/overall running time: 73.3365s / 17262.5223 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2591
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2563
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 598.8,                last time consumption/overall running time: 73.4626s / 17335.9849 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2536
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2507
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 586.4,                last time consumption/overall running time: 73.0230s / 17409.0079 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2756
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2641
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 575.05,                last time consumption/overall running time: 70.9206s / 17479.9284 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2643
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2589
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 600.0,                last time consumption/overall running time: 73.5130s / 17553.4414 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2506
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2376
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 536.7,                last time consumption/overall running time: 66.8841s / 17620.3256 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2717
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2728
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 537.55,                last time consumption/overall running time: 66.8026s / 17687.1282 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2445
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2336
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 566.85,                last time consumption/overall running time: 69.7337s / 17756.8619 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2506
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2463
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 635.65,                last time consumption/overall running time: 77.9821s / 17834.8440 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2640
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2658
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 542.3,                last time consumption/overall running time: 67.2600s / 17902.1040 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2621
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2556
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 606.95,                last time consumption/overall running time: 73.9512s / 17976.0552 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2668
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2681
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 585.65,                last time consumption/overall running time: 71.6335s / 18047.6887 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2724
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2585
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 572.45,                last time consumption/overall running time: 70.3061s / 18117.9949 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2414
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2436
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 567.1,                last time consumption/overall running time: 70.8023s / 18188.7971 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2389
env0_second_0:                 episode reward: 1.2500,                 loss: 0.2279
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 561.4,                last time consumption/overall running time: 69.0430s / 18257.8402 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2711
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2636
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 551.8,                last time consumption/overall running time: 68.4376s / 18326.2778 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2550
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2473
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 549.2,                last time consumption/overall running time: 68.8895s / 18395.1673 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2685
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2687
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 581.75,                last time consumption/overall running time: 72.5505s / 18467.7178 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2640
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2529
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 570.3,                last time consumption/overall running time: 71.3185s / 18539.0363 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.2354
env0_second_0:                 episode reward: -1.3500,                 loss: 0.2287
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 578.5,                last time consumption/overall running time: 72.0813s / 18611.1176 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.2455
env0_second_0:                 episode reward: 1.3000,                 loss: 0.2350
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 571.65,                last time consumption/overall running time: 70.9972s / 18682.1148 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2510
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2481
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 551.6,                last time consumption/overall running time: 67.7401s / 18749.8549 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2613
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2438
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 610.8,                last time consumption/overall running time: 74.4864s / 18824.3413 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2820
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2635
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 587.75,                last time consumption/overall running time: 72.3849s / 18896.7262 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2549
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2602
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 593.6,                last time consumption/overall running time: 73.2837s / 18970.0098 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2493
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2417
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 559.65,                last time consumption/overall running time: 68.9990s / 19039.0088 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2690
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2665
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 601.9,                last time consumption/overall running time: 73.8911s / 19112.8999 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.2465
env0_second_0:                 episode reward: -1.1000,                 loss: 0.2397
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 563.5,                last time consumption/overall running time: 69.3099s / 19182.2099 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2701
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2693
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 529.9,                last time consumption/overall running time: 65.8307s / 19248.0405 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2448
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2455
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 565.5,                last time consumption/overall running time: 69.4132s / 19317.4538 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2445
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2428
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 584.5,                last time consumption/overall running time: 72.2091s / 19389.6629 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2435
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2365
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 538.2,                last time consumption/overall running time: 65.9435s / 19455.6064 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2740
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2653
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 539.65,                last time consumption/overall running time: 66.8410s / 19522.4474 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2407
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2524
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 588.05,                last time consumption/overall running time: 71.6902s / 19594.1377 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2708
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2598
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 554.25,                last time consumption/overall running time: 67.6264s / 19661.7641 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2305
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2331
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 571.3,                last time consumption/overall running time: 70.5242s / 19732.2883 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2594
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2566
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 541.0,                last time consumption/overall running time: 67.0696s / 19799.3579 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2726
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2565
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 542.55,                last time consumption/overall running time: 66.5648s / 19865.9227 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2629
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2566
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 563.1,                last time consumption/overall running time: 69.0646s / 19934.9872 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2556
env0_second_0:                 episode reward: 1.2000,                 loss: 0.2479
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 583.65,                last time consumption/overall running time: 72.4529s / 20007.4402 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2639
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2585
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 551.5,                last time consumption/overall running time: 69.1297s / 20076.5698 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2871
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2865
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 554.3,                last time consumption/overall running time: 68.7737s / 20145.3435 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2813
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2697
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 548.25,                last time consumption/overall running time: 67.9634s / 20213.3070 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2337
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2254
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 573.0,                last time consumption/overall running time: 70.7695s / 20284.0764 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2594
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2359
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 594.6,                last time consumption/overall running time: 72.3838s / 20356.4602 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2665
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2538
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 592.2,                last time consumption/overall running time: 72.7810s / 20429.2412 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2600
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2472
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 594.65,                last time consumption/overall running time: 73.1432s / 20502.3844 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2299
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2269
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 551.65,                last time consumption/overall running time: 68.5377s / 20570.9221 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2717
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2637
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 575.2,                last time consumption/overall running time: 71.2062s / 20642.1283 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.2551
env0_second_0:                 episode reward: 1.1500,                 loss: 0.2487
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 581.8,                last time consumption/overall running time: 71.2070s / 20713.3353 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2416
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2290
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 587.65,                last time consumption/overall running time: 71.7691s / 20785.1045 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2408
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2438
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 554.85,                last time consumption/overall running time: 68.9383s / 20854.0428 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2777
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2707
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 538.7,                last time consumption/overall running time: 66.7032s / 20920.7460 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2448
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2389
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 572.45,                last time consumption/overall running time: 70.2529s / 20990.9989 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2990
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2994
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 531.6,                last time consumption/overall running time: 67.3238s / 21058.3227 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.2609
env0_second_0:                 episode reward: -1.9000,                 loss: 0.2584
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 512.05,                last time consumption/overall running time: 64.3590s / 21122.6817 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2430
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2281
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 574.5,                last time consumption/overall running time: 70.8866s / 21193.5683 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2601
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2483
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 568.05,                last time consumption/overall running time: 69.6691s / 21263.2373 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2361
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2232
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 578.05,                last time consumption/overall running time: 71.2700s / 21334.5074 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2581
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2492
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 575.1,                last time consumption/overall running time: 70.6441s / 21405.1515 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2570
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2422
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 607.5,                last time consumption/overall running time: 75.1218s / 21480.2733 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2655
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2606
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 523.75,                last time consumption/overall running time: 65.5623s / 21545.8356 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2597
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2476
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 521.75,                last time consumption/overall running time: 65.1510s / 21610.9865 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2322
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2390
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 588.05,                last time consumption/overall running time: 71.3864s / 21682.3729 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2692
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2588
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 605.75,                last time consumption/overall running time: 73.0413s / 21755.4142 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2342
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2247
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 611.05,                last time consumption/overall running time: 74.9606s / 21830.3748 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2501
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2390
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 564.5,                last time consumption/overall running time: 69.6064s / 21899.9812 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2729
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2546
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 567.25,                last time consumption/overall running time: 69.1913s / 21969.1725 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2799
env0_second_0:                 episode reward: -1.0500,                 loss: 0.2662
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 616.8,                last time consumption/overall running time: 75.0377s / 22044.2102 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2492
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2508
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 545.1,                last time consumption/overall running time: 68.2024s / 22112.4126 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2451
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2458
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 590.9,                last time consumption/overall running time: 73.0708s / 22185.4834 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2675
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2704
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 587.05,                last time consumption/overall running time: 71.9885s / 22257.4719 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2886
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2879
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 523.75,                last time consumption/overall running time: 65.3963s / 22322.8682 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2651
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2654
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 564.0,                last time consumption/overall running time: 70.5590s / 22393.4272 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2841
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2767
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 558.85,                last time consumption/overall running time: 68.7869s / 22462.2140 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2654
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2638
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 568.7,                last time consumption/overall running time: 70.1598s / 22532.3738 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2410
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2509
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 541.2,                last time consumption/overall running time: 67.4310s / 22599.8049 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2567
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2536
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 577.35,                last time consumption/overall running time: 71.4245s / 22671.2294 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2692
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2606
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 570.4,                last time consumption/overall running time: 70.7441s / 22741.9735 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.2644
env0_second_0:                 episode reward: -1.1000,                 loss: 0.2655
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 561.8,                last time consumption/overall running time: 69.6248s / 22811.5983 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2552
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2578
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 548.35,                last time consumption/overall running time: 67.8807s / 22879.4790 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2436
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2389
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 597.2,                last time consumption/overall running time: 72.9170s / 22952.3959 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2394
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2352
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 554.05,                last time consumption/overall running time: 68.6033s / 23020.9993 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2666
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2682
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 585.95,                last time consumption/overall running time: 72.1391s / 23093.1383 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2877
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2827
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 564.0,                last time consumption/overall running time: 69.5365s / 23162.6748 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2444
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2461
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 571.75,                last time consumption/overall running time: 71.1469s / 23233.8217 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2520
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2545
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 566.8,                last time consumption/overall running time: 69.0893s / 23302.9110 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2483
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2358
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 572.5,                last time consumption/overall running time: 70.9861s / 23373.8971 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2597
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2487
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 566.7,                last time consumption/overall running time: 69.9762s / 23443.8733 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2645
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2698
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 555.1,                last time consumption/overall running time: 69.3830s / 23513.2563 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2489
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2466
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 572.65,                last time consumption/overall running time: 71.2526s / 23584.5089 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2819
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2735
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 554.55,                last time consumption/overall running time: 68.5452s / 23653.0541 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2675
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2635
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 562.75,                last time consumption/overall running time: 69.4727s / 23722.5268 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2934
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2898
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 539.0,                last time consumption/overall running time: 66.0091s / 23788.5359 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2381
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2442
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 592.0,                last time consumption/overall running time: 72.6587s / 23861.1946 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.2650
env0_second_0:                 episode reward: 1.5000,                 loss: 0.2522
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 598.15,                last time consumption/overall running time: 73.0108s / 23934.2054 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2470
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2317
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 561.15,                last time consumption/overall running time: 69.1136s / 24003.3189 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2474
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2391
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 556.4,                last time consumption/overall running time: 68.7002s / 24072.0191 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2824
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2806
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 567.85,                last time consumption/overall running time: 69.9416s / 24141.9607 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2654
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2572
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 559.95,                last time consumption/overall running time: 68.5389s / 24210.4996 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2482
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2408
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 576.95,                last time consumption/overall running time: 70.8887s / 24281.3883 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2570
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2532
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 526.85,                last time consumption/overall running time: 66.3685s / 24347.7568 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2872
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2803
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 577.2,                last time consumption/overall running time: 70.6447s / 24418.4016 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2725
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2779
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 565.5,                last time consumption/overall running time: 69.6064s / 24488.0080 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2629
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2672
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 598.45,                last time consumption/overall running time: 73.6093s / 24561.6173 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2708
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2629
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 554.5,                last time consumption/overall running time: 68.8880s / 24630.5053 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2727
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2649
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 583.8,                last time consumption/overall running time: 71.4944s / 24701.9997 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2604
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2597
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 573.2,                last time consumption/overall running time: 70.0112s / 24772.0109 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2663
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2628
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 545.45,                last time consumption/overall running time: 68.3950s / 24840.4059 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2551
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2371
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 586.75,                last time consumption/overall running time: 72.1281s / 24912.5340 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2651
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2608
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 589.35,                last time consumption/overall running time: 71.2957s / 24983.8297 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.2294
env0_second_0:                 episode reward: 1.6000,                 loss: 0.2239
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 607.4,                last time consumption/overall running time: 74.1684s / 25057.9981 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2529
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2471
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 557.15,                last time consumption/overall running time: 68.8857s / 25126.8838 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2624
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2592
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 562.7,                last time consumption/overall running time: 69.7027s / 25196.5865 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2583
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2539
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 574.1,                last time consumption/overall running time: 71.0758s / 25267.6623 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2840
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2757
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 586.6,                last time consumption/overall running time: 72.0482s / 25339.7105 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2345
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2254
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 549.35,                last time consumption/overall running time: 68.2948s / 25408.0054 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2244
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2217
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 588.2,                last time consumption/overall running time: 72.4533s / 25480.4586 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2444
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2352
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 577.7,                last time consumption/overall running time: 70.6637s / 25551.1223 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2534
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2341
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 591.1,                last time consumption/overall running time: 72.2569s / 25623.3792 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2523
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2512
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 617.3,                last time consumption/overall running time: 75.1910s / 25698.5702 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2580
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2486
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 611.1,                last time consumption/overall running time: 73.9841s / 25772.5543 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2849
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2839
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 583.15,                last time consumption/overall running time: 71.6781s / 25844.2324 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2312
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2301
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 580.5,                last time consumption/overall running time: 70.8055s / 25915.0379 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2370
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2360
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 540.75,                last time consumption/overall running time: 67.0551s / 25982.0930 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2687
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2630
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 566.05,                last time consumption/overall running time: 69.5271s / 26051.6201 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.2473
env0_second_0:                 episode reward: 1.4500,                 loss: 0.2464
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 571.15,                last time consumption/overall running time: 70.5828s / 26122.2029 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2620
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2478
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 610.0,                last time consumption/overall running time: 73.9874s / 26196.1903 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2565
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2456
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 560.05,                last time consumption/overall running time: 69.6068s / 26265.7971 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2422
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2427
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 557.05,                last time consumption/overall running time: 69.3915s / 26335.1886 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2321
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2334
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 558.85,                last time consumption/overall running time: 69.2097s / 26404.3984 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2654
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2692
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 608.95,                last time consumption/overall running time: 74.2402s / 26478.6386 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2687
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2541
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 564.75,                last time consumption/overall running time: 69.2329s / 26547.8715 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2327
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2331
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 586.95,                last time consumption/overall running time: 72.3145s / 26620.1860 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2441
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2393
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 597.9,                last time consumption/overall running time: 73.3505s / 26693.5365 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2551
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2518
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 545.6,                last time consumption/overall running time: 67.7441s / 26761.2806 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2628
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2466
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 559.45,                last time consumption/overall running time: 68.6690s / 26829.9496 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2466
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2414
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 581.0,                last time consumption/overall running time: 71.8441s / 26901.7938 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2498
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2411
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 533.9,                last time consumption/overall running time: 66.5968s / 26968.3906 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2448
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2434
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 561.25,                last time consumption/overall running time: 69.8259s / 27038.2165 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2769
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2608
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 572.4,                last time consumption/overall running time: 70.5697s / 27108.7861 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2328
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2147
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 557.9,                last time consumption/overall running time: 68.8909s / 27177.6770 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2714
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2653
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 561.9,                last time consumption/overall running time: 69.2815s / 27246.9585 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2325
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2257
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 566.05,                last time consumption/overall running time: 69.9506s / 27316.9092 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2547
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2512
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 618.65,                last time consumption/overall running time: 75.6778s / 27392.5869 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2431
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2362
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 553.8,                last time consumption/overall running time: 68.5037s / 27461.0906 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2574
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2481
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 592.75,                last time consumption/overall running time: 71.6844s / 27532.7750 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2298
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2137
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 543.7,                last time consumption/overall running time: 67.0496s / 27599.8246 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2479
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2436
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 547.35,                last time consumption/overall running time: 67.4556s / 27667.2802 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2444
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2240
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 571.5,                last time consumption/overall running time: 70.1332s / 27737.4133 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2405
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2260
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 561.95,                last time consumption/overall running time: 69.5187s / 27806.9321 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.2599
env0_second_0:                 episode reward: -1.4500,                 loss: 0.2428
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 562.45,                last time consumption/overall running time: 68.5789s / 27875.5110 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2378
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2356
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 555.85,                last time consumption/overall running time: 68.8410s / 27944.3520 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2461
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2490
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 570.7,                last time consumption/overall running time: 69.7251s / 28014.0771 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2562
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2562
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 567.2,                last time consumption/overall running time: 69.7872s / 28083.8643 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2548
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2386
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 556.5,                last time consumption/overall running time: 68.3475s / 28152.2117 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2756
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2633
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 522.45,                last time consumption/overall running time: 65.3325s / 28217.5443 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2327
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2313
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 594.1,                last time consumption/overall running time: 73.1842s / 28290.7285 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2786
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2716
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 593.85,                last time consumption/overall running time: 72.3677s / 28363.0962 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2596
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2519
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 600.15,                last time consumption/overall running time: 73.2402s / 28436.3364 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2550
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2580
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 580.45,                last time consumption/overall running time: 70.2837s / 28506.6201 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2320
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2248
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 555.75,                last time consumption/overall running time: 68.7760s / 28575.3961 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2319
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2200
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 500.65,                last time consumption/overall running time: 62.4880s / 28637.8841 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2255
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2326
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 611.0,                last time consumption/overall running time: 75.9488s / 28713.8329 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2494
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2356
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 577.3,                last time consumption/overall running time: 71.1269s / 28784.9598 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2197
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2145
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 548.2,                last time consumption/overall running time: 68.5578s / 28853.5176 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2569
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2494
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 630.6,                last time consumption/overall running time: 77.5267s / 28931.0443 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2481
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2362
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 560.9,                last time consumption/overall running time: 69.4374s / 29000.4817 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2626
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2488
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 562.95,                last time consumption/overall running time: 69.5946s / 29070.0763 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2408
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2245
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 597.6,                last time consumption/overall running time: 72.8004s / 29142.8767 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2454
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2434
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 584.35,                last time consumption/overall running time: 72.3884s / 29215.2652 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2447
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2386
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 536.5,                last time consumption/overall running time: 65.9319s / 29281.1970 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2651
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2586
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 572.8,                last time consumption/overall running time: 70.4821s / 29351.6792 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2593
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2568
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 529.8,                last time consumption/overall running time: 66.1776s / 29417.8568 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.1922
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1780
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 535.8,                last time consumption/overall running time: 67.1115s / 29484.9683 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2637
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2465
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 597.8,                last time consumption/overall running time: 73.2811s / 29558.2494 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2560
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2575
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 595.15,                last time consumption/overall running time: 72.7768s / 29631.0263 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2354
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2288
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 545.75,                last time consumption/overall running time: 67.1022s / 29698.1285 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2545
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2399
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 546.15,                last time consumption/overall running time: 67.7344s / 29765.8629 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2452
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2334
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 583.75,                last time consumption/overall running time: 70.7309s / 29836.5938 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2763
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2682
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 555.55,                last time consumption/overall running time: 68.2092s / 29904.8030 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2165
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2170
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 540.15,                last time consumption/overall running time: 67.6910s / 29972.4940 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2587
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2583
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 600.8,                last time consumption/overall running time: 73.4389s / 30045.9329 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.2290
env0_second_0:                 episode reward: 1.4000,                 loss: 0.2208
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 534.3,                last time consumption/overall running time: 67.1368s / 30113.0697 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2476
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2361
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 546.9,                last time consumption/overall running time: 68.1073s / 30181.1770 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2589
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2624
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 550.05,                last time consumption/overall running time: 68.0284s / 30249.2054 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2524
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2409
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 555.35,                last time consumption/overall running time: 68.2965s / 30317.5019 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2405
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2269
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 523.95,                last time consumption/overall running time: 65.0743s / 30382.5762 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2690
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2640
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 567.85,                last time consumption/overall running time: 69.7769s / 30452.3530 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2285
env0_second_0:                 episode reward: 1.2000,                 loss: 0.2175
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 595.15,                last time consumption/overall running time: 73.0463s / 30525.3993 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2303
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2300
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 542.8,                last time consumption/overall running time: 68.3383s / 30593.7376 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2189
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2218
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 582.55,                last time consumption/overall running time: 71.7591s / 30665.4967 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2470
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2310
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 533.3,                last time consumption/overall running time: 66.4412s / 30731.9378 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2742
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2572
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 562.95,                last time consumption/overall running time: 70.4259s / 30802.3637 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2342
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2347
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 537.15,                last time consumption/overall running time: 66.6212s / 30868.9849 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2462
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2458
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 555.05,                last time consumption/overall running time: 68.8243s / 30937.8091 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2551
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2441
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 554.95,                last time consumption/overall running time: 68.7028s / 31006.5119 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2544
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2500
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 569.55,                last time consumption/overall running time: 70.3583s / 31076.8702 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2513
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2470
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 559.4,                last time consumption/overall running time: 69.7010s / 31146.5713 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2675
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2598
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 503.3,                last time consumption/overall running time: 64.0064s / 31210.5776 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2184
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2248
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 604.9,                last time consumption/overall running time: 74.3569s / 31284.9346 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2377
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2380
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 528.4,                last time consumption/overall running time: 65.7981s / 31350.7327 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2512
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2345
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 566.3,                last time consumption/overall running time: 70.6530s / 31421.3857 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2618
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2453
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 599.2,                last time consumption/overall running time: 73.7319s / 31495.1176 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2479
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2379
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 565.65,                last time consumption/overall running time: 69.4395s / 31564.5571 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2520
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2420
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 582.95,                last time consumption/overall running time: 71.9025s / 31636.4596 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2495
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2338
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 609.25,                last time consumption/overall running time: 74.7778s / 31711.2374 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.2404
env0_second_0:                 episode reward: -1.1000,                 loss: 0.2320
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 565.95,                last time consumption/overall running time: 69.7256s / 31780.9630 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2438
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2376
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 560.25,                last time consumption/overall running time: 69.3909s / 31850.3538 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2479
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2499
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 565.4,                last time consumption/overall running time: 69.0636s / 31919.4174 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2727
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2670
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 604.8,                last time consumption/overall running time: 74.1768s / 31993.5943 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2691
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2760
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 569.3,                last time consumption/overall running time: 70.5525s / 32064.1468 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2422
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2214
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 553.55,                last time consumption/overall running time: 68.5503s / 32132.6971 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2741
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2616
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 544.85,                last time consumption/overall running time: 68.0669s / 32200.7640 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2560
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2490
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 564.85,                last time consumption/overall running time: 69.9528s / 32270.7169 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2504
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2397
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 540.6,                last time consumption/overall running time: 66.8342s / 32337.5511 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2775
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2607
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 557.1,                last time consumption/overall running time: 68.4630s / 32406.0141 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2509
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2401
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 598.7,                last time consumption/overall running time: 73.5542s / 32479.5683 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2439
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2336
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 569.6,                last time consumption/overall running time: 70.0355s / 32549.6038 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2345
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2213
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 579.9,                last time consumption/overall running time: 71.8598s / 32621.4636 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2526
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2391
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 516.35,                last time consumption/overall running time: 64.6247s / 32686.0883 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2517
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2367
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 585.15,                last time consumption/overall running time: 72.2610s / 32758.3493 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2568
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2444
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 569.75,                last time consumption/overall running time: 69.4362s / 32827.7855 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2748
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2569
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 556.9,                last time consumption/overall running time: 69.7441s / 32897.5296 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2186
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1991
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 536.2,                last time consumption/overall running time: 67.2036s / 32964.7332 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2602
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2346
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 550.7,                last time consumption/overall running time: 67.9431s / 33032.6763 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2402
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2262
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 558.4,                last time consumption/overall running time: 68.9217s / 33101.5980 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2553
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2405
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 570.1,                last time consumption/overall running time: 70.5446s / 33172.1427 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2330
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2071
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 573.45,                last time consumption/overall running time: 70.9194s / 33243.0621 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2777
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2600
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 555.5,                last time consumption/overall running time: 68.1998s / 33311.2619 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2293
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2181
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 584.8,                last time consumption/overall running time: 72.1183s / 33383.3802 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2476
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2490
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 559.6,                last time consumption/overall running time: 69.3126s / 33452.6928 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2389
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2364
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 605.05,                last time consumption/overall running time: 73.8331s / 33526.5259 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2650
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2524
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 580.3,                last time consumption/overall running time: 71.5653s / 33598.0912 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2542
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2299
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 585.0,                last time consumption/overall running time: 71.9705s / 33670.0617 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2460
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2300
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 559.85,                last time consumption/overall running time: 68.9597s / 33739.0215 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.2599
env0_second_0:                 episode reward: 1.8000,                 loss: 0.2380
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 625.05,                last time consumption/overall running time: 75.7864s / 33814.8079 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2085
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1876
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 607.35,                last time consumption/overall running time: 73.2542s / 33888.0621 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2674
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2603
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 566.2,                last time consumption/overall running time: 69.8622s / 33957.9243 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2167
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2191
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 559.5,                last time consumption/overall running time: 69.0219s / 34026.9462 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2507
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2287
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 543.95,                last time consumption/overall running time: 66.9048s / 34093.8510 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2586
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2483
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 558.05,                last time consumption/overall running time: 68.9389s / 34162.7899 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2159
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2053
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 546.5,                last time consumption/overall running time: 67.5174s / 34230.3072 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2569
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2538
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 550.6,                last time consumption/overall running time: 68.3867s / 34298.6939 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2273
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2198
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 558.55,                last time consumption/overall running time: 69.1944s / 34367.8883 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2588
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2480
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 580.85,                last time consumption/overall running time: 71.5921s / 34439.4804 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2500
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2342
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 588.05,                last time consumption/overall running time: 71.4514s / 34510.9318 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2273
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2321
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 593.55,                last time consumption/overall running time: 73.3602s / 34584.2919 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2657
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2632
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 539.25,                last time consumption/overall running time: 67.4157s / 34651.7076 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2337
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2252
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 573.5,                last time consumption/overall running time: 70.5018s / 34722.2094 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2311
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2237
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 605.85,                last time consumption/overall running time: 73.2336s / 34795.4431 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2667
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2542Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/zihan/research/MARS/mars/rl/agents/nash_ppo.py:181: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  s,a,r,s_prime,prob_a,done_mask =    torch.tensor(s_lst, dtype=torch.float).to(self.device), torch.tensor(a_lst).to(self.device), \
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 586.55,                last time consumption/overall running time: 72.6275s / 34868.0705 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2313
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2163
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 546.35,                last time consumption/overall running time: 68.9740s / 34937.0445 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2334
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2408
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 565.2,                last time consumption/overall running time: 70.0471s / 35007.0916 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2389
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2307
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 579.8,                last time consumption/overall running time: 72.2533s / 35079.3449 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2506
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2485
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
