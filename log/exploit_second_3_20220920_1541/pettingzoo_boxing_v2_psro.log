/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:87: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.
  "The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead."
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:101: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.
  "The `action_spaces` dictionary is deprecated. Use the `action_space` function instead."
pettingzoo_boxing_v2
default:  {'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'psro', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 80, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
{'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209252250, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'psro', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 80, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'load_id': 202209201541, 'to_exploit': 'second_3'}
boxing_v2 pettingzoo
record video: interval 100, length 300
Load boxing_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 394
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f953ff81da0>
discrete_policy 18 Discrete(18)
Traceback (most recent call last):
  File "general_exploit.py", line 48, in <module>
    launch()
  File "general_exploit.py", line 30, in launch
    trained_model = eval(args.algorithm)(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/dqn.py", line 19, in __init__
    self._init_model(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/dqn.py", line 38, in _init_model
    self.model = self._select_type(env, args).to(self.device)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:87: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.
  "The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead."
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:101: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.
  "The `action_spaces` dictionary is deprecated. Use the `action_space` function instead."
pettingzoo_boxing_v2
default:  {'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'psro', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 80, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
{'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209270006, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'psro', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 80, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'load_id': 202209201541, 'to_exploit': 'second_3'}
boxing_v2 pettingzoo
record video: interval 100, length 300
Load boxing_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 364
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f6dc0912e48>
discrete_policy 18 Discrete(18)
Traceback (most recent call last):
  File "general_exploit.py", line 48, in <module>
    launch()
  File "general_exploit.py", line 30, in launch
    trained_model = eval(args.algorithm)(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/dqn.py", line 19, in __init__
    self._init_model(env, args)
  File "/data/zihan/research/MARS/mars/rl/agents/dqn.py", line 38, in _init_model
    self.model = self._select_type(env, args).to(self.device)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
pettingzoo_boxing_v2
default:  {'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'psro', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 80, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
{'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 5, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209270240, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'psro', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 80, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'load_id': 202209201541, 'to_exploit': 'second_3'}
boxing_v2 pettingzoo
record video: interval 100, length 300
Load boxing_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 627
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f22e70d6da0>
discrete_policy 18 Discrete(18)
discrete_policy 18 Discrete(18)
discrete_policy 18 Discrete(18)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [[0.    0.    0.    ... 0.    0.008 0.   ]
 [0.    0.    0.    ... 0.    0.051 0.691]]
Load checkpoints (policy family):  [['630' '1394' '1749' ... '7004' '7247' '7515']
 ['1150' '1570' '1781' ... '7031' '7299' '7541']]
Arguments:  {'env_name': 'boxing_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'record_video': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.001, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'save_id': 202209270240, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/202209201541/pettingzoo_boxing_v2_psro/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'wandb_activate': False, 'wandb_entity': '', 'wandb_project': '', 'wandb_group': '', 'wandb_name': '', 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'psro', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 80, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'load_id': 202209201541, 'to_exploit': 'second_3', 'against_baseline': False, 'idx_exploited_model': 0}
Save models to : /data/zihan/research/MARS/data/model/202209201541_exploit_first/pettingzoo_boxing_v2_psro. 
 Save logs to: /data/zihan/research/MARS/data/log/202209201541_exploit_first/pettingzoo_boxing_v2_psro.
Episode: 1/10000 (0.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 7.92s / 7.92 s
first_0:                 episode reward: 45.0000,                 loss: nan
second_0:                 episode reward: -45.0000,                 loss: 0.9666
Episode: 21/10000 (0.2100%),                 avg. length: 293.95,                last time consumption/overall running time: 131.74s / 139.66 s
first_0:                 episode reward: 33.9000,                 loss: nan
second_0:                 episode reward: -33.9000,                 loss: 0.2706
Episode: 41/10000 (0.4100%),                 avg. length: 294.1,                last time consumption/overall running time: 136.45s / 276.11 s
first_0:                 episode reward: 41.0000,                 loss: nan
second_0:                 episode reward: -41.0000,                 loss: 0.0985
Episode: 61/10000 (0.6100%),                 avg. length: 296.3,                last time consumption/overall running time: 138.53s / 414.64 s
first_0:                 episode reward: 48.0500,                 loss: nan
second_0:                 episode reward: -48.0500,                 loss: 0.1000
Episode: 81/10000 (0.8100%),                 avg. length: 291.55,                last time consumption/overall running time: 137.24s / 551.87 s
first_0:                 episode reward: 44.1000,                 loss: nan
second_0:                 episode reward: -44.1000,                 loss: 0.1122
Episode: 101/10000 (1.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 140.13s / 692.01 s
first_0:                 episode reward: 21.3500,                 loss: nan
second_0:                 episode reward: -21.3500,                 loss: 0.1086
Episode: 121/10000 (1.2100%),                 avg. length: 298.45,                last time consumption/overall running time: 140.84s / 832.85 s
first_0:                 episode reward: 25.0500,                 loss: nan
second_0:                 episode reward: -25.0500,                 loss: 0.0977
Episode: 141/10000 (1.4100%),                 avg. length: 294.1,                last time consumption/overall running time: 138.17s / 971.01 s
first_0:                 episode reward: 49.3000,                 loss: nan
second_0:                 episode reward: -49.3000,                 loss: 0.0918
Episode: 161/10000 (1.6100%),                 avg. length: 297.35,                last time consumption/overall running time: 141.43s / 1112.44 s
first_0:                 episode reward: 29.7500,                 loss: nan
second_0:                 episode reward: -29.7500,                 loss: 0.0873
Episode: 181/10000 (1.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 142.24s / 1254.68 s
first_0:                 episode reward: 31.5000,                 loss: nan
second_0:                 episode reward: -31.5000,                 loss: 0.0853
Episode: 201/10000 (2.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 143.00s / 1397.69 s
first_0:                 episode reward: 32.0500,                 loss: nan
second_0:                 episode reward: -32.0500,                 loss: 0.0770
Episode: 221/10000 (2.2100%),                 avg. length: 295.0,                last time consumption/overall running time: 141.85s / 1539.54 s
first_0:                 episode reward: 29.9000,                 loss: nan
second_0:                 episode reward: -29.9000,                 loss: 0.0799
Episode: 241/10000 (2.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 144.50s / 1684.04 s
first_0:                 episode reward: 22.1000,                 loss: nan
second_0:                 episode reward: -22.1000,                 loss: 0.0813
Episode: 261/10000 (2.6100%),                 avg. length: 295.7,                last time consumption/overall running time: 144.22s / 1828.26 s
first_0:                 episode reward: 41.5000,                 loss: nan
second_0:                 episode reward: -41.5000,                 loss: 0.0863
Episode: 281/10000 (2.8100%),                 avg. length: 296.35,                last time consumption/overall running time: 144.29s / 1972.55 s
first_0:                 episode reward: 22.1500,                 loss: nan
second_0:                 episode reward: -22.1500,                 loss: 0.0868
Episode: 301/10000 (3.0100%),                 avg. length: 295.4,                last time consumption/overall running time: 143.96s / 2116.51 s
first_0:                 episode reward: 26.1500,                 loss: nan
second_0:                 episode reward: -26.1500,                 loss: 0.0875
Episode: 321/10000 (3.2100%),                 avg. length: 292.15,                last time consumption/overall running time: 143.03s / 2259.55 s
first_0:                 episode reward: 32.7500,                 loss: nan
second_0:                 episode reward: -32.7500,                 loss: 0.0844
Episode: 341/10000 (3.4100%),                 avg. length: 297.55,                last time consumption/overall running time: 145.38s / 2404.92 s
first_0:                 episode reward: 24.3500,                 loss: nan
second_0:                 episode reward: -24.3500,                 loss: 0.0817
Episode: 361/10000 (3.6100%),                 avg. length: 295.8,                last time consumption/overall running time: 145.86s / 2550.79 s
first_0:                 episode reward: 23.7500,                 loss: nan
second_0:                 episode reward: -23.7500,                 loss: 0.0820
Episode: 381/10000 (3.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 146.05s / 2696.84 s
first_0:                 episode reward: 22.3000,                 loss: nan
second_0:                 episode reward: -22.3000,                 loss: 0.0835
Episode: 401/10000 (4.0100%),                 avg. length: 296.5,                last time consumption/overall running time: 145.81s / 2842.65 s
first_0:                 episode reward: 19.9500,                 loss: nan
second_0:                 episode reward: -19.9500,                 loss: 0.0829
Episode: 421/10000 (4.2100%),                 avg. length: 294.3,                last time consumption/overall running time: 144.19s / 2986.84 s
first_0:                 episode reward: 31.8500,                 loss: nan
second_0:                 episode reward: -31.8500,                 loss: 0.0857
Episode: 441/10000 (4.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 148.66s / 3135.50 s
first_0:                 episode reward: 14.1500,                 loss: nan
second_0:                 episode reward: -14.1500,                 loss: 0.0852
Episode: 461/10000 (4.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 147.30s / 3282.80 s
first_0:                 episode reward: 14.4000,                 loss: nan
second_0:                 episode reward: -14.4000,                 loss: 0.0811
Episode: 481/10000 (4.8100%),                 avg. length: 298.45,                last time consumption/overall running time: 147.61s / 3430.42 s
first_0:                 episode reward: 29.0000,                 loss: nan
second_0:                 episode reward: -29.0000,                 loss: 0.0842
Episode: 501/10000 (5.0100%),                 avg. length: 298.1,                last time consumption/overall running time: 147.28s / 3577.69 s
first_0:                 episode reward: 22.2000,                 loss: nan
second_0:                 episode reward: -22.2000,                 loss: 0.0854
Episode: 521/10000 (5.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 148.54s / 3726.24 s
first_0:                 episode reward: 13.9500,                 loss: nan
second_0:                 episode reward: -13.9500,                 loss: 0.0865
Episode: 541/10000 (5.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 148.33s / 3874.56 s
first_0:                 episode reward: 7.1000,                 loss: nan
second_0:                 episode reward: -7.1000,                 loss: 0.0856
Episode: 561/10000 (5.6100%),                 avg. length: 297.4,                last time consumption/overall running time: 147.95s / 4022.52 s
first_0:                 episode reward: 24.1000,                 loss: nan
second_0:                 episode reward: -24.1000,                 loss: 0.0854
Episode: 581/10000 (5.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 148.85s / 4171.37 s
first_0:                 episode reward: 9.0000,                 loss: nan
second_0:                 episode reward: -9.0000,                 loss: 0.0847
Episode: 601/10000 (6.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 147.60s / 4318.97 s
first_0:                 episode reward: 9.8500,                 loss: nan
second_0:                 episode reward: -9.8500,                 loss: 0.0844
Episode: 621/10000 (6.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 147.82s / 4466.79 s
first_0:                 episode reward: 8.5500,                 loss: nan
second_0:                 episode reward: -8.5500,                 loss: 0.0869
Episode: 641/10000 (6.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 148.52s / 4615.30 s
first_0:                 episode reward: 7.6500,                 loss: nan
second_0:                 episode reward: -7.6500,                 loss: 0.0872
Episode: 661/10000 (6.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 148.63s / 4763.94 s
first_0:                 episode reward: 15.2500,                 loss: nan
second_0:                 episode reward: -15.2500,                 loss: 0.0901
Episode: 681/10000 (6.8100%),                 avg. length: 297.9,                last time consumption/overall running time: 148.98s / 4912.91 s
first_0:                 episode reward: 11.3000,                 loss: nan
second_0:                 episode reward: -11.3000,                 loss: 0.0920
Episode: 701/10000 (7.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.04s / 5062.95 s
first_0:                 episode reward: 14.6000,                 loss: nan
second_0:                 episode reward: -14.6000,                 loss: 0.0928
Episode: 721/10000 (7.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 148.70s / 5211.66 s
first_0:                 episode reward: 4.8000,                 loss: nan
second_0:                 episode reward: -4.8000,                 loss: 0.0894
Episode: 741/10000 (7.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.42s / 5362.07 s
first_0:                 episode reward: 5.1500,                 loss: nan
second_0:                 episode reward: -5.1500,                 loss: 0.0927
Episode: 761/10000 (7.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.78s / 5511.85 s
first_0:                 episode reward: 9.4000,                 loss: nan
second_0:                 episode reward: -9.4000,                 loss: 0.0942
Episode: 781/10000 (7.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.16s / 5661.01 s
first_0:                 episode reward: 10.0500,                 loss: nan
second_0:                 episode reward: -10.0500,                 loss: 0.0913
Episode: 801/10000 (8.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.99s / 5811.00 s
first_0:                 episode reward: 3.5000,                 loss: nan
second_0:                 episode reward: -3.5000,                 loss: 0.0965
Episode: 821/10000 (8.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.33s / 5961.33 s
first_0:                 episode reward: 2.8000,                 loss: nan
second_0:                 episode reward: -2.8000,                 loss: 0.1068
Episode: 841/10000 (8.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.13s / 6111.46 s
first_0:                 episode reward: 7.5000,                 loss: nan
second_0:                 episode reward: -7.5000,                 loss: 0.1082
Episode: 861/10000 (8.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.13s / 6261.60 s
first_0:                 episode reward: 1.7500,                 loss: nan
second_0:                 episode reward: -1.7500,                 loss: 0.1085
Episode: 881/10000 (8.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.40s / 6411.00 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.1113
Episode: 901/10000 (9.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.94s / 6560.94 s
first_0:                 episode reward: 3.7500,                 loss: nan
second_0:                 episode reward: -3.7500,                 loss: 0.1137
Episode: 921/10000 (9.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.30s / 6711.24 s
first_0:                 episode reward: -2.5000,                 loss: nan
second_0:                 episode reward: 2.5000,                 loss: 0.1132
Episode: 941/10000 (9.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.68s / 6861.91 s
first_0:                 episode reward: 7.7500,                 loss: nan
second_0:                 episode reward: -7.7500,                 loss: 0.1181
Episode: 961/10000 (9.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.96s / 7012.87 s
first_0:                 episode reward: 1.8500,                 loss: nan
second_0:                 episode reward: -1.8500,                 loss: 0.1154
Episode: 981/10000 (9.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.78s / 7163.65 s
first_0:                 episode reward: 3.3000,                 loss: nan
second_0:                 episode reward: -3.3000,                 loss: 0.1142
Episode: 1001/10000 (10.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.64s / 7314.29 s
first_0:                 episode reward: -10.5000,                 loss: nan
second_0:                 episode reward: 10.5000,                 loss: 0.1097
Episode: 1021/10000 (10.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.46s / 7464.75 s
first_0:                 episode reward: 3.6500,                 loss: nan
second_0:                 episode reward: -3.6500,                 loss: 0.1146
Episode: 1041/10000 (10.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.51s / 7615.26 s
first_0:                 episode reward: 2.1500,                 loss: nan
second_0:                 episode reward: -2.1500,                 loss: 0.1210
Episode: 1061/10000 (10.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.81s / 7765.07 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.1152
Episode: 1081/10000 (10.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.83s / 7915.91 s
first_0:                 episode reward: -21.2000,                 loss: nan
second_0:                 episode reward: 21.2000,                 loss: 0.1082
Episode: 1101/10000 (11.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.78s / 8065.69 s
first_0:                 episode reward: -21.5000,                 loss: nan
second_0:                 episode reward: 21.5000,                 loss: 0.1064
Episode: 1121/10000 (11.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.31s / 8217.00 s
first_0:                 episode reward: -9.7000,                 loss: nan
second_0:                 episode reward: 9.7000,                 loss: 0.1012
Episode: 1141/10000 (11.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.15s / 8367.16 s
first_0:                 episode reward: -19.5000,                 loss: nan
second_0:                 episode reward: 19.5000,                 loss: 0.0958
Episode: 1161/10000 (11.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.15s / 8517.30 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0944
Episode: 1181/10000 (11.8100%),                 avg. length: 293.6,                last time consumption/overall running time: 148.40s / 8665.70 s
first_0:                 episode reward: -21.1500,                 loss: nan
second_0:                 episode reward: 21.1500,                 loss: 0.0923
Episode: 1201/10000 (12.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.27s / 8816.98 s
first_0:                 episode reward: -13.3500,                 loss: nan
second_0:                 episode reward: 13.3500,                 loss: 0.0870
Episode: 1221/10000 (12.2100%),                 avg. length: 297.95,                last time consumption/overall running time: 150.29s / 8967.27 s
first_0:                 episode reward: -20.0000,                 loss: nan
second_0:                 episode reward: 20.0000,                 loss: 0.0837
Episode: 1241/10000 (12.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.11s / 9118.37 s
first_0:                 episode reward: -6.8000,                 loss: nan
second_0:                 episode reward: 6.8000,                 loss: 0.0787
Episode: 1261/10000 (12.6100%),                 avg. length: 297.9,                last time consumption/overall running time: 150.19s / 9268.57 s
first_0:                 episode reward: -17.2000,                 loss: nan
second_0:                 episode reward: 17.2000,                 loss: 0.0746
Episode: 1281/10000 (12.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.98s / 9419.54 s
first_0:                 episode reward: -20.9500,                 loss: nan
second_0:                 episode reward: 20.9500,                 loss: 0.0728
Episode: 1301/10000 (13.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.33s / 9569.87 s
first_0:                 episode reward: -25.2000,                 loss: nan
second_0:                 episode reward: 25.2000,                 loss: 0.0720
Episode: 1321/10000 (13.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.41s / 9720.28 s
first_0:                 episode reward: -29.4500,                 loss: nan
second_0:                 episode reward: 29.4500,                 loss: 0.0692
Episode: 1341/10000 (13.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.52s / 9870.80 s
first_0:                 episode reward: -23.8000,                 loss: nan
second_0:                 episode reward: 23.8000,                 loss: 0.0695
Episode: 1361/10000 (13.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.65s / 10021.44 s
first_0:                 episode reward: -22.8000,                 loss: nan
second_0:                 episode reward: 22.8000,                 loss: 0.0687
Episode: 1381/10000 (13.8100%),                 avg. length: 294.05,                last time consumption/overall running time: 148.25s / 10169.70 s
first_0:                 episode reward: -5.9000,                 loss: nan
second_0:                 episode reward: 5.9000,                 loss: 0.0660
Episode: 1401/10000 (14.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.11s / 10319.80 s
first_0:                 episode reward: -12.5000,                 loss: nan
second_0:                 episode reward: 12.5000,                 loss: 0.0655
Episode: 1421/10000 (14.2100%),                 avg. length: 297.05,                last time consumption/overall running time: 149.41s / 10469.21 s
first_0:                 episode reward: -32.2000,                 loss: nan
second_0:                 episode reward: 32.2000,                 loss: 0.0648
Episode: 1441/10000 (14.4100%),                 avg. length: 296.75,                last time consumption/overall running time: 150.28s / 10619.50 s
first_0:                 episode reward: -16.8500,                 loss: nan
second_0:                 episode reward: 16.8500,                 loss: 0.0633
Episode: 1461/10000 (14.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.66s / 10771.16 s
first_0:                 episode reward: -23.4500,                 loss: nan
second_0:                 episode reward: 23.4500,                 loss: 0.0633
Episode: 1481/10000 (14.8100%),                 avg. length: 298.15,                last time consumption/overall running time: 150.30s / 10921.45 s
first_0:                 episode reward: -29.2000,                 loss: nan
second_0:                 episode reward: 29.2000,                 loss: 0.0612
Episode: 1501/10000 (15.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.14s / 11072.59 s
first_0:                 episode reward: -34.4500,                 loss: nan
second_0:                 episode reward: 34.4500,                 loss: 0.0598
Episode: 1521/10000 (15.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.28s / 11223.87 s
first_0:                 episode reward: -33.9000,                 loss: nan
second_0:                 episode reward: 33.9000,                 loss: 0.0635
Episode: 1541/10000 (15.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.83s / 11375.70 s
first_0:                 episode reward: -32.6500,                 loss: nan
second_0:                 episode reward: 32.6500,                 loss: 0.0609
Episode: 1561/10000 (15.6100%),                 avg. length: 295.95,                last time consumption/overall running time: 149.41s / 11525.11 s
first_0:                 episode reward: -10.2500,                 loss: nan
second_0:                 episode reward: 10.2500,                 loss: 0.0614
Episode: 1581/10000 (15.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.95s / 11676.06 s
first_0:                 episode reward: -40.0500,                 loss: nan
second_0:                 episode reward: 40.0500,                 loss: 0.0619
Episode: 1601/10000 (16.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.06s / 11826.13 s
first_0:                 episode reward: -34.6500,                 loss: nan
second_0:                 episode reward: 34.6500,                 loss: 0.0611
Episode: 1621/10000 (16.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.05s / 11976.18 s
first_0:                 episode reward: -35.3500,                 loss: nan
second_0:                 episode reward: 35.3500,                 loss: 0.0612
Episode: 1641/10000 (16.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.54s / 12126.72 s
first_0:                 episode reward: -36.6500,                 loss: nan
second_0:                 episode reward: 36.6500,                 loss: 0.0620
Episode: 1661/10000 (16.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.09s / 12277.81 s
first_0:                 episode reward: -34.7000,                 loss: nan
second_0:                 episode reward: 34.7000,                 loss: 0.0608
Episode: 1681/10000 (16.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.20s / 12429.01 s
first_0:                 episode reward: -40.2000,                 loss: nan
second_0:                 episode reward: 40.2000,                 loss: 0.0590
Episode: 1701/10000 (17.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.75s / 12580.76 s
first_0:                 episode reward: -43.3500,                 loss: nan
second_0:                 episode reward: 43.3500,                 loss: 0.0589
Episode: 1721/10000 (17.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.38s / 12732.14 s
first_0:                 episode reward: -42.9500,                 loss: nan
second_0:                 episode reward: 42.9500,                 loss: 0.0596
Episode: 1741/10000 (17.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.42s / 12882.57 s
first_0:                 episode reward: -42.3000,                 loss: nan
second_0:                 episode reward: 42.3000,                 loss: 0.0587
Episode: 1761/10000 (17.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.05s / 13032.62 s
first_0:                 episode reward: -40.2000,                 loss: nan
second_0:                 episode reward: 40.2000,                 loss: 0.0577
Episode: 1781/10000 (17.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.71s / 13183.33 s
first_0:                 episode reward: -37.3000,                 loss: nan
second_0:                 episode reward: 37.3000,                 loss: 0.0576
Episode: 1801/10000 (18.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.67s / 13334.00 s
first_0:                 episode reward: -53.5000,                 loss: nan
second_0:                 episode reward: 53.5000,                 loss: 0.0587
Episode: 1821/10000 (18.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.68s / 13484.68 s
first_0:                 episode reward: -38.9500,                 loss: nan
second_0:                 episode reward: 38.9500,                 loss: 0.0577
Episode: 1841/10000 (18.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.50s / 13636.19 s
first_0:                 episode reward: -45.8000,                 loss: nan
second_0:                 episode reward: 45.8000,                 loss: 0.0558
Episode: 1861/10000 (18.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.18s / 13788.37 s
first_0:                 episode reward: -45.7000,                 loss: nan
second_0:                 episode reward: 45.7000,                 loss: 0.0558
Episode: 1881/10000 (18.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.12s / 13939.48 s
first_0:                 episode reward: -52.4500,                 loss: nan
second_0:                 episode reward: 52.4500,                 loss: 0.0545
Episode: 1901/10000 (19.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.52s / 14090.00 s
first_0:                 episode reward: -55.2500,                 loss: nan
second_0:                 episode reward: 55.2500,                 loss: 0.0571
Episode: 1921/10000 (19.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.66s / 14240.66 s
first_0:                 episode reward: -46.5500,                 loss: nan
second_0:                 episode reward: 46.5500,                 loss: 0.0550
Episode: 1941/10000 (19.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.20s / 14391.87 s
first_0:                 episode reward: -57.4500,                 loss: nan
second_0:                 episode reward: 57.4500,                 loss: 0.0557
Episode: 1961/10000 (19.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.94s / 14542.80 s
first_0:                 episode reward: -32.8000,                 loss: nan
second_0:                 episode reward: 32.8000,                 loss: 0.0544
Episode: 1981/10000 (19.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.47s / 14693.27 s
first_0:                 episode reward: -50.5500,                 loss: nan
second_0:                 episode reward: 50.5500,                 loss: 0.0544
Episode: 2001/10000 (20.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.97s / 14843.25 s
first_0:                 episode reward: -51.9500,                 loss: nan
second_0:                 episode reward: 51.9500,                 loss: 0.0542
Episode: 2021/10000 (20.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.73s / 14994.97 s
first_0:                 episode reward: -48.3000,                 loss: nan
second_0:                 episode reward: 48.3000,                 loss: 0.0548
Episode: 2041/10000 (20.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.80s / 15145.78 s
first_0:                 episode reward: -54.9500,                 loss: nan
second_0:                 episode reward: 54.9500,                 loss: 0.0563
Episode: 2061/10000 (20.6100%),                 avg. length: 296.85,                last time consumption/overall running time: 150.37s / 15296.15 s
first_0:                 episode reward: -37.3000,                 loss: nan
second_0:                 episode reward: 37.3000,                 loss: 0.0551
Episode: 2081/10000 (20.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.55s / 15446.70 s
first_0:                 episode reward: -55.8500,                 loss: nan
second_0:                 episode reward: 55.8500,                 loss: 0.0555
Episode: 2101/10000 (21.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.97s / 15596.66 s
first_0:                 episode reward: -51.3000,                 loss: nan
second_0:                 episode reward: 51.3000,                 loss: 0.0558
Episode: 2121/10000 (21.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.77s / 15747.43 s
first_0:                 episode reward: -51.2000,                 loss: nan
second_0:                 episode reward: 51.2000,                 loss: 0.0558
Episode: 2141/10000 (21.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.74s / 15898.17 s
first_0:                 episode reward: -45.1000,                 loss: nan
second_0:                 episode reward: 45.1000,                 loss: 0.0559
Episode: 2161/10000 (21.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.01s / 16049.18 s
first_0:                 episode reward: -49.2500,                 loss: nan
second_0:                 episode reward: 49.2500,                 loss: 0.0555
Episode: 2181/10000 (21.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.74s / 16200.92 s
first_0:                 episode reward: -53.8500,                 loss: nan
second_0:                 episode reward: 53.8500,                 loss: 0.0576
Episode: 2201/10000 (22.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.05s / 16350.96 s
first_0:                 episode reward: -59.4500,                 loss: nan
second_0:                 episode reward: 59.4500,                 loss: 0.0562
Episode: 2221/10000 (22.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.25s / 16502.21 s
first_0:                 episode reward: -53.4000,                 loss: nan
second_0:                 episode reward: 53.4000,                 loss: 0.0564
Episode: 2241/10000 (22.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.28s / 16651.49 s
first_0:                 episode reward: -63.8500,                 loss: nan
second_0:                 episode reward: 63.8500,                 loss: 0.0556
Episode: 2261/10000 (22.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.28s / 16801.77 s
first_0:                 episode reward: -51.2000,                 loss: nan
second_0:                 episode reward: 51.2000,                 loss: 0.0567
Episode: 2281/10000 (22.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.62s / 16951.39 s
first_0:                 episode reward: -48.4000,                 loss: nan
second_0:                 episode reward: 48.4000,                 loss: 0.0571
Episode: 2301/10000 (23.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.15s / 17103.54 s
first_0:                 episode reward: -58.9000,                 loss: nan
second_0:                 episode reward: 58.9000,                 loss: 0.0577
Episode: 2321/10000 (23.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.56s / 17255.10 s
first_0:                 episode reward: -51.2500,                 loss: nan
second_0:                 episode reward: 51.2500,                 loss: 0.0613
Episode: 2341/10000 (23.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.46s / 17405.55 s
first_0:                 episode reward: -55.7500,                 loss: nan
second_0:                 episode reward: 55.7500,                 loss: 0.0619
Episode: 2361/10000 (23.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.99s / 17556.54 s
first_0:                 episode reward: -56.0000,                 loss: nan
second_0:                 episode reward: 56.0000,                 loss: 0.0624
Episode: 2381/10000 (23.8100%),                 avg. length: 295.05,                last time consumption/overall running time: 149.51s / 17706.05 s
first_0:                 episode reward: -54.1500,                 loss: nan
second_0:                 episode reward: 54.1500,                 loss: 0.0629
Episode: 2401/10000 (24.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.77s / 17855.82 s
first_0:                 episode reward: -47.8000,                 loss: nan
second_0:                 episode reward: 47.8000,                 loss: 0.0616
Episode: 2421/10000 (24.2100%),                 avg. length: 296.95,                last time consumption/overall running time: 149.64s / 18005.46 s
first_0:                 episode reward: -55.9000,                 loss: nan
second_0:                 episode reward: 55.9000,                 loss: 0.0616
Episode: 2441/10000 (24.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.93s / 18157.39 s
first_0:                 episode reward: -65.2000,                 loss: nan
second_0:                 episode reward: 65.2000,                 loss: 0.0613
Episode: 2461/10000 (24.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.88s / 18308.27 s
first_0:                 episode reward: -58.0000,                 loss: nan
second_0:                 episode reward: 58.0000,                 loss: 0.0638
Episode: 2481/10000 (24.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.82s / 18459.09 s
first_0:                 episode reward: -49.8500,                 loss: nan
second_0:                 episode reward: 49.8500,                 loss: 0.0633
Episode: 2501/10000 (25.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.67s / 18609.76 s
first_0:                 episode reward: -59.3000,                 loss: nan
second_0:                 episode reward: 59.3000,                 loss: 0.0634
Episode: 2521/10000 (25.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.81s / 18759.57 s
first_0:                 episode reward: -64.5500,                 loss: nan
second_0:                 episode reward: 64.5500,                 loss: 0.0646
Episode: 2541/10000 (25.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.36s / 18910.93 s
first_0:                 episode reward: -62.5000,                 loss: nan
second_0:                 episode reward: 62.5000,                 loss: 0.0615
Episode: 2561/10000 (25.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.49s / 19061.42 s
first_0:                 episode reward: -53.7500,                 loss: nan
second_0:                 episode reward: 53.7500,                 loss: 0.0623
Episode: 2581/10000 (25.8100%),                 avg. length: 297.65,                last time consumption/overall running time: 150.19s / 19211.60 s
first_0:                 episode reward: -48.6500,                 loss: nan
second_0:                 episode reward: 48.6500,                 loss: 0.0630
Episode: 2601/10000 (26.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.37s / 19362.97 s
first_0:                 episode reward: -63.6500,                 loss: nan
second_0:                 episode reward: 63.6500,                 loss: 0.0634
Episode: 2621/10000 (26.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.19s / 19515.16 s
first_0:                 episode reward: -59.0000,                 loss: nan
second_0:                 episode reward: 59.0000,                 loss: 0.0636
Episode: 2641/10000 (26.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.44s / 19666.60 s
first_0:                 episode reward: -61.6000,                 loss: nan
second_0:                 episode reward: 61.6000,                 loss: 0.0629
Episode: 2661/10000 (26.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 149.80s / 19816.40 s
first_0:                 episode reward: -53.5500,                 loss: nan
second_0:                 episode reward: 53.5500,                 loss: 0.0636
Episode: 2681/10000 (26.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.43s / 19966.83 s
first_0:                 episode reward: -53.5500,                 loss: nan
second_0:                 episode reward: 53.5500,                 loss: 0.0622
Episode: 2701/10000 (27.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.86s / 20117.69 s
first_0:                 episode reward: -61.4000,                 loss: nan
second_0:                 episode reward: 61.4000,                 loss: 0.0625
Episode: 2721/10000 (27.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.29s / 20268.98 s
first_0:                 episode reward: -65.3000,                 loss: nan
second_0:                 episode reward: 65.3000,                 loss: 0.0604
Episode: 2741/10000 (27.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.85s / 20419.84 s
first_0:                 episode reward: -54.0000,                 loss: nan
second_0:                 episode reward: 54.0000,                 loss: 0.0629
Episode: 2761/10000 (27.6100%),                 avg. length: 293.9,                last time consumption/overall running time: 148.66s / 20568.50 s
first_0:                 episode reward: -32.0000,                 loss: nan
second_0:                 episode reward: 32.0000,                 loss: 0.0628
Episode: 2781/10000 (27.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.28s / 20719.78 s
first_0:                 episode reward: -64.8000,                 loss: nan
second_0:                 episode reward: 64.8000,                 loss: 0.0611
Episode: 2801/10000 (28.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.53s / 20871.32 s
first_0:                 episode reward: -65.7500,                 loss: nan
second_0:                 episode reward: 65.7500,                 loss: 0.0619
Episode: 2821/10000 (28.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.32s / 21022.64 s
first_0:                 episode reward: -63.7000,                 loss: nan
second_0:                 episode reward: 63.7000,                 loss: 0.0605
Episode: 2841/10000 (28.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.78s / 21173.41 s
first_0:                 episode reward: -61.7000,                 loss: nan
second_0:                 episode reward: 61.7000,                 loss: 0.0618
Episode: 2861/10000 (28.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.95s / 21325.36 s
first_0:                 episode reward: -64.6000,                 loss: nan
second_0:                 episode reward: 64.6000,                 loss: 0.0618
Episode: 2881/10000 (28.8100%),                 avg. length: 299.0,                last time consumption/overall running time: 152.05s / 21477.41 s
first_0:                 episode reward: -59.2000,                 loss: nan
second_0:                 episode reward: 59.2000,                 loss: 0.0630
Episode: 2901/10000 (29.0100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.44s / 21628.85 s
first_0:                 episode reward: -66.7500,                 loss: nan
second_0:                 episode reward: 66.7500,                 loss: 0.0640
Episode: 2921/10000 (29.2100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.05s / 21778.90 s
first_0:                 episode reward: -49.1000,                 loss: nan
second_0:                 episode reward: 49.1000,                 loss: 0.0646
Episode: 2941/10000 (29.4100%),                 avg. length: 299.0,                last time consumption/overall running time: 151.03s / 21929.93 s
first_0:                 episode reward: -62.3500,                 loss: nan
second_0:                 episode reward: 62.3500,                 loss: 0.0663
Episode: 2961/10000 (29.6100%),                 avg. length: 299.0,                last time consumption/overall running time: 150.73s / 22080.67 s
first_0:                 episode reward: -69.0500,                 loss: nan
second_0:                 episode reward: 69.0500,                 loss: 0.0681
Episode: 2981/10000 (29.8100%),                 avg. length: 297.0,                last time consumption/overall running time: 149.43s / 22230.10 s
first_0:                 episode reward: -56.5000,                 loss: nan
second_0:                 episode reward: 56.5000,                 loss: 0.0672
Episode: 3001/10000 (30.0100%),                 avg. length: 296.85,                last time consumption/overall running time: 150.58s / 22380.68 s
first_0:                 episode reward: -52.0000,                 loss: nan
second_0:                 episode reward: 52.0000,                 loss: 0.0676
Episode: 3021/10000 (30.2100%),                 avg. length: 296.6,                last time consumption/overall running time: 150.75s / 22531.43 s
first_0:                 episode reward: -59.3500,                 loss: nan
second_0:                 episode reward: 59.3500,                 loss: 0.0693
Episode: 3041/10000 (30.4100%),                 avg. length: 296.7,                last time consumption/overall running time: 149.14s / 22680.57 s
first_0:                 episode reward: -78.4000,                 loss: nan
second_0:                 episode reward: 78.4000,                 loss: 0.0712
Episode: 3061/10000 (30.6100%),                 avg. length: 289.9,                last time consumption/overall running time: 147.15s / 22827.72 s
first_0:                 episode reward: -67.5000,                 loss: nan
second_0:                 episode reward: 67.5000,                 loss: 0.0720
Episode: 3081/10000 (30.8100%),                 avg. length: 281.35,                last time consumption/overall running time: 144.07s / 22971.79 s
first_0:                 episode reward: -54.3500,                 loss: nan
second_0:                 episode reward: 54.3500,                 loss: 0.0693
Episode: 3101/10000 (31.0100%),                 avg. length: 272.1,                last time consumption/overall running time: 138.77s / 23110.56 s
first_0:                 episode reward: -83.3500,                 loss: nan
second_0:                 episode reward: 83.3500,                 loss: 0.0694
Episode: 3121/10000 (31.2100%),                 avg. length: 260.9,                last time consumption/overall running time: 133.43s / 23243.99 s
first_0:                 episode reward: -95.6000,                 loss: nan
second_0:                 episode reward: 95.6000,                 loss: 0.0670
Episode: 3141/10000 (31.4100%),                 avg. length: 261.55,                last time consumption/overall running time: 132.40s / 23376.39 s
first_0:                 episode reward: -85.4000,                 loss: nan
second_0:                 episode reward: 85.4000,                 loss: 0.0631
Episode: 3161/10000 (31.6100%),                 avg. length: 265.45,                last time consumption/overall running time: 133.44s / 23509.83 s
first_0:                 episode reward: -97.2000,                 loss: nan
second_0:                 episode reward: 97.2000,                 loss: 0.0611
Episode: 3181/10000 (31.8100%),                 avg. length: 262.0,                last time consumption/overall running time: 134.55s / 23644.38 s
first_0:                 episode reward: -90.6500,                 loss: nan
second_0:                 episode reward: 90.6500,                 loss: 0.0602
Episode: 3201/10000 (32.0100%),                 avg. length: 264.2,                last time consumption/overall running time: 135.67s / 23780.05 s
first_0:                 episode reward: -83.9000,                 loss: nan
second_0:                 episode reward: 83.9000,                 loss: 0.0568
Episode: 3221/10000 (32.2100%),                 avg. length: 260.05,                last time consumption/overall running time: 132.52s / 23912.57 s
first_0:                 episode reward: -75.3500,                 loss: nan
second_0:                 episode reward: 75.3500,                 loss: 0.0550
Episode: 3241/10000 (32.4100%),                 avg. length: 255.65,                last time consumption/overall running time: 129.41s / 24041.98 s
first_0:                 episode reward: -90.1000,                 loss: nan
second_0:                 episode reward: 90.1000,                 loss: 0.0541
Episode: 3261/10000 (32.6100%),                 avg. length: 247.8,                last time consumption/overall running time: 126.46s / 24168.44 s
first_0:                 episode reward: -84.3500,                 loss: nan
second_0:                 episode reward: 84.3500,                 loss: 0.0508
Episode: 3281/10000 (32.8100%),                 avg. length: 243.25,                last time consumption/overall running time: 123.04s / 24291.48 s
first_0:                 episode reward: -95.7500,                 loss: nan
second_0:                 episode reward: 95.7500,                 loss: 0.0500
Episode: 3301/10000 (33.0100%),                 avg. length: 254.6,                last time consumption/overall running time: 128.83s / 24420.31 s
first_0:                 episode reward: -89.1000,                 loss: nan
second_0:                 episode reward: 89.1000,                 loss: 0.0484
Episode: 3321/10000 (33.2100%),                 avg. length: 244.4,                last time consumption/overall running time: 123.25s / 24543.55 s
first_0:                 episode reward: -96.5500,                 loss: nan
second_0:                 episode reward: 96.5500,                 loss: 0.0464
Episode: 3341/10000 (33.4100%),                 avg. length: 253.6,                last time consumption/overall running time: 128.03s / 24671.58 s
first_0:                 episode reward: -84.7500,                 loss: nan
second_0:                 episode reward: 84.7500,                 loss: 0.0472
Episode: 3361/10000 (33.6100%),                 avg. length: 249.2,                last time consumption/overall running time: 126.87s / 24798.46 s
first_0:                 episode reward: -89.7500,                 loss: nan
second_0:                 episode reward: 89.7500,                 loss: 0.0455
Episode: 3381/10000 (33.8100%),                 avg. length: 233.25,                last time consumption/overall running time: 118.23s / 24916.69 s
first_0:                 episode reward: -95.8500,                 loss: nan
second_0:                 episode reward: 95.8500,                 loss: 0.0447
Episode: 3401/10000 (34.0100%),                 avg. length: 242.95,                last time consumption/overall running time: 122.93s / 25039.61 s
first_0:                 episode reward: -71.2500,                 loss: nan
second_0:                 episode reward: 71.2500,                 loss: 0.0433
Episode: 3421/10000 (34.2100%),                 avg. length: 247.65,                last time consumption/overall running time: 125.69s / 25165.30 s
first_0:                 episode reward: -92.7000,                 loss: nan
second_0:                 episode reward: 92.7000,                 loss: 0.0431
Episode: 3441/10000 (34.4100%),                 avg. length: 246.75,                last time consumption/overall running time: 125.53s / 25290.83 s
first_0:                 episode reward: -85.3500,                 loss: nan
second_0:                 episode reward: 85.3500,                 loss: 0.0406
Episode: 3461/10000 (34.6100%),                 avg. length: 240.8,                last time consumption/overall running time: 121.33s / 25412.16 s
first_0:                 episode reward: -90.2500,                 loss: nan
second_0:                 episode reward: 90.2500,                 loss: 0.0396
Episode: 3481/10000 (34.8100%),                 avg. length: 253.1,                last time consumption/overall running time: 128.90s / 25541.06 s
first_0:                 episode reward: -91.3000,                 loss: nan
second_0:                 episode reward: 91.3000,                 loss: 0.0393
Episode: 3501/10000 (35.0100%),                 avg. length: 234.2,                last time consumption/overall running time: 118.70s / 25659.76 s
first_0:                 episode reward: -89.7500,                 loss: nan
second_0:                 episode reward: 89.7500,                 loss: 0.0383
Episode: 3521/10000 (35.2100%),                 avg. length: 246.1,                last time consumption/overall running time: 124.26s / 25784.02 s
first_0:                 episode reward: -96.3500,                 loss: nan
second_0:                 episode reward: 96.3500,                 loss: 0.0383
Episode: 3541/10000 (35.4100%),                 avg. length: 230.85,                last time consumption/overall running time: 116.74s / 25900.76 s
first_0:                 episode reward: -94.4000,                 loss: nan
second_0:                 episode reward: 94.4000,                 loss: 0.0374
Episode: 3561/10000 (35.6100%),                 avg. length: 235.0,                last time consumption/overall running time: 119.13s / 26019.89 s
first_0:                 episode reward: -96.7500,                 loss: nan
second_0:                 episode reward: 96.7500,                 loss: 0.0364
Episode: 3581/10000 (35.8100%),                 avg. length: 231.9,                last time consumption/overall running time: 117.21s / 26137.10 s
first_0:                 episode reward: -94.3500,                 loss: nan
second_0:                 episode reward: 94.3500,                 loss: 0.0358
Episode: 3601/10000 (36.0100%),                 avg. length: 242.3,                last time consumption/overall running time: 123.48s / 26260.58 s
first_0:                 episode reward: -85.1000,                 loss: nan
second_0:                 episode reward: 85.1000,                 loss: 0.0355
Episode: 3621/10000 (36.2100%),                 avg. length: 246.35,                last time consumption/overall running time: 125.18s / 26385.75 s
first_0:                 episode reward: -64.3500,                 loss: nan
second_0:                 episode reward: 64.3500,                 loss: 0.0346
Episode: 3641/10000 (36.4100%),                 avg. length: 233.45,                last time consumption/overall running time: 117.49s / 26503.24 s
first_0:                 episode reward: -82.6000,                 loss: nan
second_0:                 episode reward: 82.6000,                 loss: 0.0352
Episode: 3661/10000 (36.6100%),                 avg. length: 230.55,                last time consumption/overall running time: 117.13s / 26620.37 s
first_0:                 episode reward: -89.6000,                 loss: nan
second_0:                 episode reward: 89.6000,                 loss: 0.0334
Episode: 3681/10000 (36.8100%),                 avg. length: 239.8,                last time consumption/overall running time: 120.60s / 26740.97 s
first_0:                 episode reward: -94.0500,                 loss: nan
second_0:                 episode reward: 94.0500,                 loss: 0.0336
Episode: 3701/10000 (37.0100%),                 avg. length: 228.8,                last time consumption/overall running time: 114.85s / 26855.82 s
first_0:                 episode reward: -99.2500,                 loss: nan
second_0:                 episode reward: 99.2500,                 loss: 0.0329
Episode: 3721/10000 (37.2100%),                 avg. length: 224.7,                last time consumption/overall running time: 113.79s / 26969.61 s
first_0:                 episode reward: -98.9500,                 loss: nan
second_0:                 episode reward: 98.9500,                 loss: 0.0340
Episode: 3741/10000 (37.4100%),                 avg. length: 234.6,                last time consumption/overall running time: 118.27s / 27087.88 s
first_0:                 episode reward: -90.5000,                 loss: nan
second_0:                 episode reward: 90.5000,                 loss: 0.0336
Episode: 3761/10000 (37.6100%),                 avg. length: 224.7,                last time consumption/overall running time: 113.75s / 27201.63 s
first_0:                 episode reward: -99.1500,                 loss: nan
second_0:                 episode reward: 99.1500,                 loss: 0.0338
Episode: 3781/10000 (37.8100%),                 avg. length: 233.85,                last time consumption/overall running time: 119.33s / 27320.96 s
first_0:                 episode reward: -94.5000,                 loss: nan
second_0:                 episode reward: 94.5000,                 loss: 0.0328
Episode: 3801/10000 (38.0100%),                 avg. length: 232.75,                last time consumption/overall running time: 117.83s / 27438.79 s
first_0:                 episode reward: -89.4500,                 loss: nan
second_0:                 episode reward: 89.4500,                 loss: 0.0323
Episode: 3821/10000 (38.2100%),                 avg. length: 233.3,                last time consumption/overall running time: 119.12s / 27557.91 s
first_0:                 episode reward: -99.6000,                 loss: nan
second_0:                 episode reward: 99.6000,                 loss: 0.0320
Episode: 3841/10000 (38.4100%),                 avg. length: 236.9,                last time consumption/overall running time: 119.61s / 27677.52 s
first_0:                 episode reward: -97.8500,                 loss: nan
second_0:                 episode reward: 97.8500,                 loss: 0.0322
Episode: 3861/10000 (38.6100%),                 avg. length: 230.3,                last time consumption/overall running time: 116.27s / 27793.79 s
first_0:                 episode reward: -99.5000,                 loss: nan
second_0:                 episode reward: 99.5000,                 loss: 0.0314
Episode: 3881/10000 (38.8100%),                 avg. length: 225.65,                last time consumption/overall running time: 114.32s / 27908.11 s
first_0:                 episode reward: -98.8000,                 loss: nan
second_0:                 episode reward: 98.8000,                 loss: 0.0322
Episode: 3901/10000 (39.0100%),                 avg. length: 228.8,                last time consumption/overall running time: 115.64s / 28023.75 s
first_0:                 episode reward: -99.2500,                 loss: nan
second_0:                 episode reward: 99.2500,                 loss: 0.0316
Episode: 3921/10000 (39.2100%),                 avg. length: 242.55,                last time consumption/overall running time: 122.25s / 28146.00 s
first_0:                 episode reward: -80.3500,                 loss: nan
second_0:                 episode reward: 80.3500,                 loss: 0.0324
Episode: 3941/10000 (39.4100%),                 avg. length: 224.95,                last time consumption/overall running time: 114.24s / 28260.24 s
first_0:                 episode reward: -99.6500,                 loss: nan
second_0:                 episode reward: 99.6500,                 loss: 0.0323
Episode: 3961/10000 (39.6100%),                 avg. length: 233.4,                last time consumption/overall running time: 118.16s / 28378.40 s
first_0:                 episode reward: -83.1500,                 loss: nan
second_0:                 episode reward: 83.1500,                 loss: 0.0332
Episode: 3981/10000 (39.8100%),                 avg. length: 237.05,                last time consumption/overall running time: 120.51s / 28498.91 s
first_0:                 episode reward: -88.8500,                 loss: nan
second_0:                 episode reward: 88.8500,                 loss: 0.0330
Episode: 4001/10000 (40.0100%),                 avg. length: 241.75,                last time consumption/overall running time: 122.04s / 28620.94 s
first_0:                 episode reward: -98.9500,                 loss: nan
second_0:                 episode reward: 98.9500,                 loss: 0.0325
Episode: 4021/10000 (40.2100%),                 avg. length: 242.8,                last time consumption/overall running time: 122.99s / 28743.94 s
first_0:                 episode reward: -93.8000,                 loss: nan
second_0:                 episode reward: 93.8000,                 loss: 0.0317
Episode: 4041/10000 (40.4100%),                 avg. length: 241.85,                last time consumption/overall running time: 122.41s / 28866.34 s
first_0:                 episode reward: -68.4000,                 loss: nan
second_0:                 episode reward: 68.4000,                 loss: 0.0319
Episode: 4061/10000 (40.6100%),                 avg. length: 237.25,                last time consumption/overall running time: 121.10s / 28987.44 s
first_0:                 episode reward: -78.0500,                 loss: nan
second_0:                 episode reward: 78.0500,                 loss: 0.0321
Episode: 4081/10000 (40.8100%),                 avg. length: 236.6,                last time consumption/overall running time: 119.75s / 29107.19 s
first_0:                 episode reward: -79.9000,                 loss: nan
second_0:                 episode reward: 79.9000,                 loss: 0.0317
Episode: 4101/10000 (41.0100%),                 avg. length: 231.5,                last time consumption/overall running time: 117.39s / 29224.57 s
first_0:                 episode reward: -94.8500,                 loss: nan
second_0:                 episode reward: 94.8500,                 loss: 0.0299
Episode: 4121/10000 (41.2100%),                 avg. length: 229.9,                last time consumption/overall running time: 115.40s / 29339.98 s
first_0:                 episode reward: -99.5500,                 loss: nan
second_0:                 episode reward: 99.5500,                 loss: 0.0306
Episode: 4141/10000 (41.4100%),                 avg. length: 232.45,                last time consumption/overall running time: 117.73s / 29457.71 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.0303
Episode: 4161/10000 (41.6100%),                 avg. length: 232.8,                last time consumption/overall running time: 118.77s / 29576.48 s
first_0:                 episode reward: -99.1000,                 loss: nan
second_0:                 episode reward: 99.1000,                 loss: 0.0297
Episode: 4181/10000 (41.8100%),                 avg. length: 230.9,                last time consumption/overall running time: 116.78s / 29693.26 s
first_0:                 episode reward: -99.4500,                 loss: nan
second_0:                 episode reward: 99.4500,                 loss: 0.0302
Episode: 4201/10000 (42.0100%),                 avg. length: 223.8,                last time consumption/overall running time: 112.57s / 29805.82 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0300
Episode: 4221/10000 (42.2100%),                 avg. length: 230.95,                last time consumption/overall running time: 116.22s / 29922.04 s
first_0:                 episode reward: -99.0500,                 loss: nan
second_0:                 episode reward: 99.0500,                 loss: 0.0306
Episode: 4241/10000 (42.4100%),                 avg. length: 229.45,                last time consumption/overall running time: 116.01s / 30038.05 s
first_0:                 episode reward: -88.2000,                 loss: nan
second_0:                 episode reward: 88.2000,                 loss: 0.0297
Episode: 4261/10000 (42.6100%),                 avg. length: 238.65,                last time consumption/overall running time: 121.43s / 30159.49 s
first_0:                 episode reward: -99.4000,                 loss: nan
second_0:                 episode reward: 99.4000,                 loss: 0.0304
Episode: 4281/10000 (42.8100%),                 avg. length: 235.5,                last time consumption/overall running time: 119.90s / 30279.39 s
first_0:                 episode reward: -87.6000,                 loss: nan
second_0:                 episode reward: 87.6000,                 loss: 0.0299
Episode: 4301/10000 (43.0100%),                 avg. length: 245.05,                last time consumption/overall running time: 123.67s / 30403.06 s
first_0:                 episode reward: -74.3500,                 loss: nan
second_0:                 episode reward: 74.3500,                 loss: 0.0290
Episode: 4321/10000 (43.2100%),                 avg. length: 239.65,                last time consumption/overall running time: 121.58s / 30524.64 s
first_0:                 episode reward: -99.2000,                 loss: nan
second_0:                 episode reward: 99.2000,                 loss: 0.0294
Episode: 4341/10000 (43.4100%),                 avg. length: 239.6,                last time consumption/overall running time: 121.36s / 30646.00 s
first_0:                 episode reward: -97.5500,                 loss: nan
second_0:                 episode reward: 97.5500,                 loss: 0.0295
Episode: 4361/10000 (43.6100%),                 avg. length: 230.2,                last time consumption/overall running time: 117.10s / 30763.10 s
first_0:                 episode reward: -99.2000,                 loss: nan
second_0:                 episode reward: 99.2000,                 loss: 0.0292
Episode: 4381/10000 (43.8100%),                 avg. length: 229.7,                last time consumption/overall running time: 116.94s / 30880.04 s
first_0:                 episode reward: -82.2500,                 loss: nan
second_0:                 episode reward: 82.2500,                 loss: 0.0295
Episode: 4401/10000 (44.0100%),                 avg. length: 222.2,                last time consumption/overall running time: 112.63s / 30992.67 s
first_0:                 episode reward: -96.9500,                 loss: nan
second_0:                 episode reward: 96.9500,                 loss: 0.0300
Episode: 4421/10000 (44.2100%),                 avg. length: 229.7,                last time consumption/overall running time: 115.30s / 31107.97 s
first_0:                 episode reward: -79.4500,                 loss: nan
second_0:                 episode reward: 79.4500,                 loss: 0.0281
Episode: 4441/10000 (44.4100%),                 avg. length: 239.2,                last time consumption/overall running time: 121.21s / 31229.19 s
first_0:                 episode reward: -85.7500,                 loss: nan
second_0:                 episode reward: 85.7500,                 loss: 0.0278
Episode: 4461/10000 (44.6100%),                 avg. length: 225.4,                last time consumption/overall running time: 114.22s / 31343.41 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0277
Episode: 4481/10000 (44.8100%),                 avg. length: 224.2,                last time consumption/overall running time: 113.62s / 31457.02 s
first_0:                 episode reward: -99.6000,                 loss: nan
second_0:                 episode reward: 99.6000,                 loss: 0.0276
Episode: 4501/10000 (45.0100%),                 avg. length: 232.15,                last time consumption/overall running time: 116.46s / 31573.49 s
first_0:                 episode reward: -99.4500,                 loss: nan
second_0:                 episode reward: 99.4500,                 loss: 0.0278
Episode: 4521/10000 (45.2100%),                 avg. length: 220.45,                last time consumption/overall running time: 111.42s / 31684.90 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0291
Episode: 4541/10000 (45.4100%),                 avg. length: 230.6,                last time consumption/overall running time: 116.82s / 31801.72 s
first_0:                 episode reward: -99.1500,                 loss: nan
second_0:                 episode reward: 99.1500,                 loss: 0.0285
Episode: 4561/10000 (45.6100%),                 avg. length: 221.15,                last time consumption/overall running time: 111.90s / 31913.62 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0296
Episode: 4581/10000 (45.8100%),                 avg. length: 218.7,                last time consumption/overall running time: 110.71s / 32024.33 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0291
Episode: 4601/10000 (46.0100%),                 avg. length: 228.2,                last time consumption/overall running time: 114.90s / 32139.23 s
first_0:                 episode reward: -94.8500,                 loss: nan
second_0:                 episode reward: 94.8500,                 loss: 0.0279
Episode: 4621/10000 (46.2100%),                 avg. length: 222.85,                last time consumption/overall running time: 113.09s / 32252.32 s
first_0:                 episode reward: -94.8000,                 loss: nan
second_0:                 episode reward: 94.8000,                 loss: 0.0274
Episode: 4641/10000 (46.4100%),                 avg. length: 233.5,                last time consumption/overall running time: 117.42s / 32369.74 s
first_0:                 episode reward: -94.7000,                 loss: nan
second_0:                 episode reward: 94.7000,                 loss: 0.0265
Episode: 4661/10000 (46.6100%),                 avg. length: 222.55,                last time consumption/overall running time: 113.14s / 32482.88 s
first_0:                 episode reward: -90.9000,                 loss: nan
second_0:                 episode reward: 90.9000,                 loss: 0.0270
Episode: 4681/10000 (46.8100%),                 avg. length: 229.7,                last time consumption/overall running time: 115.76s / 32598.64 s
first_0:                 episode reward: -97.4500,                 loss: nan
second_0:                 episode reward: 97.4500,                 loss: 0.0267
Episode: 4701/10000 (47.0100%),                 avg. length: 232.1,                last time consumption/overall running time: 118.45s / 32717.09 s
first_0:                 episode reward: -87.9500,                 loss: nan
second_0:                 episode reward: 87.9500,                 loss: 0.0274
Episode: 4721/10000 (47.2100%),                 avg. length: 230.5,                last time consumption/overall running time: 116.39s / 32833.48 s
first_0:                 episode reward: -99.0000,                 loss: nan
second_0:                 episode reward: 99.0000,                 loss: 0.0272
Episode: 4741/10000 (47.4100%),                 avg. length: 224.05,                last time consumption/overall running time: 114.25s / 32947.72 s
first_0:                 episode reward: -85.6500,                 loss: nan
second_0:                 episode reward: 85.6500,                 loss: 0.0288
Episode: 4761/10000 (47.6100%),                 avg. length: 225.0,                last time consumption/overall running time: 113.73s / 33061.45 s
first_0:                 episode reward: -92.0000,                 loss: nan
second_0:                 episode reward: 92.0000,                 loss: 0.0284
Episode: 4781/10000 (47.8100%),                 avg. length: 233.65,                last time consumption/overall running time: 117.67s / 33179.12 s
first_0:                 episode reward: -83.4000,                 loss: nan
second_0:                 episode reward: 83.4000,                 loss: 0.0279
Episode: 4801/10000 (48.0100%),                 avg. length: 233.25,                last time consumption/overall running time: 118.59s / 33297.71 s
first_0:                 episode reward: -91.5000,                 loss: nan
second_0:                 episode reward: 91.5000,                 loss: 0.0281
Episode: 4821/10000 (48.2100%),                 avg. length: 222.8,                last time consumption/overall running time: 112.44s / 33410.16 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0272
Episode: 4841/10000 (48.4100%),                 avg. length: 223.3,                last time consumption/overall running time: 113.75s / 33523.91 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0285
Episode: 4861/10000 (48.6100%),                 avg. length: 226.55,                last time consumption/overall running time: 115.49s / 33639.40 s
first_0:                 episode reward: -92.4000,                 loss: nan
second_0:                 episode reward: 92.4000,                 loss: 0.0280
Episode: 4881/10000 (48.8100%),                 avg. length: 227.0,                last time consumption/overall running time: 115.78s / 33755.18 s
first_0:                 episode reward: -90.3000,                 loss: nan
second_0:                 episode reward: 90.3000,                 loss: 0.0285
Episode: 4901/10000 (49.0100%),                 avg. length: 222.6,                last time consumption/overall running time: 113.54s / 33868.72 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0284
Episode: 4921/10000 (49.2100%),                 avg. length: 218.4,                last time consumption/overall running time: 111.62s / 33980.34 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0285
Episode: 4941/10000 (49.4100%),                 avg. length: 234.0,                last time consumption/overall running time: 118.75s / 34099.09 s
first_0:                 episode reward: -86.8500,                 loss: nan
second_0:                 episode reward: 86.8500,                 loss: 0.0299
Episode: 4961/10000 (49.6100%),                 avg. length: 223.5,                last time consumption/overall running time: 113.22s / 34212.31 s
first_0:                 episode reward: -89.8500,                 loss: nan
second_0:                 episode reward: 89.8500,                 loss: 0.0288
Episode: 4981/10000 (49.8100%),                 avg. length: 223.4,                last time consumption/overall running time: 113.85s / 34326.16 s
first_0:                 episode reward: -99.3000,                 loss: nan
second_0:                 episode reward: 99.3000,                 loss: 0.0283
Episode: 5001/10000 (50.0100%),                 avg. length: 230.3,                last time consumption/overall running time: 117.84s / 34444.00 s
first_0:                 episode reward: -87.0000,                 loss: nan
second_0:                 episode reward: 87.0000,                 loss: 0.0276
Episode: 5021/10000 (50.2100%),                 avg. length: 226.25,                last time consumption/overall running time: 113.95s / 34557.95 s
first_0:                 episode reward: -98.3000,                 loss: nan
second_0:                 episode reward: 98.3000,                 loss: 0.0268
Episode: 5041/10000 (50.4100%),                 avg. length: 222.65,                last time consumption/overall running time: 112.49s / 34670.45 s
first_0:                 episode reward: -99.2500,                 loss: nan
second_0:                 episode reward: 99.2500,                 loss: 0.0279
Episode: 5061/10000 (50.6100%),                 avg. length: 227.85,                last time consumption/overall running time: 116.28s / 34786.72 s
first_0:                 episode reward: -83.5500,                 loss: nan
second_0:                 episode reward: 83.5500,                 loss: 0.0272
Episode: 5081/10000 (50.8100%),                 avg. length: 220.95,                last time consumption/overall running time: 111.81s / 34898.54 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0279
Episode: 5101/10000 (51.0100%),                 avg. length: 227.3,                last time consumption/overall running time: 114.79s / 35013.33 s
first_0:                 episode reward: -98.6000,                 loss: nan
second_0:                 episode reward: 98.6000,                 loss: 0.0276
Episode: 5121/10000 (51.2100%),                 avg. length: 234.45,                last time consumption/overall running time: 119.69s / 35133.02 s
first_0:                 episode reward: -85.7500,                 loss: nan
second_0:                 episode reward: 85.7500,                 loss: 0.0277
Episode: 5141/10000 (51.4100%),                 avg. length: 228.75,                last time consumption/overall running time: 116.59s / 35249.62 s
first_0:                 episode reward: -98.9500,                 loss: nan
second_0:                 episode reward: 98.9500,                 loss: 0.0270
Episode: 5161/10000 (51.6100%),                 avg. length: 228.95,                last time consumption/overall running time: 115.82s / 35365.44 s
first_0:                 episode reward: -90.3000,                 loss: nan
second_0:                 episode reward: 90.3000,                 loss: 0.0283
Episode: 5181/10000 (51.8100%),                 avg. length: 229.7,                last time consumption/overall running time: 116.17s / 35481.61 s
first_0:                 episode reward: -88.9000,                 loss: nan
second_0:                 episode reward: 88.9000,                 loss: 0.0278
Episode: 5201/10000 (52.0100%),                 avg. length: 224.4,                last time consumption/overall running time: 113.82s / 35595.43 s
first_0:                 episode reward: -96.2500,                 loss: nan
second_0:                 episode reward: 96.2500,                 loss: 0.0272
Episode: 5221/10000 (52.2100%),                 avg. length: 229.0,                last time consumption/overall running time: 116.84s / 35712.26 s
first_0:                 episode reward: -99.4000,                 loss: nan
second_0:                 episode reward: 99.4000,                 loss: 0.0284
Episode: 5241/10000 (52.4100%),                 avg. length: 221.95,                last time consumption/overall running time: 112.47s / 35824.73 s
first_0:                 episode reward: -99.4500,                 loss: nan
second_0:                 episode reward: 99.4500,                 loss: 0.0286
Episode: 5261/10000 (52.6100%),                 avg. length: 224.1,                last time consumption/overall running time: 114.49s / 35939.22 s
first_0:                 episode reward: -99.1000,                 loss: nan
second_0:                 episode reward: 99.1000,                 loss: 0.0277
Episode: 5281/10000 (52.8100%),                 avg. length: 223.0,                last time consumption/overall running time: 112.79s / 36052.01 s
first_0:                 episode reward: -90.8500,                 loss: nan
second_0:                 episode reward: 90.8500,                 loss: 0.0283
Episode: 5301/10000 (53.0100%),                 avg. length: 223.2,                last time consumption/overall running time: 112.84s / 36164.85 s
first_0:                 episode reward: -82.5500,                 loss: nan
second_0:                 episode reward: 82.5500,                 loss: 0.0278
Episode: 5321/10000 (53.2100%),                 avg. length: 223.35,                last time consumption/overall running time: 113.63s / 36278.48 s
first_0:                 episode reward: -90.7500,                 loss: nan
second_0:                 episode reward: 90.7500,                 loss: 0.0283
Episode: 5341/10000 (53.4100%),                 avg. length: 220.3,                last time consumption/overall running time: 111.64s / 36390.12 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0285
Episode: 5361/10000 (53.6100%),                 avg. length: 219.75,                last time consumption/overall running time: 111.68s / 36501.80 s
first_0:                 episode reward: -91.4000,                 loss: nan
second_0:                 episode reward: 91.4000,                 loss: 0.0283
Episode: 5381/10000 (53.8100%),                 avg. length: 227.65,                last time consumption/overall running time: 115.78s / 36617.58 s
first_0:                 episode reward: -99.0000,                 loss: nan
second_0:                 episode reward: 99.0000,                 loss: 0.0275
Episode: 5401/10000 (54.0100%),                 avg. length: 230.9,                last time consumption/overall running time: 116.79s / 36734.37 s
first_0:                 episode reward: -91.9500,                 loss: nan
second_0:                 episode reward: 91.9500,                 loss: 0.0276
Episode: 5421/10000 (54.2100%),                 avg. length: 228.8,                last time consumption/overall running time: 115.54s / 36849.91 s
first_0:                 episode reward: -91.6500,                 loss: nan
second_0:                 episode reward: 91.6500,                 loss: 0.0280
Episode: 5441/10000 (54.4100%),                 avg. length: 232.0,                last time consumption/overall running time: 117.53s / 36967.44 s
first_0:                 episode reward: -98.8000,                 loss: nan
second_0:                 episode reward: 98.8000,                 loss: 0.0290
Episode: 5461/10000 (54.6100%),                 avg. length: 228.75,                last time consumption/overall running time: 115.11s / 37082.55 s
first_0:                 episode reward: -90.9500,                 loss: nan
second_0:                 episode reward: 90.9500,                 loss: 0.0299
Episode: 5481/10000 (54.8100%),                 avg. length: 222.45,                last time consumption/overall running time: 113.42s / 37195.97 s
first_0:                 episode reward: -97.1500,                 loss: nan
second_0:                 episode reward: 97.1500,                 loss: 0.0288
Episode: 5501/10000 (55.0100%),                 avg. length: 227.3,                last time consumption/overall running time: 115.11s / 37311.08 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.0293
Episode: 5521/10000 (55.2100%),                 avg. length: 220.1,                last time consumption/overall running time: 110.01s / 37421.09 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0286
Episode: 5541/10000 (55.4100%),                 avg. length: 224.35,                last time consumption/overall running time: 113.38s / 37534.47 s
first_0:                 episode reward: -99.5000,                 loss: nan
second_0:                 episode reward: 99.5000,                 loss: 0.0292
Episode: 5561/10000 (55.6100%),                 avg. length: 221.2,                last time consumption/overall running time: 111.29s / 37645.76 s
first_0:                 episode reward: -89.7500,                 loss: nan
second_0:                 episode reward: 89.7500,                 loss: 0.0297
Episode: 5581/10000 (55.8100%),                 avg. length: 228.3,                last time consumption/overall running time: 116.16s / 37761.91 s
first_0:                 episode reward: -82.3500,                 loss: nan
second_0:                 episode reward: 82.3500,                 loss: 0.0298
Episode: 5601/10000 (56.0100%),                 avg. length: 225.0,                last time consumption/overall running time: 113.29s / 37875.20 s
first_0:                 episode reward: -99.0000,                 loss: nan
second_0:                 episode reward: 99.0000,                 loss: 0.0289
Episode: 5621/10000 (56.2100%),                 avg. length: 234.8,                last time consumption/overall running time: 118.33s / 37993.53 s
first_0:                 episode reward: -87.2000,                 loss: nan
second_0:                 episode reward: 87.2000,                 loss: 0.0289
Episode: 5641/10000 (56.4100%),                 avg. length: 222.25,                last time consumption/overall running time: 112.78s / 38106.31 s
first_0:                 episode reward: -91.4000,                 loss: nan
second_0:                 episode reward: 91.4000,                 loss: 0.0284
Episode: 5661/10000 (56.6100%),                 avg. length: 223.2,                last time consumption/overall running time: 113.38s / 38219.69 s
first_0:                 episode reward: -99.6500,                 loss: nan
second_0:                 episode reward: 99.6500,                 loss: 0.0299
Episode: 5681/10000 (56.8100%),                 avg. length: 227.25,                last time consumption/overall running time: 115.28s / 38334.96 s
first_0:                 episode reward: -88.8000,                 loss: nan
second_0:                 episode reward: 88.8000,                 loss: 0.0293
Episode: 5701/10000 (57.0100%),                 avg. length: 232.5,                last time consumption/overall running time: 118.28s / 38453.24 s
first_0:                 episode reward: -90.1500,                 loss: nan
second_0:                 episode reward: 90.1500,                 loss: 0.0287
Episode: 5721/10000 (57.2100%),                 avg. length: 222.6,                last time consumption/overall running time: 113.42s / 38566.66 s
first_0:                 episode reward: -96.4000,                 loss: nan
second_0:                 episode reward: 96.4000,                 loss: 0.0291
Episode: 5741/10000 (57.4100%),                 avg. length: 232.75,                last time consumption/overall running time: 118.44s / 38685.09 s
first_0:                 episode reward: -97.5500,                 loss: nan
second_0:                 episode reward: 97.5500,                 loss: 0.0290
Episode: 5761/10000 (57.6100%),                 avg. length: 240.9,                last time consumption/overall running time: 122.20s / 38807.29 s
first_0:                 episode reward: -97.2000,                 loss: nan
second_0:                 episode reward: 97.2000,                 loss: 0.0301
Episode: 5781/10000 (57.8100%),                 avg. length: 214.45,                last time consumption/overall running time: 109.15s / 38916.44 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0300
Episode: 5801/10000 (58.0100%),                 avg. length: 226.35,                last time consumption/overall running time: 113.88s / 39030.32 s
first_0:                 episode reward: -99.4500,                 loss: nan
second_0:                 episode reward: 99.4500,                 loss: 0.0300
Episode: 5821/10000 (58.2100%),                 avg. length: 216.15,                last time consumption/overall running time: 109.76s / 39140.08 s
first_0:                 episode reward: -99.6500,                 loss: nan
second_0:                 episode reward: 99.6500,                 loss: 0.0290
Episode: 5841/10000 (58.4100%),                 avg. length: 219.5,                last time consumption/overall running time: 110.99s / 39251.07 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0296
Episode: 5861/10000 (58.6100%),                 avg. length: 214.45,                last time consumption/overall running time: 108.86s / 39359.93 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0299
Episode: 5881/10000 (58.8100%),                 avg. length: 215.65,                last time consumption/overall running time: 110.34s / 39470.27 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0293
Episode: 5901/10000 (59.0100%),                 avg. length: 220.6,                last time consumption/overall running time: 110.92s / 39581.19 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0297
Episode: 5921/10000 (59.2100%),                 avg. length: 222.7,                last time consumption/overall running time: 112.94s / 39694.13 s
first_0:                 episode reward: -99.3000,                 loss: nan
second_0:                 episode reward: 99.3000,                 loss: 0.0302
Episode: 5941/10000 (59.4100%),                 avg. length: 219.95,                last time consumption/overall running time: 111.58s / 39805.71 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0309
Episode: 5961/10000 (59.6100%),                 avg. length: 224.0,                last time consumption/overall running time: 112.86s / 39918.57 s
first_0:                 episode reward: -89.4500,                 loss: nan
second_0:                 episode reward: 89.4500,                 loss: 0.0300
Episode: 5981/10000 (59.8100%),                 avg. length: 227.05,                last time consumption/overall running time: 114.61s / 40033.18 s
first_0:                 episode reward: -80.4000,                 loss: nan
second_0:                 episode reward: 80.4000,                 loss: 0.0296
Episode: 6001/10000 (60.0100%),                 avg. length: 225.7,                last time consumption/overall running time: 114.23s / 40147.41 s
first_0:                 episode reward: -88.9000,                 loss: nan
second_0:                 episode reward: 88.9000,                 loss: 0.0294
Episode: 6021/10000 (60.2100%),                 avg. length: 226.95,                last time consumption/overall running time: 115.12s / 40262.53 s
first_0:                 episode reward: -97.7000,                 loss: nan
second_0:                 episode reward: 97.7000,                 loss: 0.0307
Episode: 6041/10000 (60.4100%),                 avg. length: 218.45,                last time consumption/overall running time: 110.33s / 40372.86 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0312
Episode: 6061/10000 (60.6100%),                 avg. length: 213.0,                last time consumption/overall running time: 110.11s / 40482.97 s
first_0:                 episode reward: -99.9500,                 loss: nan
second_0:                 episode reward: 99.9500,                 loss: 0.0304
Episode: 6081/10000 (60.8100%),                 avg. length: 214.25,                last time consumption/overall running time: 109.68s / 40592.65 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0302
Episode: 6101/10000 (61.0100%),                 avg. length: 220.9,                last time consumption/overall running time: 112.41s / 40705.06 s
first_0:                 episode reward: -90.2000,                 loss: nan
second_0:                 episode reward: 90.2000,                 loss: 0.0305
Episode: 6121/10000 (61.2100%),                 avg. length: 220.05,                last time consumption/overall running time: 112.13s / 40817.19 s
first_0:                 episode reward: -99.4000,                 loss: nan
second_0:                 episode reward: 99.4000,                 loss: 0.0302
Episode: 6141/10000 (61.4100%),                 avg. length: 220.6,                last time consumption/overall running time: 111.76s / 40928.95 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0313
Episode: 6161/10000 (61.6100%),                 avg. length: 223.95,                last time consumption/overall running time: 114.56s / 41043.52 s
first_0:                 episode reward: -89.2000,                 loss: nan
second_0:                 episode reward: 89.2000,                 loss: 0.0315
Episode: 6181/10000 (61.8100%),                 avg. length: 229.35,                last time consumption/overall running time: 116.47s / 41159.99 s
first_0:                 episode reward: -99.4500,                 loss: nan
second_0:                 episode reward: 99.4500,                 loss: 0.0309
Episode: 6201/10000 (62.0100%),                 avg. length: 214.2,                last time consumption/overall running time: 109.43s / 41269.42 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0312
Episode: 6221/10000 (62.2100%),                 avg. length: 223.45,                last time consumption/overall running time: 113.25s / 41382.67 s
first_0:                 episode reward: -98.8000,                 loss: nan
second_0:                 episode reward: 98.8000,                 loss: 0.0324
Episode: 6241/10000 (62.4100%),                 avg. length: 218.45,                last time consumption/overall running time: 111.00s / 41493.67 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0324
Episode: 6261/10000 (62.6100%),                 avg. length: 221.8,                last time consumption/overall running time: 111.97s / 41605.63 s
first_0:                 episode reward: -99.4000,                 loss: nan
second_0:                 episode reward: 99.4000,                 loss: 0.0308
Episode: 6281/10000 (62.8100%),                 avg. length: 215.95,                last time consumption/overall running time: 109.78s / 41715.42 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0316
Episode: 6301/10000 (63.0100%),                 avg. length: 223.0,                last time consumption/overall running time: 113.94s / 41829.36 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0323
Episode: 6321/10000 (63.2100%),                 avg. length: 220.6,                last time consumption/overall running time: 112.44s / 41941.80 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.0327
Episode: 6341/10000 (63.4100%),                 avg. length: 223.1,                last time consumption/overall running time: 113.28s / 42055.08 s
first_0:                 episode reward: -86.5500,                 loss: nan
second_0:                 episode reward: 86.5500,                 loss: 0.0306
Episode: 6361/10000 (63.6100%),                 avg. length: 222.1,                last time consumption/overall running time: 113.40s / 42168.48 s
first_0:                 episode reward: -94.7000,                 loss: nan
second_0:                 episode reward: 94.7000,                 loss: 0.0306
Episode: 6381/10000 (63.8100%),                 avg. length: 230.85,                last time consumption/overall running time: 116.87s / 42285.35 s
first_0:                 episode reward: -88.3500,                 loss: nan
second_0:                 episode reward: 88.3500,                 loss: 0.0300
Episode: 6401/10000 (64.0100%),                 avg. length: 216.1,                last time consumption/overall running time: 109.36s / 42394.71 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0295
Episode: 6421/10000 (64.2100%),                 avg. length: 219.6,                last time consumption/overall running time: 111.79s / 42506.49 s
first_0:                 episode reward: -99.5000,                 loss: nan
second_0:                 episode reward: 99.5000,                 loss: 0.0307
Episode: 6441/10000 (64.4100%),                 avg. length: 217.4,                last time consumption/overall running time: 109.37s / 42615.87 s
first_0:                 episode reward: -99.6500,                 loss: nan
second_0:                 episode reward: 99.6500,                 loss: 0.0302
Episode: 6461/10000 (64.6100%),                 avg. length: 219.6,                last time consumption/overall running time: 110.02s / 42725.89 s
first_0:                 episode reward: -98.0000,                 loss: nan
second_0:                 episode reward: 98.0000,                 loss: 0.0307
Episode: 6481/10000 (64.8100%),                 avg. length: 220.75,                last time consumption/overall running time: 111.44s / 42837.33 s
first_0:                 episode reward: -98.9500,                 loss: nan
second_0:                 episode reward: 98.9500,                 loss: 0.0303
Episode: 6501/10000 (65.0100%),                 avg. length: 218.2,                last time consumption/overall running time: 110.92s / 42948.25 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0313
Episode: 6521/10000 (65.2100%),                 avg. length: 222.3,                last time consumption/overall running time: 112.92s / 43061.16 s
first_0:                 episode reward: -89.6000,                 loss: nan
second_0:                 episode reward: 89.6000,                 loss: 0.0324
Episode: 6541/10000 (65.4100%),                 avg. length: 223.8,                last time consumption/overall running time: 113.19s / 43174.36 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.0316
Episode: 6561/10000 (65.6100%),                 avg. length: 216.9,                last time consumption/overall running time: 109.67s / 43284.03 s
first_0:                 episode reward: -89.8000,                 loss: nan
second_0:                 episode reward: 89.8000,                 loss: 0.0316
Episode: 6581/10000 (65.8100%),                 avg. length: 221.15,                last time consumption/overall running time: 112.24s / 43396.27 s
first_0:                 episode reward: -99.4500,                 loss: nan
second_0:                 episode reward: 99.4500,                 loss: 0.0320
Episode: 6601/10000 (66.0100%),                 avg. length: 217.6,                last time consumption/overall running time: 110.53s / 43506.80 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0327
Episode: 6621/10000 (66.2100%),                 avg. length: 222.05,                last time consumption/overall running time: 112.28s / 43619.08 s
first_0:                 episode reward: -95.3500,                 loss: nan
second_0:                 episode reward: 95.3500,                 loss: 0.0314
Episode: 6641/10000 (66.4100%),                 avg. length: 218.5,                last time consumption/overall running time: 110.66s / 43729.74 s
first_0:                 episode reward: -99.6500,                 loss: nan
second_0:                 episode reward: 99.6500,                 loss: 0.0321
Episode: 6661/10000 (66.6100%),                 avg. length: 224.25,                last time consumption/overall running time: 114.12s / 43843.86 s
first_0:                 episode reward: -97.5500,                 loss: nan
second_0:                 episode reward: 97.5500,                 loss: 0.0312
Episode: 6681/10000 (66.8100%),                 avg. length: 220.1,                last time consumption/overall running time: 111.37s / 43955.23 s
first_0:                 episode reward: -80.0000,                 loss: nan
second_0:                 episode reward: 80.0000,                 loss: 0.0312
Episode: 6701/10000 (67.0100%),                 avg. length: 221.1,                last time consumption/overall running time: 112.01s / 44067.25 s
first_0:                 episode reward: -95.6000,                 loss: nan
second_0:                 episode reward: 95.6000,                 loss: 0.0295
Episode: 6721/10000 (67.2100%),                 avg. length: 221.85,                last time consumption/overall running time: 112.38s / 44179.63 s
first_0:                 episode reward: -98.2000,                 loss: nan
second_0:                 episode reward: 98.2000,                 loss: 0.0301
Episode: 6741/10000 (67.4100%),                 avg. length: 218.85,                last time consumption/overall running time: 110.64s / 44290.27 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0308
Episode: 6761/10000 (67.6100%),                 avg. length: 220.6,                last time consumption/overall running time: 112.54s / 44402.80 s
first_0:                 episode reward: -94.9500,                 loss: nan
second_0:                 episode reward: 94.9500,                 loss: 0.0304
Episode: 6781/10000 (67.8100%),                 avg. length: 226.4,                last time consumption/overall running time: 114.80s / 44517.60 s
first_0:                 episode reward: -89.1500,                 loss: nan
second_0:                 episode reward: 89.1500,                 loss: 0.0294
Episode: 6801/10000 (68.0100%),                 avg. length: 224.7,                last time consumption/overall running time: 114.28s / 44631.87 s
first_0:                 episode reward: -89.3500,                 loss: nan
second_0:                 episode reward: 89.3500,                 loss: 0.0288
Episode: 6821/10000 (68.2100%),                 avg. length: 227.85,                last time consumption/overall running time: 115.40s / 44747.27 s
first_0:                 episode reward: -98.5500,                 loss: nan
second_0:                 episode reward: 98.5500,                 loss: 0.0300
Episode: 6841/10000 (68.4100%),                 avg. length: 219.05,                last time consumption/overall running time: 111.50s / 44858.77 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0314
Episode: 6861/10000 (68.6100%),                 avg. length: 222.65,                last time consumption/overall running time: 112.79s / 44971.56 s
first_0:                 episode reward: -90.9000,                 loss: nan
second_0:                 episode reward: 90.9000,                 loss: 0.0305
Episode: 6881/10000 (68.8100%),                 avg. length: 219.8,                last time consumption/overall running time: 111.21s / 45082.77 s
first_0:                 episode reward: -98.1000,                 loss: nan
second_0:                 episode reward: 98.1000,                 loss: 0.0298
Episode: 6901/10000 (69.0100%),                 avg. length: 227.6,                last time consumption/overall running time: 114.15s / 45196.91 s
first_0:                 episode reward: -96.2500,                 loss: nan
second_0:                 episode reward: 96.2500,                 loss: 0.0309
Episode: 6921/10000 (69.2100%),                 avg. length: 229.0,                last time consumption/overall running time: 115.86s / 45312.77 s
first_0:                 episode reward: -90.9500,                 loss: nan
second_0:                 episode reward: 90.9500,                 loss: 0.0311
Episode: 6941/10000 (69.4100%),                 avg. length: 223.1,                last time consumption/overall running time: 114.07s / 45426.85 s
first_0:                 episode reward: -91.5500,                 loss: nan
second_0:                 episode reward: 91.5500,                 loss: 0.0299
Episode: 6961/10000 (69.6100%),                 avg. length: 216.5,                last time consumption/overall running time: 110.11s / 45536.96 s
first_0:                 episode reward: -99.6000,                 loss: nan
second_0:                 episode reward: 99.6000,                 loss: 0.0299
Episode: 6981/10000 (69.8100%),                 avg. length: 211.75,                last time consumption/overall running time: 107.60s / 45644.56 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0298
Episode: 7001/10000 (70.0100%),                 avg. length: 224.9,                last time consumption/overall running time: 114.20s / 45758.76 s
first_0:                 episode reward: -77.0500,                 loss: nan
second_0:                 episode reward: 77.0500,                 loss: 0.0289
Episode: 7021/10000 (70.2100%),                 avg. length: 218.95,                last time consumption/overall running time: 110.95s / 45869.72 s
first_0:                 episode reward: -95.3000,                 loss: nan
second_0:                 episode reward: 95.3000,                 loss: 0.0304
Episode: 7041/10000 (70.4100%),                 avg. length: 226.8,                last time consumption/overall running time: 115.46s / 45985.18 s
first_0:                 episode reward: -79.6500,                 loss: nan
second_0:                 episode reward: 79.6500,                 loss: 0.0294
Episode: 7061/10000 (70.6100%),                 avg. length: 213.0,                last time consumption/overall running time: 107.96s / 46093.13 s
first_0:                 episode reward: -90.0000,                 loss: nan
second_0:                 episode reward: 90.0000,                 loss: 0.0280
Episode: 7081/10000 (70.8100%),                 avg. length: 218.2,                last time consumption/overall running time: 111.41s / 46204.54 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0288
Episode: 7101/10000 (71.0100%),                 avg. length: 223.0,                last time consumption/overall running time: 113.15s / 46317.69 s
first_0:                 episode reward: -94.9000,                 loss: nan
second_0:                 episode reward: 94.9000,                 loss: 0.0278
Episode: 7121/10000 (71.2100%),                 avg. length: 217.75,                last time consumption/overall running time: 111.05s / 46428.74 s
first_0:                 episode reward: -99.6000,                 loss: nan
second_0:                 episode reward: 99.6000,                 loss: 0.0282
Episode: 7141/10000 (71.4100%),                 avg. length: 218.1,                last time consumption/overall running time: 110.85s / 46539.59 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0277
Episode: 7161/10000 (71.6100%),                 avg. length: 211.7,                last time consumption/overall running time: 107.07s / 46646.67 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0290
Episode: 7181/10000 (71.8100%),                 avg. length: 223.3,                last time consumption/overall running time: 112.57s / 46759.23 s
first_0:                 episode reward: -91.3500,                 loss: nan
second_0:                 episode reward: 91.3500,                 loss: 0.0281
Episode: 7201/10000 (72.0100%),                 avg. length: 218.55,                last time consumption/overall running time: 110.37s / 46869.60 s
first_0:                 episode reward: -92.3500,                 loss: nan
second_0:                 episode reward: 92.3500,                 loss: 0.0271
Episode: 7221/10000 (72.2100%),                 avg. length: 216.25,                last time consumption/overall running time: 109.28s / 46978.88 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0291
Episode: 7241/10000 (72.4100%),                 avg. length: 228.55,                last time consumption/overall running time: 114.75s / 47093.63 s
first_0:                 episode reward: -77.2500,                 loss: nan
second_0:                 episode reward: 77.2500,                 loss: 0.0283
Episode: 7261/10000 (72.6100%),                 avg. length: 214.25,                last time consumption/overall running time: 109.44s / 47203.07 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0286
Episode: 7281/10000 (72.8100%),                 avg. length: 216.5,                last time consumption/overall running time: 109.99s / 47313.06 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0289
Episode: 7301/10000 (73.0100%),                 avg. length: 222.55,                last time consumption/overall running time: 112.47s / 47425.52 s
first_0:                 episode reward: -91.2500,                 loss: nan
second_0:                 episode reward: 91.2500,                 loss: 0.0288
Episode: 7321/10000 (73.2100%),                 avg. length: 214.9,                last time consumption/overall running time: 108.97s / 47534.49 s
first_0:                 episode reward: -79.7000,                 loss: nan
second_0:                 episode reward: 79.7000,                 loss: 0.0284
Episode: 7341/10000 (73.4100%),                 avg. length: 223.9,                last time consumption/overall running time: 113.79s / 47648.29 s
first_0:                 episode reward: -91.2500,                 loss: nan
second_0:                 episode reward: 91.2500,                 loss: 0.0290
Episode: 7361/10000 (73.6100%),                 avg. length: 214.95,                last time consumption/overall running time: 109.32s / 47757.61 s
first_0:                 episode reward: -99.9500,                 loss: nan
second_0:                 episode reward: 99.9500,                 loss: 0.0278
Episode: 7381/10000 (73.8100%),                 avg. length: 226.55,                last time consumption/overall running time: 114.94s / 47872.55 s
first_0:                 episode reward: -90.6500,                 loss: nan
second_0:                 episode reward: 90.6500,                 loss: 0.0289
Episode: 7401/10000 (74.0100%),                 avg. length: 221.6,                last time consumption/overall running time: 112.11s / 47984.66 s
first_0:                 episode reward: -90.3000,                 loss: nan
second_0:                 episode reward: 90.3000,                 loss: 0.0294
Episode: 7421/10000 (74.2100%),                 avg. length: 221.15,                last time consumption/overall running time: 112.49s / 48097.15 s
first_0:                 episode reward: -99.6000,                 loss: nan
second_0:                 episode reward: 99.6000,                 loss: 0.0285
Episode: 7441/10000 (74.4100%),                 avg. length: 227.0,                last time consumption/overall running time: 114.65s / 48211.80 s
first_0:                 episode reward: -88.1000,                 loss: nan
second_0:                 episode reward: 88.1000,                 loss: 0.0294
Episode: 7461/10000 (74.6100%),                 avg. length: 219.15,                last time consumption/overall running time: 111.25s / 48323.05 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0281
Episode: 7481/10000 (74.8100%),                 avg. length: 223.35,                last time consumption/overall running time: 114.77s / 48437.83 s
first_0:                 episode reward: -98.9000,                 loss: nan
second_0:                 episode reward: 98.9000,                 loss: 0.0287
Episode: 7501/10000 (75.0100%),                 avg. length: 231.85,                last time consumption/overall running time: 118.06s / 48555.88 s
first_0:                 episode reward: -79.3500,                 loss: nan
second_0:                 episode reward: 79.3500,                 loss: 0.0281
Episode: 7521/10000 (75.2100%),                 avg. length: 224.2,                last time consumption/overall running time: 113.18s / 48669.06 s
first_0:                 episode reward: -92.1000,                 loss: nan
second_0:                 episode reward: 92.1000,                 loss: 0.0293
Episode: 7541/10000 (75.4100%),                 avg. length: 229.85,                last time consumption/overall running time: 117.01s / 48786.07 s
first_0:                 episode reward: -96.3500,                 loss: nan
second_0:                 episode reward: 96.3500,                 loss: 0.0291
Episode: 7561/10000 (75.6100%),                 avg. length: 216.2,                last time consumption/overall running time: 109.58s / 48895.66 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0294
Episode: 7581/10000 (75.8100%),                 avg. length: 229.45,                last time consumption/overall running time: 115.89s / 49011.55 s
first_0:                 episode reward: -89.0000,                 loss: nan
second_0:                 episode reward: 89.0000,                 loss: 0.0287
Episode: 7601/10000 (76.0100%),                 avg. length: 213.75,                last time consumption/overall running time: 109.16s / 49120.71 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0287
Episode: 7621/10000 (76.2100%),                 avg. length: 225.55,                last time consumption/overall running time: 114.26s / 49234.97 s
first_0:                 episode reward: -99.0500,                 loss: nan
second_0:                 episode reward: 99.0500,                 loss: 0.0292
Episode: 7641/10000 (76.4100%),                 avg. length: 222.5,                last time consumption/overall running time: 112.38s / 49347.35 s
first_0:                 episode reward: -93.0000,                 loss: nan
second_0:                 episode reward: 93.0000,                 loss: 0.0286
Episode: 7661/10000 (76.6100%),                 avg. length: 215.55,                last time consumption/overall running time: 109.98s / 49457.33 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0285
Episode: 7681/10000 (76.8100%),                 avg. length: 226.2,                last time consumption/overall running time: 115.72s / 49573.05 s
first_0:                 episode reward: -89.4500,                 loss: nan
second_0:                 episode reward: 89.4500,                 loss: 0.0284
Episode: 7701/10000 (77.0100%),                 avg. length: 222.1,                last time consumption/overall running time: 112.40s / 49685.45 s
first_0:                 episode reward: -90.1000,                 loss: nan
second_0:                 episode reward: 90.1000,                 loss: 0.0307
Episode: 7721/10000 (77.2100%),                 avg. length: 226.7,                last time consumption/overall running time: 115.38s / 49800.83 s
first_0:                 episode reward: -89.4000,                 loss: nan
second_0:                 episode reward: 89.4000,                 loss: 0.0297
Episode: 7741/10000 (77.4100%),                 avg. length: 221.25,                last time consumption/overall running time: 112.92s / 49913.75 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.0307
Episode: 7761/10000 (77.6100%),                 avg. length: 217.55,                last time consumption/overall running time: 110.51s / 50024.25 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0291
Episode: 7781/10000 (77.8100%),                 avg. length: 215.3,                last time consumption/overall running time: 109.05s / 50133.30 s
first_0:                 episode reward: -89.9000,                 loss: nan
second_0:                 episode reward: 89.9000,                 loss: 0.0285
Episode: 7801/10000 (78.0100%),                 avg. length: 219.75,                last time consumption/overall running time: 110.15s / 50243.45 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0293
Episode: 7821/10000 (78.2100%),                 avg. length: 223.8,                last time consumption/overall running time: 114.03s / 50357.48 s
first_0:                 episode reward: -89.7000,                 loss: nan
second_0:                 episode reward: 89.7000,                 loss: 0.0294
Episode: 7841/10000 (78.4100%),                 avg. length: 218.05,                last time consumption/overall running time: 110.60s / 50468.08 s
first_0:                 episode reward: -99.5000,                 loss: nan
second_0:                 episode reward: 99.5000,                 loss: 0.0305
Episode: 7861/10000 (78.6100%),                 avg. length: 215.4,                last time consumption/overall running time: 108.70s / 50576.78 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0297
Episode: 7881/10000 (78.8100%),                 avg. length: 216.5,                last time consumption/overall running time: 110.68s / 50687.46 s
first_0:                 episode reward: -99.9500,                 loss: nan
second_0:                 episode reward: 99.9500,                 loss: 0.0298
Episode: 7901/10000 (79.0100%),                 avg. length: 219.5,                last time consumption/overall running time: 110.63s / 50798.09 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.0298
Episode: 7921/10000 (79.2100%),                 avg. length: 223.7,                last time consumption/overall running time: 114.14s / 50912.23 s
first_0:                 episode reward: -92.6000,                 loss: nan
second_0:                 episode reward: 92.6000,                 loss: 0.0300
Episode: 7941/10000 (79.4100%),                 avg. length: 215.45,                last time consumption/overall running time: 109.23s / 51021.46 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0310
Episode: 7961/10000 (79.6100%),                 avg. length: 218.0,                last time consumption/overall running time: 110.59s / 51132.05 s
first_0:                 episode reward: -95.5000,                 loss: nan
second_0:                 episode reward: 95.5000,                 loss: 0.0323
Episode: 7981/10000 (79.8100%),                 avg. length: 218.9,                last time consumption/overall running time: 111.46s / 51243.51 s
first_0:                 episode reward: -99.3000,                 loss: nan
second_0:                 episode reward: 99.3000,                 loss: 0.0314
Episode: 8001/10000 (80.0100%),                 avg. length: 219.2,                last time consumption/overall running time: 111.62s / 51355.13 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0303
Episode: 8021/10000 (80.2100%),                 avg. length: 214.75,                last time consumption/overall running time: 109.03s / 51464.16 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0301
Episode: 8041/10000 (80.4100%),                 avg. length: 219.45,                last time consumption/overall running time: 110.36s / 51574.53 s
first_0:                 episode reward: -99.4500,                 loss: nan
second_0:                 episode reward: 99.4500,                 loss: 0.0311
Episode: 8061/10000 (80.6100%),                 avg. length: 215.0,                last time consumption/overall running time: 109.10s / 51683.62 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0321
Episode: 8081/10000 (80.8100%),                 avg. length: 223.05,                last time consumption/overall running time: 113.11s / 51796.73 s
first_0:                 episode reward: -96.5500,                 loss: nan
second_0:                 episode reward: 96.5500,                 loss: 0.0330
Episode: 8101/10000 (81.0100%),                 avg. length: 213.4,                last time consumption/overall running time: 107.96s / 51904.69 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0307
Episode: 8121/10000 (81.2100%),                 avg. length: 213.3,                last time consumption/overall running time: 106.71s / 52011.40 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0316
Episode: 8141/10000 (81.4100%),                 avg. length: 215.05,                last time consumption/overall running time: 108.77s / 52120.17 s
first_0:                 episode reward: -89.8500,                 loss: nan
second_0:                 episode reward: 89.8500,                 loss: 0.0314
Episode: 8161/10000 (81.6100%),                 avg. length: 223.1,                last time consumption/overall running time: 113.26s / 52233.43 s
first_0:                 episode reward: -94.4000,                 loss: nan
second_0:                 episode reward: 94.4000,                 loss: 0.0316
Episode: 8181/10000 (81.8100%),                 avg. length: 218.3,                last time consumption/overall running time: 110.88s / 52344.31 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0320
Episode: 8201/10000 (82.0100%),                 avg. length: 220.8,                last time consumption/overall running time: 111.76s / 52456.07 s
first_0:                 episode reward: -98.2500,                 loss: nan
second_0:                 episode reward: 98.2500,                 loss: 0.0315
Episode: 8221/10000 (82.2100%),                 avg. length: 217.35,                last time consumption/overall running time: 110.14s / 52566.20 s
first_0:                 episode reward: -95.0000,                 loss: nan
second_0:                 episode reward: 95.0000,                 loss: 0.0306
Episode: 8241/10000 (82.4100%),                 avg. length: 220.65,                last time consumption/overall running time: 112.67s / 52678.88 s
first_0:                 episode reward: -96.5500,                 loss: nan
second_0:                 episode reward: 96.5500,                 loss: 0.0306
Episode: 8261/10000 (82.6100%),                 avg. length: 214.6,                last time consumption/overall running time: 108.21s / 52787.08 s
first_0:                 episode reward: -99.6000,                 loss: nan
second_0:                 episode reward: 99.6000,                 loss: 0.0302
Episode: 8281/10000 (82.8100%),                 avg. length: 216.15,                last time consumption/overall running time: 110.41s / 52897.50 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0292
Episode: 8301/10000 (83.0100%),                 avg. length: 219.95,                last time consumption/overall running time: 111.56s / 53009.06 s
first_0:                 episode reward: -99.4000,                 loss: nan
second_0:                 episode reward: 99.4000,                 loss: 0.0309
Episode: 8321/10000 (83.2100%),                 avg. length: 222.65,                last time consumption/overall running time: 112.03s / 53121.08 s
first_0:                 episode reward: -90.2000,                 loss: nan
second_0:                 episode reward: 90.2000,                 loss: 0.0313
Episode: 8341/10000 (83.4100%),                 avg. length: 226.45,                last time consumption/overall running time: 114.86s / 53235.94 s
first_0:                 episode reward: -94.7500,                 loss: nan
second_0:                 episode reward: 94.7500,                 loss: 0.0326
Episode: 8361/10000 (83.6100%),                 avg. length: 214.3,                last time consumption/overall running time: 108.83s / 53344.76 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0309
Episode: 8381/10000 (83.8100%),                 avg. length: 216.95,                last time consumption/overall running time: 111.37s / 53456.13 s
first_0:                 episode reward: -98.8500,                 loss: nan
second_0:                 episode reward: 98.8500,                 loss: 0.0304
Episode: 8401/10000 (84.0100%),                 avg. length: 222.9,                last time consumption/overall running time: 113.14s / 53569.27 s
first_0:                 episode reward: -99.3000,                 loss: nan
second_0:                 episode reward: 99.3000,                 loss: 0.0313
Episode: 8421/10000 (84.2100%),                 avg. length: 214.2,                last time consumption/overall running time: 108.47s / 53677.74 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0315
Episode: 8441/10000 (84.4100%),                 avg. length: 211.05,                last time consumption/overall running time: 106.24s / 53783.97 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0313
Episode: 8461/10000 (84.6100%),                 avg. length: 212.55,                last time consumption/overall running time: 107.93s / 53891.90 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0301
Episode: 8481/10000 (84.8100%),                 avg. length: 215.4,                last time consumption/overall running time: 109.16s / 54001.06 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0294
Episode: 8501/10000 (85.0100%),                 avg. length: 215.45,                last time consumption/overall running time: 108.92s / 54109.98 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0316
Episode: 8521/10000 (85.2100%),                 avg. length: 225.0,                last time consumption/overall running time: 113.98s / 54223.97 s
first_0:                 episode reward: -98.8000,                 loss: nan
second_0:                 episode reward: 98.8000,                 loss: 0.0297
Episode: 8541/10000 (85.4100%),                 avg. length: 216.65,                last time consumption/overall running time: 110.33s / 54334.29 s
first_0:                 episode reward: -99.6500,                 loss: nan
second_0:                 episode reward: 99.6500,                 loss: 0.0299
Episode: 8561/10000 (85.6100%),                 avg. length: 213.5,                last time consumption/overall running time: 108.78s / 54443.07 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0296
Episode: 8581/10000 (85.8100%),                 avg. length: 222.75,                last time consumption/overall running time: 113.18s / 54556.25 s
first_0:                 episode reward: -94.3500,                 loss: nan
second_0:                 episode reward: 94.3500,                 loss: 0.0298
Episode: 8601/10000 (86.0100%),                 avg. length: 219.9,                last time consumption/overall running time: 111.54s / 54667.79 s
first_0:                 episode reward: -93.1500,                 loss: nan
second_0:                 episode reward: 93.1500,                 loss: 0.0290
Episode: 8621/10000 (86.2100%),                 avg. length: 213.85,                last time consumption/overall running time: 108.57s / 54776.36 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0300
Episode: 8641/10000 (86.4100%),                 avg. length: 221.5,                last time consumption/overall running time: 113.10s / 54889.45 s
first_0:                 episode reward: -90.5000,                 loss: nan
second_0:                 episode reward: 90.5000,                 loss: 0.0297
Episode: 8661/10000 (86.6100%),                 avg. length: 222.3,                last time consumption/overall running time: 113.01s / 55002.47 s
first_0:                 episode reward: -99.1500,                 loss: nan
second_0:                 episode reward: 99.1500,                 loss: 0.0312
Episode: 8681/10000 (86.8100%),                 avg. length: 216.8,                last time consumption/overall running time: 109.74s / 55112.20 s
first_0:                 episode reward: -99.6000,                 loss: nan
second_0:                 episode reward: 99.6000,                 loss: 0.0305
Episode: 8701/10000 (87.0100%),                 avg. length: 219.95,                last time consumption/overall running time: 111.61s / 55223.81 s
first_0:                 episode reward: -98.7000,                 loss: nan
second_0:                 episode reward: 98.7000,                 loss: 0.0312
Episode: 8721/10000 (87.2100%),                 avg. length: 217.8,                last time consumption/overall running time: 110.70s / 55334.52 s
first_0:                 episode reward: -97.9000,                 loss: nan
second_0:                 episode reward: 97.9000,                 loss: 0.0304
Episode: 8741/10000 (87.4100%),                 avg. length: 217.65,                last time consumption/overall running time: 110.45s / 55444.96 s
first_0:                 episode reward: -94.6000,                 loss: nan
second_0:                 episode reward: 94.6000,                 loss: 0.0308
Episode: 8761/10000 (87.6100%),                 avg. length: 217.8,                last time consumption/overall running time: 111.39s / 55556.35 s
first_0:                 episode reward: -94.1500,                 loss: nan
second_0:                 episode reward: 94.1500,                 loss: 0.0308
Episode: 8781/10000 (87.8100%),                 avg. length: 236.0,                last time consumption/overall running time: 120.37s / 55676.72 s
first_0:                 episode reward: -91.0000,                 loss: nan
second_0:                 episode reward: 91.0000,                 loss: 0.0322
Episode: 8801/10000 (88.0100%),                 avg. length: 222.5,                last time consumption/overall running time: 113.72s / 55790.43 s
first_0:                 episode reward: -98.0000,                 loss: nan
second_0:                 episode reward: 98.0000,                 loss: 0.0325
Episode: 8821/10000 (88.2100%),                 avg. length: 214.3,                last time consumption/overall running time: 109.07s / 55899.50 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0310
Episode: 8841/10000 (88.4100%),                 avg. length: 217.55,                last time consumption/overall running time: 110.92s / 56010.42 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0295
Episode: 8861/10000 (88.6100%),                 avg. length: 221.15,                last time consumption/overall running time: 113.00s / 56123.42 s
first_0:                 episode reward: -94.3500,                 loss: nan
second_0:                 episode reward: 94.3500,                 loss: 0.0306
Episode: 8881/10000 (88.8100%),                 avg. length: 214.35,                last time consumption/overall running time: 107.98s / 56231.40 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0299
Episode: 8901/10000 (89.0100%),                 avg. length: 219.7,                last time consumption/overall running time: 105.97s / 56337.36 s
first_0:                 episode reward: -98.9000,                 loss: nan
second_0:                 episode reward: 98.9000,                 loss: 0.0297
Episode: 8921/10000 (89.2100%),                 avg. length: 214.85,                last time consumption/overall running time: 103.90s / 56441.27 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0290
Episode: 8941/10000 (89.4100%),                 avg. length: 220.3,                last time consumption/overall running time: 106.06s / 56547.33 s
first_0:                 episode reward: -89.7000,                 loss: nan
second_0:                 episode reward: 89.7000,                 loss: 0.0295
Episode: 8961/10000 (89.6100%),                 avg. length: 219.55,                last time consumption/overall running time: 105.88s / 56653.20 s
first_0:                 episode reward: -99.5500,                 loss: nan
second_0:                 episode reward: 99.5500,                 loss: 0.0291
Episode: 8981/10000 (89.8100%),                 avg. length: 216.65,                last time consumption/overall running time: 104.78s / 56757.98 s
first_0:                 episode reward: -97.5000,                 loss: nan
second_0:                 episode reward: 97.5000,                 loss: 0.0295
Episode: 9001/10000 (90.0100%),                 avg. length: 215.4,                last time consumption/overall running time: 104.26s / 56862.24 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0297
Episode: 9021/10000 (90.2100%),                 avg. length: 218.75,                last time consumption/overall running time: 105.93s / 56968.17 s
first_0:                 episode reward: -98.3500,                 loss: nan
second_0:                 episode reward: 98.3500,                 loss: 0.0297
Episode: 9041/10000 (90.4100%),                 avg. length: 217.0,                last time consumption/overall running time: 105.05s / 57073.21 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0302
Episode: 9061/10000 (90.6100%),                 avg. length: 214.35,                last time consumption/overall running time: 103.25s / 57176.46 s
first_0:                 episode reward: -89.8000,                 loss: nan
second_0:                 episode reward: 89.8000,                 loss: 0.0303
Episode: 9081/10000 (90.8100%),                 avg. length: 225.2,                last time consumption/overall running time: 108.94s / 57285.41 s
first_0:                 episode reward: -95.8000,                 loss: nan
second_0:                 episode reward: 95.8000,                 loss: 0.0296
Episode: 9101/10000 (91.0100%),                 avg. length: 220.8,                last time consumption/overall running time: 107.54s / 57392.95 s
first_0:                 episode reward: -99.0000,                 loss: nan
second_0:                 episode reward: 99.0000,                 loss: 0.0303
Episode: 9121/10000 (91.2100%),                 avg. length: 218.3,                last time consumption/overall running time: 105.56s / 57498.51 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0318
Episode: 9141/10000 (91.4100%),                 avg. length: 221.45,                last time consumption/overall running time: 106.52s / 57605.02 s
first_0:                 episode reward: -88.0000,                 loss: nan
second_0:                 episode reward: 88.0000,                 loss: 0.0315
Episode: 9161/10000 (91.6100%),                 avg. length: 219.3,                last time consumption/overall running time: 106.88s / 57711.91 s
first_0:                 episode reward: -82.9000,                 loss: nan
second_0:                 episode reward: 82.9000,                 loss: 0.0300
Episode: 9181/10000 (91.8100%),                 avg. length: 220.8,                last time consumption/overall running time: 107.29s / 57819.20 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.0299
Episode: 9201/10000 (92.0100%),                 avg. length: 216.6,                last time consumption/overall running time: 104.78s / 57923.98 s
first_0:                 episode reward: -99.6000,                 loss: nan
second_0:                 episode reward: 99.6000,                 loss: 0.0306
Episode: 9221/10000 (92.2100%),                 avg. length: 210.6,                last time consumption/overall running time: 101.83s / 58025.81 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0306
Episode: 9241/10000 (92.4100%),                 avg. length: 216.85,                last time consumption/overall running time: 104.81s / 58130.62 s
first_0:                 episode reward: -91.4000,                 loss: nan
second_0:                 episode reward: 91.4000,                 loss: 0.0313
Episode: 9261/10000 (92.6100%),                 avg. length: 218.05,                last time consumption/overall running time: 105.26s / 58235.88 s
first_0:                 episode reward: -95.3000,                 loss: nan
second_0:                 episode reward: 95.3000,                 loss: 0.0318
Episode: 9281/10000 (92.8100%),                 avg. length: 215.45,                last time consumption/overall running time: 104.21s / 58340.09 s
first_0:                 episode reward: -99.7000,                 loss: nan
second_0:                 episode reward: 99.7000,                 loss: 0.0320
Episode: 9301/10000 (93.0100%),                 avg. length: 219.75,                last time consumption/overall running time: 105.77s / 58445.85 s
first_0:                 episode reward: -98.2500,                 loss: nan
second_0:                 episode reward: 98.2500,                 loss: 0.0314
Episode: 9321/10000 (93.2100%),                 avg. length: 220.85,                last time consumption/overall running time: 106.25s / 58552.10 s
first_0:                 episode reward: -98.5500,                 loss: nan
second_0:                 episode reward: 98.5500,                 loss: 0.0321
Episode: 9341/10000 (93.4100%),                 avg. length: 223.75,                last time consumption/overall running time: 107.75s / 58659.85 s
first_0:                 episode reward: -99.2000,                 loss: nan
second_0:                 episode reward: 99.2000,                 loss: 0.0317
Episode: 9361/10000 (93.6100%),                 avg. length: 216.1,                last time consumption/overall running time: 104.27s / 58764.12 s
first_0:                 episode reward: -99.6500,                 loss: nan
second_0:                 episode reward: 99.6500,                 loss: 0.0331
Episode: 9381/10000 (93.8100%),                 avg. length: 215.8,                last time consumption/overall running time: 103.88s / 58868.00 s
first_0:                 episode reward: -99.3000,                 loss: nan
second_0:                 episode reward: 99.3000,                 loss: 0.0320
Episode: 9401/10000 (94.0100%),                 avg. length: 216.25,                last time consumption/overall running time: 104.15s / 58972.15 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.0328
Episode: 9421/10000 (94.2100%),                 avg. length: 226.55,                last time consumption/overall running time: 108.97s / 59081.12 s
first_0:                 episode reward: -89.3500,                 loss: nan
second_0:                 episode reward: 89.3500,                 loss: 0.0329
Episode: 9441/10000 (94.4100%),                 avg. length: 221.25,                last time consumption/overall running time: 106.55s / 59187.68 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.0334
Episode: 9461/10000 (94.6100%),                 avg. length: 212.25,                last time consumption/overall running time: 102.42s / 59290.09 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0337
Episode: 9481/10000 (94.8100%),                 avg. length: 213.6,                last time consumption/overall running time: 102.94s / 59393.03 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0331
Episode: 9501/10000 (95.0100%),                 avg. length: 215.8,                last time consumption/overall running time: 103.75s / 59496.78 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0324
Episode: 9521/10000 (95.2100%),                 avg. length: 213.2,                last time consumption/overall running time: 97.96s / 59594.75 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0328
Episode: 9541/10000 (95.4100%),                 avg. length: 219.35,                last time consumption/overall running time: 93.92s / 59688.67 s
first_0:                 episode reward: -96.8500,                 loss: nan
second_0:                 episode reward: 96.8500,                 loss: 0.0328
Episode: 9561/10000 (95.6100%),                 avg. length: 217.8,                last time consumption/overall running time: 93.57s / 59782.24 s
first_0:                 episode reward: -99.7500,                 loss: nan
second_0:                 episode reward: 99.7500,                 loss: 0.0337
Episode: 9581/10000 (95.8100%),                 avg. length: 219.9,                last time consumption/overall running time: 94.38s / 59876.62 s
first_0:                 episode reward: -94.7500,                 loss: nan
second_0:                 episode reward: 94.7500,                 loss: 0.0350
Episode: 9601/10000 (96.0100%),                 avg. length: 214.95,                last time consumption/overall running time: 90.35s / 59966.97 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0345
Episode: 9621/10000 (96.2100%),                 avg. length: 214.75,                last time consumption/overall running time: 85.86s / 60052.83 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0347
Episode: 9641/10000 (96.4100%),                 avg. length: 215.25,                last time consumption/overall running time: 86.27s / 60139.10 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0345
Episode: 9661/10000 (96.6100%),                 avg. length: 213.55,                last time consumption/overall running time: 85.51s / 60224.61 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0335
Episode: 9681/10000 (96.8100%),                 avg. length: 217.15,                last time consumption/overall running time: 86.74s / 60311.35 s
first_0:                 episode reward: -99.5500,                 loss: nan
second_0:                 episode reward: 99.5500,                 loss: 0.0335
Episode: 9701/10000 (97.0100%),                 avg. length: 216.95,                last time consumption/overall running time: 86.65s / 60398.00 s
first_0:                 episode reward: -99.8500,                 loss: nan
second_0:                 episode reward: 99.8500,                 loss: 0.0341
Episode: 9721/10000 (97.2100%),                 avg. length: 221.1,                last time consumption/overall running time: 87.92s / 60485.91 s
first_0:                 episode reward: -99.3500,                 loss: nan
second_0:                 episode reward: 99.3500,                 loss: 0.0347
Episode: 9741/10000 (97.4100%),                 avg. length: 220.45,                last time consumption/overall running time: 88.02s / 60573.93 s
first_0:                 episode reward: -99.1000,                 loss: nan
second_0:                 episode reward: 99.1000,                 loss: 0.0352
Episode: 9761/10000 (97.6100%),                 avg. length: 216.9,                last time consumption/overall running time: 86.47s / 60660.40 s
first_0:                 episode reward: -98.2000,                 loss: nan
second_0:                 episode reward: 98.2000,                 loss: 0.0346
Episode: 9781/10000 (97.8100%),                 avg. length: 212.7,                last time consumption/overall running time: 84.94s / 60745.34 s
first_0:                 episode reward: -100.0000,                 loss: nan
second_0:                 episode reward: 100.0000,                 loss: 0.0347
Episode: 9801/10000 (98.0100%),                 avg. length: 222.75,                last time consumption/overall running time: 88.79s / 60834.13 s
first_0:                 episode reward: -99.3000,                 loss: nan
second_0:                 episode reward: 99.3000,                 loss: 0.0353
Episode: 9821/10000 (98.2100%),                 avg. length: 218.15,                last time consumption/overall running time: 87.01s / 60921.15 s
first_0:                 episode reward: -99.4000,                 loss: nan
second_0:                 episode reward: 99.4000,                 loss: 0.0358
Episode: 9841/10000 (98.4100%),                 avg. length: 216.75,                last time consumption/overall running time: 86.07s / 61007.21 s
first_0:                 episode reward: -92.6000,                 loss: nan
second_0:                 episode reward: 92.6000,                 loss: 0.0345
Episode: 9861/10000 (98.6100%),                 avg. length: 218.6,                last time consumption/overall running time: 87.02s / 61094.23 s
first_0:                 episode reward: -99.5500,                 loss: nan
second_0:                 episode reward: 99.5500,                 loss: 0.0340
Episode: 9881/10000 (98.8100%),                 avg. length: 233.3,                last time consumption/overall running time: 93.00s / 61187.23 s
first_0:                 episode reward: -97.2500,                 loss: nan
second_0:                 episode reward: 97.2500,                 loss: 0.0342
Episode: 9901/10000 (99.0100%),                 avg. length: 213.0,                last time consumption/overall running time: 85.26s / 61272.49 s
first_0:                 episode reward: -99.9500,                 loss: nan
second_0:                 episode reward: 99.9500,                 loss: 0.0352
Episode: 9921/10000 (99.2100%),                 avg. length: 212.35,                last time consumption/overall running time: 84.81s / 61357.30 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0338
Episode: 9941/10000 (99.4100%),                 avg. length: 216.15,                last time consumption/overall running time: 86.57s / 61443.87 s
first_0:                 episode reward: -99.6000,                 loss: nan
second_0:                 episode reward: 99.6000,                 loss: 0.0343/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:87: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.
  "The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead."
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:101: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.
  "The `action_spaces` dictionary is deprecated. Use the `action_space` function instead."
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/data/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

Episode: 9961/10000 (99.6100%),                 avg. length: 211.65,                last time consumption/overall running time: 84.41s / 61528.28 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0342
Episode: 9981/10000 (99.8100%),                 avg. length: 220.2,                last time consumption/overall running time: 87.81s / 61616.10 s
first_0:                 episode reward: -92.1500,                 loss: nan
second_0:                 episode reward: 92.1500,                 loss: 0.0333
