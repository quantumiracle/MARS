pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
arbitrary_mdp mdp
Load arbitrary_mdp environment in type mdp.
Env observation space: Box(0.0, 42.0, (1,), float32) action space: Discrete(6)
<mars.env.mdp.mdp_wrapper.MDPWrapper object at 0x7fc0fde04e48>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=1, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Error: no exploited model index given!
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  data/model/20220518032943/mdp_arbitrary_mdp_nfsp/40000_0
Arguments:  {'env_name': 'arbitrary_mdp', 'env_type': 'mdp', 'num_envs': 1, 'ram': True, 'seed': '1i', 'algorithm': 'NFSP', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.0, 'eps_decay': 100000}, 'num_process': 1, 'batch_size': 640, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': 'data/model/20220518032943/mdp_arbitrary_mdp_nfsp/40000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True, 'eta': 0.1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220518032943_exploit_40000/mdp_arbitrary_mdp_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220518032943_exploit_40000/mdp_arbitrary_mdp_nfsp.
Episode: 1/30000 (0.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 7.4179s / 7.4179 s
agent0:                 episode reward: 0.4149,                 loss: nan
agent1:                 episode reward: -0.4149,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3928s / 7.8106 s
agent0:                 episode reward: -0.2541,                 loss: nan
agent1:                 episode reward: 0.2541,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3939s / 8.2046 s
agent0:                 episode reward: 0.0956,                 loss: nan
agent1:                 episode reward: -0.0956,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3959s / 8.6004 s
agent0:                 episode reward: -0.0679,                 loss: nan
agent1:                 episode reward: 0.0679,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3965s / 8.9969 s
agent0:                 episode reward: -0.0665,                 loss: nan
agent1:                 episode reward: 0.0665,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3941s / 9.3910 s
agent0:                 episode reward: -0.2965,                 loss: nan
agent1:                 episode reward: 0.2965,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3962s / 9.7872 s
agent0:                 episode reward: 0.1383,                 loss: nan
agent1:                 episode reward: -0.1383,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4027s / 10.1899 s
agent0:                 episode reward: 0.3301,                 loss: nan
agent1:                 episode reward: -0.3301,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3976s / 10.5875 s
agent0:                 episode reward: -0.1425,                 loss: nan
agent1:                 episode reward: 0.1425,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3961s / 10.9836 s
agent0:                 episode reward: 0.1801,                 loss: nan
agent1:                 episode reward: -0.1801,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4024s / 11.3859 s
agent0:                 episode reward: -0.1821,                 loss: nan
agent1:                 episode reward: 0.1821,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4036s / 11.7896 s
agent0:                 episode reward: 0.5437,                 loss: nan
agent1:                 episode reward: -0.5437,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4004s / 12.1900 s
agent0:                 episode reward: -0.0727,                 loss: nan
agent1:                 episode reward: 0.0727,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3949s / 12.5849 s
agent0:                 episode reward: 0.1236,                 loss: nan
agent1:                 episode reward: -0.1236,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3930s / 12.9780 s
agent0:                 episode reward: 0.0609,                 loss: nan
agent1:                 episode reward: -0.0609,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3887s / 13.3666 s
agent0:                 episode reward: -0.1777,                 loss: nan
agent1:                 episode reward: 0.1777,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3985s / 13.7652 s
agent0:                 episode reward: 0.0804,                 loss: nan
agent1:                 episode reward: -0.0804,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3914s / 14.1566 s
agent0:                 episode reward: -0.5437,                 loss: nan
agent1:                 episode reward: 0.5437,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3951s / 14.5517 s
agent0:                 episode reward: -0.1585,                 loss: nan
agent1:                 episode reward: 0.1585,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3918s / 14.9435 s
agent0:                 episode reward: 0.5062,                 loss: nan
agent1:                 episode reward: -0.5062,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3940s / 15.3375 s
agent0:                 episode reward: -0.3591,                 loss: nan
agent1:                 episode reward: 0.3591,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3956s / 15.7331 s
agent0:                 episode reward: -0.2155,                 loss: nan
agent1:                 episode reward: 0.2155,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3943s / 16.1274 s
agent0:                 episode reward: -0.6361,                 loss: nan
agent1:                 episode reward: 0.6361,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3882s / 16.5156 s
agent0:                 episode reward: -0.1229,                 loss: nan
agent1:                 episode reward: 0.1229,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3885s / 16.9041 s
agent0:                 episode reward: -0.5132,                 loss: nan
agent1:                 episode reward: 0.5132,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3969s / 17.3010 s
agent0:                 episode reward: 0.5492,                 loss: nan
agent1:                 episode reward: -0.5492,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3897s / 17.6908 s
agent0:                 episode reward: 0.2688,                 loss: nan
agent1:                 episode reward: -0.2688,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3883s / 18.0790 s
agent0:                 episode reward: 0.1918,                 loss: nan
agent1:                 episode reward: -0.1918,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3915s / 18.4705 s
agent0:                 episode reward: -0.0126,                 loss: nan
agent1:                 episode reward: 0.0126,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3927s / 18.8632 s
agent0:                 episode reward: -0.1433,                 loss: nan
agent1:                 episode reward: 0.1433,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3942s / 19.2574 s
agent0:                 episode reward: -0.1538,                 loss: nan
agent1:                 episode reward: 0.1538,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3926s / 19.6500 s
agent0:                 episode reward: 0.1256,                 loss: nan
agent1:                 episode reward: -0.1256,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3955s / 20.0455 s
agent0:                 episode reward: 0.1303,                 loss: nan
agent1:                 episode reward: -0.1303,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3975s / 20.4430 s
agent0:                 episode reward: -0.0935,                 loss: nan
agent1:                 episode reward: 0.0935,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3947s / 20.8377 s
agent0:                 episode reward: -0.0321,                 loss: nan
agent1:                 episode reward: 0.0321,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3978s / 21.2355 s
agent0:                 episode reward: 0.2089,                 loss: nan
agent1:                 episode reward: -0.2089,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3947s / 21.6302 s
agent0:                 episode reward: -0.1081,                 loss: nan
agent1:                 episode reward: 0.1081,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4005s / 22.0307 s
agent0:                 episode reward: -0.0969,                 loss: nan
agent1:                 episode reward: 0.0969,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3936s / 22.4243 s
agent0:                 episode reward: -0.0064,                 loss: nan
agent1:                 episode reward: 0.0064,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3907s / 22.8150 s
agent0:                 episode reward: -0.2621,                 loss: nan
agent1:                 episode reward: 0.2621,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3936s / 23.2086 s
agent0:                 episode reward: -0.1923,                 loss: nan
agent1:                 episode reward: 0.1923,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3944s / 23.6030 s
agent0:                 episode reward: 0.1860,                 loss: nan
agent1:                 episode reward: -0.1860,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3845s / 23.9876 s
agent0:                 episode reward: 0.1900,                 loss: nan
agent1:                 episode reward: -0.1900,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3923s / 24.3799 s
agent0:                 episode reward: 0.0380,                 loss: nan
agent1:                 episode reward: -0.0380,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3888s / 24.7687 s
agent0:                 episode reward: -0.0774,                 loss: nan
agent1:                 episode reward: 0.0774,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3853s / 25.1540 s
agent0:                 episode reward: -0.2736,                 loss: nan
agent1:                 episode reward: 0.2736,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3889s / 25.5429 s
agent0:                 episode reward: -0.2268,                 loss: nan
agent1:                 episode reward: 0.2268,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3942s / 25.9371 s
agent0:                 episode reward: -0.2013,                 loss: nan
agent1:                 episode reward: 0.2013,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3938s / 26.3309 s
agent0:                 episode reward: 0.4172,                 loss: nan
agent1:                 episode reward: -0.4172,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3888s / 26.7197 s
agent0:                 episode reward: 0.7249,                 loss: nan
agent1:                 episode reward: -0.7249,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3949s / 27.1146 s
agent0:                 episode reward: -0.4895,                 loss: nan
agent1:                 episode reward: 0.4895,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3849s / 27.4995 s
agent0:                 episode reward: -0.4783,                 loss: nan
agent1:                 episode reward: 0.4783,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3962s / 27.8957 s
agent0:                 episode reward: -0.0927,                 loss: nan
agent1:                 episode reward: 0.0927,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3955s / 28.2912 s
agent0:                 episode reward: 0.3380,                 loss: nan
agent1:                 episode reward: -0.3380,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3927s / 28.6839 s
agent0:                 episode reward: -0.3393,                 loss: nan
agent1:                 episode reward: 0.3393,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3921s / 29.0760 s
agent0:                 episode reward: 0.0730,                 loss: nan
agent1:                 episode reward: -0.0730,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3884s / 29.4644 s
agent0:                 episode reward: 0.3295,                 loss: nan
agent1:                 episode reward: -0.3295,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3870s / 29.8514 s
agent0:                 episode reward: 0.3760,                 loss: nan
agent1:                 episode reward: -0.3760,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3998s / 30.2513 s
agent0:                 episode reward: -0.0672,                 loss: nan
agent1:                 episode reward: 0.0672,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3939s / 30.6452 s
agent0:                 episode reward: -0.0230,                 loss: nan
agent1:                 episode reward: 0.0230,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3991s / 31.0443 s
agent0:                 episode reward: 0.2921,                 loss: nan
agent1:                 episode reward: -0.2921,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3997s / 31.4440 s
agent0:                 episode reward: -0.2940,                 loss: nan
agent1:                 episode reward: 0.2940,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3865s / 31.8305 s
agent0:                 episode reward: -0.3569,                 loss: nan
agent1:                 episode reward: 0.3569,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3973s / 32.2277 s
agent0:                 episode reward: -0.0574,                 loss: nan
agent1:                 episode reward: 0.0574,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3907s / 32.6184 s
agent0:                 episode reward: 0.1104,                 loss: nan
agent1:                 episode reward: -0.1104,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3923s / 33.0107 s
agent0:                 episode reward: -0.1598,                 loss: nan
agent1:                 episode reward: 0.1598,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3934s / 33.4041 s
agent0:                 episode reward: 0.1844,                 loss: nan
agent1:                 episode reward: -0.1844,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3948s / 33.7990 s
agent0:                 episode reward: 0.0960,                 loss: nan
agent1:                 episode reward: -0.0960,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3984s / 34.1974 s
agent0:                 episode reward: 0.5446,                 loss: nan
agent1:                 episode reward: -0.5446,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3901s / 34.5874 s
agent0:                 episode reward: -0.0678,                 loss: nan
agent1:                 episode reward: 0.0678,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3882s / 34.9756 s
agent0:                 episode reward: 0.0318,                 loss: nan
agent1:                 episode reward: -0.0318,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3928s / 35.3684 s
agent0:                 episode reward: -0.0490,                 loss: nan
agent1:                 episode reward: 0.0490,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3958s / 35.7642 s
agent0:                 episode reward: -0.0788,                 loss: nan
agent1:                 episode reward: 0.0788,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3965s / 36.1607 s
agent0:                 episode reward: 0.0486,                 loss: nan
agent1:                 episode reward: -0.0486,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3979s / 36.5586 s
agent0:                 episode reward: 0.2167,                 loss: nan
agent1:                 episode reward: -0.2167,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3955s / 36.9541 s
agent0:                 episode reward: -0.0695,                 loss: nan
agent1:                 episode reward: 0.0695,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.4045s / 37.3587 s
agent0:                 episode reward: -0.6170,                 loss: nan
agent1:                 episode reward: 0.6170,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3738s / 37.7324 s
agent0:                 episode reward: -0.4572,                 loss: nan
agent1:                 episode reward: 0.4572,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3916s / 38.1240 s
agent0:                 episode reward: -0.5868,                 loss: nan
agent1:                 episode reward: 0.5868,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3951s / 38.5191 s
agent0:                 episode reward: 0.1519,                 loss: nan
agent1:                 episode reward: -0.1519,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3949s / 38.9141 s
agent0:                 episode reward: 0.1588,                 loss: nan
agent1:                 episode reward: -0.1588,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3851s / 39.2992 s
agent0:                 episode reward: -0.3752,                 loss: nan
agent1:                 episode reward: 0.3752,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3935s / 39.6927 s
agent0:                 episode reward: 0.1393,                 loss: nan
agent1:                 episode reward: -0.1393,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 0.3640s / 40.0567 s
agent0:                 episode reward: -0.5926,                 loss: nan
agent1:                 episode reward: 0.5926,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 2.0804s / 42.1370 s
agent0:                 episode reward: 0.3547,                 loss: nan
agent1:                 episode reward: -0.3547,                 loss: 0.4513
Episode: 1701/30000 (5.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1524s / 43.2894 s
agent0:                 episode reward: -0.3909,                 loss: nan
agent1:                 episode reward: 0.3909,                 loss: 0.4151
Episode: 1721/30000 (5.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1610s / 44.4504 s
agent0:                 episode reward: 0.0416,                 loss: nan
agent1:                 episode reward: -0.0416,                 loss: 0.4047
Episode: 1741/30000 (5.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1378s / 45.5882 s
agent0:                 episode reward: 0.0975,                 loss: nan
agent1:                 episode reward: -0.0975,                 loss: 0.3954
Episode: 1761/30000 (5.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1421s / 46.7303 s
agent0:                 episode reward: -0.7120,                 loss: nan
agent1:                 episode reward: 0.7120,                 loss: 0.3813
Episode: 1781/30000 (5.9367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1419s / 47.8722 s
agent0:                 episode reward: -0.4491,                 loss: nan
agent1:                 episode reward: 0.4491,                 loss: 0.3605
Episode: 1801/30000 (6.0033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1414s / 49.0136 s
agent0:                 episode reward: -0.0166,                 loss: nan
agent1:                 episode reward: 0.0166,                 loss: 0.3415
Episode: 1821/30000 (6.0700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1456s / 50.1593 s
agent0:                 episode reward: -0.0323,                 loss: nan
agent1:                 episode reward: 0.0323,                 loss: 0.3238
Episode: 1841/30000 (6.1367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1462s / 51.3055 s
agent0:                 episode reward: -0.6755,                 loss: nan
agent1:                 episode reward: 0.6755,                 loss: 0.3610
Episode: 1861/30000 (6.2033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1544s / 52.4599 s
agent0:                 episode reward: -0.0890,                 loss: nan
agent1:                 episode reward: 0.0890,                 loss: 0.4167
Episode: 1881/30000 (6.2700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1425s / 53.6024 s
agent0:                 episode reward: 0.1594,                 loss: nan
agent1:                 episode reward: -0.1594,                 loss: 0.4143
Episode: 1901/30000 (6.3367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1361s / 54.7386 s
agent0:                 episode reward: 0.2238,                 loss: nan
agent1:                 episode reward: -0.2238,                 loss: 0.4117
Episode: 1921/30000 (6.4033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1476s / 55.8862 s
agent0:                 episode reward: 0.7814,                 loss: nan
agent1:                 episode reward: -0.7814,                 loss: 0.4102
Episode: 1941/30000 (6.4700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1461s / 57.0322 s
agent0:                 episode reward: 0.0037,                 loss: nan
agent1:                 episode reward: -0.0037,                 loss: 0.4096
Episode: 1961/30000 (6.5367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1360s / 58.1682 s
agent0:                 episode reward: -0.2218,                 loss: nan
agent1:                 episode reward: 0.2218,                 loss: 0.4098
Episode: 1981/30000 (6.6033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1444s / 59.3126 s
agent0:                 episode reward: 0.0846,                 loss: nan
agent1:                 episode reward: -0.0846,                 loss: 0.4084
Episode: 2001/30000 (6.6700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1566s / 60.4693 s
agent0:                 episode reward: -0.0670,                 loss: nan
agent1:                 episode reward: 0.0670,                 loss: 0.4102
Episode: 2021/30000 (6.7367%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1608s / 61.6300 s
agent0:                 episode reward: -0.0068,                 loss: nan
agent1:                 episode reward: 0.0068,                 loss: 0.4392
Episode: 2041/30000 (6.8033%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1517s / 62.7817 s
agent0:                 episode reward: 0.4765,                 loss: nan
agent1:                 episode reward: -0.4765,                 loss: 0.4278
Episode: 2061/30000 (6.8700%),                 avg. length: 5.0,                last time consumption/overall running time: 1.1464s / 63.9281 s
agent0:                 episode reward: 0.3321,                 loss: nan